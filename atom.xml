<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Haldir的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://haldir65.github.io/"/>
  <updated>2019-01-25T15:20:53.207Z</updated>
  <id>https://haldir65.github.io/</id>
  
  <author>
    <name>Haldir</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hexo部署个人博客记录</title>
    <link href="https://haldir65.github.io/2217/01/08/2017-01-08-trouble-shooting-with-my-blog/"/>
    <id>https://haldir65.github.io/2217/01/08/2017-01-08-trouble-shooting-with-my-blog/</id>
    <published>2217-01-08T18:01:01.000Z</published>
    <updated>2019-01-25T15:20:53.207Z</updated>
    
    <content type="html"><![CDATA[<p>使用 hexo 写博客以来，记录下来的问题越来越多。只希望下次再碰到同样的问题时，不要再去浪费时间去查找。如果想要给自己的 blog 一个值得置顶的文章的话，我觉得一篇记录使用 hexo 过程中的一些解决问题的方法的文章是再合适不过的了。</br><br><img src="https://haldir66.ga/static/imgs/40164340_40164340_1414330224938_mthumb.jpg" alt=""></p><a id="more"></a><h2 id="1-经常更新-yilia-的-theme"><a href="#1-经常更新-yilia-的-theme" class="headerlink" title="1. 经常更新 yilia 的 theme"></a>1. 经常更新 yilia 的 theme</h2><p><a href="https://github.com/litten/hexo-theme-yilia">yilia</a>主题经常会更新，及时更新 theme 会发现很多新的特性及 bug fix</p><h2 id="2-部署相关"><a href="#2-部署相关" class="headerlink" title="2. 部署相关"></a>2. 部署相关</h2><ul><li>部署到 github</li></ul><pre><code class="javascript">hexo clean //清除缓存hexo g -d //一步到位 = hexo g + hexo dhexo s //localost:4000本地预览</code></pre><ul><li>部署过程中出现的一些错误</li></ul><pre><code class="javascript">$ hexo g -dINFO  Start processingERROR Process failed: _posts/2016-12-10-adb-command.mdYAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 3, column 11:    categories:  [技术]              ^    at generateError (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:162:10)    at throwError (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:168:9)    at readBlockMapping (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1040:9)    at composeNode (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1326:12)    at readDocument (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1488:3)    at loadDocuments (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1544:5)    at Object.load (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1561:19)    at parseYAML (D:\Blog\github\node_modules\hexo\node_modules\hexo-front-matter\lib\front_matter.js:80:21)    at parse (D:\Blog\github\node_modules\hexo\node_modules\hexo-front-matter\lib\front_matter.js:56:12)    at D:\Blog\github\node_modules\hexo\lib\plugins\processor\post.js:52:18    at tryCatcher (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\util.js:16:23)    at Promise._settlePromiseFromHandler (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:507:35)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:567:18)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at PromiseArray._resolve (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:125:19)    at PromiseArray._promiseFulfilled (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:143:14)    at PromiseArray._iterate (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:113:31)    at PromiseArray.init [as _init] (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:77:10)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:564:21)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at PromiseArray._resolve (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:125:19)    at PromiseArray._promiseFulfilled (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:143:14)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:572:26)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at Promise._resolveCallback (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:431:57)    at Promise._settlePromiseFromHandler (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:522:17)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:567:18)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\nodeback.js:42:21    at D:\Blog\github\node_modules\hexo\node_modules\hexo-fs\node_modules\graceful-fs\graceful-fs.js:78:16    at tryToString (fs.js:455:3)    at FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:442:12)INFO  Files loaded in 1.48 sINFO  Generated: sitemap.xmlINFO  Generated: atom.xmlINFO  Generated: 2017/01/08/2017-01-08-trouble-shooting-with-my-blog/index.htmlINFO  Generated: index.htmlINFO  4 files generated in 2.26 sINFO  Deploying: git</code></pre><p>找了好久，有说”_config.xml” 文件 有空格的，有说 title 被乱改的，试了好长时间，改成这样就不再报错了。所以，<strong>冒号后面一定要加空格，英文半角的</strong></p><pre><code>---title: adb常用命令手册date: 2016-12-10 21:14:14tags: - android - adb---</code></pre><p>tags 有两种写法，一种是上面这样前面加横杠另一种长这样，写成数组形式</p><pre><code>---title: my awesometitledate: 2017-05-07 16:48:01categories: blogtags: [linux,python]---</code></pre><h2 id="3-一些功能的实现"><a href="#3-一些功能的实现" class="headerlink" title="3. 一些功能的实现"></a>3. 一些功能的实现</h2><ul><li>置顶功能将 node_modules/hexo-generator-index/lib/generator.js 的文件内容替换成以下内容</li></ul><pre><code class="javascript">&quot;use strict&quot;;var pagination = require(&quot;hexo-pagination&quot;);module.exports = function(locals) {  var config = this.config;  var posts = locals.posts;  posts.data = posts.data.sort(function(a, b) {    if (a.top &amp;&amp; b.top) {      // 两篇文章top都有定义      if (a.top == b.top)        return b.date - a.date; // 若top值一样则按照文章日期降序排      else return b.top - a.top; // 否则按照top值降序排    } else if (a.top &amp;&amp; !b.top) {      // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233）      return -1;    } else if (!a.top &amp;&amp; b.top) {      return 1;    } else return b.date - a.date; // 都没定义按照文章日期降序排  });  var paginationDir = config.pagination_dir || &quot;page&quot;;  return pagination(&quot;&quot;, posts, {    perPage: config.index_generator.per_page,    layout: [&quot;index&quot;, &quot;archive&quot;],    format: paginationDir + &quot;/%d/&quot;,    data: {      __index: true    }  });};</code></pre><ul><li>同时在文章开头添加 top : 1 即可 ，实际排序按照这个数字从大到小排序</li></ul><p>另一种做法是手动将date改大，日期越靠后的越在前面。</p><pre><code class="java"> title: Hexo置顶文章date: 2016-11-11 23:26:22tags:[置顶]categories: Hexotop: 0 # 0或者1</code></pre><p>个人建议：置顶不要太多</p><h2 id="4-SublimeText-的一些快捷键"><a href="#4-SublimeText-的一些快捷键" class="headerlink" title="4. SublimeText 的一些快捷键"></a>4. SublimeText 的一些快捷键</h2><p>由于文章大部分都是使用 SublimeText 写的，Typroa 这种所见即所得的编辑器也不错，但对于掌握 MardkDown 语法没有帮助。这里摘录一些 SubLimeText 的快捷键。</p><blockquote><p><strong>Ctrl+Shift+P：打开命令面板</strong><br>Ctrl+P：搜索项目中的文件<br>Ctrl+G：跳转到第几行<br>Ctrl+W：关闭当前打开文件 CTRL+F4 也可以<br>Ctrl+Shift+W：关闭所有打开文件<br>Ctrl+Shift+V：粘贴并格式化<br>Ctrl+D：选择单词，重复可增加选择下一个相同的单词<br><strong>Ctrl+L：选择行，重复可依次增加选择下一行</strong><br><strong>Alt+Shift+数字：分屏显示</strong><br><strong>Ctrl+Shift+L：选择多行</strong><br><strong>Ctrl+Shift+D：复制粘贴当前行</strong><br><strong>Ctrl+X：删除当前行</strong><br><strong>Ctrl+Shift+左箭头 往左边选择内容</strong><br><strong>Shift+向左箭头 向左选择文本</strong><br><strong>Ctrl+B 编译，markDown 生成 html 文件</strong><br><strong>Alt+2 切换到第二个 Tab（打开的文件，记得 chrome 是 ctrl+2）</strong><br><strong>Ctrl+R：前往 对应的方法的实现*</strong><br><strong>快速加上[] 选中单词按 [ 即可</strong><br><strong>批量更改当前页面相同的单词 alt+F3 </strong><br><strong>Ctrl+Enter 在下一行插入新的一行</strong><br><strong>Ctrl+Shift+Enter 在上一行插入新的一行</strong><br><strong>Shift+ 向上箭头 向上选中多行</strong></p></blockquote><p>Ctrl+Shift+D：复制粘贴当前行 Ctrl+Shift+Enter：在当前行前插入新行<br>Ctrl+M：跳转到对应括号<br>Ctrl+U：软撤销，撤销光标位置<br>Ctrl+J：选择标签内容<br>Ctrl+F：查找内容<br>Ctrl+Shift+F：查找并替换<br>Ctrl+H：替换<br>Ctrl+N：新建窗口<br>Ctrl+K+B：开关侧栏<br>Ctrl+Shift+M：选中当前括号内容，重复可选着括号本身<br>Ctrl+F2：设置/删除标记<br>Ctrl+/：注释当前行<br>Ctrl+Shift+/：当前位置插入注释<br>Ctrl+Alt+/：块注释，并 Focus 到首行，写注释说明用的<br>Ctrl+Shift+A：选择当前标签前后，修改标签用的<br>F11：全屏<br>Shift+F11：全屏免打扰模式，只编辑当前文件<br>Alt+F3：选择所有相同<br>Alt+.：闭合标签<br>Shift+右键拖动：光标多不，用来更改或插入列内容<br>Alt+数字：切换打开第 N 个文件鼠标的前进后退键可切换 Tab 文件按 Ctrl，依次点击或选取，可需要编辑的多个位置按 Ctrl+Shift+上下键，可替换行</p><p>vscode的快捷键最重要的一个是ctrl+shift+p,ctrl+p只是在全局查找文件</p><h2 id="5-title-不能以-开头"><a href="#5-title-不能以-开头" class="headerlink" title="5. title 不能以[]开头"></a>5. title 不能以[]开头</h2><p>前面加上###确实能够让字号变大，但不要写 4 个#，后面的字母会大小写不分的</p><h2 id="6-markdown-语法"><a href="#6-markdown-语法" class="headerlink" title="6. markdown 语法"></a>6. markdown 语法</h2><p>MarkDown 页面内部跳转<br><a href="http://www.cnblogs.com/JohnTsai/p/4027229.html">MarkDown 技巧：两种方式实现页内跳转</a></p><blockquote><p><em>一个星星包起来是斜体字</em><br><strong>两个星星包起来是粗体字</strong><br><strong><em><em>那么三个星星呢</em></em></strong></p></blockquote><h2 id="7-github-提交-commit-的时候显示-Emoji"><a href="#7-github-提交-commit-的时候显示-Emoji" class="headerlink" title="7.github 提交 commit 的时候显示 Emoji"></a>7.github 提交 commit 的时候显示 Emoji</h2><p>链接<a href="https://www.webpagefx.com/tools/emoji-cheat-sheet/">在此</a></p><h2 id="8-换电脑了怎么办"><a href="#8-换电脑了怎么办" class="headerlink" title="8.换电脑了怎么办"></a>8.换电脑了怎么办</h2><p>亲测，把整个目录下所有文件全部复制粘贴到新电脑上，装上 node，然后装上 hexo，记得勾选添加到 PATH,然后就可以了。需要注意的是小文件比较多，所以复制粘贴可能要十几分钟。</p><h2 id="9-有时候写的代码会给你在每一行前面加上-true"><a href="#9-有时候写的代码会给你在每一行前面加上-true" class="headerlink" title="9. 有时候写的代码会给你在每一行前面加上 true"></a>9. 有时候写的代码会给你在每一行前面加上 true</h2><p>比如写一段 css 的代码时候，很多时候预览会给每一行前面加上一个 true，解决办法：用 TAB 键缩进即可</p><h2 id="10-markdown-live-是一个非常好用的-node-module"><a href="#10-markdown-live-是一个非常好用的-node-module" class="headerlink" title="10. markdown-live 是一个非常好用的 node module"></a>10. markdown-live 是一个非常好用的 node module</h2><p><a href="https://www.npmjs.com/package/markdown-live">项目地址</a><br><strong>前提是安装了 node</strong></p><blockquote><p>npm install -g markdown-live</p><p>md-live</p></blockquote><p><br><br><strong><em>编辑md文件的同时，保存就会同步刷新网页预览，非常好用</em></strong></p><h2 id="11-如果运行-hexo-g-生成的-index-html-是空的"><a href="#11-如果运行-hexo-g-生成的-index-html-是空的" class="headerlink" title="11. 如果运行 hexo g 生成的 index.html 是空的"></a>11. 如果运行 hexo g 生成的 index.html 是空的</h2><p>输出</p><blockquote><p>WARN No layout: tags/service/index.html<br>原因是 themes/文件夹下没有 clone 对应的主题</p></blockquote><p>换成travis之后，在travis.yml文件中，添加了</p><pre><code class="config">cache:  yarn: true  directories:  - node_modules  - themes</code></pre><p>cahe也就意味着后续，所有对于themes文件夹中的_config.yml文件的修改都不会生效。这也就是我一遍遍尝试更改theme文件夹中_config文件不生效的原因。<br>所以要么去掉cache ，要么自己写bash script一行行的改。</p><h2 id="12-markdown写表格"><a href="#12-markdown写表格" class="headerlink" title="12. markdown写表格"></a>12. markdown写表格</h2><p>直接在atom下面敲table，就会自动提示出来的</p><table><thead><tr><th>一个普通标题</th><th>一个普通标题</th><th>一个普通标题</th></tr></thead><tbody><tr><td>短文本</td><td>中等文本</td><td>稍微长一点的文本</td></tr><tr><td>稍微长一点的文本</td><td>短文本</td><td>中等文本</td></tr></tbody></table><p>中间的虚线左边的冒号表示下面的单元格左对齐，冒号放右边就右对齐，左右都放一个就表示居中</p><p>vscode的返回上一个文件快捷键是ctrl + -</p><h2 id="13-travis-ci自动部署的一些问题"><a href="#13-travis-ci自动部署的一些问题" class="headerlink" title="13 . travis ci自动部署的一些问题"></a>13 . travis ci自动部署的一些问题</h2><p><a href="https://github.com/travis-ci/travis.rb/issues/437">travis ci加密文件无法在travis以外的地方解密，因为key,value都存在travis的数据库了</a></p><p><a href="https://github.com/travis-ci/travis-ci/issues/9668">travis加密文件后用openssl解密出现iv undefined的错误</a></p><p>iv undefined</p><blockquote><p>travis env list<br>encrypted_476ad15a8e52_key=[secure]<br>encrypted_476ad15a8e52_iv=[secure]<br>明明是存在的</p></blockquote><p>在linux 里面运行travis endpoint<br>果然是 API endpoint: <a href="https://api.travis-ci.org/">https://api.travis-ci.org/</a><br>而新的endpoint应该是 <a href="https://api.travis-ci.com/">https://api.travis-ci.com/</a><br>于是travis encrypt-file –help</p><blockquote><p>–pro  short-cut for –api-endpoint ‘<a href="https://api.travis-ci.com/">https://api.travis-ci.com/</a>‘<br>–org short-cut for –api-endpoint ‘<a href="https://api.travis-ci.org/">https://api.travis-ci.org/</a>‘</p></blockquote><p>所以</p><blockquote><p>travis encrypt-file super_secret.txt 应该改成<br>travis encrypt-file super_secret.txt –pro</p></blockquote><p>因为默认的$encrypted_476ad15a8e52_key其实已经存储在travis-ci.org上了<br>所以在travis-ci.com上的项目当然找不到</p><p><a href="https://github.com/openwrtio/openwrtio.github.io/blob/mkdocs/.travis.yml">自动部署的另一个实例</a></p><h2 id="14-hexo-server本地预览出现的问题"><a href="#14-hexo-server本地预览出现的问题" class="headerlink" title="14. hexo server本地预览出现的问题"></a>14. hexo server本地预览出现的问题</h2><p><a href="Refused to execute script from" title="http://localhost:4000/slider.e37972.js&#39; because its MIME type (&#39;text/html">hexo s 本地预览样式加载失败</a> is not executable, and strict MIME type checking is enabled.)</p><p>hexo server的意思是类似于express的serve static功能，<a href="https://hexo.io/zh-cn/docs/server.html">默认只处理public文件下的文件，所以如果本地运行hexo s 出现404的话，直接copy到public文件夹下就可以了</a>注意hexo clear会删掉public文件夹</p><p>[Refused to Execute Script From Because Its MIME Type (Text/plain) Is Not Executable, and Strict MIME Type Checking Is Enabled]这句话的意思</p><h2 id="15-yilia的主题里面badjs-report的问题"><a href="#15-yilia的主题里面badjs-report的问题" class="headerlink" title="15. yilia的主题里面badjs report的问题"></a>15. yilia的主题里面badjs report的问题</h2><p>yilia的主题里面有一个badjs的report，去掉的方法：<br>cd 到themes/yilia里面,rm -rf source/ , 然后把source-src里面的report.js里面的东西删掉。yarn install ,yarn dist ,然后回到上层目录。hexo clean , hexo g就可以了。<br>其实看下里面，就是一个webpack的配置，自己重新编译一下就好了。编译后会在source里面重新生成需要的js文件。<br>奇怪的是在windows上编译失败，在linux上编译失败，在mac上终于成功了。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="http://yanhuili.github.io/2016/11/21/hexo%E5%8D%9A%E6%96%87%E7%BD%AE%E9%A1%B6%E6%8A%80%E5%B7%A7/">Hexo 博文置顶技巧</a></li><li><a href="http://www.daqianduan.com/4820.html">SublimeText 快捷键</a></li><li><a href="http://itmyhome.com/markdown/article/syntax/emphasis.html">MarkDown 语法学起来很快的</a></li><li><a href="https://blessing.studio/deploy-hexo-blog-automatically-with-travis-ci/">travis 自动部署</a></li><li><a href="https://docs.travis-ci.com/user/legacy-services-to-github-apps-migration-guide/">Legacy GitHub Services to GitHub Apps Migration Guide 2018年10月1号之后不再支持 Legacy GitHub Service</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 hexo 写博客以来，记录下来的问题越来越多。只希望下次再碰到同样的问题时，不要再去浪费时间去查找。如果想要给自己的 blog 一个值得置顶的文章的话，我觉得一篇记录使用 hexo 过程中的一些解决问题的方法的文章是再合适不过的了。&lt;/br&gt;&lt;br&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/40164340_40164340_1414330224938_mthumb.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="blog" scheme="https://haldir65.github.io/categories/blog/"/>
    
    
      <category term="hexo" scheme="https://haldir65.github.io/tags/hexo/"/>
    
      <category term="置顶" scheme="https://haldir65.github.io/tags/%E7%BD%AE%E9%A1%B6/"/>
    
  </entry>
  
  <entry>
    <title>即刻备忘录</title>
    <link href="https://haldir65.github.io/2046/12/18/2017-12-18-random-new-thoughts/"/>
    <id>https://haldir65.github.io/2046/12/18/2017-12-18-random-new-thoughts/</id>
    <published>2046-12-18T22:58:14.000Z</published>
    <updated>2019-01-25T15:20:53.215Z</updated>
    
    <content type="html"><![CDATA[<p>一个待办事项的仓库<br><img src="https://haldir66.ga/static/imgs/girlfriend lake green nature water cold.jpg" alt=""></p><a id="more"></a><h3 id="期待能够完成的"><a href="#期待能够完成的" class="headerlink" title="期待能够完成的"></a>期待能够完成的</h3><ul><li><a href="https://juejin.im/post/5a0c1956f265da430a501f51">个人分享–web 前端学习资源分享</a></li><li><a href="https://huangxuan.me/2017/02/09/nextgen-web-pwa/">WPA 所代表的 Web 开发应是未来</a>据说Electron要被PWA干掉</li><li><a href="https://segmentfault.com/a/1190000003818163">js 循环闭包的解决方法</a></li><li>动态类型一时爽，代码重构火葬场</li><li>iview，elementUi</li><li>[ ] rxjava是如何切换线程的以及源码解析</li><li>[ ] shadowsocks-android源码</li><li>[ ] chromium net移植到Android平台<a href="https://github.com/GoogleChromeLabs/cronet-sample">cronet是最简单的方式</a> <a href="https://console.cloud.google.com/storage/browser/chromium-cronet?pli=1">更多下载仓库</a></li><li><a href="https://css-tricks.com/NetMag/FluidWidthVideo/Article-FluidWidthVideo.php">embeed video with iframe</a></li><li>[ ] flex,grid</li><li>[ ] Paul Irish from google</li><li>[ ] <a href="http://lokeshdhakar.com/projects/lightbox2/">lightbox一个很好看的js图片查看库</a></li><li>[ ] <a href="https://www.js-css.cn/a/jscode/album/2014/0915/1319.html">仿门户网站js相册</a>， <a href="https://www.js-css.cn/a/jscode/album/2014/0914/1318.html">js相册2</a></li><li>[ ] <a href="http://python.jobbole.com/82270/">八大排序算法的python实现</a></li><li>[ ] Redux和Flux很像,react context api</li><li>[ ] <a href="https://www.jianshu.com/p/a4ab102fa4ac">一个展示如何在宿主App中提取一个apk文件并加载代码和资源</a></li><li>[ ] nodejs ,go ,protobuf rpc(proto更多的是作为一种协议来进行rpc数据传输)</li><li>[ ]一致性哈希原理</li><li>[ ] <a href="http://afghl.github.io/2018/06/17/distributed-lock-and-granarity.html">使用redis实现低粒度的分布式锁</a></li><li>[ ] Coordinator behavior以及scroll原理，完善blog</li><li>[ ] instagram好像通过注解的方式自己写了一个json解析器<a href="https://github.com/Instagram/ig-json-parser">ig-json-parser</a></li><li>[ ] when it comes to design , how do we translate px, pt, em  into sp,dp and others(设计方面的，各种单位之间的转换)?</li><li>[ ] classloader和class的生命周期</li><li>[ ] learning how textView works is painful yet necessary</li><li>[ ] linux环境下多进程通讯方式(管道，共享内存，信号,unix domian socket)</li><li>[ ] mqtt接入实践<a href="https://github.com/mcxiaoke/mqtt">mqtt是建立在tcp基础上的应用层协议</a>，<a href="https://github.com/netty/netty">netty</a>也做了实现</li><li>[ ] render-script utility</li><li>[ ] play around with xposed</li><li>[ ] python gui编程</li><li>[ ] kotlin的coroutine[production-ready]</li><li>[ ] 宇宙第一ide熟悉使用</li><li>[ ] js的闭包等面试常谈</li><li>[ ] java的aspectJ教程，Spring AOP 与AspectJ 实现原理上并不完全一致，但功能上是相似的</li><li>[ ] autoWired, autovalue这些java 的library</li><li>[ ] code generator(代码生成器)</li><li>[ ]<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers">content-disposition</a></li><li>[ ] 用正则检测或者解析json(jQuery源码里有)</li><li>[ ] awk，正则表达式还有数据库这些也算一门编程语言</li><li>[ ] 来来来，<a href="https://www.youtube.com/watch?v=DUNkdl0Jhgs">手写一个vm</a></li><li>[ ] <a href="https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md#System-requirements">chromium提供了如何在windows上编译chromium的教程</a></li><li>[ ]<a href="https://www.youtube.com/watch?v=M8LiOANu3Nk">How the JVM compiles bytecode into machine code</a></li><li>[ ] WebSocket协议及数据帧</li><li>netfilter框架(imbedded in linux server)</li></ul><h3 id="已完成"><a href="#已完成" class="headerlink" title="已完成"></a>已完成</h3><ul><li>用 express 转接一个知乎 Api，添加 Access-control-allow-origin,或许还可以用 redis 缓存数据结果（一个就好）由此想到一篇文章”How to use Pythonto build a restful Web Service”.只不过用的是 Tornado</li><li>git hook (github travis 持续集成，git push 会触发服务器的一系列操作)</li><li>基于前后端分离的理念，后台只负责提供数据，render page 的任务应该交给前端。（所以用 express-handlebars 写页面的方式写着很累）</li><li>集成 travis-ci，记得 after-success script 的结果并不会影响 build 的结果（即，after-success 执行脚本发生了错误，在日志里有输出 error，但实际显示的 build result 仍为 success），还有 travis 的输出 log 需要默认是折叠的，要展开才能看清楚，但在 afterSuccess 里面的指令的输出一定是有的。</li><li>随便放一个文件到/usr/bin/就可以直接调用这个文件名来起这个命令了吗？（实际操作只需要建立一个symbolic link就好了）</li><li>单个网卡最多65535个端口，c10K。<a href="https://www.zhihu.com/question/66553828">65536其实不是操作系统限制的，而是tcp协议就只给port留了2个bytes给source port，只留了2个bytes给destination port</a>端口号写在tcp包里，ip地址不是，ip地址是ip层的事情</li><li>oAuth2原理，其实流程上和很多客户端的微信登陆，新浪微博登陆很像的</li><li>在Android手机上尝试用一个unix domain socket用于localhost进程间ipc(其实就是保证端口号一致，给网络权限就好了)</li><li>写 groovy 用intelij全家桶就可以了，groovy的<a href="https://www.tutorialspoint.com/groovy/groovy_closures.htm">语法</a>其实没什么，主要是了解编译的流程和基本原理，这个需要看<a href="https://docs.gradle.org/current/userguide/build_lifecycle.html#sec:build_phases">official doc</a></li><li><a href="https://github.com/JLLK/gradle-android-maindexlist-plugin">开发gradle plugin优化MultiDex</a>。长远来看，5.0以后的手机越来越多，MultiDex也不值得过于关注。</li><li>intelij 点击run 实际调用的command line是两个，一个是javac，编译出来的class文件放到了target文件夹，紧接着用java命令带上一大串classpath去调用主函数</li><li><a href="https://fucknmb.com/2017/05/11/Android-Studio-Library%E6%A8%A1%E5%9D%97%E4%B8%ADNative%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8Cdebug%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/">Android Studio 编译过程</a>，其实就是gradle assembleXXX 好了之后adb push到手机上，再安装，最后起主界面</li><li><a href="http://mouxuejie.com/blog/2016-06-21/multidex-compile-and-dex-source-analysis/">Android 编译及 Dex 过程源码分析</a></li><li><a href="http://www.wangyuwei.me/">如何调试 Android 打包流程？</a>，一个remote的事</li><li><a href="https://github.com/chenenyu/img-optimizer-gradle-plugin">一个用于优化 png 图片的 gradle 插件</a>，用来看 groovy 语法挺好的。以及 <a href="http://yuanfentiank789.github.io/2017/09/20/%E5%9C%A8AndroidStudio%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89Gradle%E6%8F%92%E4%BB%B6/">How to write gradle plugin</a></li><li>XSS 攻击,DOM based和Stored XSS,基本上就是不要相信用户的输入，除了合法输入以外一律过滤掉</li></ul><ul><li>websocket nodejs，局限性就是前后台都得用socket.io的库。前端是浏览器的话还好，app的话java,Android都有对应的实现.[其实就是socket io] </li><li>[X]一直不会maven是在是太丢人了<a href="https://maven.apache.org/guides/getting-started/index.html#How_do_I_make_my_first_Maven_project">看文档就行了</a>，其他的<a href="https://www.tutorialspoint.com/maven/maven_build_life_cycle.htm">教程</a>也不错</li><li>[使用Spring boot后台提供protobuf接口实现客户端通信] 不要使用protobf-gradle-plugin了。直接写脚本用protoc去生成文件，指定生成文件的路径要和proto里面写的包名对的上。另外就是客户端和server端依赖的protobuf版本以及protoc工具的版本得一致，比如都是3.5。还有就是protoc的语法，什么import的比较烦。</li><li>[X] 使用jinja2生成文件。<a href="https://github.com/guokr/swagger-py-codegen">一个比较好玩的代码生成器</a></li><li>[X] URL Encoding,就是那个在网址里把字符转成百分号加上UTF-8的<a href="http://www.ruanyifeng.com/blog/2010/02/url_encoding.html">找到了阮一峰老师的解释</a></li><li>[X] 通过file input上传图片，原生ajax以及Ajax，自己搭建上传服务器<a href="https://zhuanlan.zhihu.com/p/24513281?refer=flask">大概能猜到暴风影音的局域网传输实现了</a>用flask的话自己搭建好后台最简单了，最多再使用flask-wtf和flask-upload规范操作</li><li>[X]Promise 链式调用与终止，异常处理(只是一个工具而已)</li><li>[X] Android 应用接入bugly热修复，上线之后就不用背锅了（有兴趣看看sevenZip.jar，暂时没看）</li><li>[X] <a href="http://normanmaurer.me/blog/2013/11/09/The-hidden-performance-costs-of-instantiating-Throwables/">简直碉堡了的博客</a>以及jvm 的inline等优化</li><li>[ ] <a href="https://seisman.github.io/how-to-write-makefile/introduction.html">如何写makefile</a>其实<a href="http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/">这个更加friendly</a></li><li>[X] <a href="https://www.jianshu.com/p/534741f5151c">libmp3lame移植到Android</a>,该教程针对的lame版本是3.99.5</li><li><a href="https://sspai.com/post/31500">scheme 这东西算跨客户端平台的</a>，比如在 App 中调起支付宝(用的是 alipayqr://)。其实就是一个系统内跨应用调用。<a href="http://blog.csdn.net/qq_23547831/article/details/51685310">用法</a><br>这个主要是ios app之间通信的协议，以及快速跳转某个app某个页面的功能实现，还有x-callback-URL这样类似的协议。不过有了3d-touch之后，很多app都能长按图标进入页面，所以url scheme这个功能只能说是不复往日辉煌了</li><li>[X]linux的sed命令(文本替换比较常用)</li><li><a href="https://juejin.im/post/59fffdb76fb9a0450a66bd58">nio</a> 还是netty好</li><li>[X]js 的async await,就是一个async修饰一个method，里面随便写await</li><li>[X] Linux下TCP延迟确认机制</li><li>[X]c语言的<a href="https://yq.aliyun.com/articles/413601">libevent使用教程</a> eventloop，添加回调，大致的流程就是这样</li><li>[X] <a href="http://www.ruanyifeng.com/blog/2018/07/indexeddb.html">indexed DB</a>,浏览器端数据库，还是用第三方库好</li><li>[X] <a href="http://forums.justlinux.com/showthread.php?3261-Block-size-vs-page-size">block size vs page size</a> Page是内存相关，block是硬盘相关的</li><li>[X] python 的asyncio(eventloop , generator, coroutine)</li><li>[X]<a href="https://vim.rtorr.com/">Vim cheet sheet</a> vim多用用就熟悉了。</li><li>[X] python dunder class复习。知道有python descriptor这回事就行了。</li><li>[X] form表单可以跨域一个是历史原因要保持兼容性（就是说跨域这件事，一个域名的 JS ，在未经允许的情况下，不得读取另一个域名的内容。但浏览器并不阻止你向另一个域名发送请求。所以post的表单可以发出去，但是别指望能够拿到response）</li><li>[X] a new article on open-gl intro(在Android平台上要和MediaCodec相关的音视频格式结合着来一起看)</li><li>[X] JavaScript中new FileReader(属于html5的东西)，以及canvas api(lineTo,quardTo这些都是相近的),以及<a href="https://juejin.im/post/5a98c5c26fb9a028d82b34ee">js进行图片缩放和裁剪</a> </li><li>[X] tcp-proxy实用教程 </li><li>[X]Exoplayer and the MediaCodec api<a href="https://medium.com/androiddevelopers/building-a-video-player-app-in-android-part-3-5-19543ea9d416">building-a-video-player-app-in-android</a> </li><li><a href="https://www.youtube.com/watch?v=g3F7Imjcd4k">AC2016腾讯前端技术大会 1 1 1 H5直播那些事</a></li><li>[X] tcp-proxy实用教程(tcp replay or udp relay)</li></ul><h3 id="Good-For-Nothing"><a href="#Good-For-Nothing" class="headerlink" title="Good For Nothing"></a>Good For Nothing</h3><ul><li>[ ] 用GDB调试程序</li><li>[ ] npm install graphql(mostly a server side javascript stuff)</li><li>使用 express 模拟网络延迟</li><li><a href="https://juejin.im/post/5a157b7a5188257bfe457ff0">基于 Docker 打造前端持续集成开发环境</a></li><li>vS Code Vender Prefix plugin =&gt; auto prefix loader</li><li>前后端分离</li><li>sql漏洞</li><li><a href="https://cloud.tencent.com/developer/article/1004755">深入浅出腾讯云 CDN：缓存篇</a>不管SSD盘或者SATA盘都有最小的操作单位，可能是512B，4KB，8KB。如果读写过程中不进行对齐，底层的硬件或者驱动就需要替应用层来做对齐操作，并将一次读写操作分裂为多次读写操作。</li><li>Android进程的<a href="https://juejin.im/post/5a646211f265da3e3f4cc997">加载流程</a></li><li>前后端同构</li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-with-ssl-as-a-reverse-proxy-for-jenkins">install nginx , jenkin ci, deploying nginx in docker(Http Load Balaning with Docker and nginx)</a></li><li>[ ] 网易云音乐API</li><li>[X] Django部署个人网站(Gunicorn，Nginx)。django写template就不是前后端分离了</li><li>[ ] Docker<a href="https://medium.com/@elye.project/intro-to-docker-building-android-app-cb7fb1b97602">intro-to-docker-building-android-app</a> 这篇文章其实是两件事，一个是Build docker image(docker build xxxx),另一个是run (docker run xxx)</li><li>[ ] <a href="https://blog.csdn.net/u013553529/article/details/53856800">和网页类似，Activity也有一个referer的概念</a>，用于判断当前页面是由谁发起请求的<br>OpenType® is a cross-platform font file format developed jointly by Adobe and Microsoft.</li><li>[ ]<a href="https://blog.securem.eu/serverside/2015/08/25/setting-up-owncloud-server-in-a-docker-container/">deploying owncloud using docker</a></li><li><a href="https://doc.owncloud.org/server/10.0/admin_manual/installation/docker/">owncloud官方的配合docker安装教程</a>网盘这种东西看个人喜好了</li><li>[ ]CloudFlare cdn解析以及DNS防护 </li><li>[ ] <a href="https://www.tutorialspoint.com/python/python_further_extensions.htm">python c extension</a> </li><li>[ ] <a href="https://github.com/elliotforbes/tutorialedge-rest-api">最简单的一个用go写出来的rest api大概长这样</a></li><li>[ ]<a href="https://lxneng.com/posts/201">分词器</a></li><li>[ ]<a href="http://www.wklken.me/posts/2015/04/26/elk-for-nginx-log.html">LOGSTASH+ELASTICSEARCH+KIBANA处理NGINX访问日志</a>ELK全家桶, logstash接管软件日志</li><li>[ ] <a href="https://gist.github.com/quexer/3619237">如何编写 jQuery 插件</a></li></ul><p><a href="https://jsonplaceholder.typicode.com/">jsonplaceholder</a>懒得自己写api的话<br>就用这个吧</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一个待办事项的仓库&lt;br&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/girlfriend lake green nature water cold.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>原始套接字学习指南</title>
    <link href="https://haldir65.github.io/2019/01/19/2019-01-19-learning-from-raw-socket/"/>
    <id>https://haldir65.github.io/2019/01/19/2019-01-19-learning-from-raw-socket/</id>
    <published>2019-01-19T22:20:35.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/SunFlowersStorm_EN-AU8863925685_1920x1080.jpg" alt=""><br>从原始套接字 SOCK_RAW学习到的知识<br><a id="more"></a></p><p>以下图片盗自<a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">chinaunix一篇讲解raw socket的文章</a>，感谢原作者的辛勤工作。复习一下ip包的结构。</p><ul><li><h3 id="这是IP-packet"><a href="#这是IP-packet" class="headerlink" title="这是IP packet"></a>这是IP packet</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-1.jpg" alt=""></p></li><li><h3 id="这是TCP-header"><a href="#这是TCP-header" class="headerlink" title="这是TCP header"></a>这是TCP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-2.jpg" alt=""></p></li><li><h3 id="这是IP-header"><a href="#这是IP-header" class="headerlink" title="这是IP header"></a>这是IP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-3.jpg" alt=""></p></li><li><h3 id="这是mac-header"><a href="#这是mac-header" class="headerlink" title="这是mac header"></a>这是mac header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-4.jpg" alt=""></p></li></ul><p>从内核代码来看，这些分别对应ethhdr、iphdr、tcphdr、udphdr等结构体。</p><p>一般来讲，应用层程序的数据都是在tcp或者udp的data中的，实际发送过程中，内核会帮忙添加上tcp header，ip header以及mac header等数据，开发者无需关心也无从干涉。raw socket为我们提供了直接读写这块数据的方法。</p><p>C语言中raw socket的创建方式为:</p><blockquote><p>socket(AF_INET, SOCK_RAW, protocol); //需要root权限</p></blockquote><p>raw socket一般用于网络监测程序中比较多，比如ping , nmap这种。这类协议是没有端口的。</p><p>另一种场景是伪造tcp header应对运营商udp屏蔽和流量qos，这种类似的实现在2017年出来的比较多。(就是用一个raw socket把一个udp包伪装成一个tcp包)。</p><p>接下来这个例子是使用raw socket监听server端收到的ip packet包内容<br>server.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;linux/if_ether.h&gt;#include &lt;stdlib.h&gt;#include &lt;arpa/inet.h&gt;int main(){     printf(&quot;main is running\n&quot;);int iSock, nRead, iProtocol;        char buffer[4096] = {0};char  *ethhead, *iphead, *tcphead, *udphead, *icmphead, *p;if((iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP))) &lt; 0){    printf(&quot;create iSocket error, check root\n&quot;);  // 需要root权限， 最后运行的时候， 可以用sudo ./server    return 1;}while(1) {    nRead = recvfrom(iSock, buffer, 2048, 0, NULL, NULL);      /*        以太网帧头 14        ip头       20        udp头      8        总共42字节(最少)    */    if(nRead &lt; 42)     {        printf(&quot;packet error\n&quot;);        continue;    }    int n = 0XFF;    char szVisBuf[1024] = {0};    for(unsigned int i = 0; i &lt; nRead; ++i)    {        char szTmp[3] = {0};        sprintf(szTmp, &quot;%02x&quot;, buffer[i]&amp;n);        strcat(szVisBuf, szTmp);    }    ethhead = buffer;    p = ethhead;    iphead = ethhead + 14;      p = iphead + 12;    char szIps[128] = {0};    snprintf(szIps, sizeof(szIps), &quot;IP: %d.%d.%d.%d =&gt; %d.%d.%d.%d&quot;,        p[0]&amp;n, p[1]&amp;n, p[2]&amp;n, p[3]&amp;n,        p[4]&amp;n, p[5]&amp;n, p[6]&amp;n, p[7]&amp;n);    iProtocol = (iphead + 9)[0];    p = iphead + 20;    unsigned int iDstPort = (p[2]&lt;&lt;8)&amp;0xff00 | p[3]&amp;n;    switch(iProtocol)    {        case IPPROTO_UDP :             if(iDstPort == 8888)            {                printf(&quot;source port: %u,&quot;,(p[0]&lt;&lt;8)&amp;0xff00 |  p[1]&amp;n);                printf(&quot;dest port: %u\n&quot;, iDstPort);                printf(&quot;%s\n&quot;, szIps);                    printf(&quot;%s\n&quot;, szVisBuf);                printf(&quot;nRead is %d\n&quot;, nRead);                }            break;        case IPPROTO_RAW :             printf(&quot;raw\n&quot;);            break;        default:            break;    }}}</code></pre><p>client.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;unistd.h&gt;int main(){    struct sockaddr_in srvAddr;    bzero(&amp;srvAddr, sizeof(srvAddr));    srvAddr.sin_family = AF_INET;    srvAddr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;);    srvAddr.sin_port = htons(8888);    int iSock = socket(AF_INET, SOCK_DGRAM, 0); // udp    int i = 0;    while(1)    {        printf(&quot;press enter to send data\n&quot;);        while (( i = getchar()) != &#39;\n&#39;){            char szBuf[32] = {0};            snprintf(szBuf, sizeof(szBuf), &quot;hello %d&quot;, ++i);            sendto(iSock, szBuf, strlen(szBuf) + 1, 0, (struct sockaddr *)&amp;srvAddr, sizeof(srvAddr));        }    }    close(iSock);    return 0;}</code></pre><p>从raw socket 接受过来的buffer 的地址是数据链路层的地址，具体我们获取的东西就是通过偏移量来，这个偏移量我们需要查看网络书或者抓个包分析下链路层的数据格式等等。<br>client很简单，就是一个udp发包到localhost，关键在于server这边：</p><blockquote><p>iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP)</p></blockquote><p>这个socket能够监听本机接收到的所有ip packet，接收到的数据帧的头6个字节是目的地的MAC地址，紧接着6个字节是源MAC地址 , 如果是udp或者tcp的话，还能读取到port。也就是一些常用抓包工具的实现原理。</p><p>所以可以写一个简单的抓包工具，将那些发给本机的IPV4报文全部打印出来。</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;netinet/if_ether.h&gt;int main(int argc, char **argv){int sock, n;char buffer[2048];struct ethhdr *eth;struct iphdr *iph;if (0 &gt; (sock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP)))) {    perror(&quot;socket&quot;);    exit(1);}while (1) {    printf(&quot;=====================================\n&quot;);    //注意：在这之前我没有调用bind函数，raw socket这一层已经不存在port的概念了    n = recvfrom(sock, buffer, 2048, 0, NULL, NULL);    printf(&quot;%d bytes read\n&quot;, n);    //接收到的数据帧头6字节是目的MAC地址，紧接着6字节是源MAC地址。    eth = (struct ethhdr*)buffer;    printf(&quot;Dest MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\n&quot;,eth-&gt;h_dest[0],eth-&gt;h_dest[1],eth-&gt;h_dest[2],eth-&gt;h_dest[3],eth-&gt;h_dest[4],eth-&gt;h_dest[5]);    printf(&quot;Source MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\n&quot;,eth-&gt;h_source[0],eth-&gt;h_source[1],eth-&gt;h_source[2],eth-&gt;h_source[3],eth-&gt;h_source[4],eth-&gt;h_source[5]);    iph = (struct iphdr*)(buffer + sizeof(struct ethhdr));    //我们只对IPV4且没有选项字段的IPv4报文感兴趣    if(iph-&gt;version == 4 &amp;&amp; iph-&gt;ihl == 5){    unsigned char *sd, *dd;    sd = (unsigned char*)&amp;iph-&gt;saddr;    dd = (unsigned char*)&amp;iph-&gt;daddr;    printf(&quot;Source Host: %d.%d.%d.%d Dest host: %d.%d.%d.%d\n&quot;, sd[0], sd[1], sd[2], sd[3], dd[0], dd[1], dd[2], dd[3]);    //    printf(&quot;Source host:%s\n&quot;, inet_ntoa(iph-&gt;saddr));    //    printf(&quot;Dest host:%s\n&quot;, inet_ntoa(iph-&gt;daddr));    }}return 0;}</code></pre><p>顺便提一下，一般我们在Linux机器上是可以查看到当前系统对应的内核的头文件的</p><blockquote><p> root][~]# grep -n ‘ethhdr’ /usr/include/linux/if_ether.h<br>107:struct ethhdr {<br>[root][~]#<br>[root][~]# grep -n ‘iphdr’ /usr/include/linux/*<br>/usr/include/linux/if_tunnel.h:32:      struct iphdr            iph;<br>/usr/include/linux/ip.h:85:struct iphdr {</p></blockquote><p><a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">从raw socket介绍中学到的东西</a></p><blockquote><p>接下来我们简单介绍一下网卡是怎么收报的，如果你对这部分已经很了解可以跳过这部分内容。网卡从线路上收到信号流，网卡的驱动程序会去检查数据帧开始的前6个字节，即目的主机的MAC地址，如果和自己的网卡地址一致它才会接收这个帧，不符合的一般都是直接无视。然后该数据帧会被网络驱动程序分解，IP报文将通过网络协议栈，最后传送到应用程序那里。往上层传递的过程就是一个校验和“剥头”的过程，由协议栈各层去实现。</p></blockquote><p>setsockopt (packet_send_sd, IPPROTO_IP, IP_HDRINCL, val, sizeof (one)) // IP_HDRINCL to tell the kernel that headers are included in the packet<br>这样设置告诉内核，ip packet的header将由我们自己添加，所以最终发送出去的内容需要完全由自己决定。</p><p>为了将一个udp包伪装成tcp包，需要一个SOCK_RAW的socket</p><blockquote><p>socket(AF_INET , SOCK_RAW , IPPROTO_TCP)</p></blockquote><p>接下来就是自己组装tcp包结构，</p><h2 id="python也提供了对应rawsocket的api"><a href="#python也提供了对应rawsocket的api" class="headerlink" title="python也提供了对应rawsocket的api"></a>python也提供了对应rawsocket的api</h2><blockquote><p> socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_TCP)</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.chionlab.moe/2017/04/06/kcptun-with-fake-tcp/">kcptun-raw：应对UDP QoS，重新实现kcptun的一次尝试</a><br><a href="https://github.com/linhua55/some_kcptun_tools">some_kcptun_tools</a><br><a href="https://github.com/Chion82/kcptun-raw">kcptun-raw</a><br><a href="https://coolshell.cn/articles/11609.html">tcp那些事</a> tcp协议为了对外实现可靠交付，内部实现有很多非常复杂的算法。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/SunFlowersStorm_EN-AU8863925685_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;从原始套接字 SOCK_RAW学习到的知识&lt;br&gt;
    
    </summary>
    
    
      <category term="c" scheme="https://haldir65.github.io/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>操作系统原理</title>
    <link href="https://haldir65.github.io/2019/01/10/2019-01-10-operating-system-related-topics/"/>
    <id>https://haldir65.github.io/2019/01/10/2019-01-10-operating-system-related-topics/</id>
    <published>2019-01-10T22:32:11.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>操作系统原理的一些记录<br><img src="https://www.haldir66.ga/static/imgs/SouthMoravian_ZH-CN13384331455_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>操作系统是如何做好断电保护的？<br>记得是有一个journal文件的</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.cnblogs.com/huxiao-tee/p/4657851.html">从内核文件系统看文件读写过程</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;操作系统原理的一些记录&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/SouthMoravian_ZH-CN13384331455_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>java nio使用指南</title>
    <link href="https://haldir65.github.io/2019/01/10/2019-01-10-java-nio-intro/"/>
    <id>https://haldir65.github.io/2019/01/10/2019-01-10-java-nio-intro/</id>
    <published>2019-01-10T22:25:50.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>关于java nio的一些点<br><img src="https://www.haldir66.ga/static/imgs/UmbriaCastelluccio_EN-AU8834990889_1920x1080.jpg" alt=""><br><a id="more"></a></p><p><a href="https://zhuanlan.zhihu.com/p/27625923">本文大多数内容来自知乎专栏</a>的复制粘贴，因为别人写的比我好</p><h3 id="nio及DirectByteBuffer相关操作"><a href="#nio及DirectByteBuffer相关操作" class="headerlink" title="nio及DirectByteBuffer相关操作"></a>nio及DirectByteBuffer相关操作</h3><p>nio包含了很多东西，核心的应该是selector<br>DirectBuffer这个东西很容易讲，一句话就能说清楚：这是一块在Java堆外分配的，可以在Java程序中访问的内存。<br>先来解释一下几个堆是什么。以32位系统为例（64位系统也是一样的，只是地址空间更大而已，写起来没有32位系统看上去那么简洁），操作系统会为一个进程提供4G的地址空间，换句话说，一个进程可用的内存是4G。在Linux上，又为内核空间留了1G，剩下的3G是可以供用户使用的(粗略来看是这样的)。这1G就叫做内核空间，3G被称为用户空间。<br>一个java进程下不过对于操作系统而言，肯定是一个用户进程。所以jva也就有了这3G的使用权。jvm想要使用这些内存的时候，会使用malloc方法去找操作系统去要（其实中间还隔了一个C runtime，我们不去管这个细节，只把malloc往下都看成是操作系统的功能，并不会带来太大的问题）<br>而JVM要来的这些的内存，有一块是专门供Java程序创建对象使用的，这块内存在JVM中被称为堆(heap)。堆这个词快被用烂了，操作系统有堆的概念，C runtime也有，JVM里也有，然后还有一种数据结构也叫堆（参看本课程堆排序部分），为了区别，我在以后的文章里只称JVM中的堆为Java堆。关于Java堆的结构和管理，在后面GC调优部分，我会详细地讲，这里我只介绍一下本节课所需要的内容。<br>我们使用普通的ByteBuffer，那么这个ByteBuffer就会在Java堆内，被JVM所管理：</p><pre><code class="java">ByteBuffer buf = ByteBuffer.allocate(1024);</code></pre><p>在执行GC的时候，JVM实际上会做一些整理内存的工作，也就说buf这个对象在内存中的实际地址是会发生变化的。有些时候，ByteBuffer里都是大量的字节，这些字节在JVM GC整理内存时就显得很笨重，把它们在内存中拷来拷去显然不是一个好主意。<br>那这时候，我们就会想能不能给我一块内存，可以脱离JVM的管理呢？在这样的背景下，就有了DirectBuffer。先看一下用法：</p><pre><code class="java">ByteBuffer buf = ByteBuffer.allocateDirect(1024);</code></pre><p>这两个函数的实现是有区别的:</p><pre><code class="java">public static ByteBuffer allocateDirect(int capacity) {        return new DirectByteBuffer(capacity);    }    public static ByteBuffer allocate(int capacity) {        if (capacity &lt; 0)            throw new IllegalArgumentException();        return new HeapByteBuffer(capacity, capacity);    }</code></pre><p>DirectByteBuffer的核心就是调用了 unsafe.allocateMemory(size)方法。<br>Java对象在Java堆里申请内存的时候，实际上是比malloc要快的，所以DirectBuffer的创建效率往往是比Heap Buffer差的。<br>但是，如果进行网络读写或者文件读写的时候，DirectBuffer就会比较快了。 <strong>说起来好笑，这个快是因为JDK故意把非DirectBuffer的读写搞慢的，我们看一下JDK的源代码</strong>。<br>share/classes/sun/nio/ch/IOUtil.java</p><pre><code class="java">static int write(FileDescriptor fd, ByteBuffer src, long position,                     NativeDispatcher nd)         throws IOException    {           if (src instanceof DirectBuffer)            return writeFromNativeBuffer(fd, src, position, nd);        // Substitute a native buffer        int pos = src.position();        int lim = src.limit();        assert (pos &lt;= lim);        int rem = (pos &lt;= lim ? lim - pos : 0);         ByteBuffer bb = Util.getTemporaryDirectBuffer(rem);        try {            bb.put(src);            bb.flip();        // ................略</code></pre><p>如果src是DirectBuffer，就直接调用writeFromNativeBuffer，如果不是，则要先创建一个临时的DirectBuffer，把src拷进去，然后再调用真正的写操作。为什么要这么干呢？还是要从DirectBuffer不会被GC移动说起。writeFromNativeBuffer的实现，最终会把Buffer的address传给操作系统，让操作系统把address开始的那一段内存发送到网络上。这就要求在操作系统进行发送的时候，这块内存是不能动的(jni调用传递的是地址，地址不能乱动)。而我们知道，GC是会乱搬Java堆里的东西的，所以无奈，我们必须得弄一块地址不会变化的内存，然后把这个地址发给操作系统。</p><p>常用的ByteBuffer本质上是一个byte[]，包括这么几个变量<br>容量（Capacity） 缓冲区能够容纳的数据元素的最大数量。容量在缓冲区创建时被设定，并且永远不能被改变。<br>上界（Limit） 缓冲区里的数据的总数，代表了当前缓冲区中一共有多少数据。<br>位置（Position） 下一个要被读或写的元素的位置。Position会自动由相应的 get( )和 put( )函数更新。<br>标记（Mark） 一个备忘位置。用于记录上一次读写的位置。一会儿，我会通过reset方法来说明这个属性的含义。<br>ByteBuffer是一个抽象类，不能new出来</p><pre><code class="java">ByteBuffer byteBuffer = ByteBuffer.allocate(256);</code></pre><p>以上的语句可以创建一个大小为256字节的ByteBuffer，此时，mark = -1, pos = 0, limit = 256, capacity = 256。capacity在初始化的时候确定了，运行时就不会再变化了，而另外三个变量是随着程序的执行而不断变化的。</p><p>由于本质上就是一个byte[]，读数据的时候position放到0, limit放到当前已经存放的数据的位置，读完为止。写数据的时候也差不多，position放到当前已经存放的数据的curIndex+1，limit放到capicity的位置，填满为止。</p><p>从读变成写可以这么干</p><pre><code class="java">byteBuffer.limit(byteBuffer.position())byteBuffer.position(0);//由于这个方法实在太频繁,jdk就帮忙封装了一个叫做flip的方法public final Buffer flip() {        limit = position;        position = 0;        mark = -1;        return this;    }</code></pre><p>显然连续调用flip会导致limit变成0，不能读也不能写了。<br>mark方法类似于打一个标记，待会儿通过reset回到这个position。</p><h3 id="java的byte数组在内存层面不一定是连续的，C语言里面是连续的"><a href="#java的byte数组在内存层面不一定是连续的，C语言里面是连续的" class="headerlink" title="java的byte数组在内存层面不一定是连续的，C语言里面是连续的"></a>java的byte数组在内存层面不一定是连续的，C语言里面是连续的</h3><p>原因是GC会挪动内存</p><h2 id="nio的channel"><a href="#nio的channel" class="headerlink" title="nio的channel"></a>nio的channel</h2><p>在Java IO中，基本上可以分为文件类和Stream类两大类。Channel 也相应地分为了FileChannel 和 Socket Channel，其中 socket channel 又分为三大类，一个是用于监听端口的ServerSocketChannel，第二类是用于TCP通信的SocketChannel，第三类是用于UDP通信的DatagramChannel。channel 最主要的作用还是用于非阻塞式读写。可以使用Channel结合ByteBuffer进行读写。<br>一个简单的client server echo程序可以这样写</p><pre><code class="java">// serverpublic class WebServer {    public static void main(String args[]) {        try {            ServerSocketChannel ssc = ServerSocketChannel.open();            ssc.socket().bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000));            SocketChannel socketChannel = ssc.accept();            ByteBuffer readBuffer = ByteBuffer.allocate(128);            socketChannel.read(readBuffer);            readBuffer.flip();            while (readBuffer.hasRemaining()) {                System.out.println((char)readBuffer.get());            }            socketChannel.close();            ssc.close();        }        catch (IOException e) {            e.printStackTrace();        }    }}// clientpublic class WebClient {    public static void main(String[] args) {        SocketChannel socketChannel = null;        try {            socketChannel = SocketChannel.open();            socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000));            ByteBuffer writeBuffer = ByteBuffer.allocate(128);            writeBuffer.put(&quot;hello world&quot;.getBytes());            writeBuffer.flip();            socketChannel.write(writeBuffer);            socketChannel.close();        } catch (IOException e) {        }    }}</code></pre><h3 id="MMAP-memory-mapped-file"><a href="#MMAP-memory-mapped-file" class="headerlink" title="MMAP(memory mapped file)"></a>MMAP(memory mapped file)</h3><p>将文件映射到内存空间的操作，懒得看原理的话，背下这段话就够了</p><blockquote><p><strong>常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高</strong></p></blockquote><p>mmap函数是unix/linux下的系统调用，mmap系统调用并不是完全为了用于共享内存而设计的,mmap实现共享内存也是其主要作用之一，事实上可以实现两个java进程之间的通信。</p><p>A进程</p><pre><code class="java">public class Main {    public static void main(String args[]){        RandomAccessFile f = null;        try {            f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;);            FileChannel fc = f.getChannel();            MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, 20);            buf.put(&quot;how are you?&quot;.getBytes());            Thread.sleep(10000);            fc.close();            f.close();        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p>B进程</p><pre><code class="java">public class MapMemoryBuffer {    public static void main(String[] args) throws Exception {        RandomAccessFile f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;);        FileChannel fc = f.getChannel();        MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size());        while (buf.hasRemaining()) {            System.out.print((char)buf.get());        }        System.out.println();    }}</code></pre><p>很多java方法本质上就是jni进行了系统调用。<br>在sun.nio.ch.FileChannelImpl里有map的具体实现：</p><pre><code class="java">try {            // If no exception was thrown from map0, the address is valid            addr = map0(imode, mapPosition, mapSize);        } catch (OutOfMemoryError x) {private native long map0(int prot, long position, long length)</code></pre><p>比如Java的这个map0函数，具体的实现在<br>solaris/native/sun/nio/ch/FileChannelImpl.c这个文件里</p><pre><code class="c">JNIEXPORT jlong JNICALLJava_sun_nio_ch_FileChannelImpl_map0(JNIEnv *env, jobject this,                                     jint prot, jlong off, jlong len){    void *mapAddress = 0;    jobject fdo = (*env)-&gt;GetObjectField(env, this, chan_fd);    jint fd = fdval(env, fdo);    int protections = 0;    int flags = 0;    if (prot == sun_nio_ch_FileChannelImpl_MAP_RO) {        protections = PROT_READ;        flags = MAP_SHARED;    } else if (prot == sun_nio_ch_FileChannelImpl_MAP_RW) {        protections = PROT_WRITE | PROT_READ;        flags = MAP_SHARED;    } else if (prot == sun_nio_ch_FileChannelImpl_MAP_PV) {        protections =  PROT_WRITE | PROT_READ;        flags = MAP_PRIVATE;    }    mapAddress = mmap64(        0,                    /* Let OS decide location */        len,                  /* Number of bytes to map */        protections,          /* File permissions */        flags,                /* Changes are shared */        fd,                   /* File descriptor of mapped file */        off);                 /* Offset into file */    if (mapAddress == MAP_FAILED) {        if (errno == ENOMEM) {            JNU_ThrowOutOfMemoryError(env, &quot;Map failed&quot;);            return IOS_THROWN;        }        return handle(env, -1, &quot;Map failed&quot;);    }    return ((jlong) (unsigned long) mapAddress);}</code></pre><p>其实就是通过jni调用了c语言api.</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>netty的作者在演讲中提到java官方的nio并不特别好，所以，生产环境用的都是netty这种。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/23488863">美团团队出的关于nio的解说</a><br>这里面有一句原话摘抄下来：</p><blockquote><p>线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。像Java的线程栈，一般至少分配512K～1M的空间，</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于java nio的一些点&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/UmbriaCastelluccio_EN-AU8834990889_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>tcp-proxy简单实现及socks协议相关</title>
    <link href="https://haldir65.github.io/2018/12/31/2018-12-31-tcp-proxy-and-socks-server-related/"/>
    <id>https://haldir65.github.io/2018/12/31/2018-12-31-tcp-proxy-and-socks-server-related/</id>
    <published>2018-12-31T18:45:38.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>python实现简易的tcp-proxy server及socks代理学习笔记</p><p><img src="https://www.haldir66.ga/static/imgs/MountainDayJapan_EN-AU8690491173_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>首先是基本的流程<br>本地起一个tcp代理，监听0.0.0.0的1090端口,接收到任何数据之后原封不动发送到远程服务器。接着本机或者局域网内其他机器使用telnet往这个1090端口发数据。这样的proxy其实也就是实质上的一个tcp跳板机。</p><h2 id="先介绍一下telnet的使用教程"><a href="#先介绍一下telnet的使用教程" class="headerlink" title="先介绍一下telnet的使用教程"></a>先介绍一下telnet的使用教程</h2><p>在windows上telnet好像默认关闭了。在mac上：</p><blockquote><p>telnet 127.0.0.1 1090 // 这句话类似于连接到这个port，但是还没有发送数据。接下来可以发送数据</p></blockquote><p>在mac上ctrl+]是进入命令模式，可以输入一些比较好玩的命令:<br>比如help，比如quit。<br>send ayt //原封不动发送are you there 这几个字符<br>send ? //查看可以使用send发送哪些指令，其实就是发送字符<br>telnet的输出按删除键是不会清除的，输入cls就可以了。</p><p>另外,telnet是明文发送的，ssh会加密一下<br>Telnet data is sent in clear text. It’s certainly a good idea to use SSH to access network devices especially when going through a public network like Internet. As you are probably aware SSH would encrypt all data between the client/server and even if someone gets a hand on the data it’s of no use.</p><h3 id="然后就是如何实现这个本地代理了"><a href="#然后就是如何实现这个本地代理了" class="headerlink" title="然后就是如何实现这个本地代理了"></a>然后就是如何实现这个本地代理了</h3><ol><li>本地先绑定一个socket在1090端口</li><li>1090端口每次接收到一个新的sock连接，起一个新的线程，去处理和这个新的client的一次会话</li><li>在这个会话里面，同时启动两个线程（一个从local client读数据，然后发给remote server；另一个从remote server读取数据，发给local client）</li><li>这里面每个会话的remote server都是一个一个固定的ip:port，但是local client的port是变来变去的</li></ol><p>看看第三步，其实就是一个往返，所以顺序掉个头就行了，而且彼此互相不干扰（在只有一个会话的时候，remote.recv可以认为就是对当前client.send的回应）<br>这个往返用代码描述一下就是:</p><pre><code class="python">def sock_proxy(remote, local):    local_request = local.recv(4096) ## 如果local和remote对调一下，这里就是从remote读数据    ## ....    remote.sendAll(local_request.encode()) ## 这里就是 GET / HTTP1.1 ...这种字符串，如果local和remote对调一下，就是发数据给local client</code></pre><p>省略了一些try except和socket.close的代码。上面写了4096，是说最大接收数据量是4096字节，不是一次读取4096个字节的意思。下面是python中这几个函数的定义</p><pre><code>s.recv(bufsize[,flag])接受TCP套接字的数据。数据以字符串形式返回，bufsize指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。s.send(string[,flag])发送TCP数据。将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。s.sendall(string[,flag])完整发送TCP数据。将string中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回None，失败则抛出异常。</code></pre><p>具体用什么语言来实现，其实都没什么大的差别了。用Python好在跨平台，代码量少。</p><ul><li>使用方式<blockquote><p>python tcp_proxy -l 0.0.0.0:1090 -r zhihu.com:80 -v //代码是在别人的基础上改的，直接用别人的argument parser了</p></blockquote></li></ul><p>意思就是在本地监听1090端口，任何发到本地1090端口的包都会被发到zhihu.com这个host的80端口(测试了下，知乎返回的response是正常的)</p><p>本地另外起一个telnet</p><blockquote><p>telnet 127.0.0.1 1090<br>GET / HTTP 1.1 \r\n\r\n //事实上在telnet里面输入换行符有点困难，因为按下回车的时候会顺带在后面加上换行符<br>…然后这里就会出现远程服务器的回应。</p></blockquote><p>因为直接从client的报文中提取请求信息其实挺没意思的，所以暂时在python代码里写死了发送给远程的content</p><p>发现curl原来可以直接往任意host:port发送http格式的请求</p><blockquote><p>curl localhost:1090</p></blockquote><p>在proxy一侧收到的请求报文：</p><pre><code>GET / HTTP/1.1Host: localhost:1090User-Agent: curl/7.54.0Accept: */*</code></pre><p>最后是有俩换行的</p><p>用nc(netcat)也能往1090端口发数据</p><blockquote><p>nc 127.0.0.1 1090<br>GET / HTTP 1.1 \r\n\r\n 这个可以直接打换行，更方便</p></blockquote><h3 id="接下来就是看如何处理多个client的session-sock5协议实现"><a href="#接下来就是看如何处理多个client的session-sock5协议实现" class="headerlink" title="接下来就是看如何处理多个client的session(sock5协议实现)"></a>接下来就是看如何处理多个client的session(sock5协议实现)</h3><p>以上实现的只是一个tcp proxy，就是完全不检查通信内容的代理，是直接站在tcp层的。<br>现实中还有http proxy,sock proxy，彼此之间有一些差别。</p><p>多个client或者一个client的多个port同时走这个代理去访问远程时，代理服务器不可避免要记录下client和sever之间的连线，适当的还要在packet里面塞一些标记。业内成熟的方案当然是sock5协议,对应的标准是RFC 1928和RFC 1929。</p><p>从wiki上来看sock5是在sock4版本的基础上加了鉴定、IPv6、UDP支持。</p><blockquote><p>SOCKS工作在比HTTP代理更低的层次：SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如FTP；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，CONNECT方法允许转发TCP连接；然而，SOCKS代理还可以转发UDP流量和反向代理，而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法）。</p></blockquote><p>sock5_protocol协议包括:<br>协议<br>协商<br>客户端首先向SOCKS服务器自己的协议版本号，以及支持的认证方法。SOCKS服务器向客户端返回协议版本号以及选定的认证方法。</p><p>认证<br>客户端根据服务器端选定的方法进行认证，如果选定的方法是02,则根据RFC 1929定义的方法进行认证。RFC 1929定义的密码是明文传输，安全性较差。</p><p>请求<br>一旦指定认证方法的协商过程完成, 客户端发送详细的请求信息。经常使用 SOCKS 代理服务器的同志们会发现一种现象，即使 SOCKS 代理服务器设置正确，某些网站仍然无法访问,一般来说就是DNS污染造成的。SOCKS 5是通过将域名直接提交给 SOCKS 服务器来进行远端 DNS 解析的，即 Address Type 0x03。 DNS 服务是 Internet 的基础服务，要求 DNS 解析应当尽量地快，所以浏览器默认不会使用远端 DNS 解析。在Chrome的SwitchySharp 和Firefox里面的FoxyProxy可以支持远端DNS解析，可以避开DNS污染问题。</p><p>sock5协议其实在命令行里就能用上:</p><blockquote><p>curl –sock5 127.0.0.1:1080 <a href="http://www.google.com">http://www.google.com</a></p></blockquote><p>整体的流程:</p><blockquote><p>客户端向服务器发送协议版本号及支持认证方式(在proxy server这边会收到几个字节的bind请求<br>05 01 00 xxxx)<br>服务器回应版本号及选定认证方式<br>客户端发送Connect请求<br>服务器对Connect的响应<br>客户端发送被代理的数据<br>服务器响应被代理的数据</p></blockquote><h3 id="所以最终实现的效果是实现使用代理访问知乎"><a href="#所以最终实现的效果是实现使用代理访问知乎" class="headerlink" title="所以最终实现的效果是实现使用代理访问知乎"></a>所以最终实现的效果是实现使用代理访问知乎</h3><p>因为走的是明文，这样的代理只是具有学习的性质。更多的需要参考shadowsocks的实现(tcp proxy,支持udp)。<br>另外，业内比较出名的tcp proxy有nginx，enovy以及<a href="https://github.com/google/tcpproxy">golang tcp proxy</a>的实现。</p><h3 id="raw-socket-原始套接字"><a href="#raw-socket-原始套接字" class="headerlink" title="raw socket(原始套接字)"></a>raw socket(原始套接字)</h3><p><a href="https://blessing.studio/why-do-shadowsocks-deprecate-ota/">ss的tcp包结构</a><br>主动探测方法<br><a href="https://loggerhead.me/posts/shadowsocks-yuan-ma-fen-xi-xie-yi-yu-jie-gou.html">协议与结构</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://ichuan.net/post/22/tcp-proxy-and-tcp-hub-in-python/">python小工具：tcp proxy和tcp hub</a><br><a href="https://rushter.com/blog/python-socks-server/">Writing a simple SOCKS server in Python</a><br><a href="https://geesun.github.io/posts/2015/09/socks5_protocol.html">SOCKS 5协议简析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;python实现简易的tcp-proxy server及socks代理学习笔记&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/MountainDayJapan_EN-AU8690491173_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="https://haldir65.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>bytecode基本解读</title>
    <link href="https://haldir65.github.io/2018/12/12/2018-12-12-sinking-your-teeth-into-ByteCode/"/>
    <id>https://haldir65.github.io/2018/12/12/2018-12-12-sinking-your-teeth-into-ByteCode/</id>
    <published>2018-12-12T11:11:02.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>python中可以使用diss module 轻易的查看byte code。那么在java中呢<br><img src="https://www.haldir66.ga/static/imgs/BadlandsBday_EN-AU10299777329_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>interpreting the talk from<br><a href="https://jakewharton.com/sinking-your-teeth-into-bytecode/">Sinking Your Teeth Into Bytecode</a></p><p>java 有一个关键字叫做goto，在java代码中好像不能用，但是其实在生成的bytecode里面有goto关键字(c语言也有)</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.youtube.com/watch?v=lP4ED_dN16g">JVM bytecode engineering 101</a><br><a href="https://www.youtube.com/watch?v=rPyqB1l4gko">JVM Bytecode for Dummies (and the Rest of Us Too)</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;python中可以使用diss module 轻易的查看byte code。那么在java中呢&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/BadlandsBday_EN-AU10299777329_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>select、poll、epoll学习笔记</title>
    <link href="https://haldir65.github.io/2018/12/06/2018-12-06-select-poll-epoll/"/>
    <id>https://haldir65.github.io/2018/12/06/2018-12-06-select-poll-epoll/</id>
    <published>2018-12-06T08:38:54.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。<br><img src="https://www.haldir66.ga/static/imgs/OrionNebula_EN-AU10620917199_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>用户态到内核态的内存copy的开销</p><p>mac上叫做Kqueue<br><a href="https://www.zhihu.com/question/20122137">epoll或者Kqueue的原理是什么</a></p><p>在看<a href="https://realpython.com/python-sockets/">socket programming in python</a>这篇文章时发现有selector这样的操作。其实和c语言的做法很相似。</p><p><a href="https://www.jianshu.com/p/d2f4c35cb692">Windows IOCP与Linux的epoll机制对比</a><br>系统I/O模型 可分为三类：<br>第一种： 阻塞型(blocking model)，<br>应用进程发起connect请求，进入系统内核方法调用。内核负责发送SYN,等待ACK,等到ACK、SYNC到达以后，发送ACK，连接完成，return用户态的connect调用。以上过程中，应用层一直阻塞。</p><p>第二种： 非阻塞同步型(non-blocking model): “wait until any socket is available to read or write from/to buffer, then call non blocking socket function which returns immediately.”<br>可以通过设置SOCK_NONBLOCK标记创建非阻塞的socket fd，或者用fcntl也是一样的。<br>比方说c语言在linux环境下可以这么写。</p><pre><code class="c"> // client side   int socketfd = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0);   // server side - see man page for accept4 under linux    int socketfd = accept4( ... , SOCK_NONBLOCK);</code></pre><p>对非阻塞fd调用系统接口时，不需要等待事件发生而立即返回，事件没有发生，接口返回-1，此时需要通过errno的值来区分是否出错，有过网络编程的经验的应该都了解这点。不同的接口，立即返回时的errno值不尽相同，如，recv、send、accept errno通常被设置为EAGIN 或者EWOULDBLOCK，connect 则为EINPRO- GRESS 。<br>就是说，客户端程序会不停地去尝试读取数据，但是不会阻塞在那个读方法里，如果读的时候，没有读到内容，也会立即返回。这就允许我们在客户端里，读到不数据的时候可以搞点其他的事情了。</p><p>第三种： 非阻塞异步型(asynchronous aka. overlapping model): “call a socket function which returns immediately, then wait for its completion, then access the result data object”<br>IO多路复用，I/O复用(I/O multiplexing). IO多路复用是nio的核心和关键，也是实现高性能服务器的关键。<br>应用进程通过调用epoll_wait阻塞等待可读事件，等可读事件触发时，系统会回调注册的函数。</p><p>另外还有信号，async io</p><p>IOCP基于非阻塞异步模型，而epoll基于非阻塞同步模型。</p><p><a href="https://www.slideshare.net/sm9kr/iocp-vs-epoll-perfor">Windows IOCP vs Linux EPOLL Performance Comparison</a><br><a href="https://www.cnblogs.com/Anker/p/3263780.html">IO多路复用之epoll总结</a><br><a href="https://segmentfault.com/a/1190000003063859">Linux IO模式及 select、poll、epoll详解</a><br><a href="https://my.oschina.net/hosee/blog/730598">epoll浅析以及nio中的Selector</a><br><a href="https://cloud.tencent.com/developer/article/1005481">大话 Select、Poll、Epoll</a><br><a href="https://news.ycombinator.com/item?id=8526264">There is no Windows equivalent to epoll/kqueue , but there is Overlapped IO</a> 简单说就是windows在这方面设计的更优秀，只是开发者并未买账<br><a href="https://www.youtube.com/watch?v=M5-mcKh8QmY">Coroutines, Async/Await, Asyncio and the Pulsar Library</a> node, go goroutine, nginx, gui libraries ,java nio等都以各种形式采用了或实现了自己的event loop</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/OrionNebula_EN-AU10620917199_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>tcp和udp包结构分析</title>
    <link href="https://haldir65.github.io/2018/12/03/2018-12-03-packet-structure-of-tcp-and-udp/"/>
    <id>https://haldir65.github.io/2018/12/03/2018-12-03-packet-structure-of-tcp-and-udp/</id>
    <published>2018-12-03T13:42:25.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>本文只针对ipv4网络进行分析<br><img src="https://www.haldir66.ga/static/imgs/AlanTuringNotebook_EN-AU7743633207_1920x1080.jpg" alt=""><br><a id="more"></a></p><blockquote><p>多数内容来自<a href="https://jerryc8080.gitbooks.io/understand-tcp-and-udp/chapter2.html">TCP 报文结构</a><br>同一台机器上的两个进程，可以通过管道，共享内存，信号量，消息队列等方式进行通信。通信的一个基本前提是每个进程都有唯一的标识，在同一台机器上，使用pid就可以了。两台不同的计算机之间通信，可以使用<strong>ip地址 + 协议 +协议端口号</strong> 来标识网络中的唯一进程。<br>tcp用16位端口号来标识一个端口，也就是两个bytes(65536就这么来的)。</p></blockquote><p>以下图片盗自<a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">chinaunix一篇讲解raw socket的文章</a></p><ul><li><h3 id="这是IP-packet"><a href="#这是IP-packet" class="headerlink" title="这是IP packet"></a>这是IP packet</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-1.jpg" alt=""></p></li><li><h3 id="这是TCP-header"><a href="#这是TCP-header" class="headerlink" title="这是TCP header"></a>这是TCP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-2.jpg" alt=""></p></li><li><h3 id="这是IP-header"><a href="#这是IP-header" class="headerlink" title="这是IP header"></a>这是IP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-3.jpg" alt=""></p></li><li><h3 id="这是mac-header"><a href="#这是mac-header" class="headerlink" title="这是mac header"></a>这是mac header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-4.jpg" alt=""></p></li></ul><p>什么是报文？<br>例如一个 100kb 的 HTML 文档需要传送到另外一台计算机，并不会整个文档直接传送过去，可能会切割成几个部分，比如四个分别为 25kb 的数据段。<br>而每个数据段再加上一个 TCP 首部，就组成了 TCP 报文。<br>一共四个 TCP 报文，发送到另外一个端。<br>另外一端收到数据包，然后再剔除 TCP 首部，组装起来。<br>等到四个数据包都收到了，就能还原出来一个完整的 HTML 文档了。<br>在 OSI 的七层协议中，第二层（数据链路层）的数据叫「Frame」，第三层（网络层）上的数据叫「Packet」，第四层（传输层）的数据叫「Segment」。<br>TCP 报文 (Segment)，包括首部和数据部分。</p><p>TCP 报文段首部的前20个字节是固定的，后面有 4N 字节是根据需要而增加的。<br>TCP 的首部包括以下内容：</p><ul><li>源端口 source port</li><li>目的端口 destination port</li><li>序号 sequence number</li><li>确认号 acknowledgment number</li><li>数据偏移 offset</li><li>保留 reserved</li><li>标志位 tcp flags</li><li>窗口大小 window size</li><li>检验和 checksum</li><li>紧急指针 urgent pointer</li><li>选项 tcp options</li></ul><h3 id="连接建立过程"><a href="#连接建立过程" class="headerlink" title="连接建立过程"></a>连接建立过程</h3><p>TCP 连接的建立采用客户服务器方式，主动发起连接建立的一方叫客户端（Client），被动等待连接建立的一方叫服务器（Server）。<br>最初的时候，两端都处于 CLOSED 的状态，然后服务器打开了 TCP 服务，进入 LISTEN 状态，监听特定端口，等待客户端的 TCP 请求。<br>第一次握手： 客户端主动打开连接，发送 TCP 报文，进行第一次握手，然后进入 SYN_SEND 状态，等待服务器发回确认报文。<br>这时首部的同步位 SYN = 1，同时初始化一个序号 Sequence Number = J。<br>TCP 规定，SYN 报文段不能携带数据，但会消耗一个序号。<br>第二次握手： 服务器收到了 SYN 报文，如果同意建立连接，则向客户端发送一个确认报文，然后服务器进入 SYN_RCVD 状态。<br>这时首部的 SYN = 1，ACK = 1，而确认号 Acknowledgemt Number = J + 1，同时也为自己初始化一个序号 Sequence Number = K。<br>这个报文同样不携带数据。<br>第三次握手：<br>客户端收到了服务器发过来的确认报文，还要向服务器给出确认，然后进入 ESTABLISHED 状态。<br>这时首部的 SYN 不再置为 1，而 ACK = 1，确认号 Acknowledgemt Number = K + 1，序号 Sequence Number = J + 1。<br>第三次握手，一般会携带真正需要传输的数据，当服务器收到该数据报文的时候，就会同样进入 ESTABLISHED 状态。 此时，TCP 连接已经建立。<br>对于建立连接的三次握手，主要目的是初始化序号 Sequence Number，并且通信的双方都需要告知对方自己的初始化序号，所以这个过程也叫 SYN。<br>这个序号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输问题而乱序，因为TCP 会用这个序号来拼接数据。</p><h3 id="TCP-Flood-攻击"><a href="#TCP-Flood-攻击" class="headerlink" title="TCP Flood 攻击"></a>TCP Flood 攻击</h3><p>知道了 TCP 建立一个连接，需要进行三次握手。<br>但如果你开始思考「三次握手的必要性」的时候，就会知道，其实网络是很复杂的，一个信息在途中丢失的可能性是有的。<br>如果数据丢失了，那么，就需要重新发送，这时候就要知道数据是否真的送达了。<br>这就是三次握手的必要性。<br>但是再向深一层思考，你给我发信息，我收到了，我回复，因为我是君子。<br>如果是小人，你给我发信息，我就算收到了，我也不回复，你就一直等我着我的回复。<br>那么很多小人都这样做，你就要一直记住你在等待着小人1号、小人2号、小人3号……直到你的脑容量爆棚，烧坏脑袋。<br>黑客就是利用这样的设计缺陷，实施 TCP Flood 攻击，属于 DDOS 攻击的一种。</p><h3 id="四次挥手，释放连接"><a href="#四次挥手，释放连接" class="headerlink" title="四次挥手，释放连接"></a>四次挥手，释放连接</h3><p>TCP 有一个特别的概念叫做半关闭，这个概念是说，TCP 的连接是全双工（可以同时发送和接收）的连接，因此在关闭连接的时候，必须关闭传送和接收两个方向上的连接。<br>客户端给服务器发送一个携带 FIN 的 TCP 结束报文段，然后服务器返回给客户端一个 确认报文段，同时发送一个 结束报文段，当客户端回复一个 确认报文段 之后，连接就结束了。<br>释放连接过程<br>在结束之前，通信双方都是处于 ESTABLISHED 状态，然后其中一方主动断开连接。<br>下面假如客户端先主动断开连接。<br>第一次挥手：<br>客户端向服务器发送结束报文段，然后进入 FIN_WAIT_1 状态。<br>此报文段 FIN = 1， Sequence Number = M。<br>第二次挥手：<br>服务端收到客户端的结束报文段，然后发送确认报文段，进入 CLOSE_WAIT 状态。<br>此报文段 ACK = 1， Sequence Number = M + 1。<br>客户端收到该报文，会进入 FIN_WAIT_2 状态。<br>第三次挥手：<br>同时服务端向客户端发送结束报文段，然后进入 LAST_ACK 状态。<br>此报文段 FIN = 1，Sequence Number = N。<br>第四次挥手：<br>客户端收到服务端的结束报文段，然后发送确认报文段，进入 TIME_WAIT 状态，经过 2MSL 之后，自动进入 CLOSED 状态。<br>此报文段 ACK = 1, Sequence Number = N + 1。<br>服务端收到该报文之后，进入 CLOSED 状态。<br>关于 TIME_WAIT 过渡到 CLOSED 状态说明：<br>从 TIME_WAIT 进入 CLOSED 需要经过 2MSL，其中 MSL 就叫做 最长报文段寿命（Maxinum Segment Lifetime），根据 RFC 793 建议该值这是为 2 分钟，也就是说需要经过 4 分钟，才进入 CLOSED 状态。</p><h3 id="这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些"><a href="#这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些" class="headerlink" title="这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些"></a>这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些</h3><p>下面从<a href="https://www.infoq.cn/article/2018%2F03%2Fweibo-quic">QUIC 在微博中的落地思考</a>文中摘抄一部分批判tcp</p><blockquote><p>TCP 协议在建立连接时，需要经历较为漫长的三次握手行为，而在关闭时，也有稍显冗余的 4 次摆手。而 HTTPS 初始连接需要至少 2 个 RTT 交互（添加了握手缓存就会变成了 1-RTT，这里指的是 TLS 1.2），外加 TCP 自身握手流程，最少需要 3 次 RTT 往返，才能够完整建立连接。而 QUIC 协议层面界定了 1-2 个 RTT 握手流程，再次连接为 0-RTT 握手优化流程（但需要添加握手缓存）</p></blockquote><p>关于tcp read/write buffer，shadowsocks的参数优化提到了一些东西 </p><pre><code># max open filesfs.file-max = 1024000# max read buffernet.core.rmem_max = 67108864# max write buffernet.core.wmem_max = 67108864# default read buffernet.core.rmem_default = 65536# default write buffernet.core.wmem_default = 65536# max processor input queuenet.core.netdev_max_backlog = 4096# max backlognet.core.somaxconn = 4096# resist SYN flood attacksnet.ipv4.tcp_syncookies = 1# reuse timewait sockets when safenet.ipv4.tcp_tw_reuse = 1# turn off fast timewait sockets recyclingnet.ipv4.tcp_tw_recycle = 0# short FIN timeoutnet.ipv4.tcp_fin_timeout = 30# short keepalive timenet.ipv4.tcp_keepalive_time = 1200# outbound port rangenet.ipv4.ip_local_port_range = 10000 65000# max SYN backlognet.ipv4.tcp_max_syn_backlog = 4096# max timewait sockets held by system simultaneouslynet.ipv4.tcp_max_tw_buckets = 5000# TCP receive buffernet.ipv4.tcp_rmem = 4096 87380 67108864# TCP write buffernet.ipv4.tcp_wmem = 4096 65536 67108864# turn on path MTU discoverynet.ipv4.tcp_mtu_probing = 1# for high-latency networknet.ipv4.tcp_congestion_control = hybla# forward ipv4net.ipv4.ip_forward = 1</code></pre><p><a href="https://www.cyberciti.biz/files/linux-kernel/Documentation/networking/ip-sysctl.txt">内核文档对于这些参数的定义</a><br>注意，这些参数修改了会影响所有的进程，修改还是慎重一些</p><h3 id="tcp-buffer"><a href="#tcp-buffer" class="headerlink" title="tcp buffer"></a>tcp buffer</h3><p>关键字： tcp read buffer and write buffer<br>这里要分congestion window（发送方的window，对应congestion control）和receive window(接收方的window，对应flow control)<br>receive window</p><blockquote><p>Your Network Interface Card (NIC) is performing all of the necessary tasks of collecting packets and waiting for your OS to read them. Ultimately, when you do a stream read you’re pulling from the memory that your OS has reserved and constantly stores the incoming information copy into.<br>To answer your question, yes. You are definitely doing a copy. A copy of a copy, the bits are read into a buffer within your NIC, your OS puts them somewhere, and you copy them when you do a stream read.</p></blockquote><p>用wireshark抓包的话，在tcp header里面有个”window size value”，比方说这个数是2000，也就是发来这个包的一方告诉当前接受方，你下一次最多再发2000byte的数据过来，再多就装不下了。如果接收方处理速度跟不上，buffer慢慢填满，就会在ack包里调低window size，告诉对方发慢一点。<br>client处理速度够快的时候是这样的<br><img src="https://www.haldir66.ga/static/imgs/TCP-window-syn.png" alt=""></p><p>如果不够快的话,这时候就是client在ack包里告诉server自己跟不上了<br><img src="https://www.haldir66.ga/static/imgs/TCP-window-http.png" alt=""></p><h2 id="TCP-Window-Scaling"><a href="#TCP-Window-Scaling" class="headerlink" title="TCP Window Scaling"></a>TCP Window Scaling</h2><p>注意，window size是在ack包里的,另外,tcp header里面为这个window size准备的空间是2 bytes（65536 bytes,所以一个包最大也就65K?）。这样对于那些大带宽高延迟的连接来说是不利的。事实当然没这么简单，<a href="https://www.ietf.org/rfc/rfc1323.txt">RFC 1323</a> enable the TCP receive window to be increased exponentially(指数增长)。这个功能是在握手的时候互相商定了一个增长的倍数(在tcp握手的header里面有一个window size scaling factor,比如下图这样的，一次乘以4)<br><img src="https://www.haldir66.ga/static/imgs/Transmission-control-protocol-window-scaling.png" alt=""></p><blockquote><p>In the image above, the sender of this packet is advertising a TCP Window of 63,792 bytes and is using a scaling factor of four. This means that that the true window size is 63,792 x 4 (255,168 bytes). Using scaling windows allows endpoints to advertise a window size of over 1GB. To use window scaling, both sides of the connection must advertise this capability in the handshake process. If one side or the other cannot support scaling, then neither will use this function. The scale factor, or multiplier, will only be sent in the SYN packets during the handshake and will be used for the life of the connection. This is one reason why it is so important to capture the handshake process when performing TCP analysis.</p></blockquote><p>就是说4这个数只会出现在握手的syn包中，并且只有在双方都能支持scaling的前提下才会用，而且这个4将会在这条连接的生命周期中一直是这个数，所以要分析的话，逮这个syn包去抓。</p><h3 id="TCP-Zero-window"><a href="#TCP-Zero-window" class="headerlink" title="TCP Zero window"></a>TCP Zero window</h3><p><img src="https://www.haldir66.ga/static/imgs/TCP-Zero-Window-Performance-Vision.png" alt=""><br>意思就是说，这个window size变成0了。通常不会出现这种情况，一般是接收方的进程出问题了，这时候server会等着，随着client的应用层开始处理数据，client会慢慢发TCP Keep-Alive包，带上新的window size，告诉server说，自己正在处理数据，快了快了。</p><blockquote><p>The throughput of a communication is limited by two windows: the congestion window and the receive window. The congestion window tries not to exceed the capacity of the network (congestion control); the receive window tries not to exceed the capacity of the receiver to process data (flow control). The receiver may be overwhelmed by data if for example it is very busy (such as a Web server). Each TCP segment contains the current value of the receive window. If, for example, a sender receives an ack which acknowledges byte 4000 and specifies a receive window of 10000 (bytes), the sender will not send packets after byte 14000, even if the congestion window allows it.<br>总的来说，tcp传输的速度是由congestion window and the receive window控制的，前者控制发送方的发送速度，后者限制接收方的接收速度。</p></blockquote><h3 id="可靠性交付的实现到这里也就清楚了"><a href="#可靠性交付的实现到这里也就清楚了" class="headerlink" title="可靠性交付的实现到这里也就清楚了"></a>可靠性交付的实现到这里也就清楚了</h3><p>滑动窗口(sliding window)<br>超时重传<br>流量控制 (flow control)<br>拥塞控制（congestion control）</p><h2 id="一个tcp-udp或者ip包最大多大，最小多大"><a href="#一个tcp-udp或者ip包最大多大，最小多大" class="headerlink" title="一个tcp,udp或者ip包最大多大，最小多大"></a>一个tcp,udp或者ip包最大多大，最小多大</h2><p>最小我们知道<br>传送TCP数据包的時候，TCP header 占 20 bytes， IPv4 header 占 20 bytes，所以最小40byte。<br>那么最大呢<a href="https://blog.csdn.net/caoshangpa/article/details/51530685">TCP、UDP数据包大小的限制</a><br>应用层udp最大1500-20-8 = 1472 字节(多了会被分片重组，万一分片丢失导致重组失败，就会被丢包)，1500是硬件决定的,20是ip头，8是udp的头<br>结论<br>UDP 包的大小就应该是 1500 - IP头(20) - UDP头(8) = 1472(Bytes)<br>TCP 包的大小就应该是 1500 - IP头(20) - TCP头(20) = 1460 (Bytes)<br>UDP数据报的长度是指包括报头和数据部分在内的总字节数，其中报头长度固定，数据部分可变。数据报的最大长度根据操作环境的不同而各异。从理论上说，包含报头在内的数据报的最大长度为65535字节(64K)。<br>用UDP协议发送时，用sendto函数最大能发送数据的长度为：65535- IP头(20) - UDP头(8)＝65507字节。用sendto函数发送数据时，如果发送数据长度大于该值，则函数会返回错误。<br>MTU 最大传输单元（英语：Maximum Transmission Unit，缩写MTU）是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位），怎么看</p><blockquote><p>ping -l 1472 -f www.baidu.com ##根据提示去调小这个数就是了，一般1350以上是有的</p></blockquote><p>从csdn搞来的图<br><img src="https://haldir66.ga/static/imgs/tcp_and_udp_size_limit.png" alt=""><br>传输层：<br>对于UDP协议来说，整个包的最大长度为65535，其中包头长度是65535-20=65515；<br>对于TCP协议来说，整个包的最大长度是由最大传输大小（MSS，Maxitum Segment Size）决定，MSS就是TCP数据包每次能够传<br>输的最大数据分段。为了达到最佳的传输效能TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替（需<br>要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以往往MSS为1460。通讯双方会根据双方提供的MSS值得最小值<br>确定为这次连接的最大MSS值。<br>IP层：<br>对于IP协议来说，IP包的大小由MTU决定（IP数据包长度就是MTU-28（包头长度）。 MTU值越大，封包就越大，理论上可增加传送速率，但<br>MTU值又不能设得太大，因为封包太大，传送时出现错误的机会大增。一般默认的设置，PPPoE连接的最高MTU值是1492, 而以太网<br>（Ethernet）的最高MTU值则是1500,而在Internet上，默认的MTU大小是576字节</p><h3 id="协议数据单元-Protocol-Data-Unit-PDU"><a href="#协议数据单元-Protocol-Data-Unit-PDU" class="headerlink" title="协议数据单元(Protocol Data Unit, PDU)"></a>协议数据单元(Protocol Data Unit, PDU)</h3><p>应用层数据在传输过程中沿着协议栈传递，每一层协议都会往其中添加信息，这就是封装的过程。在封装过程中，每一个阶段的PDU都有不同的名字来反映它的功能。</p><p>PDU按照TCP/IP协议的命名规范：<br>数据（Data）：应用层PDU的常用术语<br>分段（Segment）：传输层PDU<br>帧（Frame）：网络层PDU<br>比特（Bits）：在介质上物理传输数据所使用的PDU。</p><p>最终发出去的数据包应该是<br>Data link Ethernet Frame Header(Destination mac address + Source mac address) +<br>Network Layer IP Packet Header(Source network:host + Destination network: host) +<br>Transport Header(port) +<br>data</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://jerryc8080.gitbooks.io/understand-tcp-and-udp/">TCP 报文结构</a><br><a href="https://www.google.com/search?q=tcp%E5%8C%85%E7%BB%93%E6%9E%84">tcp包结构</a><br><a href="https://accedian.com/enterprises/blog/tcp-receive-window-everything-need-know/">推广商业软件的文章，当做关于tcp协议的一整个series来看还是很好的</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文只针对ipv4网络进行分析&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/AlanTuringNotebook_EN-AU7743633207_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>page-size and block size</title>
    <link href="https://haldir65.github.io/2018/12/02/2018-12-02-page-size-and-block-size/"/>
    <id>https://haldir65.github.io/2018/12/02/2018-12-02-page-size-and-block-size/</id>
    <published>2018-12-02T21:42:24.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>page size（内存相关）和block size(文件系统相关)的一些点<br><img src="https://www.haldir66.ga/static/imgs/scenery1511100718415.jpg" alt=""><br><a id="more"></a><br>wiki上说<br>Page size常由processor的架构决定的，操作系统管理内存的最小单位是一个Page size(应用程序申请分配内存时，操作系统实际分配的内存是page-size的整数倍)</p><p><a href="http://forums.justlinux.com/showthread.php?3261-Block-size-vs-page-size">Block size vs. page size</a></p><blockquote><p> block size concerns storage space on a filesystem.<br>Page size is, I believe, architecture-dependent, 4k being the size for IA-32 (x86) machines. For IA-64 architecture, I’m pretty sure you can set the page size at compile time, with 8k or 16k considered optimal. Again, I’m not positive, but I think Linux supports 4,8,16, and 64k pages.<br>Block size is a function of the filesystem in use. Many, if not all filesystems allow you to choose the block size when you format, although for some filesystems the block size is tied to/dependent upon the page size.<br>Minimun block size is usually 512 bytes, the allowed values being determined by the filesystem in question.</p></blockquote><p>unix系统中查看系统的page size</p><blockquote><p>getconf PAGESIZE ## X86架构的cpu上一般是4096byte</p></blockquote><p>一个很有意思的现象是，java BufferedInputStream的默认buffer数组大小是8192，okio 的segment的默认size也是8192，这些都是以byte为单位的。找到一个合理的<a href="https://stackoverflow.com/questions/37404068/why-is-the-default-char-buffer-size-of-bufferedreader-8192">解释</a>。大致意思是8192 = 2^13, windows和linux上这个大小正好占用两个分页文件(8kB)。</p><h2 id="block-size-硬盘块"><a href="#block-size-硬盘块" class="headerlink" title="block size(硬盘块)"></a>block size(硬盘块)</h2><p>摘抄一段来自<a href="https://zhuanlan.zhihu.com/p/26077257">深入浅出腾讯云CDN：缓存篇</a>的话：</p><blockquote><p>不管SSD盘或者SATA盘都有最小的操作单位，可能是512B，4KB，8KB。如果读写过程中不进行对齐，底层的硬件或者驱动就需要替应用层来做对齐操作，并将一次读写操作分裂为多次读写操作。</p></blockquote><p><a href="https://www.zfl9.com/c-struct.html">什么是内存对齐，为什么要对齐？</a></p><p>现代计算机中内存空间都是按照 byte 划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定变量的时候经常在特定的内存地址访问，这就需要各类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。<br>对齐的作用和原因：各个硬件平台对存储空间的处理上有很大的不同。一些平台对某些特定类型的数据只能从某些特定地址开始存取。其他平台可能没有这种情况，但是最常见的是如果不按照适合其平台的要求对数据存放进行对齐，会在存取效率上带来损失。<br>比如有些平台每次读都是从偶地址开始，如果一个 int 型（假设为32位）如果存放在偶地址开始的地方，那么一个读周期就可以读出，而如果存放在奇地址开始的地方，就可能会需要 2 个读周期，并对两次读出的结果的高低字节进行拼凑才能得到该 int 数据。显然在读取效率上下降很多，这也是空间和时间的博弈。<br>“内存对齐”应该是编译器的“管辖范围”。<br>编译器为程序中的每个“数据单元”安排在适当的位置上。<br><strong>但是C语言的一个特点就是太灵活，太强大，它允许你干预“内存对齐”</strong></p><p>对齐规则(内存相关)<br>每个特定平台上的编译器都有自己默认的“对齐系数”，我们可以通过预处理指令#pragma pack(n), n=1, 2, 4, 8, 16…来改变这一系数，这个 n 就是对齐系数</p><p>数据成员对齐规则：结构(struct)或联合(union)的数据成员，第一个数据成员放在 offset 为 0 的地方，以后的每个数据成员的对齐按照#pragma pack(n)指定的 n 值和该数据成员本身的长度 len = sizeof(type) 中，较小的那个进行，如果没有显示指定n值，则以len为准，进行对齐<br>结构/联合整体对齐规则：在数据成员对齐完成之后，结构/联合本身也要对齐，对齐按照#pragma pack(n)指定的n值和该结构/联合最大数据成员长度max_len_of_members中，较小的那个进行，如果没有显示指定n值，则以max_len_of_members为准，进行对齐<br>结合1、2可推断：当n值均超过(或等于)所有数据成员的长度时，这个n值的大小将不产生任何效果</p><h3 id="从fsize看block"><a href="#从fsize看block" class="headerlink" title="从fsize看block"></a>从fsize看block</h3><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define N 1024long fsize(FILE *fp){    fseek(fp, 0, SEEK_END);    return ftell(fp);}int main(){    printf(&quot;enter the file absolute path: \n &quot;);    char str[N];    scanf(&quot;%s&quot;,str);    printf(&quot;\n the file name you choose is: %s\n &quot;,str);    FILE *fp = fopen(str, &quot;rb&quot;);    if(fp == NULL ){        printf(&quot;error opening file \n&quot;);        exit(-1);    }    printf(&quot;len: %ld bytes\n&quot;, fsize(fp));    fclose(fp);    return 0;}</code></pre><p>简单的一个用fsize函数获取文件的bytes数的函数</p><p>./a.out sample.txt ## len: 2527 bytes<br>du sample.txt<br>4 sample.txt<br>du -b sample.txt<br>2527 sample.txt</p><p>简单的来说，fsize获取的大小和du的结果不一致。但du -b 就一样了。这事主要是因为block size的缘故,文件系统分配磁盘存储的时候是以block为单位的。所以经常看到windows里面显示一个文件的大小和“占用的磁盘空间”。就是因为block的原因。<a href="https://unix.stackexchange.com/questions/120311/why-are-there-so-many-different-ways-to-measure-disk-usage">更详细的解释在这里</a></p><blockquote><p>For files, ls -l file shows (among other things) the size of file in bytes, while du -k file shows the space occupied by file on disk (in units of 1 kB = 1204 bytes). Since disk space is allocated in blocks, the size indicated by du -k is always slightly larger than the space indicated by  ls -kl (which is the same as ls -l, but in 1 kB units).</p><p>For directories, ls -ld dir shows (among other things) the size of the list of filenames (together with a number of attributes) of the files and subdirectories in dir. This is just the list of filenames, not the files’ or subdirectories’ contents. So this size increases when you add files to dir (even when files are empty), but it stays unchanged when one of the files in dir grows.</p><p>However, when you delete files from dir the space from the list is not reclaimed immediately, but rather the entries for deleted files are marked as unused, and are later recycled (this is actually implementation-dependent, but what I described is pretty much the universal behavior these days). That’s why you may not see any changes in ls -ld output when you delete files until much later, if ever.</p><p>Finally, du -ks dir shows (an estimate of) the space occupied on disk by all files in dir, together with all files in all of dir’s subdirectories, in 1 kB = 1024 bytes units. Taking into account the description above, this has no relation whatsoever with the output of ls -kld dir.</p></blockquote><p>linux上是ext4文件系统<br>应用程序调用read()方法，系统会通过中断从用户空间进入内核处理流程，然后经过VFS(Virtual File System，虚拟文件系统)、具体文件系统、页缓存Page Cache。VFS主要是用于实现屏蔽具体的文件系统，为应用程序的操作提供一个统一的接口。<br>Page Cache(页缓存)，读文件的时候，会先看一下它是不是已经在Page Cache里面，如果命中了的话，就不会去读取磁盘。通过/proc/meminfo文件可以查看缓存的内存占用情况，当系统内存不足的时候，系统会回收这部分内存，I/O的性能就会降低。</p><p>这本应该是一篇关于操作系统原理，内核简介的文章,to be complemented</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>[ ] <a href="https://www.youtube.com/watch?v=0Rf5Jc61ArM">Paging Technique : Memory management in Operating System</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;page size（内存相关）和block size(文件系统相关)的一些点&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/scenery1511100718415.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>TextView测量及渲染原理</title>
    <link href="https://haldir65.github.io/2018/11/29/2018-11-29-how-is-text-drawn-on-android/"/>
    <id>https://haldir65.github.io/2018/11/29/2018-11-29-how-is-text-drawn-on-android/</id>
    <published>2018-11-29T16:11:54.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>Android上的TextView分为java层和native层，java层包括<br>Layout,Paint,Canvas<br>native层包括各种开源库，Minikin,ICU,HarfBuzz,FreeType<br>关于文字的形体,排版等信息是native层计算出来的。</p><p><img src="https://www.haldir66.ga/static/imgs/textview_architecture.png" alt=""></p><a id="more"></a><p>[tbd]</p><p>TextView是一个很重的控件，由于measure耗时通常很多，Android P提出了Precomputed Text的概念。类似的概念早几年instagram也提出过（如果只是想要展示一段文字，在一个子线程用Layout去计算。<br>我碰到的情况是：<br>layout.getDesiredwidth(“一个字”) &gt; layout.getDesiredwidth(“一”) + layout.getDesiredwidth(“个”)+ layout.getDesiredwidth(“字”)。<br>多数情况下，左边的值和右边的width之和是相等的，但是出现中英文夹杂的时候左边会小于右边。不清楚这是否是提前换行的原因。</p><p>Layout有BoringLayout(一行文字),StaticLayout(多行文字)和DynamicLayout(文字会变)这三个子类</p><p>在某些版本的Android上，TextView碰到中英文夹杂的时候，会出现提前换行(普遍的看法是Layout这个类里面处理全角符号的时候算错了)</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://stackoverflow.com/questions/27631736/meaning-of-top-ascent-baseline-descent-bottom-and-leading-in-androids-font">Textview的高度ascent,descent这些的详细解说</a><br><a href="http://ragnraok.github.io/textview-pre-render-research.html">TextView预渲染研究</a><br><a href="https://instagram-engineering.com/improving-comment-rendering-on-android-a77d5db3d82e">instagram的文章</a><br><a href="https://www.youtube.com/watch?v=x-FcOX6ErdI">Best practices for text on Android (Google I/O ‘18)</a><br><a href="https://www.youtube.com/watch?v=vXqwRhjd7b4">Use Android Text Like a Pro (Android Dev Summit ‘18)</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Android上的TextView分为java层和native层，java层包括&lt;br&gt;Layout,Paint,Canvas&lt;br&gt;native层包括各种开源库，Minikin,ICU,HarfBuzz,FreeType&lt;br&gt;关于文字的形体,排版等信息是native层计算出来的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/textview_architecture.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="android" scheme="https://haldir65.github.io/tags/android/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>浏览器indexedDb使用示例</title>
    <link href="https://haldir65.github.io/2018/11/27/2018-11-27-indexed-db-tutorial/"/>
    <id>https://haldir65.github.io/2018/11/27/2018-11-27-indexed-db-tutorial/</id>
    <published>2018-11-27T10:33:01.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>浏览器indexedDb使用方式及注意的点<br><img src="https://www.haldir66.ga/static/imgs/black-mountains.jpg" alt=""><br><a id="more"></a></p><p><a href="https://medium.com/@filipvitas/indexeddb-with-promises-and-async-await-3d047dddd313">浏览器上可供使用的数据持久化选择就这些</a></p><blockquote><p>1) Store all data on server database (SQL or NoSQL)<br>2) LocalStorage / SessionStorage - limited memory (around 5MB)<br>3) WebSQL - it has been deprecated in favor of IndexedDB<br>4) IndexedDB - designed as “one true” browser database with 50MB and more<br>tl;dr Use some library from conclusion section to make your life easier.</p></blockquote><h2 id="一些重要的概念"><a href="#一些重要的概念" class="headerlink" title="一些重要的概念"></a>一些重要的概念</h2><p>Database(通常一个app只有一个database)<br>127.0.0.1:8080和127.0.0.1：8000 是两个不同的Application<br>创建出来的数据库在Application-&gt;Storage-&gt;IndexedDB里面有</p><p>Object Stores(就像数据库里的table或者collections一样，但是同一个store中存储的数据类型不一定是相同的)</p><p>transaction（所有对IndexDb的操作必须通过transaction）</p><p>接下来是CURD的实例</p><p>db.open返回的是一个IDBRequest对象，没有promise的方式是这样使用的</p><pre><code class="js">var db;// Let us open our databasevar DBOpenRequest = window.indexedDB.open(&quot;toDoList&quot;, 4);// these two event handlers act on the database being// opened successfully, or notDBOpenRequest.onerror = function(event) {  note.innerHTML += &#39;&lt;li&gt;Error loading database.&lt;/li&gt;&#39;;};DBOpenRequest.onsuccess = function(event) {  note.innerHTML += &#39;&lt;li&gt;Database initialised.&lt;/li&gt;&#39;;  // store the result of opening the database.  db = DBOpenRequest.result;};</code></pre><h3 id="Create-创建db的代码"><a href="#Create-创建db的代码" class="headerlink" title="(Create)创建db的代码:"></a>(Create)创建db的代码:</h3><p>indexedDB.open(‘db-name’, 1) //第二个参数是数据库版本</p><h3 id="添加数据的方式"><a href="#添加数据的方式" class="headerlink" title="添加数据的方式"></a>添加数据的方式</h3><pre><code class="js">function putSomeData() {    let indexedDB = window.indexedDB || window.mozIndexedDB || window.webkitIndexedDB || window.msIndexedDB    let open = indexedDB.open(&#39;db-name&#39;, 1)    open.onupgradeneeded = function() {        let db = open.result        db.createObjectStore(&#39;objectStoreName&#39;, { autoIncrement: true })    }    open.onsuccess = function() {        let db = open.result        let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readwrite&#39;)        let store = tx.objectStore(&#39;objectStoreName&#39;)        store.put({ firstname: &#39;John&#39;, lastname: &#39;Doe&#39;, age: 33 })        tx.oncomplete = function() {            db.close()        }    }}</code></pre><p>真啰嗦，还是用第三方库吧，用<a href="https://github.com/jakearchibald/idb">idb</a>好了</p><pre><code class="js">async function putSomeData() {    let db = await idb.open(&#39;db-name&#39;, 1, upgradeDB =&gt; upgradeDB.createObjectStore(&#39;objectStoreName&#39;, { autoIncrement: true }))    let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readwrite&#39;)    let store = tx.objectStore(&#39;objectStoreName&#39;)    await store.put({ firstname: &#39;John&#39;, lastname: &#39;Doe&#39;, age: 33 })    await tx.complete    db.close()}async function getAllData() {    let db = await idb.open(&#39;db-name&#39;, 1)    let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readonly&#39;)    let store = tx.objectStore(&#39;objectStoreName&#39;)    // add, clear, count, delete, get, getAll, getAllKeys, getKey, put    let allSavedItems = await store.getAll()    console.log(allSavedItems)    db.close()}</code></pre><h3 id="扯一点关于存储的东西"><a href="#扯一点关于存储的东西" class="headerlink" title="扯一点关于存储的东西"></a>扯一点关于存储的东西</h3><p>当浏览器进入私人模式(private browsing mode，Google Chrome 上对应的应该是叫隐身模式)的时候，会创建一个新的、临时的、空的数据库，用以存储本地数据(local storage data)。当浏览器关闭时，里面的所有数据都将被丢弃。</p><p>判断方式</p><pre><code class="js">//隐身模式下和localStorage满了都会报同样的错误try {  window.localStorage.setItem(&#39;test&#39;, &#39;test&#39;)} catch (e)  {  console.log(e) //QuotaExceddedError(DOM Exception 22):The quota has been exceeded.}</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;浏览器indexedDb使用方式及注意的点&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/black-mountains.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="前端" scheme="https://haldir65.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
      <category term="javaScript" scheme="https://haldir65.github.io/tags/javaScript/"/>
    
  </entry>
  
  <entry>
    <title>cmake实用手册</title>
    <link href="https://haldir65.github.io/2018/11/26/2018-11-26-cmake-intro/"/>
    <id>https://haldir65.github.io/2018/11/26/2018-11-26-cmake-intro/</id>
    <published>2018-11-26T13:42:16.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>当我们敲下cmake命令的时候，cmake会在当前目录下找CMakeLists.txt这个文件，找不到会报错的</p><p><img src="https://www.haldir66.ga/static/imgs/fresh-sparkle-dew-drops-on-red-flower-wallpaper-53861cf580909.jpg" alt=""><br><a id="more"></a></p><p>下面就是最简单的一个CMakeLists.txt的例子，project(hello_cmake)是一个函数，该函数生成了PROJECT_NAME这个变量，所以下面直接用了。add_executable（）第一个参数是要生成的可执行文件的名字，第二个参数(其实可以包括所有编译需要的源文件)</p><blockquote><p>cmake_minimum_required(VERSION 3.5)<br>project (hello_cmake)<br>add_executable(${PROJECT_NAME} main.cpp)</p></blockquote><p>这个更简单</p><blockquote><p>cmake_minimum_required(VERSION 2.8)<br>project(app_project)<br>add_executable(myapp main.c)<br>install(TARGETS myapp DESTINATION bin)</p></blockquote><p>生成Makefile<br>mkdir _build &amp;&amp; cd _build &amp;&amp; cmake .. -DCMAKE_INSTALL_PREFIX=../_install<br>生成的Makefile拿来用:<br>make &amp;&amp; make install<br>省的手写Makefile了</p><p>cmake支持In-Place Build和Out-of-Source Build。前者是直接在当前文件夹（CMAKE_BINARY_DIR）中生成一大堆文件（太乱了），后者则是在一个指定的文件夹中生成文件。<br>Out-of-source build其实很简单<br>mkdir build &amp;&amp; cd build/ &amp;&amp; cmake .. (在build文件夹中会生成一个Makefile)<br>make &amp;&amp; ./hello_cmake </p><p>一堆内置的变量供参考</p><table><thead><tr><th>Variable</th><th>Info</th></tr></thead><tbody><tr><td>CMAKE_SOURCE_DIR</td><td>The root source directory</td></tr><tr><td>CMAKE_CURRENT_SOURCE_DIR</td><td>The current source directory if using sub-projects and directories.</td></tr><tr><td>PROJECT_SOURCE_DIR</td><td>The source directory of the current cmake project.</td></tr><tr><td>CMAKE_BINARY_DIR</td><td>The root binary / build directory. This is the directory where you ran the cmake command.</td></tr><tr><td>CMAKE_CURRENT_BINARY_DIR</td><td>The build directory you are currently in.</td></tr><tr><td>PROJECT_BINARY_DIR</td><td>The build directory for the current project.</td></tr></tbody></table><h3 id="header文件的处理"><a href="#header文件的处理" class="headerlink" title="header文件的处理"></a>header文件的处理</h3><p>可以指定多个源文件</p><blockquote><p>set(SOURCES<br>    src/Hello.cpp<br>    src/main.cpp<br>)<br>add_executable(${PROJECT_NAME} ${SOURCES})<br>//或者直接把src文件夹下面的所有.cpp文件加入进来<br>file(GLOB SOURCES “src/*.cpp”)</p></blockquote><h3 id="对于include文件夹"><a href="#对于include文件夹" class="headerlink" title="对于include文件夹"></a>对于include文件夹</h3><blockquote><p>target_include_directories(target<br>    PRIVATE<br>        ${PROJECT_SOURCE_DIR}/include<br>)<br>这样编译器就会在编译参数上加上-I/directory/path这种东西</p></blockquote><h3 id="static-library的处理"><a href="#static-library的处理" class="headerlink" title="static library的处理"></a>static library的处理</h3><pre><code>cmake_minimum_required(VERSION 3.5)project(hello_library)############################################################# Create a library#############################################################Generate the static library from the library sourcesadd_library(hello_library STATIC     src/Hello.cpp //创建一个libhello_library.a 的static library)target_include_directories(hello_library    PUBLIC         ${PROJECT_SOURCE_DIR}/include)############################################################# Create an executable############################################################# Add an executable with the above sourcesadd_executable(hello_binary     src/main.cpp)# link the new hello_library target with the hello_binary targettarget_link_libraries( hello_binary    PRIVATE         hello_library)</code></pre><h3 id="shared-library的处理"><a href="#shared-library的处理" class="headerlink" title="shared library的处理"></a>shared library的处理</h3><pre><code>cmake_minimum_required(VERSION 3.5)project(hello_library)############################################################# Create a library#############################################################Generate the shared library from the library sourcesadd_library(hello_library SHARED     src/Hello.cpp  // 用传入该函数的文件创建一个 libhello_library.so Library)add_library(hello::library ALIAS hello_library)target_include_directories(hello_library //hello_library需要这个include directory    PUBLIC         ${PROJECT_SOURCE_DIR}/include  )############################################################# Create an executable############################################################# Add an executable with the above sourcesadd_executable(hello_binary    src/main.cpp)# link the new hello_library target with the hello_binary targettarget_link_libraries( hello_binary // 接下来就是Link了，这里使用了上面的一个alias    PRIVATE         hello::library)</code></pre><h3 id="接下来是make-install-将生成的可执行文件安装到系统中，似乎就是复制到-usr-bin里面"><a href="#接下来是make-install-将生成的可执行文件安装到系统中，似乎就是复制到-usr-bin里面" class="headerlink" title="接下来是make install (将生成的可执行文件安装到系统中，似乎就是复制到/usr/bin里面)"></a>接下来是make install (将生成的可执行文件安装到系统中，似乎就是复制到/usr/bin里面)</h3><p>默认情况下cmake会把生成的可执行文件安装到系统中，我们可以指定安装到特定的位置<br>cmake .. -DCMAKE_INSTALL_PREFIX=/install/location</p><pre><code>install (TARGETS cmake_examples_inst_bin    DESTINATION bin)// target cmake_examples_inst_bin target to the destination ${CMAKE_INSTALL_PREFIX}/bininstall (TARGETS cmake_examples_inst    LIBRARY DESTINATION lib) //install the shared library generated from the target cmake_examples_inst target to the destination ${CMAKE_INSTALL_PREFIX}/lib</code></pre><blockquote><p>$ ls /usr/local/bin/<br>cmake_examples_inst_bin</p><p>$ ls /usr/local/lib<br>libcmake_examples_inst.so</p><p>$ ls /usr/local/etc/<br>cmake-examples.conf</p><p>$ LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib cmake_examples_inst_bin<br>Hello Install! //把生成的bin文件复制到/sur/local/bin目录下，再修改LDPATH,就能去/usr/locallib这个目录去找生成的library了</p></blockquote><h2 id="Autoconf-Automake教程"><a href="#Autoconf-Automake教程" class="headerlink" title="Autoconf/Automake教程"></a>Autoconf/Automake教程</h2><p>GNU Autotools 一般指的是3个 GNU 工具包：Autoconf，Automake 和 Libtool (本文先介绍前两个工具，Libtool留到今后介绍)<br>它们能解决什么问题，要先从 GNU 开源软件的 Build 系统说起。一般来说。GNU 软件的安装过程都是：</p><p>解压源代码包<br>./configure<br>make<br>make install（可能要切root用户）<br>这个过程中， 需要有一个 configure 脚本，同时也需要一个 Makefile 文件。</p><p>而 Autoconf 和 Automake 就是一套自动生成 configure 脚本和 Makefile 文件的工具。</p><p>在ubuntu上安装autoconf,automake,libtool:</p><blockquote><p>sudo apt install build-essential autoconf automake libtool libtool-bin autotools-dev</p></blockquote><p>configure文件是用autoconf根据configure.ac创建出来的，而configure.ac能用autoscan自动创建出来</p><p>随便创建一个文件夹</p><p>$ ls<br>epoch.c Makefile</p><p>$ cat epoch.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;sys/time.h&gt;#include &lt;time.h&gt;#include &quot;config.h&quot;double get_epoch(){  double sec;  #ifdef HAVE_GETTIMEOFDAY     struct timeval tv;     gettimeofday(&amp;tv, NULL);     sec = tv.tv_sec;     sec += tv.tv_usec / 1000000.0;  #else     sec = time(NULL);  #endif  return sec;}int main(int argc, char* argv[]){   printf(&quot;%f\n&quot;, get_epoch());   return 0;}</code></pre><p>这么写的原因是gettimeofday()这个函数不是在所有的平台上都有，这种时候就要用time()函数了。</p><p>$ cat Makefile</p><pre><code># Makefile: A standard Makefile for epoch.call: epochclean:    rm ­f epoch</code></pre><p>这样其实已经可以直接make生成可执行文件了。但是我们用autoconf来生成试一下</p><ol><li>生成config.h文件<br>config.h文件是configure命令根据config.h.in文件生成的，config.h.in文件是由autoheader（C的source code）中生成的（总之也是自动的）<br>$ ls<br>epoch.c Makefile<br>$ autoscan<br>$ ls<br>autoscan.log  configure.scan  epoch.c  Makefile<br>$  mv configure.scan configure.ac<br>$ ls<br>autoscan.log  configure.ac  epoch.c  Makefile<br>$ autoheader<br>$ ls<br>autom4te.cache  autoscan.log  config.h.in  configure.ac  epoch.c  Makefile<br>$  mv Makefile Makefile.in<br>$ autoconf<br>$ ls<br>autom4te.cache  autoscan.log  config.h.in  configure  configure.ac  epoch.c  Makefile.in<br>$ ./configure<br>checking for gcc… gcc<br>checking whether the C compiler works… yes<br>checking for C compiler default output file name… a.out<br>checking for suffix of executables…<br>checking whether we are cross compiling… no<br>checking for suffix of object files… o<br>checking whether we are using the GNU C compiler… yes<br>checking whether gcc accepts -g… yes<br>checking for gcc option to accept ISO C89… none needed<br>checking how to run the C preprocessor… gcc -E<br>checking for grep that handles long lines and -e… /bin/grep<br>checking for egrep… /bin/grep -E<br>checking for ANSI C header files… yes<br>checking for sys/types.h… yes<br>checking for sys/stat.h… yes<br>checking for stdlib.h… yes<br>checking for string.h… yes<br>checking for memory.h… yes<br>checking for strings.h… yes<br>checking for inttypes.h… yes<br>checking for stdint.h… yes<br>checking for unistd.h… yes<br>checking sys/time.h usability… yes<br>checking sys/time.h presence… yes<br>checking for sys/time.h… yes<br>checking for gettimeofday… yes<br>configure: creating ./config.status<br>config.status: creating Makefile<br>config.status: creating config.h<br>$  ls<br>autom4te.cache  autoscan.log  config.h  config.h.in  config.log  config.status  configure  configure.ac  epoch.c  Makefile  Makefile.in<br>$ make<br>$ ls<br>autom4te.cache  config.h     config.log     configure     epoch    Makefile<br>autoscan.log    config.h.in  config.status  configure.ac  epoch.c  Makefile.in<br>$  ./epoch<br>1544345416.704451</li></ol><p>//到此结束（这样做的意义在于一份代码就能够拥有多平台兼容性）</p><p>另一种方式<br>手动创造“Makefile.am”文件<br>$ cat Makefile.am</p><h1 id="Makefile-am-for-epoch-c"><a href="#Makefile-am-for-epoch-c" class="headerlink" title="Makefile.am for epoch.c"></a>Makefile.am for epoch.c</h1><p>bin_PROGRAMS=epoch<br>epoch_SOURCES=epoch.c</p><p>$ ls<br>epoch.c  Makefile.am</p><p>$ autoscan<br>$  mv configure.scan configure.ac<br>$ autoheader<br>$ ls<br>autom4te.cache  autoscan.log  config.h.in  configure.ac  epoch.c  Makefile.am<br>$ vim configure.ac<br>改成这样</p><pre><code>#                                               -*- Autoconf -*-# Process this file with autoconf to produce a configure script.AC_PREREQ([2.69])AC_INIT([FULL-PACKAGE-NAME], [VERSION], [BUG-REPORT-ADDRESS])AM_INIT_AUTOMAKEAC_CONFIG_SRCDIR([epoch.c])AC_CONFIG_HEADERS([config.h])# Checks for programs.AC_PROG_CC# Checks for libraries.# Checks for header files.AC_CHECK_HEADERS([sys/time.h])# Checks for typedefs, structures, and compiler characteristics.AC_HEADER_TIME# Checks for library functions.AC_CHECK_FUNCS([gettimeofday])AC_CONFIG_FILES([Makefile])AC_OUTPUT</code></pre><p>其实就是加了AM_INIT_AUTOMAKE这一行还有AC_HEADER_TIME<br>$ aclocal<br>$ automake ­­add­missing ­­copy<br>$ autoconf<br>$ ./configure 在这一步因为没有生成Makefile.in所以停下来了</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://mirkokiefer.com/cmake-by-example-f95eb47d45b1">cmake的教程，非常好</a><br><a href="https://github.com/ttroy50/cmake-examples">Useful CMake Examples</a>本文来自这里的实例<br><a href="http://www.lugod.org/presentations/autotools/presentation/autotools.pdf">autotools教程</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当我们敲下cmake命令的时候，cmake会在当前目录下找CMakeLists.txt这个文件，找不到会报错的&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/fresh-sparkle-dew-drops-on-red-flower-wallpaper-53861cf580909.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="C" scheme="https://haldir65.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>opengl学习笔记</title>
    <link href="https://haldir65.github.io/2018/11/15/2018-11-15-opengl-related-topics/"/>
    <id>https://haldir65.github.io/2018/11/15/2018-11-15-opengl-related-topics/</id>
    <published>2018-11-15T22:53:55.000Z</published>
    <updated>2019-01-25T15:20:53.219Z</updated>
    
    <content type="html"><![CDATA[<p>topics relating opengl stuff<br><img src="https://www.haldir66.ga/static/imgs/scenery151110074347.jpg" alt=""></p><a id="more"></a><p><a href="https://github.com/doggycoder/AndroidOpenGLDemo">本文多数代码来自这个系列</a></p><p>首先，<a href="https://medium.com/@wrongway4you/opengl-learning-in-2018-d556d96d7e7">不要学旧的版本</a>。<br>It is much better to start from the “modern” OpenGL versions: Learn OpenGL &gt;3.0.</p><p>opengl device support on android</p><ul><li>OpenGL ES 1.0 &amp; 1.1 since Android 1.0 (API 4)</li><li>OpenGL ES 2.0 since Android 2.2 (API 8)</li><li>OpenGL ES 3.0 since Android 4.3 (API 18) (almost)</li><li>OpenGL ES 3.1 since Android 5.0 (API 21)</li></ul><p>OpenGL ES is a variant of OpenGL’s specifications for embedded system. </p><blockquote><p>Graphics progamming for OpenGL ES 2.0 and 3.0 is largely similar, with version 3.0 representing a superset of the 2.0 API with additional features. Programming for the OpenGL ES 1.0/1.1 API versus OpenGL ES 2.0 and 3.0 differs significantly(2.0和3.0的语法差不多，3.0就是加了点特性。1.0和他俩的语法不同，不要学)<br>总的来讲，2.0和3.0要比1.0的性能好，能够对硬件有更自由的掌控（the API provides a great deal of control over the graphics rendering pipeline.），但是语法要复杂些。</p></blockquote><h2 id="Android提供了很多用于和OPENGL环境交互的class"><a href="#Android提供了很多用于和OPENGL环境交互的class" class="headerlink" title="Android提供了很多用于和OPENGL环境交互的class"></a>Android提供了很多用于和OPENGL环境交互的class</h2><p>开发者使用java环境  -&gt; 描述绘制图形 -&gt; graphics rendering pipeline<br>最简单的View是GLSurfaceView，实现渲染的逻辑在GLSurfaceView.Renderer中。如果想要只在view的布局一部分中使用gl功能的请使用TextureView，For real, do-it-yourself developers, it is also possible to build up an OpenGL ES view using SurfaceView, but this requires writing quite a bit of additional code。</p><p>GLSurfaceView.Renderer</p><pre><code class="java">    public interface Renderer {        void onSurfaceCreated(GL10 gl, EGLConfig config);        void onSurfaceChanged(GL10 gl, int width, int height);        void onDrawFrame(GL10 gl);    }</code></pre><p>render就这么三个方法，这三个方法都在一条叫做GLThread的线程上被调用</p><h2 id="检查当前设备的opengles版本"><a href="#检查当前设备的opengles版本" class="headerlink" title="检查当前设备的opengles版本:"></a>检查当前设备的opengles版本:</h2><p>在GLSurfaceView.Renderer的onSurfaceCreated中添加</p><pre><code class="java">// Create a minimum supported OpenGL ES context, then check:String version = gl.glGetString(GL10.GL_VERSION);Log.w(TAG, &quot;Version: &quot; + version );// The version format is displayed as: &quot;OpenGL ES &lt;major&gt;.&lt;minor&gt;&quot;// followed by optional content provided by the implementation.</code></pre><p>我在一台5.1的设备上打印出来的是”OpenGL ES 3.1”这么几个字。</p><h2 id="坐标系"><a href="#坐标系" class="headerlink" title="坐标系"></a>坐标系</h2><blockquote><p>By default, OpenGL ES assumes a coordinate system where [0,0,0] (X,Y,Z) specifies the center of the GLSurfaceView frame, [1,1,0] is the top right corner of the frame and [-1,-1,0] is bottom left corner of the frame<br>opengl使用三维坐标系，右手坐标，屏幕中心为原点，z轴垂直于屏幕，往上是正数。屏幕中心往右走是x轴正轴，屏幕中心往上走是y轴正轴。</p></blockquote><h2 id="culling"><a href="#culling" class="headerlink" title="culling"></a>culling</h2><p>（就是告诉opengl完全忽略掉背面，不要浪费时间去渲染看不见的地方）<br>Face culling is an option for the OpenGL environment which allows the rendering pipeline to ignore (not calculate or draw) the back face of a shape, saving time, memory and processing cycles:（好处就是节省时间和运算量）<br>比方说完全忽略掉背面</p><pre><code class="java">// enable face culling featuregl.glEnable(GL10.GL_CULL_FACE);// specify which faces to not drawgl.glCullFace(GL10.GL_BACK);</code></pre><p>还有，默认的作图顺序是<strong>逆时针</strong>的</p><h2 id="Texture-compression"><a href="#Texture-compression" class="headerlink" title="Texture compression"></a>Texture compression</h2><p>能够极大的节约内存，并充分利用内存带宽提升性能<br>包括这么几个:<br>ETC1 compression format(但不支持有alpha channel，就是带透明度的)<br>The ETC2/EAC texture compression formats (支持带alpha channel)</p><p>查看当前设备支持的OpenGL extensions(entension就是标准之外的，部分厂商硬件支持的特性)</p><pre><code class="java"> // Get the list of extensions.        String extensionList = GLES10.glGetString(GLES10.GL_EXTENSIONS);        if (!TextUtils.isEmpty(extensionList)) {            // The list of extensions comes from the driver separated by spaces.            // Split them apart and add them into a Set for deduping purposes.            for (String extension : extensionList.split(&quot; &quot;)) {                glExtensions.add(extension);            }        }</code></pre><p><a href="https://blog.csdn.net/junzia/article/details/52793354">OpenGL ES 2.0过程及理解</a><br>OpenGL ES 2.0渲染过程为：<br>读取顶点数据——执行顶点着色器——组装图元——光栅化图元——执行片元着色器——写入帧缓冲区——显示到屏幕上。<br>OpenGL作为本地库直接运行在硬件上，没有虚拟机，也没有垃圾回收或者内存压缩。在Java层定义图像的数据需要能被OpenGL存取，因此，需要把内存从Java堆复制到本地堆。<br>顶点着色器是针对每个顶点都会执行的程序，是确定每个顶点的位置。同理，片元着色器是针对每个片元都会执行的程序，确定每个片元的颜色。<br>着色器需要进行编译，然后链接到OpenGL程序中。一个OpenGL的程序就是把一个顶点着色器和一个片段着色器链接在一起变成单个对象。</p><h3 id="定义shape"><a href="#定义shape" class="headerlink" title="定义shape"></a>定义shape</h3><p>点，线，三角形，这三个是opengl的图形基础，其他任何集合图形都可以用三角形拼凑出来。<br><a href="https://developer.android.com/training/graphics/opengl/shapes">根据官方文档</a>，开发者需要往opengl传一个float的array作为要绘制的对象的坐标，在java里用ArrayBuffer比较好(这部分内存是传到硬件层的)。<br>官方文档上这样定义了一个三角形</p><pre><code class="java">public class Triangle {    private FloatBuffer vertexBuffer;    // number of coordinates per vertex in this array    static final int COORDS_PER_VERTEX = 3;    static float triangleCoords[] = {   // in counterclockwise order:             0.0f,  0.622008459f, 0.0f, // top            -0.5f, -0.311004243f, 0.0f, // bottom left             0.5f, -0.311004243f, 0.0f  // bottom right    }; //逆时针走向    // Set color with red, green, blue and alpha (opacity) values    float color[] = { 0.63671875f, 0.76953125f, 0.22265625f, 1.0f };    public Triangle() {        // initialize vertex byte buffer for shape coordinates        ByteBuffer bb = ByteBuffer.allocateDirect(                // (number of coordinate values * 4 bytes per float)                triangleCoords.length * 4);        // use the device hardware&#39;s native byte order        bb.order(ByteOrder.nativeOrder()); //字节序        // create a floating point buffer from the ByteBuffer        vertexBuffer = bb.asFloatBuffer();        // add the coordinates to the FloatBuffer        vertexBuffer.put(triangleCoords);        // set the buffer to read the first coordinate        vertexBuffer.position(0);    }}</code></pre><p>正方形就可以由两个三角形拼在一起组成</p><pre><code class="java">public class Square {    private FloatBuffer vertexBuffer;    private ShortBuffer drawListBuffer;    // number of coordinates per vertex in this array    static final int COORDS_PER_VERTEX = 3;    static float squareCoords[] = {            -0.5f,  0.5f, 0.0f,   // top left            -0.5f, -0.5f, 0.0f,   // bottom left             0.5f, -0.5f, 0.0f,   // bottom right             0.5f,  0.5f, 0.0f }; // top right    private short drawOrder[] = { 0, 1, 2, 0, 2, 3 }; // order to draw vertices    public Square() {        // initialize vertex byte buffer for shape coordinates        ByteBuffer bb = ByteBuffer.allocateDirect(        // (# of coordinate values * 4 bytes per float)                squareCoords.length * 4);        bb.order(ByteOrder.nativeOrder());        vertexBuffer = bb.asFloatBuffer();        vertexBuffer.put(squareCoords);        vertexBuffer.position(0);        // initialize byte buffer for the draw list        ByteBuffer dlb = ByteBuffer.allocateDirect(        // (# of coordinate values * 2 bytes per short)                drawOrder.length * 2);        dlb.order(ByteOrder.nativeOrder());        drawListBuffer = dlb.asShortBuffer();        drawListBuffer.put(drawOrder);        drawListBuffer.position(0);    }}</code></pre><h3 id="绘制定义的shape"><a href="#绘制定义的shape" class="headerlink" title="绘制定义的shape"></a>绘制定义的shape</h3><p>首先在onSurfaceCreated里面创建要绘制的shape对象</p><pre><code class="java">   private Triangle mTriangle;    private Square   mSquare;    public void onSurfaceCreated(GL10 unused, EGLConfig config) {        ...        // initialize a triangle        mTriangle = new Triangle();        // initialize a square        mSquare = new Square();    }</code></pre><p>接下来就是比较麻烦的地方了，必须要定义这几样东西</p><ul><li>Vertex Shader - OpenGL ES graphics code for rendering the vertices of a shape.（顶点着色器）</li><li>Fragment Shader - OpenGL ES code for rendering the face of a shape with colors or textures.(片元着色器)</li><li>Program - An OpenGL ES object that contains the shaders you want to use for drawing one or more shapes.</li></ul><p>至少需要一个vertex shader去画shape，一个fragment shader去画shape的颜色，这俩被编译并添加到opengles program中，后者将被用来画这个shape</p><pre><code class="java">public class Triangle {    private final String vertexShaderCode =        &quot;attribute vec4 vPosition;&quot; +        &quot;void main() {&quot; +        &quot;  gl_Position = vPosition;&quot; +        &quot;}&quot;;    private final String fragmentShaderCode =        &quot;precision mediump float;&quot; +        &quot;uniform vec4 vColor;&quot; +        &quot;void main() {&quot; +        &quot;  gl_FragColor = vColor;&quot; +        &quot;}&quot;;    ...}public static int loadShader(int type, String shaderCode){    // create a vertex shader type (GLES20.GL_VERTEX_SHADER)    // or a fragment shader type (GLES20.GL_FRAGMENT_SHADER)    int shader = GLES20.glCreateShader(type);    // add the source code to the shader and compile it    GLES20.glShaderSource(shader, shaderCode);    GLES20.glCompileShader(shader); //编译shader并link program很耗费cpu，所以只要做一次，一般放在shape的构造函数里面    return shader;}</code></pre><p>所以最后Triangle的代码变成这样</p><pre><code class="js">// number of coordinates per vertex in this arrayconst val COORDS_PER_VERTEX = 3var triangleCoords = floatArrayOf(     // in counterclockwise order:    0.0f, 0.622008459f, 0.0f,      // top    -0.5f, -0.311004243f, 0.0f,    // bottom left    0.5f, -0.311004243f, 0.0f      // bottom right)class Triangle {    // Set color with red, green, blue and alpha (opacity) values    val color = floatArrayOf(0.63671875f, 0.76953125f, 0.22265625f, 1.0f)    private var vertexBuffer: FloatBuffer =    // (number of coordinate values * 4 bytes per float)        ByteBuffer.allocateDirect(triangleCoords.size * 4).run {            // use the device hardware&#39;s native byte order            order(ByteOrder.nativeOrder())            // create a floating point buffer from the ByteBuffer            asFloatBuffer().apply {                // add the coordinates to the FloatBuffer                put(triangleCoords)                // set the buffer to read the first coordinate                position(0)            }        }    private var mProgram: Int    private val vertexShaderCode =        &quot;attribute vec4 vPosition;&quot; +                &quot;void main() {&quot; +                &quot;  gl_Position = vPosition;&quot; +                &quot;}&quot;    private val fragmentShaderCode =        &quot;precision mediump float;&quot; +                &quot;uniform vec4 vColor;&quot; +                &quot;void main() {&quot; +                &quot;  gl_FragColor = vColor;&quot; +                &quot;}&quot;    private val vertexCount: Int = triangleCoords.size / COORDS_PER_VERTEX    private val vertexStride: Int = COORDS_PER_VERTEX * 4 // 4 bytes per vertex    init {        val vertexShader: Int = loadShader(GLES20.GL_VERTEX_SHADER, vertexShaderCode)        val fragmentShader: Int = loadShader(GLES20.GL_FRAGMENT_SHADER, fragmentShaderCode)        // create empty OpenGL ES Program        mProgram = GLES20.glCreateProgram().also {            // add the vertex shader to program            GLES20.glAttachShader(it, vertexShader)            // add the fragment shader to program            GLES20.glAttachShader(it, fragmentShader)            // creates OpenGL ES program executables            GLES20.glLinkProgram(it)        }    }    private var mPositionHandle: Int = 0    private var mColorHandle: Int = 0    fun loadShader(type: Int, shaderCode: String): Int {        // create a vertex shader type (GLES20.GL_VERTEX_SHADER)        // or a fragment shader type (GLES20.GL_FRAGMENT_SHADER)        return GLES20.glCreateShader(type).also { shader -&gt;            // add the source code to the shader and compile it            GLES20.glShaderSource(shader, shaderCode)            GLES20.glCompileShader(shader)        }    }    fun draw() {        // Add program to OpenGL ES environment        GLES20.glUseProgram(mProgram)        // get handle to vertex shader&#39;s vPosition member        mPositionHandle = GLES20.glGetAttribLocation(mProgram, &quot;vPosition&quot;).also {            // Enable a handle to the triangle vertices            GLES20.glEnableVertexAttribArray(it)            // Prepare the triangle coordinate data            GLES20.glVertexAttribPointer(                it,                COORDS_PER_VERTEX,                GLES20.GL_FLOAT,                false,                vertexStride,                vertexBuffer            )            // get handle to fragment shader&#39;s vColor member            mColorHandle = GLES20.glGetUniformLocation(mProgram, &quot;vColor&quot;).also { colorHandle -&gt;                // Set color for drawing the triangle                GLES20.glUniform4fv(colorHandle, 1, color, 0)            }            // Draw the triangle            GLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0, vertexCount)            // Disable vertex array            GLES20.glDisableVertexAttribArray(it)        }    }}</code></pre><h3 id="接下来是-Apply-projection-and-camera-views"><a href="#接下来是-Apply-projection-and-camera-views" class="headerlink" title="接下来是 Apply projection and camera views"></a>接下来是 Apply projection and camera views</h3><p>Projection 就是根据设备的实际屏幕尺寸调节绘制坐标<br>Camera View 就是根据一个假想的camera视角调节坐标</p><h3 id="着色器语言GLSL"><a href="#着色器语言GLSL" class="headerlink" title="着色器语言GLSL"></a>着色器语言GLSL</h3><p>写到这里，基本的流程就是在onSurfaceCreated中去loadShader，而shaderCode一般是这样的。</p><pre><code class="s">uniform mat4 vMatrix;varying vec4 vColor;attribute vec4 vPosition;void main(){    gl_Position=vMatrix*vPosition;    if(vPosition.z!=0.0){        vColor=vec4(0.0,0.0,0.0,1.0);    }else{        vColor=vec4(0.9,0.9,0.9,1.0);    }}</code></pre><p>这是一门高级的图形化编程语言，其源于应用广泛的C语言，主要特性包括:</p><ul><li>GLSL是一种面向过程的语言，和Java的面向对象是不同的。</li><li>GLSL的基本语法与C/C++基本相同。</li><li>它完美的支持向量和矩阵操作。</li><li>它是通过限定符操作来管理输入输出类型的。</li><li>GLSL提供了大量的内置函数来提供丰富的扩展功能。</li></ul><h3 id="顶点着色器的内建变量"><a href="#顶点着色器的内建变量" class="headerlink" title="顶点着色器的内建变量"></a>顶点着色器的内建变量</h3><p>gl_Position：顶点坐标<br>gl_PointSize：点的大小，没有赋值则为默认值1，通常设置绘图为点绘制才有意义。</p><h3 id="片元着色器的内建变量"><a href="#片元着色器的内建变量" class="headerlink" title="片元着色器的内建变量"></a>片元着色器的内建变量</h3><p>输入变量<br>gl_FragCoord：当前片元相对窗口位置所处的坐标。<br>gl_FragFacing：bool型，表示是否为属于光栅化生成此片元的对应图元的正面。<br>输出变量<br>gl_FragColor：当前片元颜色<br>gl_FragData：vec4类型的数组。向其写入的信息，供渲染管线的后继过程使用。</p><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数:"></a>内置函数:</h3><p>纹理采样函数<br>纹理采样函数有texture2D、texture2DProj、texture2DLod、texture2DProjLod、textureCube、textureCubeLod及texture3D、texture3DProj、texture3DLod、texture3DProjLod等。</p><p>向量在GPU中由硬件支持运算，比CPU快的多。<br><a href="https://blog.csdn.net/junzia/article/details/52830604">总的来说这门语言要比其他编程语言简单些</a></p><h3 id="用OpenGL-ES显示图片"><a href="#用OpenGL-ES显示图片" class="headerlink" title="用OpenGL ES显示图片"></a>用OpenGL ES显示图片</h3><p>纹理(texture):<br>在理解纹理映射时，可以将纹理看做应用在物体表面的像素颜色。在真实世界中，纹理表示一个对象的颜色、图案以及触觉特征。纹理只表示对象表面的彩色图案，它不能改变对象的几何形式。更进一步的说，它只是一种高强度的计算行为。</p><p>比如一张矩形的图片是由两个三角形拼起来的，左下 -&gt; 左上 -&gt; 右下 -&gt; 右上 的顺序就能得到图片的纹理<br>下面这段代码也不是很懂，照着注释看吧</p><pre><code class="java">  @Override    public void onDrawFrame(GL10 gl) {        GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT|GLES20.GL_DEPTH_BUFFER_BIT);        GLES20.glUseProgram(mProgram);        onDrawSet(); // 在这里添加模糊，暖色调，冷色调等滤镜效果        GLES20.glUniform1i(hIsHalf,isHalf?1:0);        GLES20.glUniform1f(glHUxy,uXY);        GLES20.glUniformMatrix4fv(glHMatrix,1,false,mMVPMatrix,0);        GLES20.glEnableVertexAttribArray(glHPosition);        GLES20.glEnableVertexAttribArray(glHCoordinate);        GLES20.glUniform1i(glHTexture, 0);        textureId=createTexture();        GLES20.glVertexAttribPointer(glHPosition,2,GLES20.GL_FLOAT,false,0,bPos);        GLES20.glVertexAttribPointer(glHCoordinate,2,GLES20.GL_FLOAT,false,0,bCoord);        GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP,0,4);    }    public abstract void onDrawSet();    public abstract void onDrawCreatedSet(int mProgram);    private int createTexture(){        int[] texture=new int[1];        if(mBitmap!=null&amp;&amp;!mBitmap.isRecycled()){            //生成纹理            GLES20.glGenTextures(1,texture,0);            //生成纹理            GLES20.glBindTexture(GLES20.GL_TEXTURE_2D,texture[0]);            //设置缩小过滤为使用纹理中坐标最接近的一个像素的颜色作为需要绘制的像素颜色            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_MIN_FILTER,GLES20.GL_NEAREST);            //设置放大过滤为使用纹理中坐标最接近的若干个颜色，通过加权平均算法得到需要绘制的像素颜色            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D,GLES20.GL_TEXTURE_MAG_FILTER,GLES20.GL_LINEAR);            //设置环绕方向S，截取纹理坐标到[1/2n,1-1/2n]。将导致永远不会与border融合            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_S,GLES20.GL_CLAMP_TO_EDGE);            //设置环绕方向T，截取纹理坐标到[1/2n,1-1/2n]。将导致永远不会与border融合            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_T,GLES20.GL_CLAMP_TO_EDGE);            //根据以上指定的参数，生成一个2D纹理            GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, mBitmap, 0);             return texture[0];        }        return 0;    }</code></pre><p>显示图片的关键代码:<br>GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, mBitmap, 0);</p><p>滤镜这些特效本质上是在onDrawFrame里面去调用这两个函数</p><pre><code class="java">GLES20.glUniform1i(hChangeType,filter.getType());GLES20.glUniform3fv(hChangeColor,1,filter.data(),0);</code></pre><p>所以，滤镜(filter)效果对应的片元着色器可以这样写:<br>GLSL语言</p><pre><code class="s">precision mediump float;uniform sampler2D vTexture;uniform int vChangeType;uniform vec3 vChangeColor;uniform int vIsHalf;uniform float uXY;      //屏幕宽高比varying vec4 gPosition;varying vec2 aCoordinate;varying vec4 aPos;void modifyColor(vec4 color){    color.r=max(min(color.r,1.0),0.0);    color.g=max(min(color.g,1.0),0.0);    color.b=max(min(color.b,1.0),0.0);    color.a=max(min(color.a,1.0),0.0);}void main(){    vec4 nColor=texture2D(vTexture,aCoordinate);    if(aPos.x&gt;0.0||vIsHalf==0){        if(vChangeType==1){    //黑白图片            float c=nColor.r*vChangeColor.r+nColor.g*vChangeColor.g+nColor.b*vChangeColor.b;            gl_FragColor=vec4(c,c,c,nColor.a);        }else if(vChangeType==2){    //简单色彩处理，冷暖色调、增加亮度、降低亮度等            vec4 deltaColor=nColor+vec4(vChangeColor,0.0);            modifyColor(deltaColor);            gl_FragColor=deltaColor;        }else if(vChangeType==3){    //模糊处理            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.r,aCoordinate.y-vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.r,aCoordinate.y+vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.r,aCoordinate.y-vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.r,aCoordinate.y+vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.g,aCoordinate.y-vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.g,aCoordinate.y+vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.g,aCoordinate.y-vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.g,aCoordinate.y+vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.b,aCoordinate.y-vChangeColor.b));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.b,aCoordinate.y+vChangeColor.b));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.b,aCoordinate.y-vChangeColor.b));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.b,aCoordinate.y+vChangeColor.b));            nColor/=13.0;            gl_FragColor=nColor;        }else if(vChangeType==4){  //放大镜效果            float dis=distance(vec2(gPosition.x,gPosition.y/uXY),vec2(vChangeColor.r,vChangeColor.g));            if(dis&lt;vChangeColor.b){                nColor=texture2D(vTexture,vec2(aCoordinate.x/2.0+0.25,aCoordinate.y/2.0+0.25));            }            gl_FragColor=nColor;        }else{            gl_FragColor=nColor;        }    }else{        gl_FragColor=nColor;    }</code></pre><h3 id="相机预览"><a href="#相机预览" class="headerlink" title="相机预览"></a>相机预览</h3><p>利用OpenGLES显示图片处理图片。视频每一帧其实也是一张图片，Camera预览时，每一帧自然也是一幅图片，我们可以把每张图片按照时间顺序显示出来，就完成了Camera预览的实现。<br>当然不可能把相机每一帧的数据转成一个bitmap来操作，GLES20提供了绑定纹理贴图的函数。<br>GLES20.java</p><pre><code> // C function void glTexImage2D ( GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, const GLvoid *pixels )    public static native void glTexImage2D(        int target,        int level,        int internalformat,        int width,        int height,        int border,        int format,        int type,        java.nio.Buffer pixels    );</code></pre><p>完全就是c函数的包装<br>虽然OpenGLES给我们提供的入口是传入Buffer，然而，它却限制了Buffer的格式为单一通道，或者是RGBA、RGB等格式，而Camera的帧数据却只能为NV21或者YV21的<br>Android的Camera及Camera2都允许使用SurfaceTexture作为预览载体，但是它们所使用的SurfaceTexture传入的OpenGL texture object name必须为GLES11Ext.GL_TEXTURE_EXTERNAL_OES。这种方式，实际上就是两个OpenGL Thread共享一个Texture，不再需要数据导入导出，从Camera采集的数据直接在GPU中完成转换和渲染。<br>关键函数是surfaceTexture.updateTexImage()，每当摄像头有新的数据来时，我们需要通过surfaceTexture.updateTexImage()更新预览上的图像。</p><h3 id="图片处理"><a href="#图片处理" class="headerlink" title="图片处理"></a>图片处理</h3><p>冷色调、暖色调、复古、黑白这些滤镜效果其实就是把hex color的ARGB channel调整一下。</p><pre><code class="xml">&lt;color name=&quot;bg_color&quot;&gt;#FF88269F&lt;/color&gt;</code></pre><p>黑白图片是怎么来的？<br>黑白图片上，每个像素点的RGB三个通道值应该是相等的。知道了这个，将彩色图片处理成黑白图片就非常简单了。我们直接获取像素点的RGB三个通道，相加然后除以3作为处理后每个通道的值就可以得到一个黑白图片了。这是均值的方式是常见黑白图片处理的一种方法。类似的还有权值方法（给予RGB三个通道不同的比例）、只取绿色通道等方式。<br>与之类似的，冷色调的处理就是单一增加蓝色通道的值，暖色调的处理可以增加红绿通道的值。还有其他复古、浮雕等处理也都差不多。</p><p>图片模糊<br>图片模糊处理相对上面的色调处理稍微复杂一点，通常图片模糊处理是采集周边多个点，然后利用这些点的色彩和这个点自身的色彩进行计算，得到一个新的色彩值作为目标色彩。模糊处理有很多算法，类似高斯模糊、径向模糊等等。</p><h3 id="YUV格式解释-相机返回的是YUV格式的图像数据"><a href="#YUV格式解释-相机返回的是YUV格式的图像数据" class="headerlink" title="YUV格式解释(相机返回的是YUV格式的图像数据)"></a>YUV格式解释(相机返回的是YUV格式的图像数据)</h3><blockquote><p>RGB图像大家都了解，RGB图像分为了三个颜色分量，R红色分量，G绿色分量，B蓝色分量。而YUV图像，也是分为了三个分量，Y亮度分量，用来表示明亮度，也叫灰阶值，U分量和V分量是色值分量，用来表示图像色彩与饱和度，其中U分量也叫Cb，表示的图像蓝色偏移量，V分量也叫Cr，用来表示图像红色部分偏移量，所以YUV有时也写作YCbCr。<br>YUV图像把亮度和色度分开了，避免了亮度和色度的相互干扰，可以在降低色度采样率的情况下，保持图像的视觉质量。<br>```<br>RGB转YUV:</p></blockquote><p>Y = 0.299 R + 0.587 G + 0.114 B</p><p>U = - 0.1687 R - 0.3313 G + 0.5 B + 128</p><p>V = 0.5 R - 0.4187 G - 0.0813 B + 128</p><p>YUV转RGB:</p><p>R = Y + 1.402 (V - 128)</p><p>G = Y - 0.34414 (U - 128) - 0.71414 (V - 128)</p><p>B = Y + 1.772 (U - 128)</p><pre><code>Camera可以通过setPreviewFormat()方法来设置预览图像的数据格式，推荐选择的有ImageFormat.NV21和ImageFormat.YV12，默认是NV21。NV21属于YUV图像.[YuvImage.compressToJpeg](https://developer.android.com/reference/android/graphics/YuvImage.html#compressToJpeg(android.graphics.Rect,%20int,%20java.io.OutputStream)) android sdk提供了将yuv转为jpg的方法</code></pre><p>public boolean compressToJpeg (Rect rectangle,<br>                int quality,<br>                OutputStream stream)<br>```<br>将一个YuvImage压缩成jpeg，存到一个outputStream中。<strong>这个方法借助Android的JNI，实现了非常高效率的JPEG格式文件写入（比Bitmap.compress()效率都要高不少）</strong></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://developer.android.com/guide/topics/graphics/opengl">opengles guide on android</a><br><a href="https://blog.csdn.net/junzia/article/details/77924629">Android利用硬解硬编和OpenGLES来高效的处理MP4视频</a><br><a href="https://github.com/aiyaapp/AiyaEffectsAndroid">第三方实例</a><br><a href="https://blog.csdn.net/tanningzhong/article/details/77989686">利用 FFmpeg 在 Android 上做视频编辑</a><br><a href="https://github.com/JimSeker/opengl">2018年还在更新的</a><br><a href="https://www.polarxiong.com/archives/Android-MediaCodec%E8%A7%86%E9%A2%91%E6%96%87%E4%BB%B6%E7%A1%AC%E4%BB%B6%E8%A7%A3%E7%A0%81-%E9%AB%98%E6%95%88%E7%8E%87%E5%BE%97%E5%88%B0YUV%E6%A0%BC%E5%BC%8F%E5%B8%A7-%E5%BF%AB%E9%80%9F%E4%BF%9D%E5%AD%98JPEG%E5%9B%BE%E7%89%87-%E4%B8%8D%E4%BD%BF%E7%94%A8OpenGL.html">硬件解码视频范例</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;topics relating opengl stuff&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/scenery151110074347.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="opengl" scheme="https://haldir65.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>python中多进程、多线程以及GIL记录</title>
    <link href="https://haldir65.github.io/2018/11/11/2018-11-11-python-gil-and-what-you-can-do-about-it/"/>
    <id>https://haldir65.github.io/2018/11/11/2018-11-11-python-gil-and-what-you-can-do-about-it/</id>
    <published>2018-11-11T22:21:52.000Z</published>
    <updated>2019-01-25T15:20:53.215Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/1102533137-5.jpg" alt=""></p><ul><li>If your code has a lot of I/O or Network usage:<br>Multithreading is your best bet because of its low overhead</li><li>If you have a GUI<br>Multithreading so your UI thread doesn’t get locked up</li><li>If your code is CPU bound:<br>You should use multiprocessing (if your machine has multiple cores)</li></ul><a id="more"></a><p>Python Global Interpreter Lock(GIL)<br>对于CPython，所有的python bytecode在执行前都需要获得interpreter的lock,one vm thread at a time。(java实现的python似乎没有这个烦恼)<br>GIL的出现似乎是历史原因（为了方便的直接使用当时现有的c extension）。而没有在python3中被移除的原因是因为这会造成单线程的程序在python3中跑的反而比python2中慢。</p><p>因为GIL的存在，python中的线程并不能实现cpu的并发运行(同时只能有一条线程在运行)。但对于I/O intensive的任务来说，cpu都在等待I/O操作完成，所以爬虫这类操作使用多线程是合适的。根据<a href="https://www.youtube.com/watch?v=7SSYhuk5hmc">A Jesse Jiryu Davis</a>在pycon2017上的演讲，在多线程python程序中，如果某条线程开始进行I/O操作，就会主动放弃GIL(这是在socket module的源码中)，或者在cpu-intensive程序中，一条线程连续执行1000次(python2中是一个常数)后就会被夺走gil。<a href="https://github.com/python/cpython/blob/master/Modules/socketmodule.c">socket里面找关键字Py_BEGIN_ALLOW_THREADS和Py_END_ALLOW_THREADS</a></p><h2 id="多线程以及一些同步的问题"><a href="#多线程以及一些同步的问题" class="headerlink" title="多线程以及一些同步的问题"></a>多线程以及一些同步的问题</h2><p>单线程的版本</p><pre><code class="python"># single_threaded.pyimport timefrom threading import ThreadCOUNT = 50000000def countdown(n):    while n&gt;0:        n -= 1start = time.time()countdown(COUNT)end = time.time()print(&#39;Time taken in seconds -&#39;, end - start)</code></pre><p>多线程的版本</p><pre><code class="python"># multi_threaded.pyimport timefrom threading import ThreadCOUNT = 50000000def countdown(n):    while n&gt;0:        n -= 1t1 = Thread(target=countdown, args=(COUNT//2,))t2 = Thread(target=countdown, args=(COUNT//2,))start = time.time()t1.start()t2.start()t1.join()t2.join()end = time.time()print(&#39;Time taken in seconds -&#39;, end - start)</code></pre><p>多线程虽然同一时刻只能有一条线程运行，但牵涉到数据共享的时候还是要加锁<br><img src="https://haldir66.ga/static/imgs/lockExplanation.jpg" alt=""></p><p>比如这个例子，照说打印出来的应该是0，但实际操作中可能打出来正数</p><pre><code class="python">import time, threading# 假定这是你的银行存款:balance = 0def change_it(n):    # 先存后取，结果应该为0:    global balance    balance = balance + n    balance = balance - ndef run_thread(n):    for i in range(1000000):        change_it(n)t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print(balance)</code></pre><p>上述过程的原因在于<br>balance = balance + n<br>这一步其实需要至少两条cpu语句：<br>x = balance +n<br>balance = x </p><p>正常顺序是t1 (+5,-5) t2 (+8, -8) 这样的顺序<br>不正常的顺序</p><pre><code>初始值 balance = 0t1: x1 = balance + 5  # x1 = 0 + 5 = 5t2: x2 = balance + 8  # x2 = 0 + 8 = 8t2: balance = x2      # balance = 8t1: balance = x1      # balance = 5t1: x1 = balance - 5  # x1 = 5 - 5 = 0t1: balance = x1      # balance = 0t2: x2 = balance -8 # x2 =-8t2: balance = x2 # balance = -8结果 balance = -8</code></pre><p>所以是有可能打印出-8这样的错误的结果的</p><p>这种情况下只要加锁就可以了</p><pre><code class="python">import time, threadingbalance = 0lock = threading.Lock()def change_it(n):    global balance    balance = balance + n    balance = balance - ndef run_thread(n):    for i in range(1000000):        lock.acquire()        try:            change_it(n)        finally:            lock.release()t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print(balance)</code></pre><p>改成每一次对共享变量进行操作都需要加锁之后，打印结果就正常了<br><a href="https://hackernoon.com/synchronization-primitives-in-python-564f89fee732">多进程之间的同步方式包括queue,Event,Semaphores，Conditions等</a></p><p>从bytecode来看，<a href="https://www.youtube.com/watch?v=7SSYhuk5hmc&amp;t=890s">increment这一操作并不是atomic的</a><br>python里面很方便<br>incremnt-is-not-atomic.py</p><pre><code class="python">def foo():    global n    n += 1import disdis.dis(foo)</code></pre><p>python incremnt-is-not-atomic.py</p><pre><code> 3           0 LOAD_GLOBAL              0 (n)              2 LOAD_CONST               1 (1)              4 INPLACE_ADD              6 STORE_GLOBAL             0 (n)              8 LOAD_CONST               0 (None)             10 RETURN_VALUE</code></pre><h2 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h2><p>多进程的版本</p><pre><code class="python">from multiprocessing import Poolimport timeCOUNT = 50000000def countdown(n):    while n&gt;0:        n -= 1if __name__ == &#39;__main__&#39;:    pool = Pool(processes=2)    start = time.time()    r1 = pool.apply_async(countdown, [COUNT//2])    r2 = pool.apply_async(countdown, [COUNT//2])    pool.close()    pool.join()    end = time.time()    print(&#39;Time taken in seconds -&#39;, end - start)</code></pre><p>多进程之间内存不共享，同步方式是使用Queue(fifo)</p><pre><code class="python">#!/usr/bin/env python3import multiprocessingimport timeimport randomimport osfrom multiprocessing import Queueq = Queue()def hello(n):    time.sleep(random.randint(1,3))    q.put(os.getpid())    print(&quot;[{0}] Hello!&quot;.format(n))processes = [ ]for i in range(10):    t = multiprocessing.Process(target=hello, args=(i,))    processes.append(t)    t.start()for one_process in processes:    one_process.join()mylist = [ ]while not q.empty():    mylist.append(q.get())print(&quot;Done!&quot;)print(len(mylist))print(mylist)</code></pre><p>更加Pythonic的方式是使用asyncio</p><h2 id="Asyncio"><a href="#Asyncio" class="headerlink" title="Asyncio"></a>Asyncio</h2><p>优点包括</p><ul><li>Based on futures</li><li>Faster than threads</li><li>Massive I/O concurrency</li></ul><pre><code class="python">async def fetch_url(url):        return await aiohttp.request(&#39;GET&#39; , url) ## you get the future, the function is not executed immediatedlyasync def fetch_two(url_a,url_b):        future_a = fetch_url(url_a)        future_b = fetch_url(url_b)        a ,b = await asyncio.gather(future_a, future_b)  ## 一旦开始await这个future,这个coroutine才会被加入event loop        return a, b</code></pre><p>上述代码虽然还是在同一个进程中运行，还受到GIL制约，但是由于是I/O操作，所以也没什么问题。只是在process返回的结果是，就会受到GIL的影响了。（实际操作中你会发现coroutine还没执行就timeout了）<br>也就是说，I/O操作用asyncio，数据处理使用multi-processing，这是最好的情况。<br>由于coroutine和multi-processing是两个相对独立的模块，所以需要自己把两者结合起来。用多进程进行数据处理，每个进程中各自有独立的coroutine在运行。<br><a href="https://www.youtube.com/watch?v=0kXaLh8Fz3k">John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018</a></p><pre><code class="python">async def run_loop(tx, rx):        ... ## real work here         limit = 10        pending = set()        while True:                while len(pending) &lt; limit:                        task = tx.get_nowait()                        fn ,args, kwargs = task                        pending.add(fn(args,kwargs))                done, pending = await asyncio.wait(pending, ..)                        for future in done:                        rx.put_nowait(await future)def bootstrap(tx, rx):        loop = asyncio.new_event_loop()        asyncio.set_event_loop(loop)        loop.run_untile_complete(run_loop(tx, rx))def main():                p = multiprocessing.Process(target = bootstrap, args = (tx, rx))        p.start()</code></pre><p>实际操作可能看起来像这样</p><pre><code class="python">async def fetch_url(url):        return await aiohttp.request(&#39;GET&#39; , url) def fetch_all(urls):       tx, rx = Queue(), Queue()       Process(               target=bootstrap,               args=(tx,rx)       ).start()       for url in urls:           task = fetch_url,(url,), {}           tx.put_nowait(task)</code></pre><p>已经开源 pip install aiomultiprocess<br><a href="https://github.com/dano/aioprocessing">aioprocessing</a></p><h2 id="关于协程"><a href="#关于协程" class="headerlink" title="关于协程"></a>关于协程</h2><p>coroutine是一个在很多编程语言中都有的概念，在python中coroutine一般指的是generator based coroutines。<br>首先，因为协程是一种能暂停的函数，那么它暂停是为了什么？一般是等待某个事件，比如说某个连接建立了；某个 socket 接收到数据了；某个计时器归零了等。而这些事件应用程序只能通过轮询的方式得知是否完成，<strong>但是操作系统（所有现代的操作系统）可以提供一些中断的方式通知应用程序，如 select, epoll, kqueue 等等</strong>。<br><a href="https://lotabout.me/2017/understand-python-asyncio/">understand-python-asyncio</a></p><p>基础是generator(任何包含yield expression的函数)</p><pre><code>$ &gt;&gt;&gt;def gen_fn():        print(&#39;start&#39;)        yiled 1        print(&#39;middle&#39;)        yield 2        print(&#39;done&#39;)$ &gt;&gt;&gt; gen = gen_fn()$ &gt;&gt;&gt; gen$ &lt;generator object gen_fn at 0x7f83cddc0b48&gt;&gt;&gt;&gt; gen.gi_code.co_code //对应的bytecodeb&#39;t\x00d\x01\x83\x01\x01\x00d\x02V\x00\x01\x00t\x00d\x03\x83\x01\x01\x00d\x04V\x00\x01\x00t\x00d\x05\x83\x01\x01\x00d\x00S\x00&#39;&gt;&gt;&gt; len(gen.gi_code.co_code)40&gt;&gt;&gt; gen.gi_frame.f_lasti //instruction pointer , 说明当前执行到哪个指令了，-1说明还没有开始执行-1&gt;&gt;&gt; next(gen)start1&gt;&gt;&gt; ret = next(gen)middle&gt;&gt;&gt; ret2 // next方法返回的是yield里面的值&gt;&gt;&gt; next(gen)doneTraceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;StopIteration // 这是正常的，说明generator执行完毕&gt;&gt;&gt; import dis&gt;&gt;&gt; dis.dis(gen)  2           0 LOAD_GLOBAL              0 (print)              2 LOAD_CONST               1 (&#39;start&#39;)              4 CALL_FUNCTION            1              6 POP_TOP  3           8 LOAD_CONST               2 (1)             10 YIELD_VALUE             12 POP_TOP  4          14 LOAD_GLOBAL              0 (print)             16 LOAD_CONST               3 (&#39;middle&#39;)             18 CALL_FUNCTION            1             20 POP_TOP  5          22 LOAD_CONST               4 (2)             24 YIELD_VALUE             26 POP_TOP  6          28 LOAD_GLOBAL              0 (print)             30 LOAD_CONST               5 (&#39;done&#39;)             32 CALL_FUNCTION            1             34 POP_TOP             36 LOAD_CONST               0 (None)             38 RETURN_VALUE&gt;&gt;&gt;</code></pre><p>python3.3中开始出现yield关键字，python3.4中开始引入asyncio标准库，python 3.5标准库中出现的async await关键字只是基于generator的sytatic sugar，那么<a href="https://stackoverflow.com/questions/8389812/how-are-generators-and-coroutines-implemented-in-cpython">generator是如何实现的</a>.</p><ul><li>The yield instruction takes the current executing context as a closure, and transforms it into an own living object. This object has a <strong>iter</strong> method which will continue after this yield statement.<br>So the call stack gets transformed into a heap object.</li></ul><p><a href="https://hackernoon.com/the-magic-behind-python-generator-functions-bc8eeea54220">解释generator实现原理的文章</a></p><p><a href="https://snarky.ca/how-the-heck-does-async-await-work-in-python-3-5/">python 2.5开始，generator能够返回数据，这之前还只是iteratble的</a> 还可以通过gen.send函数往generator传参数<br><a href="https://github.com/AndreLouisCaron/a-tale-of-event-loops">event-loop的实现原理简述</a></p><p>python3.4需要使用@coroutine的decorator，3.5之后直接使用async await关键字，确实更加方便</p><pre><code class="python">import asyncioimport timeasync def speak_async():     print(&#39;starting====&#39;)     r = await asyncio.sleep(1) ##这里不能使用time.sleep(1)    print(&#39;OMG asynchronicity!&#39;)loop = asyncio.get_event_loop()  loop.run_until_complete(speak_async())  loop.close()</code></pre><h3 id="多线程环境下对资源的操作需要考虑线程安全问题"><a href="#多线程环境下对资源的操作需要考虑线程安全问题" class="headerlink" title="多线程环境下对资源的操作需要考虑线程安全问题"></a>多线程环境下对资源的操作需要考虑线程安全问题</h3><p>有些操作不是原子性的<br><a href="https://www.youtube.com/watch?v=Bv25Dwe84g0">Thinking about Concurrency, Raymond Hettinger, Python core developer</a><br>java中最初的设计是有kill thread的method的，但是后来被deprecated了（假设你kill了一个获取了锁的线程，程序将进入死锁状态）。 python中理论上是可以kill一个线程的，但是kill一个线程这件事本身就是不应该的。</p><p>一个最简单的多线程资源竞争的例子</p><pre><code class="python">import threadingcounter = 0def worker():    global counter    counter += 1     print(&#39;The count is %d&#39; % counter)    print(&#39;------------&#39;)print(&#39;Starting up --------&#39;)for i in range(10):    threading.Thread(target=worker).start()print(&#39;Finishing up&#39;)</code></pre><p>输出</p><pre><code>Starting up --------The count is 1------------The count is 2------------The count is 3------------The count is 4------------The count is 5------------The count is 6------------The count is 7------------The count is 8------------The count is 9------------The count is 10------------Finishing up</code></pre><p>数据量比较小的时候不容易发现这里存在的race condition。如果在每一次对资源进行操作之间都插入一段thread.sleep，问题就出来了</p><pre><code class="python">import threading,time, randomFUZZ = Truedef fuzz():    if FUZZ:        time.sleep(random.random())counter = 0def worker():    global counter    fuzz()    oldcnt = counter    fuzz()    counter = oldcnt +1    fuzz()    print(&#39;The count is %d&#39; % counter)    fuzz()    print(&#39;------------&#39;)    fuzz()print(&#39;Starting up --------\n&#39;)fuzz()for i in range(10):    t = threading.Thread(target=worker)    t.start()    fuzz()print(&#39;Finishing up&#39;)  fuzz()</code></pre><p>资源竞争场景下，问题就出来了</p><pre><code>Starting up --------The count is 1------------The count is 2The count is 3------------------------The count is 5The count is 5------------------------The count is 5------------Finishing upThe count is 7The count is 8------------------------The count is 8------------The count is 8------------</code></pre><p>多线程之间的同步问题，一种是加锁，另一种是使用atomic message queue.<br>python中有些module内部已经加了锁，logging,decimal(thread local),databases(reader locks and writer locks),email(atomic message queue)。<br>锁在写operating system的时候非常有用，但是其他时候不要用。<br>所有的资源都应该只能同时被一条线程操作。<br>threading中的join就属于一种barrier（主线程调用t.join，就是等t跑完了之后，主线程再去干接下来的事情） </p><h3 id="Raymond-Hettinger提到message-queue的task-done方法是他created的。-还是atomic-measge-queue-好像是内部加了锁，操作queue中资源的只有那么一条线程，当然不存在并发问题-其实raymod也提到了，你也可以用RabbitMQ等-ZEROMQ-甚至是database（内部有read-write-lock）"><a href="#Raymond-Hettinger提到message-queue的task-done方法是他created的。-还是atomic-measge-queue-好像是内部加了锁，操作queue中资源的只有那么一条线程，当然不存在并发问题-其实raymod也提到了，你也可以用RabbitMQ等-ZEROMQ-甚至是database（内部有read-write-lock）" class="headerlink" title="Raymond Hettinger提到message queue的task_done方法是他created的。(还是atomic measge queue, 好像是内部加了锁，操作queue中资源的只有那么一条线程，当然不存在并发问题). 其实raymod也提到了，你也可以用RabbitMQ等,ZEROMQ 甚至是database（内部有read write lock）"></a>Raymond Hettinger提到message queue的task_done方法是他created的。(还是atomic measge queue, 好像是内部加了锁，操作queue中资源的只有那么一条线程，当然不存在并发问题). 其实raymod也提到了，你也可以用RabbitMQ等,ZEROMQ 甚至是database（内部有read write lock）</h3><pre><code class="python">def worker():    while True:        item = q.get()        do_work(item)        q.task_done()q = Queue()for i in range(num_worker_threads):     t = Thread(target=worker)     t.daemon = True     t.start()for item in source():    q.put(item)q.join()       # block until all tasks are done</code></pre><p>爬虫简单的多线程版本是每个线程创建的时候，就给出一个args = [someurl] ，然后有多少任务就创建多少线程。但是这样做迟早会碰上操作系统对最大线程数的设置[据说400+]，于是又想到用threadPool,自己实现threadpool的也是大有人在（内部持有一个任务队列，不停去队列里获取任务）。(<a href="https://www.shanelynn.ie/using-python-threading-for-multiple-results-queue/">https://www.shanelynn.ie/using-python-threading-for-multiple-results-queue/</a>)</p><pre><code>error: can&#39;t start new threadFile &quot;/usr/lib/python2.5/threading.py&quot;, line 440, in start    _start_new_thread(self.__bootstrap, ())</code></pre><p>那么比较实用的使用场景是，spawn 10条线程去进行while not queue.empty() -&gt; requests.get()操作，各自在完成之后丢到一个通用的容器中，再由message queue独立完成所有response的processing.</p><h2 id="牵涉到一些celery的点"><a href="#牵涉到一些celery的点" class="headerlink" title="牵涉到一些celery的点"></a>牵涉到一些celery的点</h2><p>celery能够利用好多进程<br>todo</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://codewithoutrules.com/2018/09/04/python-multiprocessing/">多进程还可以牵涉到进程池的概念</a><br><a href="https://realpython.com/python-gil/">What is the Python Global Interpreter Lock (GIL)?</a><br><a href="https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/">multiprocessing-vs-multithreading-in-python-what-you-need-to-know</a><br><a href="https://emptysqua.re/blog/links-for-how-python-coroutines-work/">A. Jesse Jiryu Davis</a><br><a href="https://www.youtube.com/watch?v=7sCu4gEjH5I">How Do Python Coroutines Work</a><br><a href="https://www.youtube.com/watch?v=7SSYhuk5hmc">A Jesse Jiryu Davis Grok the GIL Write Fast And Thread Safe Python PyCon 2017</a> the only thing two threads cann’t do in once in Python is run python<br><a href="https://engineering.mongodb.com/post/the-saga-of-concurrent-dns-in-python-and-the-defeat-of-the-wicked-mutex-troll/">Behold, my friends, the getaddrinfo lock in Python’s socketmodule.c:</a>  A. Jesse Jiryu Davis关于python中parallel dns query的文章也很好</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/1102533137-5.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If your code has a lot of I/O or Network usage:&lt;br&gt;Multithreading is your best bet because of its low overhead&lt;/li&gt;
&lt;li&gt;If you have a GUI&lt;br&gt;Multithreading so your UI thread doesn’t get locked up&lt;/li&gt;
&lt;li&gt;If your code is CPU bound:&lt;br&gt;You should use multiprocessing (if your machine has multiple cores)&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="python" scheme="https://haldir65.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>tcpdump和wireshark使用手册</title>
    <link href="https://haldir65.github.io/2018/11/10/2018-11-10-tcpdump-and-wireshark-etc/"/>
    <id>https://haldir65.github.io/2018/11/10/2018-11-10-tcpdump-and-wireshark-etc/</id>
    <published>2018-11-10T20:57:53.000Z</published>
    <updated>2019-01-25T15:20:53.215Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/osi-model.png" alt=""><br><a href="http://packetlife.net/media/library/13/Wireshark_Display_Filters.pdf">wireshark expression cheetsheet</a><br><a href="http://packetlife.net/media/library/12/tcpdump.pdf">tcpdump cheet</a><br>wireshark能抓tcp,arp,http,dns,udp,icmp,dhcp…</p><a id="more"></a><p>先从wireshark说起，在win10上安装wireshark需要顺带装上winpacp，不过现在的安装包默认都会提示去安装，所以也都很简单<br>tcpdump在Linux上比较容易安装，类似于wireshark的command line tool</p><h3 id="wireshark的filter"><a href="#wireshark的filter" class="headerlink" title="wireshark的filter"></a>wireshark的filter</h3><p>现在wireshark的filter都会自动提示了，所以基本上随手敲几个就行了</p><p>http ##只看http的<br>http.request<br>tcp.dstport == 443 ## 只看https的<br>tcp.port == 113 ## 不管是source还是destination，只要是port 113的都筛出来(113是一个特殊的端口 Identification Protocol, Ident)<br>udp.port== 53 ## 筛选出所有的dns查询<br>ip.addr eq 192.168.1.3 and ip.addr eq 192.168.1.1 //假设本机ip是192.168.1.3并且路由器是192.168.1.1的话，这个可以筛选出所有的ipv4包<br>ip.src == 192.168.1.3 &amp;&amp; tcp.port == 80 //两个命令串联起来也是可以的<br>ip.addr //既包含src也包含dst<br>udp ||http // udp或者http的包<br>frame.len &lt;=128 //显示所有体积小于128个字节的包</p><p>//如果一开始就只对特定协议感兴趣<br>capture -&gt; filters 里面可以选择只抓某些协议的包。因为默认是什么都抓，这样会少很多</p><h3 id="一些有用的操作"><a href="#一些有用的操作" class="headerlink" title="一些有用的操作"></a>一些有用的操作</h3><p>选中一个column，右键 -&gt; follow -&gt;tcpstream ，可以查看这个packet的来回信息。（如果是http的话，request和response都给出来了）<br>菜单栏上的Statistics -&gt; conversatitons （查看所有的会话）<br>wireshark的结果可以save成.cap文件，下次可以打开<br>菜单栏上的Statistics -&gt; protocol Hierarchy(查看所有的协议)<br>菜单栏view -&gt; coloring rule（直接将特定的协议变成特定颜色的背景，方便识别）<br>view -&gt; time displayformat(格式化packet的时间显示成便于识别的时间，因为默认的显示单位是毫秒)<br>Statistics -&gt; endpoints // 查看所有连接过的ip</p><p>Statistics -&gt; packet length //查看所有的packet length（多数时候包的大小在40-79和1280-2559这个区间里面，没有小于40的，因为最少得40个字节）</p><ul><li>arp(addression resolution protocol)<br>一台电脑在发出去一个包之前，已经知道dest的ip地址，但是不知道这个ip地址对于的mac地址是多少，于是会发出一份arp request。<br>在局域网内部，是这样的</li><li>who has 192.168.1.1 ? Tell 192.168.1.7  //电脑发出arp请求</li><li>192.168.1.1 is at 00:xx:00:xe:b5 //很快得到了回应</li></ul><p><a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol">arp包结构</a></p><p>一个ipv4地址需要32个bit表示,192.168.1.1这种写法叫做base10<br>一般情况下，192.168这俩一般表示的是network address, .1.1这俩一般表示的是Host address(physical computer)<br>net mask(255.255.0.0) 192.168.1/16。</p><h3 id="选中一个tcp包，查看Internet-Protocol-Version4-这里就是第三层-network层了-。"><a href="#选中一个tcp包，查看Internet-Protocol-Version4-这里就是第三层-network层了-。" class="headerlink" title="选中一个tcp包，查看Internet Protocol Version4 ..(这里就是第三层,network层了)。"></a>选中一个tcp包，查看Internet Protocol Version4 ..(这里就是第三层,network层了)。</h3><p><img src="https://haldir66.ga/static/imgs/wire_shark_internet_protocol_version4.png" alt=""><br>从上到下依次是<br>version: 4<br>Header length 20bytes<br>Differentiated Services Filed(不懂)<br>Total Length(这个是包含了)<br>Identification(类似于id)<br>Flags : 0x4000, Dont’t fragment(这个牵涉到mtu,maximum transmission unit size, 这个数值在ethernet上是1500bytes。假如一个包大小超过这个数，切成两个,也就是fragment.这个Flags里面可以看到More fragment: not set （0），意思就是说这个包没有被切成两个。有两种情况下这个标志设为0，一是没有分包，而是这个包恰好是最后一个)<br>Fragment offset：0 (假如被切成两个了，这里就表示当前这个包是被切完之后的第一个还是第二个，就当是index吧)。<br>这个包是访问google时留下的</p><p>有一个Time to live:128 (就是说这个包最多走128hop，就是最多经手128个router就丢掉)</p><h3 id="再看第四层（Transport-layer），也就是tcp-udp这类了。"><a href="#再看第四层（Transport-layer），也就是tcp-udp这类了。" class="headerlink" title="再看第四层（Transport layer），也就是tcp,udp这类了。"></a>再看第四层（Transport layer），也就是tcp,udp这类了。</h3><p>还是上面这个包<br><img src="https://haldir66.ga/static/imgs/wire_shark_capture_transmission_control_protocol.png" alt=""><br>从上到下依次是<br>Source Port<br>Destination Port :443 //https无疑<br>stream index: 4<br>sequence number 496 //确保数据没有丢失<br>Acknowledgement number : 4043 //下一个包的sequence number<br>Flags(urg:urgent,push:push,rst:reset,sin&amp;fin(finished))这张图里面写的是Acknowledgment(显然是ack包)<br>window size value: 2053(这个是tcp receiver buffer，单位是byte，这个数值变来变去的)<br>checksum(检查数据完整)</p><h2 id="说一说handshake"><a href="#说一说handshake" class="headerlink" title="说一说handshake"></a>说一说handshake</h2><p>tcp packets始于一个handshake<br>检查端口，发送一个sequence number(随机的),客户端会发送一个syn packet到接受方。接受方会返回一个syn ack packet,接下来客户端发送一个ack packet。上述步骤每一次sequence number都会+1<br><img src="https://haldir66.ga/static/imgs/wireshark_tcp_handshake.png" alt=""></p><pre><code>1. Client 发送 SYN 包（seq: x），告诉 Server：我要建立连接；Client 进入SYN-SENT状态；2. Server 收到 SYN 包后，发送 SYN+ACK 包（seq: y; ack: x+1），告诉它：好的；Server 进入SYN-RCVD状态；3. Client 收到 SYN+ACK 包后，发现 ack=x+1，于是进入ESTABLISHED状态，同时发送 ACK 包（seq: x+1; ack: y+1）给 Server；Server 发现 ack=y+1，于是也进入ESTABLISHED状态；接下来就是互相发送数据、接收数据了……</code></pre><h3 id="tcp-teardown-四次挥手告别"><a href="#tcp-teardown-四次挥手告别" class="headerlink" title="tcp teardown(四次挥手告别)"></a>tcp teardown(四次挥手告别)</h3><p>host发送给destination一个fin acknowledge packet<br>destination发挥一个ack packet和一个fin ack packet<br>host再发送一个ack(这些都可以从flags里面看到)<br><img src="https://haldir66.ga/static/imgs/wireshark_tcp_wave.png" alt=""></p><pre><code>注意，可以是连接的任意一方主动 close，这里假设 Client 主动关闭连接：1. Client 发送 FIN 包，告诉 Server：我已经没有数据要发送了；Client 进入FIN-WAIT-1状态；2. Server 收到 FIN 包后，回复 ACK 包，告诉 Client：好的，不过你需要再等会，我可能还有数据要发送；Server 进入CLOSE-WAIT状态；而 Client 收到 ACK 包后，继续等待 Server 做好准备， Client 进入FIN-WAIT-2状态；3. Server 准备完毕后，发送 FIN 包，告诉 Client：我也没有什么要发送了，准备关闭连接吧；Server 进入LAST-ACK状态；4. Client 收到 FIN 包后，知道 Server 准备完毕了，于是给它回复 ACK 包，告诉它我知道了，于是进入TIME-WAIT状态；而 Server 收到 ACK 包后，即进入CLOSED状态；Client 等待 2MSL 时间后，没有再次收到 Server 的 FIN 包，于是确认 Server 收到了 ACK 包并且已关闭，于是 Client 也进入CLOSED状态；</code></pre><p>MSL即报文最大生存时间，RFC793 中规定 MSL 为 2 分钟，但这完全是从工程上来考虑，对于现在的网络，MSL=2分钟可能太长了一些。实际应用中常用的是 30 秒、1 分钟、2 分钟等；可以修改/etc/sysctl.conf内核参数，来缩短TIME_WAIT的时间，避免不必要的资源浪费。</p><p>所以整个tcp传输的过程看起来像这样<br><img src="https://haldir66.ga/static/imgs/wireshark_tcp_handwave.jpg" alt=""></p><p>有时候会看到rest，意味着连接突然中断了（tcp会断掉这个sequence的所有packet，把flags里面的reset设置为1）</p><h3 id="DHCP-Dynamic-Host-Configuration-Protocol-这个位于第7层"><a href="#DHCP-Dynamic-Host-Configuration-Protocol-这个位于第7层" class="headerlink" title="DHCP (Dynamic Host Configuration Protocol)这个位于第7层"></a>DHCP (Dynamic Host Configuration Protocol)这个位于第7层</h3><h3 id="DNS包结构"><a href="#DNS包结构" class="headerlink" title="DNS包结构"></a>DNS包结构</h3><p>DNS走的是udp的53端口，发出去的请求的dst.port=53，收到的response的src.port = 53.<br>在局域网内,dst就是路由ip(192.168.1.1)</p><p>访问tmall主页<br><img src="https://haldir66.ga/static/imgs/dns_query_round_trip.png" alt=""><br>一来一回的</p><p>先看request<br><img src="https://haldir66.ga/static/imgs/dns_query_request_detail.png" alt=""><br>在Domain Name System query的<br>Flags下有一个opcode(这个值可能是standard query，也可能是authoritated answers,如果response是从name server回来的话)<br>Flags下面还有一个Truncated(意思就是你发出的这个包是不是太大了，太大了塞不进一个packet)<br>还有Recursion desire:Do query recursively(这意味着servername支持recursive query，就是当前dns server找不到的话，会往上继续查找)</p><p>再来看response<br><img src="https://haldir66.ga/static/imgs/dns_query_response_detail.png" alt=""><br>结果在Answers里面</p><h3 id="https结构"><a href="#https结构" class="headerlink" title="https结构"></a>https结构</h3><p>wireshark上显示成tlsv1.2<br>找application data，在secure socket layer里面有encrypted Application Data(加密过的)<br>如果是http的话，在hypertext transfer protocol里面最底下会显示html encoded的post的data</p><h3 id="tcp-retransmission"><a href="#tcp-retransmission" class="headerlink" title="tcp retransmission"></a>tcp retransmission</h3><p>网速慢的时候(latency高)tcp会发现这些问题，重发<br>如果一个packet始终没有收到ack(在限定的时间内)，重发<br>两个packet之间的时间叫做round-trip time,每当出现retransmission的时候，z这个packet的rto直接double（windows上默认尝试5次，linux上有的达到15次），一直这样double的操作超过5次后，直接丢包</p><p>如果找到一个retransmission的包<br>rto time在transmission control protocol下面的expert info，里面有个<br>(the rto for this segment was: 0.220 seconds)<br>如果这次重发还不成功,0.44s后,0.88秒后。直到超过5次尝试</p><h3 id="tcp-duplicates"><a href="#tcp-duplicates" class="headerlink" title="tcp  duplicates"></a>tcp  duplicates</h3><p>duplicate ack，这通常出现在receiver收到了out of order packet。<br>所有的tcp连接都有一个isn( initial sequence number)，就是初始序列号了。后续的packet会在这个数字的基础上,data payload传递了多少，这个数就加多少。比方说src这边的isn是1000，发送了200bytes的数据，那么我收到的ack应该是1200.</p><p>上述是一切正常的情况，但是假如src这边的isn是1000，发出去200bytes，dst那边返回1200的sequence number的ack。此时，src这边出了问题，发出去一个1400的packet，dst那边就会认为，你这不对，重来一遍（发回一个1200的ack，一直尝试3次，直到src终于反应过来发出1200的包，这个正确的包叫做fast retransmission）。<br>在wireshark里面，dst发回来的重复的ack会显示为tcp dup ack。src最后一次正确的packet显示为tcp fast retransmission</p><p>所以一旦出现了skip isn的情况，要么dst发回dup ack，要么src发出fast retransmission</p><h3 id="tcp-flow-control"><a href="#tcp-flow-control" class="headerlink" title="tcp flow control"></a>tcp flow control</h3><p>即sliding window mechanism，原理是调整retransmission的速度（根据dst的recive window），因为dst那边是有一个tcp buffer space的，万一这个buffer溢出，就会造成丢包<br>wireshark中，在transmission control protocol下面，有一个window size.<br>比方说，src发送了一个isn =1的packet，window size = 8760。dst返回一个ack number = 2921的ack,同时window size变成5840.<br>这么来来回回，这个window迟早被消耗玩，tcp zero window（正常情况下dst的应用层能够读走这部分数据，但是如果接收方读取速度跟不上的话，会发送一个ack包，告诉src发送慢一点,src接收到了之后，就会一直发keep-alive packet(非常小的包，66byte).如果dst那边还没处理好的话，会一直返回Tcp Zero window 的ack，这样往返数次）。这个专门的名词叫做Zero Window Probe<br>在wireshark里面,tcp zero window的ack包里面会显示window size value: 0<br><strong>只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。（关于这方面的攻击，大家可以移步看一下Wikipedia的SockStress词条）</strong></p><h3 id="high-latency"><a href="#high-latency" class="headerlink" title="high latency"></a>high latency</h3><p>这个主要的标志是time这一栏超过1秒，延迟的原因很多。可以分析是去程慢还是返程慢。也有可能是服务器处理很慢。<br>network baseline(正常的延迟是多少，比如国内到美国一般150ms以上是起码的，这是物理决定的)</p><h2 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h2><p>安装</p><blockquote><p>sudo apt-get install tcpdump</p></blockquote><p>使用<br>sudo tcpdump -i wlan0 ##i的意思是指定某个网络接口，输出非常多<br>sudo tcpdump -D ##哪些接口可用<br>sudo tcpdump -i 2 ##只看-D显示的第二个设备<br>sudo tcpdump -v -A ## A的意思是ASCII，至少内容容易辨识<br>sudo tcpdump -i 2 -c 4 ##只抓4个包<br>sudo tcpdump -i 2 -c -4 -n arp ##只抓arp的包,n的意思是supress host name,也能用来指定协议<br>sudo tcpdump -i 2 -c -4 -n tcp ##只抓4个tcp<br>sudo tcpdump -i 2 -c -4 -n icmp ##只抓4个icmp<br>sudo tcpdump -i 2 -c -4 src 192.168.1.1 ##指定src</p><p>sudo tcpdump -i 2 -c -4 -w filename.pcap ##保存到文件,这个文件用tcpdump打开也是可以的<br>sudo tcpdump -r  filename.pcap ##读取这个文件</p><p>可以和egrep一起用<br>sudo tcpdump -A -i 2 | egrep -i ‘pass=|pwd=|password=|username=’ –color=auto –line-buffered<br>//比方说抓到了md5过的密码，随便找个解密网站，就能解出来了</p><p><a href="https://segmentfault.com/a/1190000009562333">ARP欺骗</a> arp cache poisoning attack<br><a href="http://packetlife.net/media/library/23/common_ports.pdf">常用的端口号</a><br><a href="https://github.com/chrissanders/packets">各种可能的pcap文件</a><br><a href="https://www.zfl9.com/c-socket.html">本文大量文字图片出处</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/osi-model.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;a href=&quot;http://packetlife.net/media/library/13/Wireshark_Display_Filters.pdf&quot;&gt;wireshark expression cheetsheet&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://packetlife.net/media/library/12/tcpdump.pdf&quot;&gt;tcpdump cheet&lt;/a&gt;&lt;br&gt;wireshark能抓tcp,arp,http,dns,udp,icmp,dhcp…&lt;/p&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>tcp-nagel-algorithm-and-delay-ack</title>
    <link href="https://haldir65.github.io/2018/11/06/2018-11-06-nagel-algorithm-and-delay-ack/"/>
    <id>https://haldir65.github.io/2018/11/06/2018-11-06-nagel-algorithm-and-delay-ack/</id>
    <published>2018-11-06T13:25:55.000Z</published>
    <updated>2019-01-25T15:20:53.215Z</updated>
    
    <content type="html"><![CDATA[<p>Nagle’s Algorithm 和 Delayed ACK 一起用在特定场景下可能会造成网速不必要的延迟<br>傳送 TCP 封包的時候， TCP header 占 20 bytes， IPv4 header 占 20 bytes，若傳送的資料太小， TCP/IPv4 headers 造成的 overhead (40bytes) 並不划算。想像傳送資料只有 1 byte，卻要另外傳 40 bytes header，這是很大的浪費。若網路上有大量小封包，會占去網路頻寬，可能會造成網路擁塞 。这个是针对发送方而言的。</p><p><img src="https://www.haldir66.ga/static/imgs/nature-grass-wet-plants-high-resolution-wallpaper-573f2c6413708.jpg" alt=""><br><a id="more"></a></p><p>一个TCP数据包的传输至少需要固定的40字节头部信息(20字节TCP + 20字节IP)，如果数据包实际负载都比较小的话，那么传输的效率就非常低，但是如果将这些小包的负载都尽量集中起来，封装到一个TCP数据包中进行传输，那么传输效率势必将会大大提高。此处我们再次强调，TCP传输的是一个字节流，本身不存在所谓的离散形式的数据包的概念，协议可以任意组合、拆分每次调用实际传输的数据长度。</p><p>Nagle算法的思路在<a href="https://zh.wikipedia.org/wiki/%E7%B4%8D%E6%A0%BC%E7%AE%97%E6%B3%95">wiki</a>上也能找到</p><pre><code>if there is new data to send  if the window size &gt;= MSS and available data is &gt;= MSS    send complete MSS segment now  else    if there is unconfirmed data still in the pipe      enqueue data in the buffer until an acknowledge is received    else      send data immediately    end if  end ifend if</code></pre><p>如果发送内容大于1个MSS， 立即发送；<br>如果之前没有包未被确认， 立即发送；<br>如果之前有包未被确认， 缓存发送内容；<br>如果收到ack， 立即发送缓存的内容。</p><p>概括地说来，其流程表述为：(a)不考虑窗口流量控制的限制，一旦累积的数据达到MSS就立即执行传输；(b)否则如果当前有未ACK的数据，就将数据堆积到发送队列里延迟发送；(c)如果没有待需要ACK的数据，就立即发送。简单说来，就是在数据没有累积到MSS的大小情况下，整个连接中允许有未ACK的数据。<br>　　Nagel算法本质上就是个时间换带宽的方法，所以对于那些带宽要求不大但对实时性要求高的程序，比如类似网络游戏类，需要使用TCP_NODELAY这个socket选项来关闭这个特性以减小延时发生。不过话外说来，对于这类程序或许使用UDP协议也是个选择。</p><p>想象一下，同时丢出去一大堆只有50个字节的包还是会造成带宽的浪费，还不如攒在一起发出去。</p><p>在Nagle算法中参数MSS(maximum segment size，IPv4默认值是576-20-20 = 536)<br><a href="https://en.wikipedia.org/wiki/Maximum_segment_size">Maximum_segment_size在wiki上还有专门的介绍</a></p><p>一些关键词：</p><p>acknowledged: TCP 傳送封包時會帶有流水號 ，起始值隨機，後面每傳 1 byte 就 +1。對方收到後會回傳 ACK 封包，帶有最後收到 byte 的數字。比方說收到 100 bytes，再收到 200 bytes，只要 ACK「起始值+300」即可。</p><p>sliding window: 允許傳送 unacked bytes 的最大值，確保在網路不佳的情況下，傳送端不會傳送過多封包加重擁塞。sliding window 的最大值是 2¹⁶ = 64 (KB)</p><h3 id="Delay-ACK"><a href="#Delay-ACK" class="headerlink" title="Delay ACK"></a>Delay ACK</h3><p>ACK 也是小封包，為了避免產生太多小封包，所以接收端不會每次收到封包都立即發 ACK，如果之後剛好需要送資料 ，順便帶上 ACK去可以省去小封包。實例: telnet server 會回傳使用者剛打的字，順便送 ACK 就可以省去小封包。</p><p>Linux的实现在 <a href="https://github.com/torvalds/linux/blob/master/net/ipv4/tcp_input.c#L5066">__tcp_ack_snd_check</a>这个方法</p><p>通常最多延遲 200ms，RFC 規定不能超過 500ms。<br>每收到兩個 full-sized packet，一定要回一次 ACK。</p><h3 id="兩者合用的問題"><a href="#兩者合用的問題" class="headerlink" title="兩者合用的問題"></a>兩者合用的問題</h3><p>假設傳送端有開 Nagle’s Algorithm，接收端有開 delayed ACK (兩者在 Linux 都是預設值)。</p><p>以 HTTP 為例，若 server 的 response 被切成兩次 send，一次送 header，一次送 body，兩者都 &lt;MSS。</p><p>server 送完 header 後，因為 client 沒有回 ACK (delayed ACK)，server 也不會送 body (應用層覺得它已經送出了，但 kernel 還沒送)。<br>client 過了 200ms，送出收到 header 的 ACK。<br>server 收到 ACK 後，送出 body。<br>於是 client 多等了 200ms 才收到完整的 response。</p><h3 id="tcp缓冲的概念"><a href="#tcp缓冲的概念" class="headerlink" title="tcp缓冲的概念"></a>tcp缓冲的概念</h3><p><a href="https://www.cnblogs.com/promise6522/archive/2012/03/03/2377935.html">tcp缓冲</a><br>这些东西对于应用层来说是无感的</p><p>socket支持blocking(默认)和non-blocking模式，读写都存在阻塞问题</p><pre><code class="c">#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count);</code></pre><p>牵涉到tcp缓冲层大小</p><p>首先，write成功返回，只是buf中的数据被复制到了kernel中的TCP发送缓冲区。至于数据什么时候被发往网络，什么时候被对方主机接收，什么时候被对方进程读取，系统调用层面不会给予任何保证和通知。<br>已经发送到网络的数据依然需要暂存在send buffer中，只有收到对方的ack后，kernel才从buffer中清除这一部分数据，为后续发送数据腾出空间。接收端将收到的数据暂存在receive buffer中，自动进行确认。但如果socket所在的进程不及时将数据从receive buffer中取出，最终导致receive buffer填满，由于TCP的滑动窗口和拥塞控制，接收端会阻止发送端向其发送数据。这些控制皆发生在TCP/IP栈中，对应用程序是透明的，应用程序继续发送数据，最终导致send buffer填满，write调用阻塞。</p><p>一般来说，由于接收端进程从socket读数据的速度跟不上发送端进程向socket写数据的速度，最终导致发送端write调用阻塞。</p><p>而read调用的行为相对容易理解，从socket的receive buffer中拷贝数据到应用程序的buffer中。read调用阻塞，通常是发送端的数据没有到达。</p><ul><li>read总是在接收缓冲区有数据时立即返回，而不是等到给定的read buffer填满时返回。只有当receive buffer为空时，blocking模式才会等待，而nonblock模式下会立即返回-1（errno = EAGAIN或EWOULDBLOCK）</li><li>blocking的write只有在缓冲区足以放下整个buffer时才返回（与blocking read并不相同）</li><li><p>nonblock write则是返回能够放下的字节数，之后调用则返回-1（errno = EAGAIN或EWOULDBLOCK）</p><p>对于blocking的write有个特例：当write正阻塞等待时对面关闭了socket，则write则会立即将剩余缓冲区填满并返回所写的字节数，再次调用则write失败（connection reset by peer）</p></li></ul><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>启示就是应用层进行开发的时候不要零零散散的发数据，尽量攒成一个大一点的包再发出去。不要让系统层去做这件事。<br>TCP_NODELAY 是可以关闭Nagle算法的</p><h2 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h2><p>window congestion<br>超时重传<br>阻塞，超时，</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://taozj.net/201808/nagle-and-delayed-ack.html">Nagle和Delayed ACK优化算法合用导致的死锁问题</a><br><a href="https://medium.com/fcamels-notes/nagles-algorithm-%E5%92%8C-delayed-ack-%E4%BB%A5%E5%8F%8A-minshall-%E7%9A%84%E5%8A%A0%E5%BC%B7%E7%89%88-8fadcb84d96f">Nagle’s Algorithm 和 Delayed ACK 以及 Minshall 的加強版</a><br><a href="https://cloud.tencent.com/developer/article/1004431">再说TCP神奇的40ms</a><br><a href="https://www.cnblogs.com/promise6522/archive/2012/03/03/2377935.html">tcp缓冲非常好的文章</a><br><a href="https://coolshell.cn/articles/11609.html">TCP 的那些事儿（下）</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Nagle’s Algorithm 和 Delayed ACK 一起用在特定场景下可能会造成网速不必要的延迟&lt;br&gt;傳送 TCP 封包的時候， TCP header 占 20 bytes， IPv4 header 占 20 bytes，若傳送的資料太小， TCP/IPv4 headers 造成的 overhead (40bytes) 並不划算。想像傳送資料只有 1 byte，卻要另外傳 40 bytes header，這是很大的浪費。若網路上有大量小封包，會占去網路頻寬，可能會造成網路擁塞 。这个是针对发送方而言的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/nature-grass-wet-plants-high-resolution-wallpaper-573f2c6413708.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何写shell脚本</title>
    <link href="https://haldir65.github.io/2018/11/04/2018-11-04-how-to-write-shell-scripts/"/>
    <id>https://haldir65.github.io/2018/11/04/2018-11-04-how-to-write-shell-scripts/</id>
    <published>2018-11-04T08:50:58.000Z</published>
    <updated>2019-01-25T15:20:53.215Z</updated>
    
    <content type="html"><![CDATA[<p>linux下shell脚本语句的语法<br>，脚本以<a href="https://en.wikipedia.org/wiki/Shebang_(Unix">Shebang</a>)开始</p><blockquote><p>#!/bin/sh</p></blockquote><p><img src="https://www.haldir66.ga/static/imgs/timg.jpg" alt=""><br><a id="more"></a></p><h3 id="linux下shell脚本语句的语法"><a href="#linux下shell脚本语句的语法" class="headerlink" title="linux下shell脚本语句的语法"></a>linux下shell脚本语句的语法</h3><p>linux大小写敏感</p><p>eg: echo类似于print</p><pre><code class="bash">##例：myvar=“Hi there！”    echo $myvar  ## Hi there！    echo &quot;$myvar&quot;  ## Hi there!    echo &#39; $myvar&#39; ## $myvar    echo \$myvar ## $myvar</code></pre><p>eg:</p><pre><code class="bash">#!/bin/shmyPath=&quot;/var/log/httpd/&quot;myFile=&quot;/var /log/httpd/access.log&quot;#这里的-x 参数判断$myPath是否存在并且是否具有可执行权限if [ ! -x &quot;$myPath&quot;]; thenmkdir &quot;$myPath&quot;fi#这里的-d 参数判断$myPath是否存在if [ ! -d &quot;$myPath&quot;]; thenmkdir &quot;$myPath&quot;fi#这里的-f参数判断$myFile是否存在if [ ! -f &quot;$myFile&quot; ]; thentouch &quot;$myFile&quot;fi#其他参数还有-n,-n是判断一个变量是否是否有值if [ ! -n &quot;$myVar&quot; ]; thenecho &quot;$myVar is empty&quot;exit 0fi#两个变量判断是否相等if [ &quot;$var1&quot; == &quot;$var2&quot; ]; then  //if 后面必须加thenecho &#39;$var1 eq $var2&#39;elseecho &#39;$var1 not eq $var2&#39;fi //else后面必须加fiif list then    do something hereelif list then    do another thing hereelse    do something else herefi</code></pre><pre><code class="bash">#!/bin/bashbashecho &quot;hello there&quot;foo=&quot;Hello&quot;foo=&quot;$foo World&quot;  ## 拼接一个现成的string到另一个string的尾部，用冒号跟美元符号就好了echo $fooecho &quot;Number of files in this directory: `ls | wc -l`&quot;  ## 但是将ls | wc -l的输出作为一个String拼接到一个string中，用单引号echo &quot;all the files under the directory `ls  /usr/*/g* | head -n3`&quot;</code></pre><p>一个把文件夹（/public/imgs）下所有文件重命名为img-x.jpg的shell脚本</p><pre><code class="bash">#!/bin/bashFORMAT_JPG=&quot;jpg&quot;FORMAT_JPEG=&quot;jpeg&quot;index=1dir=$(eval pwd)/public/imgsALLIMGES=$(ls $dir | grep  &quot;.$FORMAT_JPEG\|.$FORMAT_JPG&quot;)for file in $ALLIMGES        do        name=img-${index}.jpg        echo renaming $dir/$file to  $dir/$name        mv $dir/$file $dir/$name        ((index++))        # name=$(ls $file | cut -d. -f1)        # mv $dir/public/imgs/$file ${name}.$suffix        doneecho &quot;renaming $index image files =====&gt; x.jpg done!&quot;</code></pre><p>同时grep多种文件的时候，比如又想要jpg又想要jpeg的话，grep 要加上反斜杠，或者下面这三种</p><pre><code>grep &quot;aaa\|bbb&quot;grep -E &quot;aaa|bbb&quot;grep -E aaa\|bbb</code></pre><p><a href="https://www.cyberciti.biz/faq/howto-use-grep-command-in-linux-unix/">how to grep</a></p><p>想要在bash中设置一个variable为一个命令的输出</p><pre><code class="bash">#!/bin/bashOUTPUT=&quot;$(ls -1)&quot;  ## 注意，这里等于号前后不能有空格echo &quot;${OUTPUT}&quot;##那如果就是平时在terminal里面随便敲敲呢，下面这些亲测无误echo &quot;$(ls -al | wc)&quot;&quot;$(which java)&quot; -h## 比如说我想把java的路径填充到一段命令中间echo &quot;$(which java)&quot;/something&gt;&gt; /usr/bin/java/something#!/bin/bashjava_stuff=&quot;$(which java)&quot;${java_stuff} --version</code></pre><p>经常会在别人的bash脚本最前面看到一行 <a href="http://www.ruanyifeng.com/blog/2017/11/bash-set.html">set-e</a>：在阮一峰老师的博客中找到了解释</p><pre><code>#!/usr/bin/env bashset -e ## 这个set -e的原因，因为bash一般对错误容忍度比较高，一行命令出了错还能往下走，可是实际生产中，我们希望出了错就此打住。在文件前面写这个就行了## 总比下面这些这么写好吧command || exit 1 command || { echo &quot;command failed&quot;; exit 1; }set -eo pipefail ##set -e对于管道无效，这么写就连管道的错误都拦下来了</code></pre><p>$ set -e</p><p>这行代码之后的任何代码，如果返回一个非0的值，那么整个脚本立即退出，官方的说明是为了防止错误出现滚雪球的现象</p><p>$ set -o pipefail</p><p>原文解释如下：</p><p>If set, the return value of a pipeline is the value of the last (rightmost) command to exit with a non-zero status,or zero if all commands in the pipeline exit successfully. This option is disabled by default.</p><p>可理解为：</p><p>告诉 bash 返回从右到左第一个以非0状态退出的管道命令的返回值，如果所有命令都成功执行时才返回0</p><h3 id="变量-其实就是美元符号了"><a href="#变量-其实就是美元符号了" class="headerlink" title="变量($其实就是美元符号了)"></a>变量($其实就是美元符号了)</h3><p>变量调用符号($)</p><pre><code class="bash">LI=date$LI ### Tue Dec  5 04:06:18 EST 2017# 所以经常会有这样的脚本# Check if user is rootif [ $(id -u) != &quot;0&quot; ]; then    echo &quot; Not the root user! Try using sudo Command ! &quot;    exit 1fiecho &quot;Pass the test! You are the root user!&quot;## 亲测下面这种可用if [ `whoami` = &quot;root&quot; ];then      echo &quot;root用户！&quot;  else      echo &quot;非root用户！&quot;  fi</code></pre><p>变量分为用户自定义的和环境变量（其实就是系统预设的）,有些区别</p><blockquote><p>用户自定义变量只在当前的shell中生效，环境变量在当前shell和这个shell的所有子shell中生效。<br>环境变量是全局变量，用户自定义变量是局部变量。<br>对系统生效的环境变量名和变量作用是固定的。</p></blockquote><h3 id="常用的环境变量"><a href="#常用的环境变量" class="headerlink" title="常用的环境变量"></a>常用的环境变量</h3><blockquote><p>HOSTNAME：主机名<br>SHELL：当前的shell<br>TREM：终端环境<br>HISTSIZE：历史命令条数<br>SSH_CLIENT：当前操作环境是用ssh链接的，这里记录客户端的ip<br>SSH_TTY：ssh连接的终端是pts/1<br>USER:当前登录的用户</p></blockquote><pre><code class="bash">echo $HOSTNAME## unbutu$? 最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；如果这个变量的值非0（具体是哪个数，由命令自己决定），则证明上一个命令执行不正确了。$$ 当前进程的进程号（PID）$! 后台运行的最后一个进程的进程号（PID）</code></pre><p>unix下查看环境变量命令：</p><blockquote><p>export</p></blockquote><p>windows下查看环境变量:</p><blockquote><p>set</p></blockquote><p>直接把一个curl的脚本导到bash去执行的方式</p><ul><li>bash &lt;(curl -L -s <a href="https://install.direct/go.sh">https://install.direct/go.sh</a>)</li></ul><p><a href="https://stackoverflow.com/questions/59895/getting-the-source-directory-of-a-bash-script-from-within?rq=1">在sh脚本中判断当前脚本所在的位置</a>)</p><pre><code class="sh">#!/bin/bashecho &quot;The script you are running has basename `basename &quot;$0&quot;`, dirname `dirname &quot;$0&quot;`&quot;echo &quot;The present working directory is `pwd`&quot;</code></pre><p>在c语言的main函数中,args[0]就是当前文件的路径，所以在shell里也差不多</p><p>//统计一下这个脚本耗时多久</p><blockquote><p>time bash -c ‘echo “hey”‘<br>time somescript.sh</p></blockquote><p><a href="http://blog.51cto.com/litaotao/1187983">LINUX下的21个特殊符号</a><br><a href="https://notes.wanghao.work/2015-06-02-Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html">Shell学习笔记</a><br><a href="https://www.youtube.com/watch?v=Lu-xzWajbFo">how to use variables in shell scripts</a></p><h2 id="shell-script-tutorial"><a href="#shell-script-tutorial" class="headerlink" title="shell script tutorial"></a><a href="https://www.youtube.com/watch?v=hwrnmQumtPw">shell script tutorial</a></h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;linux下shell脚本语句的语法&lt;br&gt;，脚本以&lt;a href=&quot;https://en.wikipedia.org/wiki/Shebang_(Unix&quot;&gt;Shebang&lt;/a&gt;)开始&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;#!/bin/sh&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/timg.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>linux常用命令(三)</title>
    <link href="https://haldir65.github.io/2018/11/04/2018-11-04-linux-affiliated-commands/"/>
    <id>https://haldir65.github.io/2018/11/04/2018-11-04-linux-affiliated-commands/</id>
    <published>2018-11-04T08:44:22.000Z</published>
    <updated>2019-01-25T15:20:53.215Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/green_forset_alongside_river_2.jpg" alt=""></p><a id="more"></a><h3 id="linux-sed命令"><a href="#linux-sed命令" class="headerlink" title="linux sed命令"></a>linux sed命令</h3><p><a href="https://www.digitalocean.com/community/tutorials/the-basics-of-using-the-sed-stream-editor-to-manipulate-text-in-linux">basic sed</a></p><blockquote><p> sed operates on a stream of text that it reads from either standard input or from a file.</p></blockquote><p>基本命令格式<br>sed [options] commands [file-to-edit]</p><h2 id="默认情况下-sed会把结果输出到standoutput里面"><a href="#默认情况下-sed会把结果输出到standoutput里面" class="headerlink" title="默认情况下,sed会把结果输出到standoutput里面"></a>默认情况下,sed会把结果输出到standoutput里面</h2><p>sed ‘’ BSD ##等同于cat<br>cat BSD | sed ‘’ ##操作cat的输出流<br>sed ‘p’ BSD ##p是命令，明确告诉它要去print，这会导致每一行都被打印两遍<br>sed -n ‘p’ BSD ##我不希望你自动打印，每行只被打印一遍<br>sed -n ‘1p’ BSD ##只打印第一行<br>sed -n ‘1,5p’ BSD ##打印前5行<br>sed -n ‘1,+4p’ BSD ##这个也是打印前五行<br>sed -n ‘1~2p’ BSD ##every other line，打印一行跳过一行，从第一行开始算<br>sed ‘1~2d’ BSD ##也是隔一行进行操作，只不过这里的d表示删除，结果就是1，3，5…行被从cat的结果中删掉</p><p>默认情况下,sed不会修改源文件，加上-i就能改了<br>sed -i ‘1~2d’ everyother.txt ##第1，3，5，…行被删掉<br>sed -i.bak ‘1~2d’ everyother.txt ##在编辑文件之前保存一份.bak文件作为备份</p><p>sed最为常用的命令就是substituting text了<br>echo “<a href="http://www.example.com/index.html">http://www.example.com/index.html</a>“ | sed ‘s_com/index<em>org/home</em>‘<br><a href="http://www.example.org/home.html">http://www.example.org/home.html</a></p><p>命令是这么用的,首先s表示substitute<br>‘s/old_word/new_word/‘</p><p>准备好这么一份text文件<br>echo “this is the song that never ends<br>yes, it goes on and on, my friend<br>some people started singing it<br>not knowing what it was<br>and they’ll continue singing it forever<br>just because…” &gt; annoying.txt</p><p>sed ‘s/on/forward/‘ annoying.txt ##把所有的on换成forward，同时打印出结果。但如果当前行已经替换过一次了，就跳到下一行。所以可能没有替换干净</p><p>sed ‘s/on/forward/g’ annoying.txt ## 加上g就好了<br>sed ‘s/on/forward/2’ annoying.txt ##每一行只替换第二个匹配上的<br>sed -n ‘s/on/forward/2p’ annoying.text ## n是supress自动print，只打印出哪些被换了的<br>sed ‘s/SINGING/saying/i’ annoying.txt ##希望大小写不敏感<br>sed ‘s/^.<em>at/REPLACED/‘ annoying.txt ##从每一行的开头到”at”<br>sed ‘s/^.</em>at/(&amp;)/‘ annoying.txt ## 把那些会匹配上的文字用括号包起来</p><p><a href="https://www.digitalocean.com/community/tutorials/intermediate-sed-manipulating-streams-of-text-in-a-linux-environment">intermediate training</a></p><p>linux下查看一个文件的时间戳</p><blockquote><p>stat test</p></blockquote><p>c语言下对应的函数在sys/stat.h头文件中</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;sys/stat.h&gt;int main(void){    struct stat filestat;    stat(&quot;/etc/sysctl.conf&quot;, &amp;filestat);    printf(&quot;size: %ld bytes, uid: %d, gid: %d, mode: %#o\n&quot;, filestat.st_size, filestat.st_uid, filestat.st_gid, filestat.st_mode);    return 0;}</code></pre><blockquote><p>windows的换行符是 \r\l，linux的是 \l，mac的是 \r<br>从根本上讲，二进制文件和文本文件在磁盘中没有区别，都是以二进制的形式存储<br>二进制和文本模式的区别在于对换行符和一些非可见字符的转化上，如非必要，是使用二进制读取会比较安全一些</p></blockquote><p><a href="https://www.jianshu.com/p/8d33019d1c69">换行和回车在不同平台上的解释</a></p><blockquote><p>Dos 和 windows 采用“回车+换行，CR/LF”表示下一行；<br>UNIX/Linux 采用“换行符，LF”表示下一行；<br>苹果机(MAC OS 系统)则采用“回车符，CR”表示下一行。<br>CR 用符号’\r’表示, 十进制ASCII代码是 13, 十六进制代码为 0x0D;<br>LF 使用’\n’符号表示，ASCII代码是 10, 十六制为 0x0A。<br>所以 Windows 平台上换行在文本文件中是使用 0d 0a 两个字节表示，而 UNIX 和苹果平台上换行则是使用 0a 或 0d 一个字节表示。<br>一般操作系统上的运行库会自动决定文本文件的换行格式，如一个程序在 windows 上运行就生成 CR/LF 换行格式的文本文件，而在 Linux 上运行就生成 LF 格式换行的文本文件。<br>在不同平台间使用 FTP 软件传送文件时，在 ASCII 文本模式传输模式下， 一些 FTP 客户端程序会自动对换行格式进行转换，经过这种传输的文件字节数可能会发生变化，如果你不想 FTP 修改原文件，可以使用 bin 模式（二进制模式）传输文本。<br>在计算机还没有出现之前，有一种叫做电传打字机（Teletype Model 33，Linux/Unix下的tty概念也来自于此）的玩意，每秒钟可以打 10 个字符。但是它有一个问题，就是打完一行换行的时候，要用去0.2秒，正好可以打两个字符。要是在这 0.2 秒里面，又有新的字符传过来，那么这个字符将丢失。<br>于是，研制人员想了个办法解决这个问题，就是在每行后面加两个表示结束的字符。一个叫做“回车”，告诉打字机把打印头定位在左边界；另一个叫做“换行”，告诉打字机把纸向下移一行。这就是“换行”和“回车”的来历，从它们的英语名字上也可以看出一二。<br>后来，计算机发明了，这两个概念也就被搬到了计算机上。那时，存储器很贵，一些科学家认为在每行结尾加两个字符太浪费了，加一个就可以。于是，就出现了分歧。<br>Unix系统里，每行结尾只有“&lt;换行&gt;”，即”\n”；<br>Mac系统里，每行结尾是“&lt;回车&gt;”，即”\r”；<br>Windows系统里面，每行结尾是“&lt;换行&gt;&lt;回车 &gt;”，即“\n\r”。<br>一个直接后果是，Unix/Mac系统下的文件在 Windows里打开的话，所有文字会变成一行；而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号。</p></blockquote><p>因为 Windows 和 Linux 中的换行符不一致，前者使用CRLF(即\r\n)表示换行，后者则使用LF(即\n)表示换行<br>而C语言本身使用LF(即\n)表示换行，所以在文本模式下，需要转换格式(如Windows)，但是在 Linux 下，文本模式和二进制模式就没有什么区别</p><p>另外，以文本方式打开时，遇到结束符CTRLZ(0x1A)就认为文件已经结束<br>所以，若使用文本方式打开二进制文件，就很容易出现文件读不完整，或內容不对的错误<br>即使是用文本方式打开文本文件，也要谨慎使用，比如复制文件，就不应该使用文本方式</p><h3 id="signal处理"><a href="#signal处理" class="headerlink" title="signal处理"></a>signal处理</h3><p><a href="https://www.youtube.com/watch?v=XUhGdORXL54">HakTip - Linux Terminal 101: Controlling Processes</a></p><p>linux上信号有32种，多数在C语言中都有默认的处理方式（并且这种默认的处置方式也是可以更改的），除了SIGKILL(强行terminate)和SIGSTOP(debug遇到断点)不允许开发者更改处理方式。(kill -9也就是强杀非常有效)<br>c程序可以通过signal(比较老了)函数或者sigaction(推荐)函数注册收到信号之后的动作</p><p><a href="https://unix.stackexchange.com/questions/6593/force-directory-to-always-be-in-cache">Linux by default use the RAM as disk cache</a><br>这里的回答解释了系统会默认在内存中缓存磁盘节点的信息，下一次进行find的操作时候，就会快很多。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/green_forset_alongside_river_2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="blog" scheme="https://haldir65.github.io/categories/blog/"/>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>网络传输的字节序问题</title>
    <link href="https://haldir65.github.io/2018/11/03/2018-11-03-idea-byte-endianness/"/>
    <id>https://haldir65.github.io/2018/11/03/2018-11-03-idea-byte-endianness/</id>
    <published>2018-11-03T10:38:04.000Z</published>
    <updated>2019-01-25T15:20:53.215Z</updated>
    
    <content type="html"><![CDATA[<p>字节序（Endianness），在计算机科学领域中，是跨越<strong><em>多字节</em></strong>的程序对象的存储规则。 </p><p><img src="https://haldir66.ga/static/imgs/ship_docking_along_side_bay.jpg" alt=""><br><a id="more"></a></p><h2 id="首先确认下c语言下基本数据类型大小"><a href="#首先确认下c语言下基本数据类型大小" class="headerlink" title="首先确认下c语言下基本数据类型大小"></a>首先确认下c语言下基本数据类型大小</h2><pre><code class="c">printf(&quot;sizeof(int)= %ld\n&quot;,sizeof(int));printf(&quot;sizeof(char)= %ld\n&quot;,sizeof(char));printf(&quot;sizeof(long)= %ld\n&quot;,sizeof(long));printf(&quot;sizeof(float)= %ld\n&quot;,sizeof(float));printf(&quot;sizeof(short)= %ld\n&quot;,sizeof(short));</code></pre><blockquote><p>sizeof(int)= 4<br>sizeof(char)= 1<br>sizeof(long)= 8<br>sizeof(float)= 4<br>sizeof(short)= 2</p></blockquote><h2 id="来看一下c语言这边用socket以int，long的形式发送数据，Python这边接收会是怎么样的"><a href="#来看一下c语言这边用socket以int，long的形式发送数据，Python这边接收会是怎么样的" class="headerlink" title="来看一下c语言这边用socket以int，long的形式发送数据，Python这边接收会是怎么样的"></a>来看一下c语言这边用socket以int，long的形式发送数据，Python这边接收会是怎么样的</h2><p>c语言的server长这样</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/socket.h&gt; // socket#include &lt;sys/types.h&gt;  // 基本数据类型#include &lt;unistd.h&gt; // read write#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;fcntl.h&gt; // open close#include &lt;sys/shm.h&gt;#include &lt;signal.h&gt;#define PORT 7037#define SERV &quot;0.0.0.0&quot;#define QUEUE 20#define BUFF_SIZE 1024int sockfd;int main(int argc,char *argv[ ]){        signal(SIGINT,handle_signal);        int count = 0; // 计数        // 定义 socket        sockfd = socket(AF_INET,SOCK_STREAM,0);        // 定义 sockaddr_in        struct sockaddr_in skaddr;        skaddr.sin_family = AF_INET; // ipv4        skaddr.sin_port   = htons(PORT);        skaddr.sin_addr.s_addr = inet_addr(SERV);        // bind，绑定 socket 和 sockaddr_in        if( bind(sockfd,(struct sockaddr *)&amp;skaddr,sizeof(skaddr)) == -1 ){                perror(&quot;bind error&quot;);                exit(1);        }        // listen，开始添加端口        if( listen(sockfd,QUEUE) == -1 ){                perror(&quot;listen error&quot;);                exit(1);        }        // 客户端信息        char buff[BUFF_SIZE];        struct sockaddr_in claddr;        socklen_t length = sizeof(claddr);        while(1){                int sock_client = accept(sockfd,(struct sockaddr *)&amp;claddr, &amp;length);                printf(&quot;%d\n&quot;,++count);                if( sock_client &lt;0 ){                        perror(&quot;accept error&quot;);                        exit(1);                }                int a[3]={1,2,3}; //在这里发送出byte数组                send(sock_client,(char*)a,sizeof(a),0);                close(sock_client);        }        fputs(&quot;have a nice day&quot;,stdout);        close(sockfd);        return 0;}</code></pre><p>python的client长这样：</p><pre><code class="python">#!/usr/bin/python# -*- coding: UTF-8 -*-import socket# 创建一个socket:s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 建立连接:s.connect((&#39;192.168.1.45&#39;, 7037))s.send(b&#39;GET / HTTP/1.1\r\nHost: www.sina.com.cn\r\nConnection: close\r\n\r\n&#39;)# 接收数据:buffer = []while True:    # 每次最多接收1个字节:    d = s.recv(1)    t = &#39;&#39;    for x in d:        print(format(x,&#39;b&#39;))    if d:        buffer.append(d)    else:        breakdata = b&#39;&#39;.join(buffer)print(data)s.close()</code></pre><p>在局域网内的两台电脑,server跑在mac上,client跑在win10<br>client这边打印出了</p><pre><code>1    000===我是四个byte等于一个int的手动分割线===10000===我是四个byte等于一个int的手动分割线===11000</code></pre><p>按照server端(intel cpu)是小端的理论，把上面接收到的横过来掉个头<br>前四个字节是”1”<br>1   0   0   0<br>0   0   0   1  -&gt; 显然是1</p><p>中间四个字节是”2”<br>10  0   0   0<br>0   0   0   10 -&gt; 显然是2</p><p>最后四个字节是”3”<br>11  0   0   0<br>0   0   0   11 -&gt; 显然是3</p><p>教科书诚不我欺也</p><p>这里如果把c语言的server改一下</p><pre><code class="c">float a[3]={1,2,3}; //在这里发送出byte数组send(sock_client,(char*)a,sizeof(a),0);</code></pre><p>client一字不改，得到的是</p><pre><code>0010000000111111===我是四个byte等于一个float的手动分割线===0001000000===我是四个byte等于一个float的手动分割线===0010000001000000</code></pre><p>这个其实跟float是如何表示小数有关了，float有几个bit是专门给小数点后面的数值和指数准备的。<br>float是4个byte，这32位是这么分的：<br>1bit（符号位） 8bits（指数位） 23bits（尾数位）（内存中就长这样）</p><p>改成long呢，short呢？<br>改成long</p><pre><code>1    0000000===我是八个byte等于一个long的手动分割线===100000000===我是八个byte等于一个long的手动分割线===110000000</code></pre><p>问题已经很清楚了。<br>上述是把数字当做int,long,float这种数据类型来发送，但如果是把123这三个数字当做”123”这种字符串，数字1其实只用一个byte就解决了，也就不存在什么字节序的问题了</p><p>如C编写的进程和Java编写的进程间通信，(JVM也是大端）。在主机和网络字节序的互相转化主要涉及IP地址和端口。c语言写server要老老实实去转换ip地址和端口的字节序，这也是为了遵守规范</p><pre><code class="c">#include &lt;netstat/in.h&gt;unsigned long int htonl(unsigned long int hostlong);unsigned short  int htons(unsigned short int hostshort);unsigned long int ntohl(unsigned long int netlong);unsigned short int ntohs(unsigned short int netshort);</code></pre><p>网络字节序是一种规定，它规定了传输的数据应该按照大端，因为通信双方的字节序其实是不确定的，但是按照规定我们都认为接收到的数据都是大端，即遵守规定的顺序，这样老老实实地通过htons系列函数处理格式化的数据（如int）保证了不会出现任何错误。</p><p>但是，我们自己写的C/S因为都是小端，所以即使没有遵守规定，依然可以用，但这样并不规范，有潜在的隐患。</p><p>而对于IP地址或者端口，因为这些数据的处理全部是在应用层以下，是路由器，网卡进行处理，它们在设计时自然遵守规定全部依照网络字节序对数据进行处理，而你自己不把IP地址转换顺序，交给下层处理时自然会出错。</p><p>所以，在应用层，也应该遵守规定，对于int double 这样的数据也应该转换字节序，当然字符串也挺好（这大概也就是Json的优势了，而像protobuf这种传输时就要注意顺序）。</p><p><a href="https://blog.csdn.net/XiyouLinux_Kangyijie/article/details/72991235">抓包看ip地址字节序转换</a><br>utf-8还有一个byte-order-mark(bom)的问题</p><p>C语言下可以把一个byte按照binary的方式打印出来(就是把一个byte的每一个bit输出来),int也可以。</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;limits.h&gt;void print_bin(unsigned char byte){    int i = CHAR_BIT; /* however many bits are in a byte on your platform */    while(i--) {        putchar(&#39;0&#39; + ((byte &gt;&gt; i) &amp; 1)); /* loop through and print the bits */    }    printf(&quot;\n\n&quot;);}void print_bin_int(unsigned int integer){    int i = CHAR_BIT * sizeof integer; /* however many bits are in an integer */    while(i--) {        putchar(&#39;0&#39; + ((integer &gt;&gt; i) &amp; 1));    }    printf(&quot;\n\n&quot;);}int checkCPUendian(){  union  {    unsigned int a;    unsigned char b;  }c;  c.a = 1;  printf(&quot;a = %a , b= %a \n&quot;,c.a , c.b);  printf(&quot;a = %X , b= %X \n&quot;,c.a , c.b);  printf(&quot;a = %p , b= %p \n&quot;,c.a , c.b);  printf(&quot;a = %u , b= %u \n&quot;,c.a , c.b);  print_bin(c.b);  print_bin_int(c.a);  return (c.b == 1);}int main(int argc, char const *argv[]) {        if(checkCPUendian()){                printf(&quot;Little endian platform!\n&quot;);        } else {                printf(&quot;Big Endian platform!\n&quot;);        }        return 0;}</code></pre><p>输出，这里是从高地址内存开始往低地址的内存读取</p><pre><code>a = 0x0.07fcbc8474a98p-1022 , b= 0x0p+0a = 1 , b= 1a = 0x1 , b= 0x1a = 1 , b= 10000000100000000000000000000000000000001Little endian platform!</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;字节序（Endianness），在计算机科学领域中，是跨越&lt;strong&gt;&lt;em&gt;多字节&lt;/em&gt;&lt;/strong&gt;的程序对象的存储规则。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/ship_docking_along_side_bay.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
