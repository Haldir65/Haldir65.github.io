<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Haldir的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://haldir65.github.io/"/>
  <updated>2019-03-13T02:30:25.314Z</updated>
  <id>https://haldir65.github.io/</id>
  
  <author>
    <name>Haldir</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hexo部署个人博客记录</title>
    <link href="https://haldir65.github.io/2217/01/08/2017-01-08-trouble-shooting-with-my-blog/"/>
    <id>https://haldir65.github.io/2217/01/08/2017-01-08-trouble-shooting-with-my-blog/</id>
    <published>2217-01-08T18:01:01.000Z</published>
    <updated>2019-03-13T02:30:25.314Z</updated>
    
    <content type="html"><![CDATA[<p>使用 hexo 写博客以来，记录下来的问题越来越多。只希望下次再碰到同样的问题时，不要再去浪费时间去查找。如果想要给自己的 blog 一个值得置顶的文章的话，我觉得一篇记录使用 hexo 过程中的一些解决问题的方法的文章是再合适不过的了。</br><br><img src="https://haldir66.ga/static/imgs/40164340_40164340_1414330224938_mthumb.jpg" alt=""></p><a id="more"></a><h2 id="1-经常更新-yilia-的-theme"><a href="#1-经常更新-yilia-的-theme" class="headerlink" title="1. 经常更新 yilia 的 theme"></a>1. 经常更新 yilia 的 theme</h2><p><a href="https://github.com/litten/hexo-theme-yilia">yilia</a>主题经常会更新，及时更新 theme 会发现很多新的特性及 bug fix</p><h2 id="2-部署相关"><a href="#2-部署相关" class="headerlink" title="2. 部署相关"></a>2. 部署相关</h2><ul><li>部署到 github</li></ul><pre><code class="javascript">hexo clean //清除缓存hexo g -d //一步到位 = hexo g + hexo dhexo s //localost:4000本地预览</code></pre><ul><li>部署过程中出现的一些错误</li></ul><pre><code class="javascript">$ hexo g -dINFO  Start processingERROR Process failed: _posts/2016-12-10-adb-command.mdYAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 3, column 11:    categories:  [技术]              ^    at generateError (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:162:10)    at throwError (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:168:9)    at readBlockMapping (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1040:9)    at composeNode (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1326:12)    at readDocument (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1488:3)    at loadDocuments (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1544:5)    at Object.load (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1561:19)    at parseYAML (D:\Blog\github\node_modules\hexo\node_modules\hexo-front-matter\lib\front_matter.js:80:21)    at parse (D:\Blog\github\node_modules\hexo\node_modules\hexo-front-matter\lib\front_matter.js:56:12)    at D:\Blog\github\node_modules\hexo\lib\plugins\processor\post.js:52:18    at tryCatcher (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\util.js:16:23)    at Promise._settlePromiseFromHandler (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:507:35)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:567:18)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at PromiseArray._resolve (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:125:19)    at PromiseArray._promiseFulfilled (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:143:14)    at PromiseArray._iterate (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:113:31)    at PromiseArray.init [as _init] (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:77:10)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:564:21)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at PromiseArray._resolve (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:125:19)    at PromiseArray._promiseFulfilled (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:143:14)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:572:26)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at Promise._resolveCallback (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:431:57)    at Promise._settlePromiseFromHandler (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:522:17)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:567:18)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\nodeback.js:42:21    at D:\Blog\github\node_modules\hexo\node_modules\hexo-fs\node_modules\graceful-fs\graceful-fs.js:78:16    at tryToString (fs.js:455:3)    at FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:442:12)INFO  Files loaded in 1.48 sINFO  Generated: sitemap.xmlINFO  Generated: atom.xmlINFO  Generated: 2017/01/08/2017-01-08-trouble-shooting-with-my-blog/index.htmlINFO  Generated: index.htmlINFO  4 files generated in 2.26 sINFO  Deploying: git</code></pre><p>找了好久，有说”_config.xml” 文件 有空格的，有说 title 被乱改的，试了好长时间，改成这样就不再报错了。所以，<strong>冒号后面一定要加空格，英文半角的</strong></p><pre><code>---title: adb常用命令手册date: 2016-12-10 21:14:14tags: - android - adb---</code></pre><p>tags 有两种写法，一种是上面这样前面加横杠另一种长这样，写成数组形式</p><pre><code>---title: my awesometitledate: 2017-05-07 16:48:01categories: blogtags: [linux,python]---</code></pre><h2 id="3-一些功能的实现"><a href="#3-一些功能的实现" class="headerlink" title="3. 一些功能的实现"></a>3. 一些功能的实现</h2><ul><li>置顶功能将 node_modules/hexo-generator-index/lib/generator.js 的文件内容替换成以下内容</li></ul><pre><code class="javascript">&quot;use strict&quot;;var pagination = require(&quot;hexo-pagination&quot;);module.exports = function(locals) {  var config = this.config;  var posts = locals.posts;  posts.data = posts.data.sort(function(a, b) {    if (a.top &amp;&amp; b.top) {      // 两篇文章top都有定义      if (a.top == b.top)        return b.date - a.date; // 若top值一样则按照文章日期降序排      else return b.top - a.top; // 否则按照top值降序排    } else if (a.top &amp;&amp; !b.top) {      // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233）      return -1;    } else if (!a.top &amp;&amp; b.top) {      return 1;    } else return b.date - a.date; // 都没定义按照文章日期降序排  });  var paginationDir = config.pagination_dir || &quot;page&quot;;  return pagination(&quot;&quot;, posts, {    perPage: config.index_generator.per_page,    layout: [&quot;index&quot;, &quot;archive&quot;],    format: paginationDir + &quot;/%d/&quot;,    data: {      __index: true    }  });};</code></pre><ul><li>同时在文章开头添加 top : 1 即可 ，实际排序按照这个数字从大到小排序</li></ul><p>另一种做法是手动将date改大，日期越靠后的越在前面。</p><pre><code class="java"> title: Hexo置顶文章date: 2016-11-11 23:26:22tags:[置顶]categories: Hexotop: 0 # 0或者1</code></pre><p>个人建议：置顶不要太多</p><h2 id="4-SublimeText-的一些快捷键"><a href="#4-SublimeText-的一些快捷键" class="headerlink" title="4. SublimeText 的一些快捷键"></a>4. SublimeText 的一些快捷键</h2><p>由于文章大部分都是使用 SublimeText 写的，Typroa 这种所见即所得的编辑器也不错，但对于掌握 MardkDown 语法没有帮助。这里摘录一些 SubLimeText 的快捷键。</p><blockquote><p><strong>Ctrl+Shift+P：打开命令面板</strong><br>Ctrl+P：搜索项目中的文件<br>Ctrl+G：跳转到第几行<br>Ctrl+W：关闭当前打开文件 CTRL+F4 也可以<br>Ctrl+Shift+W：关闭所有打开文件<br>Ctrl+Shift+V：粘贴并格式化<br>Ctrl+D：选择单词，重复可增加选择下一个相同的单词<br><strong>Ctrl+L：选择行，重复可依次增加选择下一行</strong><br><strong>Alt+Shift+数字：分屏显示</strong><br><strong>Ctrl+Shift+L：选择多行</strong><br><strong>Ctrl+Shift+D：复制粘贴当前行</strong><br><strong>Ctrl+X：删除当前行</strong><br><strong>Ctrl+Shift+左箭头 往左边选择内容</strong><br><strong>Shift+向左箭头 向左选择文本</strong><br><strong>Ctrl+B 编译，markDown 生成 html 文件</strong><br><strong>Alt+2 切换到第二个 Tab（打开的文件，记得 chrome 是 ctrl+2）</strong><br><strong>Ctrl+R：前往 对应的方法的实现*</strong><br><strong>快速加上[] 选中单词按 [ 即可</strong><br><strong>批量更改当前页面相同的单词 alt+F3 </strong><br><strong>Ctrl+Enter 在下一行插入新的一行</strong><br><strong>Ctrl+Shift+Enter 在上一行插入新的一行</strong><br><strong>Shift+ 向上箭头 向上选中多行</strong></p></blockquote><p>Ctrl+Shift+D：复制粘贴当前行 Ctrl+Shift+Enter：在当前行前插入新行<br>Ctrl+M：跳转到对应括号<br>Ctrl+U：软撤销，撤销光标位置<br>Ctrl+J：选择标签内容<br>Ctrl+F：查找内容<br>Ctrl+Shift+F：查找并替换<br>Ctrl+H：替换<br>Ctrl+N：新建窗口<br>Ctrl+K+B：开关侧栏<br>Ctrl+Shift+M：选中当前括号内容，重复可选着括号本身<br>Ctrl+F2：设置/删除标记<br>Ctrl+/：注释当前行<br>Ctrl+Shift+/：当前位置插入注释<br>Ctrl+Alt+/：块注释，并 Focus 到首行，写注释说明用的<br>Ctrl+Shift+A：选择当前标签前后，修改标签用的<br>F11：全屏<br>Shift+F11：全屏免打扰模式，只编辑当前文件<br>Alt+F3：选择所有相同<br>Alt+.：闭合标签<br>Shift+右键拖动：光标多不，用来更改或插入列内容<br>Alt+数字：切换打开第 N 个文件鼠标的前进后退键可切换 Tab 文件按 Ctrl，依次点击或选取，可需要编辑的多个位置按 Ctrl+Shift+上下键，可替换行</p><p>vscode的快捷键最重要的一个是ctrl+shift+p,ctrl+p只是在全局查找文件</p><h2 id="5-title-不能以-开头"><a href="#5-title-不能以-开头" class="headerlink" title="5. title 不能以[]开头"></a>5. title 不能以[]开头</h2><p>前面加上###确实能够让字号变大，但不要写 4 个#，后面的字母会大小写不分的</p><h2 id="6-markdown-语法"><a href="#6-markdown-语法" class="headerlink" title="6. markdown 语法"></a>6. markdown 语法</h2><p>MarkDown 页面内部跳转<br><a href="http://www.cnblogs.com/JohnTsai/p/4027229.html">MarkDown 技巧：两种方式实现页内跳转</a></p><blockquote><p><em>一个星星包起来是斜体字</em><br><strong>两个星星包起来是粗体字</strong><br><strong><em><em>那么三个星星呢</em></em></strong></p></blockquote><h2 id="7-github-提交-commit-的时候显示-Emoji"><a href="#7-github-提交-commit-的时候显示-Emoji" class="headerlink" title="7.github 提交 commit 的时候显示 Emoji"></a>7.github 提交 commit 的时候显示 Emoji</h2><p>链接<a href="https://www.webpagefx.com/tools/emoji-cheat-sheet/">在此</a></p><h2 id="8-换电脑了怎么办"><a href="#8-换电脑了怎么办" class="headerlink" title="8.换电脑了怎么办"></a>8.换电脑了怎么办</h2><p>亲测，把整个目录下所有文件全部复制粘贴到新电脑上，装上 node，然后装上 hexo，记得勾选添加到 PATH,然后就可以了。需要注意的是小文件比较多，所以复制粘贴可能要十几分钟。</p><h2 id="9-有时候写的代码会给你在每一行前面加上-true"><a href="#9-有时候写的代码会给你在每一行前面加上-true" class="headerlink" title="9. 有时候写的代码会给你在每一行前面加上 true"></a>9. 有时候写的代码会给你在每一行前面加上 true</h2><p>比如写一段 css 的代码时候，很多时候预览会给每一行前面加上一个 true，解决办法：用 TAB 键缩进即可</p><h2 id="10-markdown-live-是一个非常好用的-node-module"><a href="#10-markdown-live-是一个非常好用的-node-module" class="headerlink" title="10. markdown-live 是一个非常好用的 node module"></a>10. markdown-live 是一个非常好用的 node module</h2><p><a href="https://www.npmjs.com/package/markdown-live">项目地址</a><br><strong>前提是安装了 node</strong></p><blockquote><p>npm install -g markdown-live</p><p>md-live</p></blockquote><p><br><br><strong><em>编辑md文件的同时，保存就会同步刷新网页预览，非常好用</em></strong></p><h2 id="11-如果运行-hexo-g-生成的-index-html-是空的"><a href="#11-如果运行-hexo-g-生成的-index-html-是空的" class="headerlink" title="11. 如果运行 hexo g 生成的 index.html 是空的"></a>11. 如果运行 hexo g 生成的 index.html 是空的</h2><p>输出</p><blockquote><p>WARN No layout: tags/service/index.html<br>原因是 themes/文件夹下没有 clone 对应的主题</p></blockquote><p>换成travis之后，在travis.yml文件中，添加了</p><pre><code class="config">cache:  yarn: true  directories:  - node_modules  - themes</code></pre><p>cahe也就意味着后续，所有对于themes文件夹中的_config.yml文件的修改都不会生效。这也就是我一遍遍尝试更改theme文件夹中_config文件不生效的原因。<br>所以要么去掉cache ，要么自己写bash script一行行的改。</p><h2 id="12-markdown写表格"><a href="#12-markdown写表格" class="headerlink" title="12. markdown写表格"></a>12. markdown写表格</h2><p>直接在atom下面敲table，就会自动提示出来的</p><table><thead><tr><th>一个普通标题</th><th>一个普通标题</th><th>一个普通标题</th></tr></thead><tbody><tr><td>短文本</td><td>中等文本</td><td>稍微长一点的文本</td></tr><tr><td>稍微长一点的文本</td><td>短文本</td><td>中等文本</td></tr></tbody></table><p>中间的虚线左边的冒号表示下面的单元格左对齐，冒号放右边就右对齐，左右都放一个就表示居中</p><p>vscode的返回上一个文件快捷键是ctrl + -</p><h2 id="13-travis-ci自动部署的一些问题"><a href="#13-travis-ci自动部署的一些问题" class="headerlink" title="13 . travis ci自动部署的一些问题"></a>13 . travis ci自动部署的一些问题</h2><p><a href="https://github.com/travis-ci/travis.rb/issues/437">travis ci加密文件无法在travis以外的地方解密，因为key,value都存在travis的数据库了</a></p><p><a href="https://github.com/travis-ci/travis-ci/issues/9668">travis加密文件后用openssl解密出现iv undefined的错误</a></p><p>iv undefined</p><blockquote><p>travis env list<br>encrypted_476ad15a8e52_key=[secure]<br>encrypted_476ad15a8e52_iv=[secure]<br>明明是存在的</p></blockquote><p>在linux 里面运行travis endpoint<br>果然是 API endpoint: <a href="https://api.travis-ci.org/">https://api.travis-ci.org/</a><br>而新的endpoint应该是 <a href="https://api.travis-ci.com/">https://api.travis-ci.com/</a><br>于是travis encrypt-file –help</p><blockquote><p>–pro  short-cut for –api-endpoint ‘<a href="https://api.travis-ci.com/">https://api.travis-ci.com/</a>‘<br>–org short-cut for –api-endpoint ‘<a href="https://api.travis-ci.org/">https://api.travis-ci.org/</a>‘</p></blockquote><p>所以</p><blockquote><p>travis encrypt-file super_secret.txt 应该改成<br>travis encrypt-file super_secret.txt –pro</p></blockquote><p>因为默认的$encrypted_476ad15a8e52_key其实已经存储在travis-ci.org上了<br>所以在travis-ci.com上的项目当然找不到</p><p><a href="https://github.com/openwrtio/openwrtio.github.io/blob/mkdocs/.travis.yml">自动部署的另一个实例</a></p><h2 id="14-hexo-server本地预览出现的问题"><a href="#14-hexo-server本地预览出现的问题" class="headerlink" title="14. hexo server本地预览出现的问题"></a>14. hexo server本地预览出现的问题</h2><p><a href="Refused to execute script from" title="http://localhost:4000/slider.e37972.js&#39; because its MIME type (&#39;text/html">hexo s 本地预览样式加载失败</a> is not executable, and strict MIME type checking is enabled.)</p><p>hexo server的意思是类似于express的serve static功能，<a href="https://hexo.io/zh-cn/docs/server.html">默认只处理public文件下的文件，所以如果本地运行hexo s 出现404的话，直接copy到public文件夹下就可以了</a>注意hexo clear会删掉public文件夹</p><p>[Refused to Execute Script From Because Its MIME Type (Text/plain) Is Not Executable, and Strict MIME Type Checking Is Enabled]这句话的意思,这其实是我本地跑hexo server的时候，没有找到一个xx.js文件，所以express返回了一个类似于404的plain text（而不是js文件），所以就出这个问题了。</p><h2 id="15-yilia的主题里面badjs-report的问题"><a href="#15-yilia的主题里面badjs-report的问题" class="headerlink" title="15. yilia的主题里面badjs report的问题"></a>15. yilia的主题里面badjs report的问题</h2><p>yilia的主题里面有一个badjs的report，去掉的方法：<br>cd 到themes/yilia里面,rm -rf source/ , 然后把source-src里面的report.js里面的东西删掉。yarn install ,yarn dist ,然后回到上层目录。hexo clean , hexo g就可以了。<br>其实看下里面，就是一个webpack的配置，自己重新编译一下就好了。编译后会在source里面重新生成需要的js文件。<br>奇怪的是在windows上编译失败，在linux上编译失败，在mac上终于成功了。</p><h2 id="16-hexo-server"><a href="#16-hexo-server" class="headerlink" title="16. hexo server"></a>16. hexo server</h2><p><a href="https://stackoverflow.com/questions/22475849/node-js-what-is-enospc-error-and-how-to-solve">enospc的解决方式</a><br>由于需要监听多个文件，所以linux下允许监听的文件数有个上限，这里修改一下就可以了</p><h2 id="17-hexo自带的代码高亮有一些不是很好的地方"><a href="#17-hexo自带的代码高亮有一些不是很好的地方" class="headerlink" title="17. hexo自带的代码高亮有一些不是很好的地方"></a>17. hexo自带的代码高亮有一些不是很好的地方</h2><p>改用highlightjs就可以了。<br>首先要把最外面的_config.yml里面的高亮关掉</p><pre><code>highlight:  enable: false</code></pre><p>由于最终生成的html文件中引用的是theme中webpack -p 打出来的js文件，所以照着highlightjs的说明修改一下yilia的源码，source-src目录，npm install highlight.js –save重新yarn dist就好了。yilia的theme修改还算简单。</p><h2 id="18-hexo渲染md文件时有些特定字符串是不能写的"><a href="#18-hexo渲染md文件时有些特定字符串是不能写的" class="headerlink" title="18. hexo渲染md文件时有些特定字符串是不能写的"></a>18. hexo渲染md文件时有些特定字符串是不能写的</h2><p>hexo本质上是一个js模板渲染工具，和jinja，handlerbars这一类模板一样，经常会用花括号包起来表示一个变量<br>下面这个，美元符号加一个花括号抱起来的井号就不能单独拿出来写</p><pre><code>${#}</code></pre><p>报的错大概长这样</p><pre><code>Template render error: (unknown path) [Line 101, Column 142]  unexpected token: }}</code></pre><p><a href="https://github.com/hexojs/hexo/issues/2384#issuecomment-277494121">原因是这种看上去像是引用一个变量的东西是某些js库的保留syntax</a></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="http://yanhuili.github.io/2016/11/21/hexo%E5%8D%9A%E6%96%87%E7%BD%AE%E9%A1%B6%E6%8A%80%E5%B7%A7/">Hexo 博文置顶技巧</a></li><li><a href="http://www.daqianduan.com/4820.html">SublimeText 快捷键</a></li><li><a href="http://itmyhome.com/markdown/article/syntax/emphasis.html">MarkDown 语法学起来很快的</a></li><li><a href="https://blessing.studio/deploy-hexo-blog-automatically-with-travis-ci/">travis 自动部署</a></li><li><a href="https://docs.travis-ci.com/user/legacy-services-to-github-apps-migration-guide/">Legacy GitHub Services to GitHub Apps Migration Guide 2018年10月1号之后不再支持 Legacy GitHub Service</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 hexo 写博客以来，记录下来的问题越来越多。只希望下次再碰到同样的问题时，不要再去浪费时间去查找。如果想要给自己的 blog 一个值得置顶的文章的话，我觉得一篇记录使用 hexo 过程中的一些解决问题的方法的文章是再合适不过的了。&lt;/br&gt;&lt;br&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/40164340_40164340_1414330224938_mthumb.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="blog" scheme="https://haldir65.github.io/categories/blog/"/>
    
    
      <category term="置顶" scheme="https://haldir65.github.io/tags/%E7%BD%AE%E9%A1%B6/"/>
    
      <category term="hexo" scheme="https://haldir65.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>即刻备忘录</title>
    <link href="https://haldir65.github.io/2046/12/18/2017-12-18-random-new-thoughts/"/>
    <id>https://haldir65.github.io/2046/12/18/2017-12-18-random-new-thoughts/</id>
    <published>2046-12-18T22:58:14.000Z</published>
    <updated>2019-03-13T02:30:25.322Z</updated>
    
    <content type="html"><![CDATA[<p>一个待办事项的仓库<br><img src="https://haldir66.ga/static/imgs/girlfriend lake green nature water cold.jpg" alt=""></p><a id="more"></a><h3 id="期待能够完成的"><a href="#期待能够完成的" class="headerlink" title="期待能够完成的"></a>期待能够完成的</h3><ul><li><a href="https://juejin.im/post/5a0c1956f265da430a501f51">个人分享–web 前端学习资源分享</a></li><li><a href="https://huangxuan.me/2017/02/09/nextgen-web-pwa/">PWA 所代表的 Web 开发应是未来</a>据说Electron要被PWA干掉</li><li><a href="https://segmentfault.com/a/1190000003818163">js 循环闭包的解决方法</a></li><li>动态类型一时爽，代码重构火葬场</li><li>iview，elementUi</li><li>[ ] shadowsocks-android源码（据说是起了一个c进程守护）</li><li>[ ] chromium net移植到Android平台<a href="https://github.com/GoogleChromeLabs/cronet-sample">cronet是最简单的方式</a> <a href="https://console.cloud.google.com/storage/browser/chromium-cronet?pli=1">更多下载仓库</a></li><li><a href="https://css-tricks.com/NetMag/FluidWidthVideo/Article-FluidWidthVideo.php">embeed video with iframe</a></li><li>[ ] Paul Irish from google</li><li>[ ] <a href="http://lokeshdhakar.com/projects/lightbox2/">lightbox一个很好看的js图片查看库</a></li><li>[ ] <a href="https://github.com/wangpengfei15975/skPlayer/">一个很好看的h5音乐播放器</a></li><li>[ ] <a href="https://www.js-css.cn/a/jscode/album/2014/0915/1319.html">仿门户网站js相册</a>， <a href="https://www.js-css.cn/a/jscode/album/2014/0914/1318.html">js相册2</a></li><li>[ ] <a href="http://python.jobbole.com/82270/">八大排序算法的python实现</a></li><li>[ ] Redux和Flux很像,react context api</li><li>[ ] <a href="https://www.jianshu.com/p/a4ab102fa4ac">一个展示如何在宿主App中提取一个apk文件并加载代码和资源</a></li><li>[ ] nodejs ,go ,protobuf rpc(proto更多的是作为一种协议来进行rpc数据传输)</li><li>[ ]一致性哈希原理</li><li>[ ] <a href="http://afghl.github.io/2018/06/17/distributed-lock-and-granarity.html">使用redis实现低粒度的分布式锁</a></li><li>[ ] Coordinator behavior以及scroll原理，完善blog</li><li>[ ] instagram好像通过注解的方式自己写了一个json解析器<a href="https://github.com/Instagram/ig-json-parser">ig-json-parser</a></li><li>[ ] when it comes to design , how do we translate px, pt, em  into sp,dp and others(设计方面的，各种单位之间的转换)?</li><li>[ ] learning how textView works is painful yet necessary</li><li>[ ] linux环境下多进程通讯方式(管道，共享内存，信号,unix domian socket)</li><li>[ ] mqtt接入实践<a href="https://github.com/mcxiaoke/mqtt">mqtt是建立在tcp基础上的应用层协议</a>，<a href="https://github.com/netty/netty">netty</a>也做了实现</li><li>[ ] play around with xposed</li><li>[ ] python gui编程</li><li>[ ] <a href="https://www.youtube.com/watch?v=jYuK1qzFrJg">Kotlin Coroutines Tutorial (STABLE VERSION) </a></li><li>[ ] 宇宙第一ide熟悉使用</li><li>[ ] js的闭包等面试常谈</li><li>[ ] java的aspectJ教程，Spring AOP 与AspectJ 实现原理上并不完全一致，但功能上是相似的</li><li>[ ] autoWired, autovalue这些java 的library</li><li>[ ] code generator(代码生成器)</li><li>[ ]<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers">content-disposition</a></li><li>[ ] 用正则检测或者解析json(jQuery源码里有) 在线正则检测网站</li><li>[ ] awk，正则表达式还有数据库这些也算一门编程语言</li><li>[ ] 来来来，<a href="https://www.youtube.com/watch?v=DUNkdl0Jhgs">手写一个vm</a></li><li>[ ] <a href="https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md#System-requirements">chromium提供了如何在windows上编译chromium的教程</a></li><li>[ ]<a href="https://www.youtube.com/watch?v=M8LiOANu3Nk">How the JVM compiles bytecode into machine code</a></li><li>[ ] WebSocket协议及数据帧</li><li>[ ]Lua脚本是一个很轻量级的脚本，也是号称性能最高的脚本。路由器上都有运行环境，语法和c语言差不多</li><li><a href="https://juejin.im/post/5baf8ae8f265da0ae92a7df5">腾讯的mmkv是shared preference的有效替代品</a> mmap的使用值得学习</li><li>[ ] <a href="https://github.com/keerath/openjdk-8-source/blob/master/jdk/src/windows/native/java/net/SocketOutputStream.c">openjdk的C语言实现可以随便调几处来看看</a></li><li><a href="https://www.jianshu.com/p/5f9a7bc902e1">简单的组件化方案</a></li></ul><h3 id="已完成"><a href="#已完成" class="headerlink" title="已完成"></a>已完成</h3><ul><li>用 express 转接一个知乎 Api，添加 Access-control-allow-origin,或许还可以用 redis 缓存数据结果（一个就好）由此想到一篇文章”How to use Pythonto build a restful Web Service”.只不过用的是 Tornado</li><li>git hook (github travis 持续集成，git push 会触发服务器的一系列操作)</li><li>基于前后端分离的理念，后台只负责提供数据，render page 的任务应该交给前端。（所以用 express-handlebars 写页面的方式写着很累）</li><li>集成 travis-ci，记得 after-success script 的结果并不会影响 build 的结果（即，after-success 执行脚本发生了错误，在日志里有输出 error，但实际显示的 build result 仍为 success），还有 travis 的输出 log 需要默认是折叠的，要展开才能看清楚，但在 afterSuccess 里面的指令的输出一定是有的。</li><li>随便放一个文件到/usr/bin/就可以直接调用这个文件名来起这个命令了吗？（实际操作只需要建立一个symbolic link就好了）</li><li>单个网卡最多65535个端口，c10K。<a href="https://www.zhihu.com/question/66553828">65536其实不是操作系统限制的，而是tcp协议就只给port留了2个bytes给source port，只留了2个bytes给destination port</a>端口号写在tcp包里，ip地址不是，ip地址是ip层的事情</li><li>oAuth2原理，其实流程上和很多客户端的微信登陆，新浪微博登陆很像的</li><li>在Android手机上尝试用一个unix domain socket用于localhost进程间ipc(其实就是保证端口号一致，给网络权限就好了)</li><li>写 groovy 用intelij全家桶就可以了，groovy的<a href="https://www.tutorialspoint.com/groovy/groovy_closures.htm">语法</a>其实没什么，主要是了解编译的流程和基本原理，这个需要看<a href="https://docs.gradle.org/current/userguide/build_lifecycle.html#sec:build_phases">official doc</a></li><li><a href="https://github.com/JLLK/gradle-android-maindexlist-plugin">开发gradle plugin优化MultiDex</a>。长远来看，5.0以后的手机越来越多，MultiDex也不值得过于关注。</li><li>intelij 点击run 实际调用的command line是两个，一个是javac，编译出来的class文件放到了target文件夹，紧接着用java命令带上一大串classpath去调用主函数</li><li><a href="https://fucknmb.com/2017/05/11/Android-Studio-Library%E6%A8%A1%E5%9D%97%E4%B8%ADNative%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8Cdebug%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/">Android Studio 编译过程</a>，其实就是gradle assembleXXX 好了之后adb push到手机上，再安装，最后起主界面</li><li><a href="http://mouxuejie.com/blog/2016-06-21/multidex-compile-and-dex-source-analysis/">Android 编译及 Dex 过程源码分析</a></li><li><a href="http://www.wangyuwei.me/">如何调试 Android 打包流程？</a>，一个remote的事</li><li><a href="https://github.com/chenenyu/img-optimizer-gradle-plugin">一个用于优化 png 图片的 gradle 插件</a>，用来看 groovy 语法挺好的。以及 <a href="http://yuanfentiank789.github.io/2017/09/20/%E5%9C%A8AndroidStudio%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89Gradle%E6%8F%92%E4%BB%B6/">How to write gradle plugin</a></li><li>XSS 攻击,DOM based和Stored XSS,基本上就是不要相信用户的输入，除了合法输入以外一律过滤掉</li></ul><ul><li>websocket nodejs，局限性就是前后台都得用socket.io的库。前端是浏览器的话还好，app的话java,Android都有对应的实现.[其实就是socket io] </li><li>[X]一直不会maven是在是太丢人了<a href="https://maven.apache.org/guides/getting-started/index.html#How_do_I_make_my_first_Maven_project">看文档就行了</a>，其他的<a href="https://www.tutorialspoint.com/maven/maven_build_life_cycle.htm">教程</a>也不错</li><li>[使用Spring boot后台提供protobuf接口实现客户端通信] 不要使用protobf-gradle-plugin了。直接写脚本用protoc去生成文件，指定生成文件的路径要和proto里面写的包名对的上。另外就是客户端和server端依赖的protobuf版本以及protoc工具的版本得一致，比如都是3.5。还有就是protoc的语法，什么import的比较烦。</li><li>[X] 使用jinja2生成文件。<a href="https://github.com/guokr/swagger-py-codegen">一个比较好玩的代码生成器</a></li><li>[X] URL Encoding,就是那个在网址里把字符转成百分号加上UTF-8的<a href="http://www.ruanyifeng.com/blog/2010/02/url_encoding.html">找到了阮一峰老师的解释</a></li><li>[X] 通过file input上传图片，原生ajax以及Ajax，自己搭建上传服务器<a href="https://zhuanlan.zhihu.com/p/24513281?refer=flask">大概能猜到暴风影音的局域网传输实现了</a>用flask的话自己搭建好后台最简单了，最多再使用flask-wtf和flask-upload规范操作</li><li>[X]Promise 链式调用与终止，异常处理(只是一个工具而已)</li><li>[X] Android 应用接入bugly热修复，上线之后就不用背锅了（有兴趣看看sevenZip.jar，暂时没看）</li><li>[X] <a href="http://normanmaurer.me/blog/2013/11/09/The-hidden-performance-costs-of-instantiating-Throwables/">简直碉堡了的博客</a>以及jvm 的inline等优化</li><li>[ ] <a href="https://seisman.github.io/how-to-write-makefile/introduction.html">如何写makefile</a>其实<a href="http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/">这个更加friendly</a></li><li>[X] <a href="https://www.jianshu.com/p/534741f5151c">libmp3lame移植到Android</a>,该教程针对的lame版本是3.99.5</li><li><a href="https://sspai.com/post/31500">scheme 这东西算跨客户端平台的</a>，比如在 App 中调起支付宝(用的是 alipayqr://)。其实就是一个系统内跨应用调用。<a href="http://blog.csdn.net/qq_23547831/article/details/51685310">用法</a><br>这个主要是ios app之间通信的协议，以及快速跳转某个app某个页面的功能实现，还有x-callback-URL这样类似的协议。不过有了3d-touch之后，很多app都能长按图标进入页面，所以url scheme这个功能只能说是不复往日辉煌了</li><li>[X]linux的sed命令(文本替换比较常用)</li><li><a href="https://juejin.im/post/59fffdb76fb9a0450a66bd58">nio</a> 还是netty好。也可以看点别的<a href="http://ifeve.com/java-nio%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E5%8D%81%E5%85%AD%EF%BC%89-java-nio-files/">并发编程网</a></li><li>[X]js 的async await,就是一个async修饰一个method，里面随便写await</li><li>[X] Linux下TCP延迟确认机制</li><li>[X]c语言的<a href="https://yq.aliyun.com/articles/413601">libevent使用教程</a> eventloop，添加回调，大致的流程就是这样</li><li>[X] <a href="http://www.ruanyifeng.com/blog/2018/07/indexeddb.html">indexed DB</a>,浏览器端数据库，还是用第三方库好</li><li>[X] <a href="http://forums.justlinux.com/showthread.php?3261-Block-size-vs-page-size">block size vs page size</a> Page是内存相关，block是硬盘相关的</li><li>[X] python 的asyncio(eventloop , generator, coroutine)</li><li>[X]<a href="https://vim.rtorr.com/">Vim cheet sheet</a> vim多用用就熟悉了。</li><li>[X] python dunder class复习。知道有python descriptor这回事就行了。</li><li>[X] form表单可以跨域一个是历史原因要保持兼容性（就是说跨域这件事，一个域名的 JS ，在未经允许的情况下，不得读取另一个域名的内容。但浏览器并不阻止你向另一个域名发送请求。所以post的表单可以发出去，但是别指望能够拿到response）</li><li>[X] a new article on open-gl intro(在Android平台上要和MediaCodec相关的音视频格式结合着来一起看)</li><li>[X] JavaScript中new FileReader(属于html5的东西)，以及canvas api(lineTo,quardTo这些都是相近的),以及<a href="https://juejin.im/post/5a98c5c26fb9a028d82b34ee">js进行图片缩放和裁剪</a> </li><li>[X] tcp-proxy实用教程 </li><li>[X]Exoplayer and the MediaCodec api<a href="https://medium.com/androiddevelopers/building-a-video-player-app-in-android-part-3-5-19543ea9d416">building-a-video-player-app-in-android</a> </li><li><a href="https://www.youtube.com/watch?v=g3F7Imjcd4k">AC2016腾讯前端技术大会 1 1 1 H5直播那些事</a></li><li>[X] tcp-proxy实用教程(tcp replay or udp relay)</li><li>[X] render-script utility</li><li>[X]C语言fork进程以及进程之间通信的套路</li><li>[X] flex,grid. css的box-size真是坑人</li><li>[X] rxjava是如何切换线程的以及源码解析，ObserveOnObserver和ObservableSubscribeOn实例是桥梁</li></ul><h3 id="Good-For-Nothing"><a href="#Good-For-Nothing" class="headerlink" title="Good For Nothing"></a>Good For Nothing</h3><ul><li>[ ] 用GDB调试程序</li><li>[ ] npm install graphql(mostly a server side javascript stuff)</li><li>使用 express 模拟网络延迟</li><li><a href="https://juejin.im/post/5a157b7a5188257bfe457ff0">基于 Docker 打造前端持续集成开发环境</a></li><li>vS Code Vender Prefix plugin =&gt; auto prefix loader</li><li>前后端分离</li><li>sql漏洞</li><li><a href="https://cloud.tencent.com/developer/article/1004755">深入浅出腾讯云 CDN：缓存篇</a>不管SSD盘或者SATA盘都有最小的操作单位，可能是512B，4KB，8KB。如果读写过程中不进行对齐，底层的硬件或者驱动就需要替应用层来做对齐操作，并将一次读写操作分裂为多次读写操作。</li><li>Android进程的<a href="https://juejin.im/post/5a646211f265da3e3f4cc997">加载流程</a></li><li>前后端同构</li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-with-ssl-as-a-reverse-proxy-for-jenkins">install nginx , jenkin ci, deploying nginx in docker(Http Load Balaning with Docker and nginx)</a></li><li>[ ] 网易云音乐API</li><li>[X] Django部署个人网站(Gunicorn，Nginx)。django写template就不是前后端分离了</li><li>[ ] Docker<a href="https://medium.com/@elye.project/intro-to-docker-building-android-app-cb7fb1b97602">intro-to-docker-building-android-app</a> 这篇文章其实是两件事，一个是Build docker image(docker build xxxx),另一个是run (docker run xxx)</li><li>[ ] <a href="https://blog.csdn.net/u013553529/article/details/53856800">和网页类似，Activity也有一个referer的概念</a>，用于判断当前页面是由谁发起请求的<br>OpenType® is a cross-platform font file format developed jointly by Adobe and Microsoft.</li><li>[ ]<a href="https://blog.securem.eu/serverside/2015/08/25/setting-up-owncloud-server-in-a-docker-container/">deploying owncloud using docker</a></li><li><a href="https://doc.owncloud.org/server/10.0/admin_manual/installation/docker/">owncloud官方的配合docker安装教程</a>网盘这种东西看个人喜好了</li><li>[ ]CloudFlare cdn解析以及DNS防护 </li><li>[ ] <a href="https://www.tutorialspoint.com/python/python_further_extensions.htm">python c extension</a> </li><li>[ ] <a href="https://github.com/elliotforbes/tutorialedge-rest-api">最简单的一个用go写出来的rest api大概长这样</a></li><li>[ ]<a href="https://lxneng.com/posts/201">分词器</a></li><li>[ ]<a href="http://www.wklken.me/posts/2015/04/26/elk-for-nginx-log.html">LOGSTASH+ELASTICSEARCH+KIBANA处理NGINX访问日志</a>ELK全家桶, logstash接管软件日志</li><li>[ ] <a href="https://gist.github.com/quexer/3619237">如何编写 jQuery 插件</a></li><li>netfilter框架(imbedded in linux server)</li></ul><p><a href="https://jsonplaceholder.typicode.com/">jsonplaceholder</a>懒得自己写api的话<br>就用这个吧</p><script>console.log("hey there")</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一个待办事项的仓库&lt;br&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/girlfriend lake green nature water cold.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>ndk入门笔记</title>
    <link href="https://haldir65.github.io/2019/02/13/2019-02-13-ndk-related-topics/"/>
    <id>https://haldir65.github.io/2019/02/13/2019-02-13-ndk-related-topics/</id>
    <published>2019-02-13T18:25:01.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p>android中ndk及jni编写注意事项（本文主要讲CMake）<br><img src="https://www.haldir66.ga/static/imgs/ShanwangpingKarst_EN-AU5360258756_1920x1080.jpg" alt=""><br><a id="more"></a><br>一些小窍门</p><blockquote><p>cmake最终执行的命令在这个文件里面.externalNativeBuild/cmake/debug/{abi}/cmake_build_command.txt<br>cmake生成的.so文件在”\app\build\intermediates\cmake\debug\obj\arm64-v8a”这个路径下。<br>CMake 一共有2种编译工具链 - clang 和 gcc，gcc 已经废弃，clang 是默认的。</p></blockquote><p><a href="https://developer.android.com/ndk/guides/">ndk官方入门指南</a></p><p>cpu架构</p><pre><code>armeabiarmeabi­v7aarm64­v8ax86x86_64mipsmips64</code></pre><p>cmake交叉编译</p><h3 id="abi-application-binary-interface"><a href="#abi-application-binary-interface" class="headerlink" title="abi(application binary interface)"></a>abi(application binary interface)</h3><p><a href="https://developer.android.com/ndk/guides/abis">abis</a><br>ndk支持的abi包括<br>armeabi，armeabi-v7a，arm64-v8a，x86，x86_64，mips，mips64</p><p><strong><em>NDK 17 不再支持 ABI: armeabi、mips、mips64</em></strong></p><p>x86设备上，libs/x86目录中如果存在.so文件的话，会被安装，如果不存在，则会选择armeabi-v7a中的.so文件，如果也不存在，则选择armeabi目录中的.so文件。</p><p>x86设备能够很好的运行ARM类型函数库，但并不保证100%不发生crash，特别是对旧设备。</p><p>64位设备（arm64-v8a, x86_64, mips64）能够运行32位的函数库，但是以32位模式运行，在64位平台上运行32位版本的ART和Android组件，将丢失专为64位优化过的性能（ART，webview，media等等）。<br>所有的x86/x86_64/armeabi-v7a/arm64-v8a设备都支持armeabi架构的.so文件，因此似乎移除其他ABIs的.so文件是一个减少APK大小的好技巧。</p><h3 id="abiFilter"><a href="#abiFilter" class="headerlink" title="abiFilter"></a>abiFilter</h3><p><a href="https://developer.android.com/studio/projects/gradle-external-native-builds">只想让cmake打arm64-v8a一种arch的包怎么办</a></p><blockquote><p>In most cases, you only need to specify abiFilters in the ndk block, as shown above, because it tells Gradle to both build and package those versions of your native libraries. However, if you want to control what Gradle should build, independently of what you want it to package into your APK, configure another abiFilters flag in the defaultConfig.externalNativeBuild.cmake block (or defaultConfig.externalNativeBuild.ndkBuild block). Gradle builds those ABI configurations but only packages the ones you specify in the defaultConfig.ndk block.</p></blockquote><p>翻译过来就是</p><pre><code>android {  ...  defaultConfig {    ...    externalNativeBuild {      cmake {          abiFilters &quot;arm64-v8a&quot; //只帮我打这个架构的就好了      }      // or ndkBuild {...}    }    // Similar to other properties in the defaultConfig block,    // you can configure the ndk block for each product flavor    // in your build configuration.    ndk {      // Specifies the ABI configurations of your native      // libraries Gradle should build and package with your APK.      abiFilters &#39;x86&#39;, &#39;x86_64&#39;, &#39;armeabi&#39;, &#39;armeabi-v7a&#39;,                   &#39;arm64-v8a&#39; //这些架构的包我全部都要打进apk里面    //当然，如果 externalNativeBuild里面只打了arm64-v8a的so文件，这种写法导致最终生成的apk里面装了x86，x86_64..的so文件夹，但其实里面放的都是arm64-v8a的so，当然是不行的。    //默认情况下，不写abiFilter的话，所有支持的abi对应的so文件都会打出来，大小略有差异    }  }  buildTypes {...}  // Use this block to link Gradle to your CMake or ndk-build script.似乎只是用来告诉gradle CMakeList.txt的位置在哪里  externalNativeBuild {       cmake {            path &#39;CMakeLists.txt&#39; //这个是说明CMakeLists.txt这个文件在哪里的，studio 里面link project with c++ program就是干这个的        }  }}</code></pre><p><a href="https://rangaofei.github.io/2018/02/22/shell脚本生成安卓全abi动态库与静态库">所以现在看来这种手动调用cmake的方式也没有太大必要了</a></p><h3 id="abi支持缺失导致的crash"><a href="#abi支持缺失导致的crash" class="headerlink" title="abi支持缺失导致的crash"></a>abi支持缺失导致的crash</h3><p>android第三方 sdk是以aar形式提供的,甚至是远程aar，如果这个sdk对abi的支持比较全，可能会包含armeabi, armeabi-v7a,x86, arm64-v8a,x86_64五种abi,而你应用的其它so只支持armeabi,armeabi-v7a，x86三种，直接引用sdk的aar,会自动编译出支持5种abi的包。但是应用的其它so缺少对其它两种abi的支持，那么如果应用运行于arm64-v8a,x86_64为首选abi的设备上时，就会CRASH。<br>所以解决方法就分两种<br>第一种：</p><pre><code>productFlavors {      necess {          ndk {              abiFilters &quot;armeabi-v7a&quot;              abiFilters &quot;x86&quot;              abiFilters &quot;armeabi&quot;          }      }      abiall {          ndk {              abiFilters &quot;armeabi-v7a&quot;              abiFilters &quot;x86&quot;              abiFilters &quot;armeabi&quot;              abiFilters &quot;arm64-v8a&quot;              abiFilters &quot;x86_64&quot;          }      }  }</code></pre><p>第二种：<br>app/build.gradle中这句话的意思是指让生成的apk中包含下面三种abi的so文件</p><pre><code class="gradle">defaultConfig {    ndk {        abiFilters &quot;armeabi&quot;, &quot;armeabi-v7a&quot;, &quot;arm64-v8a&quot;    }}</code></pre><p>在apk文件中，so文件放在lib/armeabi-v7a lib/x86_64 lib/x86 lib/arm64-v8a这些文件夹下面</p><h3 id="添加prebuilt-library"><a href="#添加prebuilt-library" class="headerlink" title="添加prebuilt library"></a>添加prebuilt library</h3><p>Add other prebuilt libraries<br>在CMakeLists.txt中添加<br>add_library( imported-lib<br>             SHARED<br>             IMPORTED )<br>关键词IMPORTED ，就拿ffmepg来说，首先在linux上编译出不同abi的so文件，ffmpeg有好几个so文件，比方说libavcodec.so这个文件。</p><pre><code>Some libraries provide separate packages for specific CPU architectures, or Application Binary Interfaces (ABI), and organize them into separate directories. This approach helps libraries take advantage of certain CPU architectures while allowing you to use only the versions of the library you want. To add multiple ABI versions of a library to your CMake build script, without having to write multiple commands for each version of the library, you can use the ANDROID_ABI path variable. This variable uses a list of the default ABIs that the NDK supports, or a filtered list of ABIs you manually configure Gradle to use.</code></pre><p>有些第三方库针对不同的cpu架构提供了不同的so文件</p><pre><code># 添加库——外部引入的库# 库名称：avcodec（不需要包含前缀lib）# 库类型：SHARED，表示动态库，后缀为.so（如果是STATIC，则表示静态库，后缀为.a）# IMPORTED表明是外部引入的库set(distribution_DIR ../../../../libs) //这个libs文件夹名字随便取，下面要包含armeabi-v7a,x86,x86_64等你想要支持的架构对应的so文件（在Linux上编出来的）add_library( avcodec        SHARED        IMPORTED)set_target_properties( avcodec        PROPERTIES IMPORTED_LOCATION        ${distribution_DIR}/${ANDROID_ABI}/libavcodec.so) //最终gradle编译的时候会把abiFilter中指定的cpu架构一个个去对应的文件夹去找so文件，找不到就会报错include_directories( avcodec/include/ )//告诉cmake，把这个目录下面的文件当做头文件拿进来，不用自己一个个去copy了，注意这个不是recursive的，也就是照顾不到子文件夹//这一步就是Link了target_link_libraries( native-lib //这个是我们自己的lib的名字        avcodec        avfilter        avformat        avutil        swresample        swscale        -landroid        ${log-lib} )</code></pre><h3 id="预先编译好的so文件放置的目录要告诉gradle"><a href="#预先编译好的so文件放置的目录要告诉gradle" class="headerlink" title="预先编译好的so文件放置的目录要告诉gradle"></a>预先编译好的so文件放置的目录要告诉gradle</h3><blockquote><p>f you want Gradle to package prebuilt native libraries with your APK, modify the default source set configuration to include the directory of your prebuilt .so files, as shown below. Keep in mind, you don’t need to do this to include artifacts of CMake build scripts that you link to Gradle.</p></blockquote><pre><code>android {    ...    sourceSets {        main {            jniLibs.srcDirs &#39;imported-lib/src/&#39;, &#39;more-imported-libs/src/&#39;        }    }}</code></pre><h3 id="调用ndk的api"><a href="#调用ndk的api" class="headerlink" title="调用ndk的api"></a>调用ndk的api</h3><p>比方说这种头文件</p><pre><code class="c">#include &lt;android/native_window_jni.h&gt;#include &lt;android/cpu-features.h&gt;#include &lt;android/multinetwork.h&gt;</code></pre><p>native_window_jni 在ndk 的libandroid.so库中，需要在CMakeLists.txt中引入android库，像这样</p><pre><code>target_link_libraries( my-lib        ...        -landroid        ${log-lib} )</code></pre><p>从<a href="https://www.jianshu.com/p/7a165b9f9fad">fmpeg+native_window实现万能视频播放器播放本地视频</a>抄来一段cpp代码</p><pre><code class="cpp"> extern &quot;C&quot; {    //编码    #include &quot;libavcodec/avcodec.h&quot;    //封装格式处理    #include &quot;libavformat/avformat.h&quot;    //像素处理    #include &quot;libswscale/swscale.h&quot;    //native_window_jni 在ndk 的libandroid.so库中，需要在CMakeLists.txt中引入android库    #include &lt;android/native_window_jni.h&gt;    #include &lt;unistd.h&gt;//sleep用的头文件    }    /**        *将任意格式的视频在手机上进行播放，使用native进行绘制        * env:虚拟机指针        * inputStr：视频文件路径        * surface: 从java层传递过来的SurfaceView的serface对象         */    void ffmpegVideoPlayer(JNIEnv *env, char *inputStr, jobject surface) {        // 1.注册各大组件，执行ffmgpe都必须调用此函数        av_register_all();        //2.得到一个ffmpeg的上下文（上下文里面封装了视频的比特率，分辨率等等信息...非常重要）        AVFormatContext *pContext = avformat_alloc_context();        //3.打开一个视频        if (avformat_open_input(&amp;pContext, inputStr, NULL, NULL) &lt; 0) {            LOGE(&quot;打开失败&quot;);            return;        }        //4.获取视频信息（将视频信息封装到上下文中）        if (avformat_find_stream_info(pContext, NULL) &lt; 0) {            LOGE(&quot;获取信息失败&quot;);            return;        }        //5.用来记住视频流的索引        int vedio_stream_idx = -1;        //从上下文中寻找找到视频流        for (int i = 0; i &lt; pContext-&gt;nb_streams; ++i) {            LOGE(&quot;循环  %d&quot;, i);            //codec：每一个流 对应的解码上下文            //codec_type：流的类型            if (pContext-&gt;streams[i]-&gt;codec-&gt;codec_type == AVMEDIA_TYPE_VIDEO) {                //如果找到的流类型 == AVMEDIA_TYPE_VIDEO 即视频流，就将其索引保存下来                vedio_stream_idx = i;            }        }        //获取到解码器上下文        AVCodecContext *pCodecCtx = pContext-&gt;streams[vedio_stream_idx]-&gt;codec;        //获取解码器（加密视频就是在此处无法获取）        AVCodec *pCodex = avcodec_find_decoder(pCodecCtx-&gt;codec_id);        LOGE(&quot;获取视频编码 %p&quot;, pCodex);        //6.打开解码器。 （ffempg版本升级名字叫做avcodec_open2）        if (avcodec_open2(pCodecCtx, pCodex, NULL) &lt; 0) {            LOGE(&quot;解码失败&quot;);            return;        }        //----------------------解码前准备--------------------------------------        //准备开始解码时需要一个AVPacket存储数据（通过av_malloc分配内存）        AVPacket *packet = (AVPacket *) av_malloc(sizeof(AVPacket));        av_init_packet(packet);//初始化结构体        //解封装需要AVFrame        AVFrame *frame = av_frame_alloc();        //声明一个rgb_Frame的缓冲区        AVFrame *rgb_Frame = av_frame_alloc();        //rgb_Frame  的缓冲区 初始化        uint8_t *out_buffer = (uint8_t *) av_malloc(                avpicture_get_size(AV_PIX_FMT_RGBA, pCodecCtx-&gt;width, pCodecCtx-&gt;height));        //给缓冲区进行替换        int re = avpicture_fill((AVPicture *) rgb_Frame, out_buffer, AV_PIX_FMT_RGBA, pCodecCtx-&gt;width,                                pCodecCtx-&gt;height);        LOGE(&quot;宽 %d  高 %d&quot;, pCodecCtx-&gt;width, pCodecCtx-&gt;height);        //格式转码需要的转换上下文（根据封装格式的宽高和编码格式，以及需要得到的格式的宽高）        //pCodecCtx-&gt;pix_fmt 封装格式文件的上下文        //AV_PIX_FMT_RGBA ： 目标格式 需要跟SurfaceView设定的格式相同        //SWS_BICUBIC ：清晰度稍微低一点的算法（转换算法，前面的算法清晰度高效率低，下面的算法清晰度低效率高）         //NULL,NULL,NULL ： 过滤器等        SwsContext *swsContext = sws_getContext(pCodecCtx-&gt;width, pCodecCtx-&gt;height, pCodecCtx-&gt;pix_fmt,                                                pCodecCtx-&gt;width, pCodecCtx-&gt;height, AV_PIX_FMT_RGBA,                                                SWS_BICUBIC, NULL, NULL, NULL        );        int frameCount = 0;        //获取nativeWindow对象,准备进行绘制        ANativeWindow *nativeWindow = ANativeWindow_fromSurface(env, surface);        ANativeWindow_Buffer outBuffer;//申明一块缓冲区 用于绘制        //------------------------一桢一帧开始解码--------------------        int length = 0;        int got_frame;        while (av_read_frame(pContext, packet) &gt;= 0) {//开始读每一帧的数据            if (packet-&gt;stream_index == vedio_stream_idx) {//如果这是一个视频流                //7.解封装（将packet解压给frame，即：拿到了视频数据frame）                length = avcodec_decode_video2(pCodecCtx, frame, &amp;got_frame, packet);//解封装函数                LOGE(&quot; 获得长度   %d 解码%d  &quot;, length, frameCount++);                if (got_frame &gt; 0) {                    //8.准备绘制                    //配置绘制信息 宽高 格式(这个绘制的宽高直接决定了视频在屏幕上显示的情况，这样会平铺整个屏幕，可以根据特定的屏幕分辨率和视频宽高进行匹配)                    ANativeWindow_setBuffersGeometry(nativeWindow, pCodecCtx-&gt;width, pCodecCtx-&gt;height,                                                     WINDOW_FORMAT_RGBA_8888);                    ANativeWindow_lock(nativeWindow, &amp;outBuffer, NULL);//锁定画布(outBuffer中将会得到数据)                    //9.转码（转码上下文，原数据，一行数据，开始位置，yuv的缓冲数组，yuv一行的数据）                    sws_scale(swsContext, (const uint8_t *const *) frame-&gt;data, frame-&gt;linesize, 0,                              frame-&gt;height, rgb_Frame-&gt;data,                              rgb_Frame-&gt;linesize                    );                    //10.绘制                    uint8_t *dst = (uint8_t *) outBuffer.bits; //实际的位数                    int destStride = outBuffer.stride * 4; //拿到一行有多少个字节 RGBA                    uint8_t *src = (uint8_t *) rgb_Frame-&gt;data[0];//像素数据的首地址                    int srcStride = rgb_Frame-&gt;linesize[0]; //实际内存一行的数量                    for (int i = 0; i &lt; pCodecCtx-&gt;height; ++i) {                        //将rgb_Frame缓冲区里面的数据一行一行copy到window的缓冲区里面                        //copy到window缓冲区的时候进行一些偏移设置可以将视频播放居中                        memcpy(dst + i * destStride, src + i * srcStride, srcStride);                    }                    ANativeWindow_unlockAndPost(nativeWindow);//解锁画布                    usleep(1000 * 16);//可以根据帧率休眠16ms                }            }            av_free_packet(packet);//释放        }        ANativeWindow_release(nativeWindow);//释放window        av_frame_free(&amp;frame);        av_frame_free(&amp;rgb_Frame);        avcodec_close(pCodecCtx);        avformat_free_context(pContext);        free(inputStr);    }</code></pre><h3 id="ffmpeg移植到Android上（多个abi）"><a href="#ffmpeg移植到Android上（多个abi）" class="headerlink" title="ffmpeg移植到Android上（多个abi）"></a>ffmpeg移植到Android上（多个abi）</h3><p><a href="https://github.com/ejoker88/FFmpeg-3.4-Android">首先是编译不同架构的ffmpeg library</a><br>这个库使用了FFmpeg 3.4 和 NDK r16b stable. 版本搭配真的很重要，这个脚本还要调用python创建不同abi的toolchain。<br>使用ndk编译ffmpeg满满的都是坑</p><pre><code>In file included from libavfilter/aeval.c:26:0:./libavutil/avassert.h:30:20: fatal error: stdlib.h: No such file or directory #include &lt;stdlib.h&gt;                    ^出现这个错误是因为使用最新版的NDK造成的，最新版的NDk将头文件和库文件进行了分离，我们指定的sysroot文件夹下只有库文件，而头文件放在了NDK目录下的sysroot内，只需在--extra-cflags中添加 &quot;-isysroot $NDK/sysroot&quot; 即可，还有有关汇编的头文件也进行了分离，需要根据目标平台进行指定 &quot;-I$NDK/sysroot/usr/include/arm-linux-androideabi&quot;，将 &quot;arm-linux-androideabi&quot; 改为需要的平台就可以，终于可以顺利的进行编译了</code></pre><pre><code>nasm/yasm not found or too old. use --disable-x86asm for a crippled build</code></pre><p>这是汇编工具没有安装导致的<br>sudo apt install yasm</p><p><a href="https://github.com/coopsrc/FFPlayerDemo">找到一个编译不同abi的so文件的脚本</a><br>armeabi-v7a arm64-v8a x86 x86_64这么几个host每个都要花上10分钟，所以这个脚本跑起来之后可以去喝杯茶了</p><pre><code class="bash">#!/bin/shPREFIX=android-buildHOST_PLATFORM=linux-x86_64COMMON_OPTIONS=&quot;\    --target-os=android \    --disable-static \    --enable-shared \    --enable-small \    --disable-programs \    --disable-ffmpeg \    --disable-ffplay \    --disable-ffprobe \    --disable-doc \    --disable-symver \    --disable-asm \    --enable-decoder=vorbis \    --enable-decoder=opus \    --enable-decoder=flac     &quot;build_all(){    for version in armeabi-v7a arm64-v8a x86 x86_64; do        echo &quot;======== &gt; Start build $version&quot;        case ${version} in        armeabi-v7a )            ARCH=&quot;arm&quot;            CPU=&quot;armv7-a&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/arm-linux-androideabi-4.9/prebuilt/$HOST_PLATFORM/bin/arm-linux-androideabi-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-arm/&quot;            EXTRA_CFLAGS=&quot;-march=armv7-a -mfpu=neon -mfloat-abi=softfp -mvectorize-with-neon-quad&quot;            EXTRA_LDFLAGS=&quot;-Wl,--fix-cortex-a8&quot;        ;;        arm64-v8a )            ARCH=&quot;aarch64&quot;            CPU=&quot;armv8-a&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/aarch64-linux-android-4.9/prebuilt/$HOST_PLATFORM/bin/aarch64-linux-android-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-arm64/&quot;            EXTRA_CFLAGS=&quot;&quot;            EXTRA_LDFLAGS=&quot;&quot;        ;;        x86 )            ARCH=&quot;x86&quot;            CPU=&quot;i686&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/x86-4.9/prebuilt/$HOST_PLATFORM/bin/i686-linux-android-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-x86/&quot;            EXTRA_CFLAGS=&quot;&quot;            EXTRA_LDFLAGS=&quot;&quot;        ;;        x86_64 )            ARCH=&quot;x86_64&quot;            CPU=&quot;x86_64&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/x86_64-4.9/prebuilt/$HOST_PLATFORM/bin/x86_64-linux-android-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-x86_64/&quot;            EXTRA_CFLAGS=&quot;&quot;            EXTRA_LDFLAGS=&quot;&quot;        ;;        esac        echo &quot;-------- &gt; Start clean workspace&quot;        make clean        echo &quot;-------- &gt; Start config makefile&quot;        configuration=&quot;\            --prefix=${PREFIX} \            --libdir=${PREFIX}/libs/${version}            --incdir=${PREFIX}/includes/${version} \            --pkgconfigdir=${PREFIX}/pkgconfig/${version} \            --arch=${ARCH} \            --cpu=${CPU} \            --cross-prefix=${CROSS_PREFIX} \            --sysroot=${SYSROOT} \            --extra-ldexeflags=-pie \            ${COMMON_OPTIONS}            &quot;        echo &quot;-------- &gt; Start config makefile with ${configuration}&quot;        ./configure ${configuration}        echo &quot;-------- &gt; Start make ${version} with -j8&quot;        make j8        echo &quot;-------- &gt; Start install ${version}&quot;        make install        echo &quot;++++++++ &gt; make and install ${version} complete.&quot;    done}echo &quot;-------- Start --------&quot;build_allecho &quot;-------- End --------&quot;</code></pre><p><a href="https://blog.csdn.net/u011485531/article/details/55804380">如何把ffmpeg生成的so文件压缩大小</a></p><p>然后才是交叉编译</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://developer.android.com/studio/projects/configure-cmake">configure-cmake</a><br><a href="https://github.com/googlesamples/android-ndk">googlesamples/android-ndk</a><br><a href="https://www.jianshu.com/p/6332418b12b1">Android NDK开发扫盲及最新CMake的编译使用</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;android中ndk及jni编写注意事项（本文主要讲CMake）&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/ShanwangpingKarst_EN-AU5360258756_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="android" scheme="https://haldir65.github.io/tags/android/"/>
    
  </entry>
  
  <entry>
    <title>C语言中多进程之间通信的方式</title>
    <link href="https://haldir65.github.io/2019/01/30/2019-01-30-ipc-in-c-programming-language/"/>
    <id>https://haldir65.github.io/2019/01/30/2019-01-30-ipc-in-c-programming-language/</id>
    <published>2019-01-30T07:57:28.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p><strong><em>进程是资源分配的最小单位，线程是CPU调度的最小单位</em></strong><br><img src="https://www.haldir66.ga/static/imgs/Prayercard_ZH-CN13472871640_1920x1080.jpg" alt=""></p><p>本文多数来自<a href="https://www.zfl9.com/c-multi-proc.html">c语言多进程编程</a></p><p>当Linux启动的时候，init是系统创建的第一个进程，这一进程会一直存在，直到我们关闭计算机；虽然后面systemd取代了init进程。后面的所有进程都是init进程fork出来的,linux下使用pstree可以看到所有的进程都是以systemd为根节点的<br>当进程调用fork的时候，Linux在内存中开辟出一片新的内存空间给新的进程，并将老的进程空间中的内容复制到新的空间中，此后两个进程同时运行；老进程成为新进程的父进程(parent process)，而相应的，新进程就是老进程的子进程(child process)；</p><a id="more"></a><h2 id="fork的最简单实例"><a href="#fork的最简单实例" class="headerlink" title="fork的最简单实例"></a>fork的最简单实例</h2><p>fork是系统调用，会有两次返回，分别是父进程和子进程。</p><pre><code class="C">#include &lt;stdint.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;void print_process_message(){    __pid_t myprocess_id = getpid();    __uid_t uid = getuid();    __gid_t ugid = getgid();    printf(&quot;getpid = %d getuid= %d  getgid= %d \n&quot;,myprocess_id,uid, ugid);}int main(int argc, char const *argv[]){    int n =0;    printf(&quot;before fork: n = %d\n&quot;,n);    __pid_t fpid =fork();    if(fpid &lt;0 )    {        perror(&quot;fork error&quot;);        exit(EXIT_FAILURE);    }else if (fpid == 0)    {        n++;        printf(&quot;child_proc(%d, ppid=%d): n= %d\n&quot;,getpid(),getppid(),n);    } else    {        n--;        printf(&quot;parent_proc(%d): n= %d\n&quot;,getpid(),n);    }    print_process_message();    printf(&quot;quit_proc(%d) ...\n&quot;,getpid());    return 0;}</code></pre><h3 id="fork和vfrok"><a href="#fork和vfrok" class="headerlink" title="fork和vfrok"></a>fork和vfrok</h3><p>fork创建子进程，把父进程数据空间、堆和栈复制一份；<br>vfork创建子进程，与父进程内存数据共享；<br>但是后来的fork也学聪明了，不是一开始调用fork就复制数据，而是只有在子进程要修改数据的时候，才进行复制，即copy-on-write；<br>所以我们现在也很少去用vfork，因为vfork的优势已经不复存在了；</p><h2 id="孤儿进程和僵尸进程以及wait"><a href="#孤儿进程和僵尸进程以及wait" class="headerlink" title="孤儿进程和僵尸进程以及wait"></a>孤儿进程和僵尸进程以及wait</h2><p>正常的操作流程：子进程终结时会通知父进程，并通过return code告诉内核自己的退出信息，父进程知道后，有责任对该子进程使用<strong><em>wait</em></strong>系统调用，这个wait函数能够从内核中取出子进程的退出信息，并清空该信息在内核中所占据的空间；</p><p><strong><em>不正常的流程：</em></strong><br>父进程早于子进程挂掉，那么子进程就成了孤儿进程</p><p>如果程序写的糟糕，父进程忘记对子进程调用wait，子进程就成为僵尸(zombie)进程。（在htop里面看到state是Z）<br>当进程退出，释放大多数资源和它的父进程收集它的返回值、释放剩余资源这两段时间之间，子进程处于一个特殊状态，被称为僵尸进程；<br>每个进程都会经过一个短暂的僵尸状态，僵尸进程的最大危害就是会占用宝贵的PID资源，如果不及时清理，会导致无法再创建新的进程；</p><p><strong><em>解决僵尸进程的方法是干掉僵尸进程的父进程</em></strong>，僵尸进程也就变成了孤儿进程，最终被init进程接管，init进程会负责wait这些孤儿进程，释放占用的资源。</p><h2 id="wait和waitpid函数"><a href="#wait和waitpid函数" class="headerlink" title="wait和waitpid函数"></a>wait和waitpid函数</h2><p>pid_t wait(int <em>status);：等待任意子进程退出，并捕获退出状态<br>pid_t waitpid(pid_t pid, int </em>status, int options);：等待子进程退出，并捕获退出状态<br>这两个函数返回的都是退出的子进程的id</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;wait.h&gt;int main(int argc, char const *argv[],char *envp[]){    pid_t fpid = fork(), pid;    if(fpid &lt; 0)    {        perror(&quot;fork error&quot;);        exit(EXIT_FAILURE);    }    else if(fpid ==0 )    {        sleep(5);        exit(5);    } else {        int stat;        for(;;){            pid = waitpid(fpid,&amp;stat,WNOHANG); //stat用于记录子进程的返回结果            if(pid&gt;0) {                break;            }else {                printf(&quot;wait child proc ... \n&quot;);                sleep(1);            }        }        if(WIFEXITED(stat))//这个函数如果子进程正常退出的话就返回真        {            printf(&quot;child_proc(%d): exit_code :%d\n&quot;,pid,WEXITSTATUS(stat));        }    }    return 0;}</code></pre><p><strong>处理子进程的退出有以下两种方式：</strong><br>第一种：通过信号处理函数signal()，如可以忽略子进程的SIGCHLD信号来防止僵尸进程的产生：signal(SIGCHLD, SIG_IGN);<br>第二种：通过调用wait()、waitpid()函数，来回收子进程，防止产生僵尸进程，占用<strong>PID等宝贵的系统资源</strong>；</p><p>经常在parent process中看到wait(NULL)的操作，意思就是让父进程等child process 返回exit status。<br><a href="https://stackoverflow.com/questions/42426816/how-does-waitnull-exactly-work?rq=1">wait(NULL)是什么意思</a></p><pre><code>wait(NULL) will block parent process until any of its children has finished. If child terminates before parent process reaches wait(NULL) then the child process turns to a zombie process until its parent waits on it and its released from memory.If parent process doesn&#39;t wait for its child, and parent finishes first, then the child process becomes orphan and is assigned to init as its child. And init will wait and release the process entry in the process table.In other words: parent process will be blocked until child process returns an exit status to the operating system which is then returned to parent process. If child finishes before parent reaches wait(NULL) then it will read the exit status, release the process entry in the process table and continue execution until it finishes as well.</code></pre><h3 id="exec系列函数"><a href="#exec系列函数" class="headerlink" title="exec系列函数"></a>exec系列函数</h3><p><strong>fork出来一个新的进程当然是要干活的</strong>，就要用到exec系统调用<br>exec系统调用是以新的进程空间替换现在的进程空间，但是pid不变，还是原来的pid，相当于换了个身体，但是名字不变；<br>调用exec后，系统会申请一块新的进程空间来存放被调用的程序，然后当前进程会携带pid跳转到新的进程空间，并从main函数开始执行，旧的进程空间被回收；<br>exec用被执行的程序完全替换调用它的程序的影像。fork创建一个新的进程就产生了一个新的PID，<br>exec启动一个新程序，替换原有的进程，因此这个新的被exec执行的进程的PID不会改变，</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main(int arg,char **args){    char *argv[]={&quot;ls&quot;,&quot;-al&quot;,&quot;/usr/include/linux&quot;,NULL};//传递给执行文件的参数数组，这里包含执行文件的参数     char *envp[]={0,NULL};//传递给执行文件新的环境变量数组    execve(&quot;/bin/ls&quot;,argv,envp);}</code></pre><p>这个函数的参数</p><pre><code>int   execve( char *pathname,char *argv[],char *envp[])</code></pre><h3 id="exit-可以注册进程退出的时候的回调函数"><a href="#exit-可以注册进程退出的时候的回调函数" class="headerlink" title="exit(可以注册进程退出的时候的回调函数)"></a>exit(可以注册进程退出的时候的回调函数)</h3><p>exit是系统调用级别的，用于进程运行的过程中，随时结束进程；<br>return是语言级别的，用于调用堆栈的返回，返回上一层调用；<br>在main函数中调用exit(0)等价于return 0；<br>_exit()函数的作用最为简单：直接使进程停止运行，清除其使用的内存空间，并销毁其在内核中的各种数据结构；<br>exit()函数则在这些基础上作了一些包装，在执行退出之前加了若干道工序；<br>exit()函数与_exit()函数最大的区别就在于exit()要检查文件的打开情况，把文件缓冲区中的内容写回文件，就是”清理I/O缓冲”；</p><p>按照ANSI C的规定，一个进程可以登记至多32个函数，这些函数将由exit自动调用；（也就是说在调用exit的时候会调用这些回调函数）<br>分为atexit和on_exit</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;signal.h&gt;void func1(void){    printf(&quot;&lt;atexit&gt; func1 getpid = %d \n&quot;,getpid());}void func2(void){    printf(&quot;&lt;atexit&gt; func2 getpid = %d \n&quot;,getpid());}void func3(void){    printf(&quot;&lt;atexit&gt; func3 getpid = %d \n&quot;,getpid());}void func(int status, void *str){    printf(&quot;&lt;on_exit&gt; exit_code: %d, arg: %s getpid = %d \n&quot;, status, (char *)str,getpid());}int main(void){    signal(SIGCHLD, SIG_IGN);    on_exit(func, &quot;on_exit3&quot;);    on_exit(func, &quot;on_exit2&quot;);    on_exit(func, &quot;on_exit1&quot;);    atexit(func3);    atexit(func2);    atexit(func1);    pid_t pid;    pid = fork();    if(pid &lt; 0){        perror(&quot;fork error&quot;);        exit(EXIT_FAILURE);    }else if(pid == 0){        exit(0);    }else{        sleep(3);    }    return 0;}</code></pre><p><strong><em>输出：</em></strong></p><pre><code>&lt;atexit&gt; func1 getpid = 13508&lt;atexit&gt; func2 getpid = 13508&lt;atexit&gt; func3 getpid = 13508&lt;on_exit&gt; exit_code: 0, arg: on_exit1 getpid = 13508&lt;on_exit&gt; exit_code: 0, arg: on_exit2 getpid = 13508&lt;on_exit&gt; exit_code: 0, arg: on_exit3 getpid = 13508&lt;atexit&gt; func1 getpid = 13507&lt;atexit&gt; func2 getpid = 13507&lt;atexit&gt; func3 getpid = 13507&lt;on_exit&gt; exit_code: 0, arg: on_exit1 getpid = 13507&lt;on_exit&gt; exit_code: 0, arg: on_exit2 getpid = 13507</code></pre><p>也就是说fork出来的子进程会继承父进程的终止处理函数、信号处理设置；</p><h2 id="Daemon守护进程"><a href="#Daemon守护进程" class="headerlink" title="Daemon守护进程"></a>Daemon守护进程</h2><p>Linux Daemon进程是运行在后台的一种特殊进程。<br>一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，<strong><em>所以它是一个由init继承的孤儿进程；</em></strong><br>守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理；<br>守护进程的名称通常以d结尾，比如sshd、xinetd、crond等；</p><p>头文件：unistd.h<br><strong><em>int daemon(int nochdir, int noclose);</em></strong></p><h2 id="system和popen"><a href="#system和popen" class="headerlink" title="system和popen"></a>system和popen</h2><p><strong><em>system是去执行一个shell命令</em></strong><br>system()函数调用/bin/sh来执行参数指定的命令，/bin/sh一般是一个软连接，指向某个具体的shell，比如bash；</p><pre><code class="C">system(&quot;cat /etc/sysctl.conf&quot;);；</code></pre><p>实际上system()函数执行了三步操作：<br>fork一个子进程；<br>在子进程中调用exec函数去执行command；<br>在父进程中调用wait去等待子进程结束；<br>一个不好的地方是system()，并不能获取命令执行的输出结果，只能得到执行的返回值；</p><p><strong>popen</strong><br>标准I/O函数库提供了popen函数，它启动另外一个进程去执行一个shell命令行；<br>这里我们称调用popen的进程为父进程，由popen启动的进程称为子进程；</p><p>popen函数还创建一个管道用于父子进程间通信；父进程要么从管道读信息，要么向管道写信息，至于是读还是写取决于父进程调用popen时传递的参数；</p><pre><code class="C">#include &lt;stdio.h&gt;FILE *popen(const char *command, const char *type);/*函数功能：popen()会调用fork()产生子进程，然后从子进程中调用/bin/sh -c来执行参数command的指令;          参数type可使用&quot;r&quot;代表读取，&quot;w&quot;代表写入;          依照此type值，popen()会建立管道连到子进程的标准输出设备或标准输入设备，然后返回一个文件指针;          随后进程便可利用此文件指针来读取子进程的输出设备或是写入到子进程的标准输入设备中;返回值：若成功则返回文件指针，否则返回NULL，错误原因存于errno中*/int pclose(FILE *stream);/*函数功能：pclose()用来关闭由popen所建立的管道及文件指针；参数stream为先前由popen()所返回的文件指针;返回值：若成功则返回shell的终止状态(也即子进程的终止状态)，若出错返回-1，错误原因存于errno中;*/</code></pre><p><strong>这里正式使用到了进程之间的管道通信</strong></p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 2){        fprintf(stderr, &quot;usage: %s &lt;cmd&gt;\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    char output[1024+1];    FILE *pp = popen(argv[1], &quot;r&quot;);    if(pp == NULL){        perror(&quot;popen error&quot;);        exit(EXIT_FAILURE);    }    int nread = fread(output, 1, 1024, pp); //父进程通过文件指针读取子进程的输出设备。    int status = pclose(pp);    if(status &lt; 0){        perror(&quot;pclose error&quot;);        exit(EXIT_FAILURE);    }    output[nread] = &#39;\0&#39;;    if(WIFEXITED(status)){        printf(&quot;status: %d\n%s&quot;, WEXITSTATUS(status), output);    }    return 0;}</code></pre><h2 id="signal信号"><a href="#signal信号" class="headerlink" title="signal信号"></a>signal信号</h2><p>信号(signal)是一种软中断，信号机制是进程间通信的一种方式，采用<strong>异步通信方式</strong><br>用kill -l　可以查看可以发出的信号</p><pre><code>$ kill -l           HUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM 16 CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL 30 SYS</code></pre><p>挑几个重要的:<br>SIGINT(2) 中断　（CTRL + C）<br>SIGKILL(9) kill信号（强杀，进程不能阻止）<br>SIGPIPE(13) 管道破损，没有读端的管道写数据,就是那个brokenpipe。<strong>默认是杀进程的，所以网络编程中要处理这个信号。</strong>（当服务器close一个连接时，若client端接着发数据。根据TCP协议的规定，会收到一个RST响应，client再往这个服务器发送数据时，系统会发出一个SIGPIPE信号给进程，告诉进程这个连接已经断开了，不要再写了。）<br>SIGTERM（１５）　终止信号，这个不是强制的，它可以被捕获和解释（或忽略）的过程。类似于和这个进程商量一下，让它退出。不听话的话可以用９杀掉。<br>SIGCHLD(１７) 子进程退出。　默认忽略<br>SIGSTOP（１９）　进程停止　不能被忽略、处理和阻塞<br>SIGPWR(30) 关机　默认忽略<br>进程可以注册收到信号时的处理函数</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;void handle_signal(int signum){    printf(&quot;received signal: %d\n&quot;, signum);    exit(0);}int main(void){    signal(SIGINT, handle_signal);    for(;;){        printf(&quot;running ... \n&quot;);        sleep(1);    }    return 0;}</code></pre><p>这里添一句，cpython因为是用Ｃ语言写的，在处理信号这方面几乎是一模一样。<br><a href="https://stackabuse.com/handling-unix-signals-in-python/">注册signal_handler</a></p><blockquote><p>＝＝＝＝＝＝＝＝＝介绍进程的基础知识到此结束＝＝＝＝＝＝＝＝＝＝＝＝＝＝</p></blockquote><h2 id="进程之间的通信"><a href="#进程之间的通信" class="headerlink" title="进程之间的通信"></a>进程之间的通信</h2><h3 id="使用管道"><a href="#使用管道" class="headerlink" title="使用管道"></a>使用管道</h3><p>管道是FIFO的<br>下面是创建一个匿名管道的代码</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 3){        fprintf(stderr, &quot;usage: %s parent_sendmsg child_sendmsg\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int pipes[2];    if(pipe(pipes) &lt; 0){        perror(&quot;pipe&quot;);        exit(EXIT_FAILURE);    }    pid_t pid = fork();    if(pid &lt; 0){        perror(&quot;fork&quot;);        exit(EXIT_FAILURE);    }else if(pid &gt; 0){        char buf[BUFSIZ + 1];        int nbuf;        strcpy(buf, argv[1]);        write(pipes[1], buf, strlen(buf));        sleep(1); //这里sleep是为了让子进程有时间把管道中的数据读走，不然数据就会被底下的父进程的read读走.        //因为实质上内核中只有一个管道缓冲区，是父进程创建的，只不过子进程同时拥有了它的引用        nbuf = read(pipes[0], buf, BUFSIZ);        buf[nbuf] = 0;        printf(&quot;parent_proc(%d) recv_from_child: %s\n&quot;, getpid(), buf);        close(pipes[0]);        close(pipes[1]);    }else if(pid == 0){        char buf[BUFSIZ + 1];        int nbuf = read(pipes[0], buf, BUFSIZ);        buf[nbuf] = 0;        printf(&quot;child_proc(%d) recv_from_parent: %s\n&quot;, getpid(), buf);        strcpy(buf, argv[2]);        write(pipes[1], buf, strlen(buf));        close(pipes[0]);        close(pipes[1]);    }    return 0;}</code></pre><blockquote><p>./a.out parent_say_tochild child_say_to_parent</p></blockquote><p>实际中为了实现双向通信，应该准备两根管道，一根负责从父进程往子进程写数据（同时子进程从这里读取数据），一根负责从子进程往父进程写数据（父进程也从这里读数据）</p><p>管道默认是阻塞模式的，fcntl(fd, F_SETFL, flags | O_NONBLOCK);可以设置非阻塞的管道，这个跟socket很像。</p><h3 id="命名管道"><a href="#命名管道" class="headerlink" title="命名管道"></a>命名管道</h3><p>上面说的匿名管道要求这些进程都是由同一个祖先创建的。所以在不相干的进程之间交换数据就不方便了，为此，我们需要命名管道<br>命名管道也被称为FIFO文件<br>我们可以使用以下两个函数之一来创建一个命名管道，原型如下：</p><pre><code class="C">头文件：sys/types.h、sys/stat.hint mkfifo(const char *filename, mode_t mode);int mknod(const char *filename, mode_t mode | S_IFIFO, (dev_t)0);返回值：执行成功返回0，失败返回-1，并设置errno</code></pre><p>注意这样的方式是在文件系统中创建了一个真实的文件, 可以对其进行读写操作(注意不能同时读写)<br>sender.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 3){        fprintf(stderr, &quot;usage: %s fifo_file filename\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int fifo = open(argv[1], O_WRONLY);    if(fifo &lt; 0){        perror(&quot;open&quot;);        exit(EXIT_FAILURE);    }    FILE *fp = fopen(argv[2], &quot;rb&quot;);    if(fp == NULL){        perror(&quot;fopen&quot;);        exit(EXIT_FAILURE);    }    char buf[BUFSIZ];    int nbuf;    while((nbuf = fread(buf, 1, BUFSIZ, fp)) &gt; 0){        write(fifo, buf, nbuf);    }    fclose(fp);    close(fifo);    return 0;}</code></pre><p>receiver.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;errno.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 3){        fprintf(stderr, &quot;usage: %s fifo_file filename\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int fifo = open(argv[1], O_RDONLY);    if(fifo &lt; 0){        perror(&quot;fifo&quot;);        exit(EXIT_FAILURE);    }    FILE *fp = fopen(argv[2], &quot;wb&quot;);    if(fp == NULL){        perror(&quot;fopen&quot;);        exit(EXIT_FAILURE);    }    char buf[BUFSIZ];    int nbuf;    while((nbuf = read(fifo, buf, BUFSIZ)) &gt; 0){        printf(&quot;i got something %s\n&quot;, buf);        fwrite(buf, nbuf, 1, fp);    }    close(fifo);    fclose(fp);    return 0;}</code></pre><pre><code>mkfifo fifo ##使用mkfifo这个命令创建一个管道文件./bin/sender fifo /var/log/syslog ###把/var/log/syslog这个文件里面的内容读出来，通过fifo这个文件传到另一个进程。注意到这里卡在这里了./bin/receiver fifo syslog.copy ##从管道文件中读取输出，写到syslog.copy文件中.注意到这里读完了之后前面卡住的进程成功退出了</code></pre><p>这里还要提到命名管道的安全问题，有可能存在多个进程同时往一个FIFO文件写数据，这样会存在数据顺序错乱的问题。解决方案就是每次写入的数据的大小保持在PIPE_BUF大小以内，要么全部写入，要么一个字节也不写入。</p><h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p><strong><em>概念:</em></strong></p><blockquote><p>什么是共享内存<br>顾名思义，共享内存就是允许两个不相关的进程访问同一个逻辑内存；共享内存是在两个正在运行的进程之间共享和传递数据的一种非常有效的方式；<br>不同进程之间共享的内存通常安排为同一段物理内存，进程可以将同一段共享内存连接到它们自己的地址空间中，所有进程都可以访问共享内存中的地址；<br>而如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程；<br>特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前，并无自动机制可以阻止第二个进程开始对它进行读取；所以我们通常需要用其他的机制来同步对共享内存的访问，例如信号量、互斥锁；</p></blockquote><p><strong><em>共享内存的函数接口</em></strong><br><strong><br>头文件：sys/types.h、sys/ipc.h、sys/shm.h<br>int shmget(key_t shm_key, size_t shm_size, int shm_flg);：创建共享内存<br>shm_key用来标识一块共享内存：<br>shm_size：输入参数，共享内存的大小（单位：byte）：注意内存分配的单位是页（一般为4kb，可通过getpagesize()获取）；也就是说如果shm_size为1，那么也会分配4096字节的内存；只获取共享内存时，shm_size可指定为0；</strong></p><p>程序对信号量的操作都是<code>原子操作</code>，并且只能对它进行等待和发送操作</p><h2 id="Unix-domain-socket"><a href="#Unix-domain-socket" class="headerlink" title="Unix domain socket"></a>Unix domain socket</h2><p>socket原本是为了网络通讯设计的，但是后来在socket的框架上发展出一种IPC机制，就是UNIX Domain Socket；<br>虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率：</p><ol><li>不需要经过网络协议栈；</li><li>不需要打包拆包；</li><li>不需要计算校验和；</li><li>不需要维护序号和应答；</li></ol><p>这是因为IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的；<br>UNIX Domain Socket也提供面向流和面向数据报两种API接口，类似TCP和UDP，但是面向数据报的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱；<br>使用UNIX Domain Socket的过程和网络socket十分相似，也要先调用socket()创建一个socket文件描述符，address family指定为AF_UNIX，type可以选择SOCK_STREAM或SOCK_DGRAM，protocol参数仍然指定为0即可；<br>UNIX Domain Socket与网络socket编程最明显的不同在于地址格式不同，用结构体<code>sockaddr_un</code>表示；<br>网络编程的socket地址是IP地址加端口号，而UNIX Domain Socket的地址是一个socket类型的文件在文件系统中的路径，这个socket文件由bind()调用创建，如果调用bind()时该文件已经存在，则bind()错误返回；</p><p>unix_domain_server.c</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/un.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;netdb.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;signal.h&gt;#include &lt;sys/wait.h&gt;#define SOCK_PATH &quot;/run/echo.sock&quot;#define BUF_SIZE 1024int listenfd;void handle_signal(int signo);int main(void){    signal(SIGINT, handle_signal);    signal(SIGHUP, handle_signal);    signal(SIGTERM, handle_signal);    if((listenfd = socket(AF_UNIX, SOCK_STREAM, 0)) &lt; 0){        perror(&quot;socket&quot;);        exit(EXIT_FAILURE);    }    struct sockaddr_un servaddr;    memset(&amp;servaddr, 0, sizeof(servaddr));    servaddr.sun_family = AF_UNIX;    strcpy(servaddr.sun_path, SOCK_PATH);    unlink(SOCK_PATH);    if(bind(listenfd, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) &lt; 0){ //因为这里要在/var/目录下创建一个临时文件，这个程序需要sudo运行        perror(&quot;bind&quot;);        exit(EXIT_FAILURE);    }    chmod(SOCK_PATH, 00640);    if(listen(listenfd, SOMAXCONN) &lt; 0){        perror(&quot;listen&quot;);        exit(EXIT_FAILURE);    }    int connfd, nbuf;    char buf[BUF_SIZE + 1];    for(;;){        if((connfd = accept(listenfd, NULL, NULL)) &lt; 0){            perror(&quot;accept&quot;);            continue;        }        nbuf = recv(connfd, buf, BUF_SIZE, 0);        buf[nbuf] = 0;        printf(&quot;new msg: \&quot;%s\&quot;\n&quot;, buf);        send(connfd, buf, nbuf, 0);        close(connfd);    }    return 0;}void handle_signal(int signo){    if(signo == SIGINT){        fprintf(stderr, &quot;received signal: SIGINT(%d)\n&quot;, signo);    }else if(signo == SIGHUP){        fprintf(stderr, &quot;received signal: SIGHUP(%d)\n&quot;, signo);    }else if(signo == SIGTERM){        fprintf(stderr, &quot;received signal: SIGTERM(%d)\n&quot;, signo);    }    close(listenfd);    unlink(SOCK_PATH);    exit(EXIT_SUCCESS);}</code></pre><p>unix_domain_client.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/un.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;netdb.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;signal.h&gt;#include &lt;sys/wait.h&gt;#define SOCK_PATH &quot;/run/echo.sock&quot;#define BUF_SIZE 1024int main(int argc, char *argv[]){    if(argc &lt; 2){        fprintf(stderr, &quot;usage: %s msg\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int sockfd;    if((sockfd = socket(AF_UNIX, SOCK_STREAM, 0)) &lt; 0){        perror(&quot;socket&quot;);        exit(EXIT_FAILURE);    }    struct sockaddr_un servaddr;    memset(&amp;servaddr, 0, sizeof(servaddr));    servaddr.sun_family = AF_UNIX;    strcpy(servaddr.sun_path, SOCK_PATH);    if(connect(sockfd, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) &lt; 0){        perror(&quot;connect&quot;);        exit(EXIT_FAILURE);    }    char buf[BUF_SIZE + 1];    int nbuf;    nbuf = strlen(argv[1]);    send(sockfd, argv[1], nbuf, 0);    nbuf = recv(sockfd, buf, BUF_SIZE, 0);    buf[nbuf] = 0;    printf(&quot;echo msg: \&quot;%s\&quot;\n&quot;, buf);    close(sockfd);    return 0;}</code></pre><p>上述程序实现了通过uninx domain socket的client-server 数据传输，就像是通过/var/echo.sock这个文件传输数据。印象中uwsi也是这样实现nginx和django进程的通信。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>现在把进程之间传递信息的各种途径（包括各种IPC机制）总结如下：<br>父进程通过fork可以将打开文件的描述符传递给子进程<br>子进程结束时，父进程调用wait可以得到子进程的终止信息<br>几个进程可以在文件系统中读写某个共享文件，也可以通过给文件加锁来实现进程间同步<br>进程之间互发信号，一般使用SIGUSR1和SIGUSR2实现用户自定义功能<br>管道<br>FIFO<br>mmap函数，几个进程可以映射同一内存区<br>SYS V IPC，以前的SYS V UNIX系统实现的IPC机制，包括消息队列、信号量和共享内存，现在已经基本废弃<br>Linux内核继承和兼容了丰富的Unix系统进程间通信（IPC）机制。有传统的管道（Pipe）、信号（Signal）和跟踪（Trace），这三项通信手段只能用于父进程与子进程之间，或者兄弟进程之间；后来又增加了命令管道（Named Pipe），使得进程间通信不再局限于父子进程或者兄弟进程之间；为了更好地支持商业应用中的事务处理，在AT&amp;T的Unix系统V中，又增加了三种称为“System V IPC”的进程间通信机制，分别是报文队列（Message）、共享内存（Share Memory）和信号量（Semaphore）；后来BSD Unix对“System V IPC”机制进行了重要的扩充，提供了一种称为插口（Socket）的进程间通信机制。<br>UNIX Domain Socket是目前最广泛使用的IPC机制</strong></p><p><a href="https://www.zhihu.com/question/39440766/answer/89210950">Linux现有的所有进程间IPC方式</a></p><ol><li>管道：在创建时分配一个page大小的内存，缓存区大小比较有限；</li><li>消息队列：信息复制两次，额外的CPU消耗；不合适频繁或信息量大的通信；</li><li>共享内存：无须复制，共享缓冲区直接付附加到进程虚拟地址空间，速度快；但进程间的同步问题操作系统无法实现，必须各进程利用同步工具解决；</li><li>套接字：作为更通用的接口，传输效率低，主要用于不通机器或跨网络的通信；</li><li>信号量：常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。</li><li>信号: 不适用于信息交换，更适用于进程中断控制，比如非法内存访问，杀死某个进程等；</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.zfl9.com/c-multi-proc.html">c语言多进程编程</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;&lt;em&gt;进程是资源分配的最小单位，线程是CPU调度的最小单位&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/Prayercard_ZH-CN13472871640_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文多数来自&lt;a href=&quot;https://www.zfl9.com/c-multi-proc.html&quot;&gt;c语言多进程编程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当Linux启动的时候，init是系统创建的第一个进程，这一进程会一直存在，直到我们关闭计算机；虽然后面systemd取代了init进程。后面的所有进程都是init进程fork出来的,linux下使用pstree可以看到所有的进程都是以systemd为根节点的&lt;br&gt;当进程调用fork的时候，Linux在内存中开辟出一片新的内存空间给新的进程，并将老的进程空间中的内容复制到新的空间中，此后两个进程同时运行；老进程成为新进程的父进程(parent process)，而相应的，新进程就是老进程的子进程(child process)；&lt;/p&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="c" scheme="https://haldir65.github.io/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>编程语言中使用到的多线程基础数据结构</title>
    <link href="https://haldir65.github.io/2019/01/30/2019-01-30-concurrency-primitives-in-programing-languages/"/>
    <id>https://haldir65.github.io/2019/01/30/2019-01-30-concurrency-primitives-in-programing-languages/</id>
    <published>2019-01-30T07:53:33.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/HongKongFireworks_ZH-CN13422096721_1920x1080.jpg" alt=""><br>主要讲讲java中的notify,wait,synchronized ，unsafe等多线程基础工具的使用方式。</p><a id="more"></a><h2 id="java"><a href="#java" class="headerlink" title="java"></a>java</h2><h3 id="wait和notify"><a href="#wait和notify" class="headerlink" title="wait和notify"></a>wait和notify</h3><p>有一个异常叫做java.lang.IllegalMonitorStateException。意思就是没有在synchronized block中调用wait或者notify方法。<br>java Object中是有一个monitor对象的，wait和notify就是基于这个属性去实现的。只要在同一对象上去调用notify/notifyAll方法，就可以唤醒对应对象monitor上等待的线程了。<br>为什么jvm需要对象的头部信息呢，一是给GC，锁做标记，二是hash数据和分代年龄，三是为了从对象指针就可以会的其数据类型及动态分派的能力，四是数组类型需要有数量信息。</p><h3 id="synchronized关键字"><a href="#synchronized关键字" class="headerlink" title="synchronized关键字"></a>synchronized关键字</h3><p>从语法上讲，synchronized可以用在<br>instance　method(锁在这个instance上), static method (锁在这个class )以及method block(锁这一块代码逻辑)。<br>➜ $ cat SynchronizedSample.java </p><pre><code class="java">package com.me.harris.concurrent;public class SynchronizedSample {    public void method() {        synchronized (this) {            System.out.println(&quot;Method 1 start&quot;);        }    }}</code></pre><p>javac SynchronizedSample.java<br>javap -c SynchronizedSample</p><pre><code>Warning: Binary file SynchronizedSample contains com.me.harris.concurrent.SynchronizedSampleCompiled from &quot;SynchronizedSample.java&quot;public class com.me.harris.concurrent.SynchronizedSample {  public com.me.harris.concurrent.SynchronizedSample();    Code:       0: aload_0       1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V       4: return  public void method();    Code:       0: aload_0       1: dup       2: astore_1          3: monitorenter  ///看这里       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;       7: ldc           #3                  // String Method 1 start       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V      12: aload_1      13: monitorexit //看这里      14: goto          22      17: astore_2      18: aload_1      19: monitorexit      20: aload_2      21: athrow      22: return    Exception table:       from    to  target type           4    14    17   any          17    20    17   any}</code></pre><p>java doc是这么解释的</p><blockquote><p>Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:<br>• If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.<br>• If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.<br>• If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership.<br>看上去很像c语言里面的semctl嘛。<br>Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。</p></blockquote><p><a href="http://www.cnblogs.com/paddix/p/5405678.html">轻量级锁和偏向锁</a></p><p>类似的，synchronized修饰的instance method在编译后添加了一个ACC_SYNCHRONIZED的flag，同步是通过这个标志实现的。</p><h2 id="回顾一下用notify-wait-synchronized实现的生产者-消费者模型"><a href="#回顾一下用notify-wait-synchronized实现的生产者-消费者模型" class="headerlink" title="回顾一下用notify,wait,synchronized实现的生产者-消费者模型"></a>回顾一下用notify,wait,synchronized实现的生产者-消费者模型</h2><p>Effective java里面说要把wait写在一个while检查里面</p><pre><code class="java">// The standard idiom for calling the wait method in Java synchronized (sharedObject) {     while (condition) {     sharedObject.wait();         // (Releases lock, and reacquires on wakeup)     }     // do action based upon condition e.g. take or put into queue }</code></pre><p>基本的思路就是生产者和消费者共同持有一个锁（随便new一个Object出来就是了），生产者和消费者都extends Thread。<br>生产者的run方法里while(true)，再加上synchronized，往queue里面丢东西，塞满了就notify一下（让消费者去消费）。<br>消费者的run方法里面while(true)，再加上synchronized，从queue里面取东西，发现没东西了。notify一下其他人（让生产者去生产）。</p><h2 id="Sleep和wait的区别"><a href="#Sleep和wait的区别" class="headerlink" title="Sleep和wait的区别"></a>Sleep和wait的区别</h2><p>不要搞混淆了，sleep是不会让出cpu的执行权的，而wait则会让出cpu执行权，也就是释放锁。</p><h2 id="yield的用法"><a href="#yield的用法" class="headerlink" title="yield的用法"></a>yield的用法</h2><p>yield是让当前线程从running的状态变成runnable的状态（不过这个方法很少用到）</p><h2 id="join的用法"><a href="#join的用法" class="headerlink" title="join的用法"></a>join的用法</h2><p>和python一样，主线程调用childThread.join()就是让主线程等子线程执行完了之后再去执行后面的语句。不过从源码来看,join调用了wait。</p><pre><code class="java">public final void join() throws InterruptedException {    join(0); //这里面调用了wait方法，也就是主线程会wait住}public synchronized void start() {    //Thread的start方法中做了相应的处理，所以当join的线程执行完成以后，会自动唤醒主线程继续往下执行}</code></pre><p><a href="https://stackoverflow.com/questions/9866193/who-and-when-notify-the-thread-wait-when-thread-join-is-called">调用join的线程总得被唤醒啊</a> stackoverflow上说是在native层面调用的notify。有人翻出来openjdk的cpp源码</p><pre><code class="cpp">void JavaThread::run() {  ...  thread_main_inner();}void JavaThread::thread_main_inner() {  ...  this-&gt;exit(false);  delete this;}void JavaThread::exit(bool destroy_vm, ExitType exit_type) {  ...  // Notify waiters on thread object. This has to be done after exit() is called  // on the thread (if the thread is the last thread in a daemon ThreadGroup the  // group should have the destroyed bit set before waiters are notified).  ensure_join(this);  ...}static void ensure_join(JavaThread* thread) {  // We do not need to grap the Threads_lock, since we are operating on ourself.  Handle threadObj(thread, thread-&gt;threadObj());  assert(threadObj.not_null(), &quot;java thread object must exist&quot;);  ObjectLocker lock(threadObj, thread);  // Ignore pending exception (ThreadDeath), since we are exiting anyway  thread-&gt;clear_pending_exception();  // Thread is exiting. So set thread_status field in  java.lang.Thread class to TERMINATED.  java_lang_Thread::set_thread_status(threadObj(), java_lang_Thread::TERMINATED);  // Clear the native thread instance - this makes isAlive return false and allows the join()  // to complete once we&#39;ve done the notify_all below  java_lang_Thread::set_thread(threadObj(), NULL);  lock.notify_all(thread);  // Ignore pending exception (ThreadDeath), since we are exiting anyway  thread-&gt;clear_pending_exception();}</code></pre><p>答案就在<br>lock.notify_all(thread);这里</p><p><a href="https://www.jianshu.com/p/acf667ccec40">锁的实现</a><br>java中的锁一共有4种状态，级别从低到高分别是：</p><ul><li>无锁状态</li><li>偏向锁</li><li>轻量级锁</li><li>重量级锁</li></ul><h3 id="偏向锁："><a href="#偏向锁：" class="headerlink" title="偏向锁："></a>偏向锁：</h3><p>顾名思义，为了让线程获得锁的代价更低，引入了偏向锁。<br><strong>加锁</strong><br>当一个线程访问同步块并且获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程id，这样，这个线程便获取了这个对象的偏向锁，之后这个线程进入和退出就不需要通过CAS操作，也就是原子操作，来进行加锁和解锁，只需要简单的测试下对象头存储的偏向锁的线程id是否和自身的id一致，如果一致，那么已经获取锁，直接进入。否则，判断对象中是否已经存储了偏向锁，如果没有锁，那么使用CAS竞争锁，如果设置了，那么尝试使用CAS将对象头的偏向锁指向当前线程。<br><strong>解锁</strong><br>偏向锁的解锁时机是在竞争时才会释放锁,撤销时需要等待全局安全点，这个时间点没有正在执行的字节码，首先会暂停拥有偏向锁的线程，然后检查偏向锁的线程是否存活，如果不活动，那么直接设置为无锁状态。否则要么偏向其他锁，要么恢复到无锁或者标记对象不适合偏向锁。</p><h3 id="轻量锁"><a href="#轻量锁" class="headerlink" title="轻量锁"></a>轻量锁</h3><p>会自旋尝试获取锁，消耗cpu资源<br><strong>加锁</strong><br>一旦多线程发起了锁竞争，并且释放了偏向锁之后，线程通过CAS修改Mark Word，如果当前没有对象持有同步体的锁，那么直接将同步体的锁修改的轻量锁，否则，该线程将自旋获取锁，直到膨胀为重量级锁，修改同步体的Mark Word为重量级锁，然后阻塞<br><strong>解锁</strong><br>一旦有其他线程因想获取当前锁而膨胀为重量级锁，那么这个线程将会通过CAS替换Mark Word，然后失败，解锁，并且唤醒其他等待线程。</p><h3 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h3><p>会阻塞，不消耗cpu资源，但是响应时间较慢<br>synchronized<br>内部也是利用了锁。<br>每一个对象都有一个自己的monitor，必须先获取这个monitor对象才能够进入同步块或同步方法，而这个monitor对象的获取是排他的，也就是同一时刻只能有一个线程获取到这个monitor</p><p><a href="http://ifeve.com/图解java并发上/">图解java并发</a><br>unSafe</p><p>hacknoon中有关于python中多线程primitives的文章<br>c语言中多线程通信基础<br>基本的思想都是相通的</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://tech.meituan.com/2018/11/15/java-lock.html">美团博客中关于java锁的一片文章</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/HongKongFireworks_ZH-CN13422096721_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;主要讲讲java中的notify,wait,synchronized ，unsafe等多线程基础工具的使用方式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>iptables速查手册</title>
    <link href="https://haldir65.github.io/2019/01/29/2019-01-29-iptables-cheatsheet/"/>
    <id>https://haldir65.github.io/2019/01/29/2019-01-29-iptables-cheatsheet/</id>
    <published>2019-01-29T11:46:11.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/lidongjieya_ZH-CN9263684179_1920x1080.jpg" alt=""><br>iptables是控制linux 内核netfilter的command line frontend tool，只存在于linux平台，是system admin常用的防火墙。(虽然已经被nftables取代了，学习点网络知识还是很有必要)<br><a id="more"></a></p><p>iptables的manpage这么写的</p><blockquote><p>DESCRIPTION<br>Iptables and ip6tables are used to set up, maintain, and inspect  the  tables<br>of  IPv4 and IPv6 packet filter rules in the Linux kernel.  Several different<br>tables may be defined.  Each table contains a number of built-in  chains  and<br>may also contain user-defined chains.<br>Each  chain  is  a list of rules which can match a set of packets.  Each rule<br>specifies what to do with a packet that matches.  This is called a  `target’,<br>which may be a jump to a user-defined chain in the same table.</p></blockquote><h2 id="概念"><a href="#概念" class="headerlink" title="概念:"></a>概念:</h2><p><strong>iptables命令需要root权限执行</strong><br>每个表包含有若干个不同的链，比如 filter 表默认包含有 INPUT，FORWARD，OUTPUT 三个链。iptables有四个表，分别是：raw，nat，mangle和filter，每个表都有自己专门的用处，比如最常用filter表就是专门用来做包过滤的，而 nat 表是专门用来做NAT的。</p><p><strong>iptables中有3个chain</strong></p><ul><li>INPUT —&gt; 所有进入这台主机的连接</li><li>FORWARD  —&gt; 借由这台主机发出的（路由器）</li><li>OUTPUT —&gt; 所有从这台主机发出去的连接</li></ul><p>每一条Chain上都有一个rules的列表(用A去append,用I去Insert)</p><pre><code>#~ iptables -L INPUT -n -v --line-numbersChain INPUT (policy DROP)num  target     prot opt source               destination1    DROP       all  --  202.54.1.1           0.0.0.0/02    DROP       all  --  202.54.1.2           0.0.0.0/03    ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           state NEW,ESTABLISHED</code></pre><p>执行顺序(这个比较麻烦):</p><blockquote><p>每一个chain是从上往下读取的。<br>iptables执行规则时，是从从规则表中从上至下顺序执行的，如果没遇到匹配的规则，就一条一条往下执行，如果遇到匹配的规则后，那么就执行本规则，执行后根据本规则的动作(accept, reject, log等)，决定下一步执行的情况。<br>比如说上面这个，拉黑了202.54.1.2虽然第三条规则说全部接受，其实202.54.1.2的包是进不来的。<br>这也是很多教程建议把自己的iptables写在后面的原因，不要把系统现有规则覆盖掉。</p><p>iptables -L -n -v //查看已添加的iptables规则</p></blockquote><p>默认是全部接受的</p><pre><code>Chain INPUT (policy ACCEPT) ## 允许进入这台电脑target     prot opt source               destinationChain FORWARD (policy ACCEPT)  ## 路由相关target     prot opt source               destinationChain OUTPUT (policy ACCEPT) ## 允许发出这台电脑target     prot opt source               destination</code></pre><h3 id="允许所有连接"><a href="#允许所有连接" class="headerlink" title="允许所有连接"></a>允许所有连接</h3><pre><code class="bash">iptables --policy INPUT ACCEPTiptables --policy OUTPUT ACCEPTiptables --policy FORWARD ACCEPT</code></pre><p>iptables后面可以跟的参数很多</p><pre><code># iptables -t mangle -X# iptables -P INPUT ACCEPT# iptables -P OUTPUT ACCEPT# iptables -P FORWARD ACCEPT</code></pre><h3 id="来解释一下这些参数的意思"><a href="#来解释一下这些参数的意思" class="headerlink" title="来解释一下这些参数的意思"></a>来解释一下这些参数的意思</h3><pre><code>-L List rules的意思-v verbose-n numeric 不走dns，直接显示ip,这样会快一点-F flushing（删除）所有的rules-X delete chain-t table_name(一般就nat和mangle两种)-P 设置policy(比如说DROP , REJECT, REDIRECT)--line-numbers //显示每条规则所在的行号-s source iP-i interface，就是eth0这些网卡设备什么的--dport destination端口 ，比方说80LOG --log-prefix &quot;IP_SPOOF A: &quot; //加日志,这个LOG关键词和DROP,ACCEPT都差不多的，跟在-j 屁股后面-m mac --mac-source //-m 我猜是metrics ，就是说根据哪种评判标准，这里是mac地址-m state --state NEW,ESTABLISHED -j ACCEPT-p tcp protocol之类的，比方说tcp,udp,icmp(ping)等等</code></pre><p>拉黑一个ip</p><blockquote><p>iptables -I INPUT -s xxx.xxx.xxx.xxx -j DROP //这个拉黑的效果是tcp,udp,icmp全部不通。对方的curl,ping全部卡住</p></blockquote><p>DROP是直接不回话了，REJECT则是会给对方发一个 ACK/RST （这跟不回应对方是有区别的）<br>REJECT differs to DROP that it does send a packet back, but the answer is as if a server is located on the IP, but does not have the port in a listening state. IPtables will sent a RST/ACK in case of TCP or with UDP an ICMP destination port unreachable.(对方收到后，看起了就像是这台http服务器没有listen在80端口上一样)<br>在互联网的服务器上，拉黑别人一般都是用DROP，因为没必要再去通知对方已被拉黑。</p><p>取消拉黑：也就是删除上面这条规则</p><blockquote><p>iptables -D INPUT -s xxx.xxx.xxx.xxx -j DROP</p></blockquote><p>比方说我不小心把202.54.1.1拉黑了，怎么挽回</p><pre><code>iptables -L OUTPUT -n --line-numbers | grep 202.54.1.1 //发现在条规则第四行iptabels -D INPUT 4 //把这个第四行的规则删掉iptables -D INPUT -s 202.54.1.1 -j DROP //这个也是一样的</code></pre><p>上面说了，iptables的顺序是从上往下读取的，后面的会依据前面的规则作出决定。所以假如第2条规则说全部接受，我想拉黑某个ip，就得用-I，把拉黑的规则插入到最前面（-I 1 就是插入到第一位）:<br>iptables -I 1 INPUT -s xxx.xxx.xxx.xxx -j DROP</p><pre><code class="bash">iptables -P FORWARD DROP ## 把forward 一律改为drop（走本机代理的包全部丢掉）iptables -A INPUT -s  192.168.1.3  ## A是append s是source，拒绝接受192.168.1.3的访问，就是黑名单了iptables -A INPUT -s  192.168.0.0/24 -p tcp --destination-port 25 -j DROP  ## block all devices on this network ,  p是protocol,SMTP一般是25端口iptables -A INPUT -s 192.168.0.66 -j ACCEPT  ## 白名单iptables -D INPUT 3 ##这个3是当前INPUT链的第3条规则，就是说删掉这个chain里面的第3条规则iptables -I INPUT -s 192.168.0.66 -j ACCEPT  ## 白名单，和-A不同，A是加到尾部，I是加到list的头部，顺序很重要。iptables -I INPUT -s 123.45.6.7 -j DROP       #屏蔽单个IP的命令iptables -I INPUT -s 123.0.0.0/8 -j DROP      #封整个段即从123.0.0.1到123.255.255.254的命令iptables -I INPUT -s 124.45.0.0/16 -j DROP    #封IP段即从123.45.0.1到123.45.255.254的命令</code></pre><h3 id="public-interface（对外提供服务的网卡应该把私有的ip拉黑掉）"><a href="#public-interface（对外提供服务的网卡应该把私有的ip拉黑掉）" class="headerlink" title="public interface（对外提供服务的网卡应该把私有的ip拉黑掉）"></a>public interface（对外提供服务的网卡应该把私有的ip拉黑掉）</h3><p>//假如你的某个公共网卡专门对外服务，ip嗅探没什么的，但是下面这种私有ip号段应该禁止。non-routable source addresses的包都可以被DROP掉（就是说拒绝局域网内设备192.168.x.x就不要想着访问这台主机的eth1网卡了）</p><p>具体来说，这些都是保留的私有ip地址</p><pre><code>iptables -A INPUT -i eth1 -s 192.168.0.0/24 -j DROP10.0.0.0/8 -j (A)172.16.0.0/12 (B)192.168.0.0/16 (C)224.0.0.0/4 (MULTICAST D)240.0.0.0/5 (E)127.0.0.0/8 (LOOPBACK) // See Wikipedia and RFC5735 for full list of reserved networks.</code></pre><pre><code class="bash">#允许所有本机向外的访问iptables -A OUTPUT -j ACCEPT# 允许访问22端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT#允许访问80端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT#允许访问443端口iptables -A INPUT -p tcp --dport 443 -j ACCEPT#允许FTP服务的21和20端口iptables -A INPUT -p tcp --dport 21 -j ACCEPTiptables -A INPUT -p tcp --dport 20 -j ACCEPT#如果有其他端口的话，规则也类似，稍微修改上述语句就行#允许pingiptables -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT#禁止其他未允许的规则访问iptables -A INPUT -j REJECT  #（注意：如果22端口未加入允许规则，SSH链接会直接断开。）iptables -A FORWARD -j REJECT</code></pre><h2 id="CIDR（比如说封掉facebook-com）"><a href="#CIDR（比如说封掉facebook-com）" class="headerlink" title="CIDR（比如说封掉facebook.com）"></a>CIDR（比如说封掉facebook.com）</h2><pre><code># host -t a www.facebook.comwww.facebook.com has address 69.171.228.40# whois 69.171.228.40 | grep CIDRCIDR:           69.171.224.0/19 //就是说facebook的网端在69.171.224.0/19这个范围里# iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j DROP // 这台主机没法上facebook了# ping www.facebook.comping: sendmsg: Operation not permitted(就是被发出去的包被iptables拦下来了)//上面这堆看起来挺麻烦的iptables -A OUTPUT -p tcp -d www.facebook.com -j DROP //直接搞定,但是不推荐这么干</code></pre><h3 id="拉黑某个mac地址"><a href="#拉黑某个mac地址" class="headerlink" title="拉黑某个mac地址"></a>拉黑某个mac地址</h3><pre><code># iptables -A INPUT -m mac --mac-source 00:0F:EA:91:04:08 -j DROP</code></pre><h3 id="不允许别人ping我"><a href="#不允许别人ping我" class="headerlink" title="不允许别人ping我"></a>不允许别人ping我</h3><pre><code># iptables -A INPUT -p icmp --icmp-type echo-request -j DROP# iptables -A INPUT -i eth1 -p icmp --icmp-type echo-request -j DROPiptables -A INPUT -s 192.168.1.0/24 -p icmp --icmp-type echo-request -j ACCEPT### ** assumed that default INPUT policy set to DROP ** #############iptables -A INPUT -p icmp --icmp-type echo-reply -j ACCEPTiptables -A INPUT -p icmp --icmp-type destination-unreachable -j ACCEPTiptables -A INPUT -p icmp --icmp-type time-exceeded -j ACCEPT## ** all our server to respond to pings ** ##iptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPT</code></pre><h2 id="打log"><a href="#打log" class="headerlink" title="打log"></a>打log</h2><p>先照上面的做法把facebook给封了（所有发到facebook的包全部drop，只是我们这一次想要看日志）</p><pre><code>iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j LOG --log-prefix &quot;IP_SPOOF A: &quot;iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j DROP //默认情况下所有信息都被log到/var/log/messgaes文件中了，我试了下，并没有，不过这并不重要吧tail -f /var/log/messagesgrep --color &#39;IP SPOOF&#39; /var/log/messages</code></pre><h3 id="只开7000-7010端口-只允许某个网段的ip发请求"><a href="#只开7000-7010端口-只允许某个网段的ip发请求" class="headerlink" title="只开7000-7010端口,只允许某个网段的ip发请求"></a>只开7000-7010端口,只允许某个网段的ip发请求</h3><pre><code>iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 7000:7010 -j ACCEPT## only accept connection to tcp port 80 (Apache) if ip is between 192.168.1.100 and 192.168.1.200 ##iptables -A INPUT -p tcp --destination-port 80 -m iprange --src-range 192.168.1.100-192.168.1.200 -j ACCEPT## nat example ##iptables -t nat -A POSTROUTING -j SNAT --to-source 192.168.1.20-192.168.1.25Replace ACCEPT with DROP to block port:## open port ssh tcp port 22 ##iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 22 -j ACCEPT## open cups (printing service) udp/tcp port 631 for LAN users ##iptables -A INPUT -s 192.168.1.0/24 -p udp -m udp --dport 631 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -p tcp -m tcp --dport 631 -j ACCEPT## allow time sync via NTP for lan users (open udp port 123) ##iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p udp --dport 123 -j ACCEPT## open tcp port 25 (smtp) for all ##iptables -A INPUT -m state --state NEW -p tcp --dport 25 -j ACCEPT# open dns server ports for all ##iptables -A INPUT -m state --state NEW -p udp --dport 53 -j ACCEPTiptables -A INPUT -m state --state NEW -p tcp --dport 53 -j ACCEPT## open http/https (Apache) server port to all ##iptables -A INPUT -m state --state NEW -p tcp --dport 80 -j ACCEPTiptables -A INPUT -m state --state NEW -p tcp --dport 443 -j ACCEPT## open tcp port 110 (pop3) for all ##iptables -A INPUT -m state --state NEW -p tcp --dport 110 -j ACCEPT## open tcp port 143 (imap) for all ##iptables -A INPUT -m state --state NEW -p tcp --dport 143 -j ACCEPT## open access to Samba file server for lan users only ##iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 137 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 138 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 139 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 445 -j ACCEPT## open access to proxy server for lan users only ##iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 3128 -j ACCEPT## open access to mysql server for lan users only ##iptables -I INPUT -p tcp --dport 3306 -j ACCEPT</code></pre><h3 id="限制最大连接数"><a href="#限制最大连接数" class="headerlink" title="限制最大连接数"></a>限制最大连接数</h3><pre><code>To allow 3 ssh connections per client host, enter:(一个client最多能够连3个ssh连接过来)# iptables -A INPUT -p tcp --syn --dport 22 -m connlimit --connlimit-above 3 -j REJECThttp端口一个client最多20个连接# iptables -p tcp --syn --dport 80 -m connlimit --connlimit-above 20 --connlimit-mask 24 -j DROP</code></pre><h3 id="使用iptables阻止syn-flood"><a href="#使用iptables阻止syn-flood" class="headerlink" title="使用iptables阻止syn-flood"></a>使用iptables阻止syn-flood</h3><p>一般在路由器里面都有这么一条</p><pre><code>iptables -N syn-floodiptables -A syn-flood -m limit --limit 50/s --limit-burst 10 -j RETURNiptables -A syn-flood -j DROPiptables -I INPUT -j syn-flood</code></pre><pre><code>-N 创建一个条新的链--limit 50/s 表示每秒50次;1/m 则为每分钟一次--limit-burst 表示允许触发 limit 限制的最大包个数 (预设5)，它就像是一个容器，最多装10个，超过10个就装不下了，这些包就给后面的规则了-I INPUT -j syn-flood  把INPUT的包交给syn-flood链处理这里的--limit-burst=10相当于说最开始有10个可以匹配的包去转发，然后匹配的包的个数是根据--limit=50/s进行限制的，也就是每秒限制转发50个数据包，多余的会被下面符合要求的DROP规则去处理，进行丢弃，这样就实现了对数据包的限速问题。</code></pre><h2 id="现在来看看fail2ban是怎么拉黑一个ip的"><a href="#现在来看看fail2ban是怎么拉黑一个ip的" class="headerlink" title="现在来看看fail2ban是怎么拉黑一个ip的"></a>现在来看看fail2ban是怎么拉黑一个ip的</h2><p>一般来说要拒绝一个ip访问http,https可以这么干</p><pre><code>iptables -L INPUT -s xxx.xxx.xxx.xxx -p tcp --dport 80 -j DROPiptables -L INPUT -s xxx.xxx.xxx.xxx -p tcp --dport 443 -j DROP而事实上就是创建了一个chain~ cat /etc/fail2ban/action.d/iptables.conf# Option:  actionban# Notes.:  command executed when banning an IP. Take care that the#          command is executed with Fail2Ban user rights.# Tags:    See jail.conf(5) man page# Values:  CMD#actionban = &lt;iptables&gt; -I f2b-&lt;name&gt; 1 -s &lt;ip&gt; -j &lt;blocktype&gt;</code></pre><h2 id="REDIRECT-Transparent-proxy-related"><a href="#REDIRECT-Transparent-proxy-related" class="headerlink" title="REDIRECT (Transparent proxy related)"></a>REDIRECT (Transparent proxy related)</h2><p>首先来看一个把所有走网卡eth0的数据包都转发到redSocks的规则</p><pre><code>// 新建路由转发表中的一个链 REDSOCKSsudo iptables -t nat -N REDSOCKS// 设置不需要代理转发的网段// 目的为墙外代理服务器的数据包一定不能转发sudo iptables -t nat -A REDSOCKS -d $SS_SERVER_IP -j RETURN// 目的为局域网和本地回环地址的数据包不用转发sudo iptables -t nat -A REDSOCKS -d 172.0.0.0/24 -j RETURNsudo iptables -t nat -A REDSOCKS -d 192.168.0.0/16 -j RETURN// 将数据包转发到 redsockssudo iptables -t nat -A REDSOCKS -p tcp -j REDIRECT --to-ports 12345// 将 REDSOCKS 链的规则应用到经过 eth0 网卡的数据包sudo iptables -t nat -A OUTPUT -p tcp -o eth0 -j REDSOCKS</code></pre><p>经常会看到教程如何把一台局域网linux nas或者虚拟机变成软路由的教程，首先需要设备开启ip转发</p><pre><code>cat /proc/sys/net/ipv4/ip_forward1 // 这个值默认是0</code></pre><p>比方说把所有incoming 流量(目标端口是80的)导向8080端口</p><pre><code>iptables -t nat -I PREROUTING --src 0/0 --dst 192.168.1.5 -p tcp --dport 80 -j REDIRECT --to-ports 8080</code></pre><p>然后根据v2ray的配置文件设置透明代理。<br>再接下来把所有nat表上的流量交给v2ray监听的端口</p><pre><code>openwrt在/etc/firewall.user中添加如下脚本，实现本地透明代理（其实并不完美）```shiptables -t nat -N V2RAY //在nat这个表里面创建一个V2RAY的chainiptables -t nat -A V2RAY -d x.x.x.x -j RETURN ##xxx是vps的ip地址iptables -t nat -A V2RAY -d 0.0.0.0/8 -j RETURNiptables -t nat -A V2RAY -d 10.0.0.0/8 -j RETURNiptables -t nat -A V2RAY -d 127.0.0.0/8 -j RETURNiptables -t nat -A V2RAY -d 169.254.0.0/16 -j RETURNiptables -t nat -A V2RAY -d 172.16.0.0/12 -j RETURNiptables -t nat -A V2RAY -d 192.168.0.0/16 -j RETURNiptables -t nat -A V2RAY -d 224.0.0.0/4 -j RETURNiptables -t nat -A V2RAY -d 240.0.0.0/4 -j RETURNiptables -t nat -A V2RAY -p tcp -j REDIRECT --to-ports 1060iptables -t nat -A PREROUTING -p tcp -j V2RAY//下面是把所有的udp包导到1080端口，为什么这么写我不知道ip rule add fwmark 1 table 100ip route add local 0.0.0.0/0 dev lo table 100iptables -t mangle -N V2RAY_MASKiptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -j RETURNiptables -t mangle -A V2RAY_MASK -p udp -j TPROXY --on-port 1080 --tproxy-mark 1iptables -t mangle -A PREROUTING -p udp -j V2RAY_MASK</code></pre><p><strong><em>亲测，透明代理的效果是可以的。只是比不上在windows上的速度,cpu占用达到50%以上，没什么意思。</em></strong></p><p>相比起来,shadowsocks-libev给出了这样一份transparent proxy的代码，更加清楚</p><pre><code># Create new chainiptables -t nat -N SHADOWSOCKSiptables -t mangle -N SHADOWSOCKS# Ignore your shadowsocks server&#39;s addresses# It&#39;s very IMPORTANT, just be careful.iptables -t nat -A SHADOWSOCKS -d 123.123.123.123 -j RETURN# Ignore LANs and any other addresses you&#39;d like to bypass the proxy# See Wikipedia and RFC5735 for full list of reserved networks.# See ashi009/bestroutetb for a highly optimized CHN route list.iptables -t nat -A SHADOWSOCKS -d 0.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 10.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 127.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 169.254.0.0/16 -j RETURNiptables -t nat -A SHADOWSOCKS -d 172.16.0.0/12 -j RETURNiptables -t nat -A SHADOWSOCKS -d 192.168.0.0/16 -j RETURNiptables -t nat -A SHADOWSOCKS -d 224.0.0.0/4 -j RETURNiptables -t nat -A SHADOWSOCKS -d 240.0.0.0/4 -j RETURN# Anything else should be redirected to shadowsocks&#39;s local portiptables -t nat -A SHADOWSOCKS -p tcp -j REDIRECT --to-ports 12345# Add any UDP rulesip route add local default dev lo table 100ip rule add fwmark 1 lookup 100iptables -t mangle -A SHADOWSOCKS -p udp --dport 53 -j TPROXY --on-port 12345 --tproxy-mark 0x01/0x01# Apply the rulesiptables -t nat -A PREROUTING -p tcp -j SHADOWSOCKSiptables -t mangle -A PREROUTING -j SHADOWSOCKS# Start the shadowsocks-redirss-redir -u -c /etc/config/shadowsocks.json -f /var/run/shadowsocks.pid</code></pre><p>代理的原理:参考<a href="https://paper.tuisec.win/detail/4f9d95db284d609">ss/ssr/v2ray/socks5 透明代理</a>里面的解释</p><blockquote><p>ss-redir 是 ss-libev、ssr-libev 中的一个工具，配合 iptables 可以在 Linux 上实现 ss、ssr 透明代理，ss-redir 的透明代理是通过 DNAT 实现的，但是 udp 包在经过 DNAT 后会无法获取原目的地址，所以 ss-redir 无法代理经过 DNAT 的 udp 包；但是 ss-redir 提供了另一种 udp 透明代理方式：xt_TPROXY 内核模块（不涉及 NAT 操作），配合 iproute2 即可实现 udp 的透明代理，但缺点是只能代理来自内网主机的 udp 流量。强调一点，利用 ss-redir 实现透明代理必须使用 ss-libev 或 ssr-libev，python、go 等实现版本没有 ss-redir、ss-tunnel 程序。当然，ss、ssr 透明代理并不是只能用 ss-redir 来实现，使用 ss-local + redsocks/tun2socks 同样可以实现 socks5（ss-local 是 socks5 服务器）全局透明代理，ss-local + redsocks 实际上是 ss-redir 的分体实现，都是通过 NAT 进行代理的，因此也不能代理本机的 udp，当然内网的 udp 也不能代理，因为 redsocks 不支持 xt_TPROXY 方式（redsocks2 支持 TPROXY 模块，但是依旧无法代理本机 udp，不考虑）。所以这里只讨论 ss-local + tun2socks，这个组合方式其实和 Android 上的 VPN 模式差不多（ss-redir 或 ss-local + redsocks 则是 NAT 模式），因为不涉及 NAT 操作，所以能够代理所有 tcp、udp 流量（包括本机、内网的 udp）。很显然，利用 tun2socks 可以实现任意 socks5 透明代理（不只是 ss/ssr，ssh、v2ray 都可以，只要能提供 socks5 本地代理）。最后再说一下 v2ray 的透明代理，其实原理和 ss/ssr-libev 一样，v2ray 可以看作是 ss-local、ss-redir、ss-tunnel 三者的合体，因为一个 v2ray 客户端可以同时充当这三个角色（当然端口要不一样）；所以 v2ray 的透明代理也有两种实现方式，一是利用对应的 ss-redir/ss-tunnel + iptables，二是利用对应的 ss-local + tun2socks（这其实就是前面说的 socks5 代理）。</p></blockquote><p>shell中全局的http代理可以这么设置</p><pre><code>export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy//如果是socks5协议的话可以改一下export http_proxy=socks5://127.0.0.1:8118; export https_proxy=$http_proxy//只对当前shell有效</code></pre><p>接下来，git、curl、wget 等命令会自动从环境变量中读取 http 代理信息，然后通过 http 代理连接目的服务器。但有些软件是不认这个的。<br>那问题来了，ss-local 提供的是 socks5 代理，不能直接使用怎么办？也简单，Linux 中有很多将 socks5 包装为 http 代理的工具，比如 privoxy。只需要在 /etc/privoxy/config 里面添加一行 forward-socks5 / 127.0.0.1:1080 .，启动 privoxy，默认监听 127.0.0.1:8118 端口，注意别搞混了，8118 是 privoxy 提供的 http 代理地址，而 1080 是 ss-local 提供的 socks5 代理地址，发往 8118 端口的数据会被 privoxy 处理并转发给 ss-local。所以我们现在可以执行 export http_proxy=<a href="http://127.0.0.1:8118">http://127.0.0.1:8118</a>; export https_proxy=$http_proxy 来配置当前终端的 http 代理，这样 git、curl、wget 这些就会自动走 ss-local 出去了。</p><blockquote><p>Often, services on the computer communicate with each other by sending network packets to each other. They do this by utilizing a pseudo network interface called the loopback device, which directs traffic back to itself rather than to other computers.<br>同一台机器的不同进程之间有时候是通过一个虚拟的网络(loopback device)进行通信的，所以，必须要让iptables允许这些通信<br>$ sudo iptables -I INPUT 1 -i lo -j ACCEPT // -I的意思是插入，就是插入到INPUT这个规则里面。 1是说插到第一位，因为iptables排在前面的优先级高。 -i是interface的意思，lo就是loopback的简称。（也就是说，所有使用本地loopback这个interface发过来的包，放行）</p></blockquote><p><strong>注意还需要将上述规则添加到开机启动中，想要持久化的话好像有一个iptables-persistent</strong>，还有使用iptables屏蔽来自<a href="https://www.vpser.net/security/iptables-block-countries-ip.html">某个国家的IP</a>的教程</p><h2 id="tbd"><a href="#tbd" class="headerlink" title="tbd"></a>tbd</h2><h3 id="nat相关"><a href="#nat相关" class="headerlink" title="nat相关"></a>nat相关</h3><pre><code>iptables -t nat -L -n -v //在路由器上这个会有</code></pre><p>一般路由器就是干这个的（使用iptables配置nat）<br>POSTROUTING 和 PREROUTING的概念</p><p>还有一个ipset 可以认为是一次性执行多个iptables命令,openwrt上经常用</p><p>netfilter是kernel的实现</p><blockquote><p>Iptables is a standard firewall included in most Linux distributions by default (a modern variant called nftables will begin to replace it). It is actually a front end to the kernel-level netfilter hooks that can manipulate the Linux network stack.</p></blockquote><p>iptables的工作流程</p><blockquote><p>direct the packet to the appropriate chain, check it against each rule until one matches, issue the default policy of the chain if no match is found</p></blockquote><p><a href="https://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture">a-deep-dive-into-iptables-and-netfilter-architecture</a></p><p><a href="https://unix.stackexchange.com/questions/413545/what-does-iptables-j-redirect-actually-do-to-packet-headers">iptable在透明代理中的原理就是修改了packet的destination address，同时还记住了原来的address</a></p><blockquote><p>iptables overrites the original destination address but it remembers the old one. The application code can then fetch it by asking for a special socket option, SO_ORIGINAL_DST<br><a href="https://github.com/darkk/redsocks">著名tcp代理redsocks就是用SO_ORIGINAL_DST的</a></p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cyberciti.biz/tips/linux-iptables-examples.html">linux-iptables-examples</a><br><a href="https://blog.dreamtobe.cn/r7800-openwrt-v2ray/">网件R7800 OpenWrt使用V2Ray+mKcp+透明代理完美翻墙</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/lidongjieya_ZH-CN9263684179_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;iptables是控制linux 内核netfilter的command line frontend tool，只存在于linux平台，是system admin常用的防火墙。(虽然已经被nftables取代了，学习点网络知识还是很有必要)&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>原始套接字学习指南</title>
    <link href="https://haldir65.github.io/2019/01/19/2019-01-19-learning-from-raw-socket/"/>
    <id>https://haldir65.github.io/2019/01/19/2019-01-19-learning-from-raw-socket/</id>
    <published>2019-01-19T22:20:35.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/SunFlowersStorm_EN-AU8863925685_1920x1080.jpg" alt=""><br>从原始套接字 SOCK_RAW学习到的知识<br><a id="more"></a></p><p>以下图片盗自<a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">chinaunix一篇讲解raw socket的文章</a>，感谢原作者的辛勤工作。复习一下ip包的结构。</p><ul><li><h3 id="这是IP-packet"><a href="#这是IP-packet" class="headerlink" title="这是IP packet"></a>这是IP packet</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-1.jpg" alt=""></p></li><li><h3 id="这是TCP-header"><a href="#这是TCP-header" class="headerlink" title="这是TCP header"></a>这是TCP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-2.jpg" alt=""></p></li><li><h3 id="这是IP-header"><a href="#这是IP-header" class="headerlink" title="这是IP header"></a>这是IP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-3.jpg" alt=""></p></li><li><h3 id="这是mac-header"><a href="#这是mac-header" class="headerlink" title="这是mac header"></a>这是mac header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-4.jpg" alt=""></p></li></ul><p>从内核代码来看，这些分别对应ethhdr、iphdr、tcphdr、udphdr等结构体。</p><p>一般来讲，应用层程序的数据都是在tcp或者udp的data中的，实际发送过程中，内核会帮忙添加上tcp header，ip header以及mac header等数据，开发者无需关心也无从干涉。raw socket为我们提供了直接读写这块数据的方法。</p><p>C语言中raw socket的创建方式为:</p><blockquote><p>socket(AF_INET, SOCK_RAW, protocol); //需要root权限</p></blockquote><p>raw socket一般用于网络监测程序中比较多，比如ping , nmap这种。这类协议是没有端口的。</p><p>另一种场景是伪造tcp header应对运营商udp屏蔽和流量qos，这种类似的实现在2017年出来的比较多。(就是用一个raw socket把一个udp包伪装成一个tcp包)。</p><p>接下来这个例子是使用raw socket监听server端收到的ip packet包内容<br>server.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;linux/if_ether.h&gt;#include &lt;stdlib.h&gt;#include &lt;arpa/inet.h&gt;int main(){     printf(&quot;main is running\n&quot;);int iSock, nRead, iProtocol;        char buffer[4096] = {0};char  *ethhead, *iphead, *tcphead, *udphead, *icmphead, *p;if((iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP))) &lt; 0){    printf(&quot;create iSocket error, check root\n&quot;);  // 需要root权限， 最后运行的时候， 可以用sudo ./server    return 1;}while(1) {    nRead = recvfrom(iSock, buffer, 2048, 0, NULL, NULL);      /*        以太网帧头 14        ip头       20        udp头      8        总共42字节(最少)    */    if(nRead &lt; 42)     {        printf(&quot;packet error\n&quot;);        continue;    }    int n = 0XFF;    char szVisBuf[1024] = {0};    for(unsigned int i = 0; i &lt; nRead; ++i)    {        char szTmp[3] = {0};        sprintf(szTmp, &quot;%02x&quot;, buffer[i]&amp;n);        strcat(szVisBuf, szTmp);    }    ethhead = buffer;    p = ethhead;    iphead = ethhead + 14;      p = iphead + 12;    char szIps[128] = {0};    snprintf(szIps, sizeof(szIps), &quot;IP: %d.%d.%d.%d =&gt; %d.%d.%d.%d&quot;,        p[0]&amp;n, p[1]&amp;n, p[2]&amp;n, p[3]&amp;n,        p[4]&amp;n, p[5]&amp;n, p[6]&amp;n, p[7]&amp;n);    iProtocol = (iphead + 9)[0];    p = iphead + 20;    unsigned int iDstPort = (p[2]&lt;&lt;8)&amp;0xff00 | p[3]&amp;n;    switch(iProtocol)    {        case IPPROTO_UDP :             if(iDstPort == 8888)            {                printf(&quot;source port: %u,&quot;,(p[0]&lt;&lt;8)&amp;0xff00 |  p[1]&amp;n);                printf(&quot;dest port: %u\n&quot;, iDstPort);                printf(&quot;%s\n&quot;, szIps);                    printf(&quot;%s\n&quot;, szVisBuf);                printf(&quot;nRead is %d\n&quot;, nRead);                }            break;        case IPPROTO_RAW :             printf(&quot;raw\n&quot;);            break;        default:            break;    }}}</code></pre><p>client.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;unistd.h&gt;int main(){    struct sockaddr_in srvAddr;    bzero(&amp;srvAddr, sizeof(srvAddr));    srvAddr.sin_family = AF_INET;    srvAddr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;);    srvAddr.sin_port = htons(8888);    int iSock = socket(AF_INET, SOCK_DGRAM, 0); // udp    int i = 0;    while(1)    {        printf(&quot;press enter to send data\n&quot;);        while (( i = getchar()) != &#39;\n&#39;){            char szBuf[32] = {0};            snprintf(szBuf, sizeof(szBuf), &quot;hello %d&quot;, ++i);            sendto(iSock, szBuf, strlen(szBuf) + 1, 0, (struct sockaddr *)&amp;srvAddr, sizeof(srvAddr));        }    }    close(iSock);    return 0;}</code></pre><p>从raw socket 接受过来的buffer 的地址是数据链路层的地址，具体我们获取的东西就是通过偏移量来，这个偏移量我们需要查看网络书或者抓个包分析下链路层的数据格式等等。<br>client很简单，就是一个udp发包到localhost，关键在于server这边：</p><blockquote><p>iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP)</p></blockquote><p>这个socket能够监听本机接收到的所有ip packet，接收到的数据帧的头6个字节是目的地的MAC地址，紧接着6个字节是源MAC地址 , 如果是udp或者tcp的话，还能读取到port。也就是一些常用抓包工具的实现原理。</p><p>所以可以写一个简单的抓包工具，将那些发给本机的IPV4报文全部打印出来。</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;netinet/if_ether.h&gt;int main(int argc, char **argv){int sock, n;char buffer[2048];struct ethhdr *eth;struct iphdr *iph;if (0 &gt; (sock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP)))) {    perror(&quot;socket&quot;);    exit(1);}while (1) {    printf(&quot;=====================================\n&quot;);    //注意：在这之前我没有调用bind函数，raw socket这一层已经不存在port的概念了    n = recvfrom(sock, buffer, 2048, 0, NULL, NULL);    printf(&quot;%d bytes read\n&quot;, n);    //接收到的数据帧头6字节是目的MAC地址，紧接着6字节是源MAC地址。    eth = (struct ethhdr*)buffer;    printf(&quot;Dest MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\n&quot;,eth-&gt;h_dest[0],eth-&gt;h_dest[1],eth-&gt;h_dest[2],eth-&gt;h_dest[3],eth-&gt;h_dest[4],eth-&gt;h_dest[5]);    printf(&quot;Source MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\n&quot;,eth-&gt;h_source[0],eth-&gt;h_source[1],eth-&gt;h_source[2],eth-&gt;h_source[3],eth-&gt;h_source[4],eth-&gt;h_source[5]);    iph = (struct iphdr*)(buffer + sizeof(struct ethhdr));    //我们只对IPV4且没有选项字段的IPv4报文感兴趣    if(iph-&gt;version == 4 &amp;&amp; iph-&gt;ihl == 5){    unsigned char *sd, *dd;    sd = (unsigned char*)&amp;iph-&gt;saddr;    dd = (unsigned char*)&amp;iph-&gt;daddr;    printf(&quot;Source Host: %d.%d.%d.%d Dest host: %d.%d.%d.%d\n&quot;, sd[0], sd[1], sd[2], sd[3], dd[0], dd[1], dd[2], dd[3]);    //    printf(&quot;Source host:%s\n&quot;, inet_ntoa(iph-&gt;saddr));    //    printf(&quot;Dest host:%s\n&quot;, inet_ntoa(iph-&gt;daddr));    }}return 0;}</code></pre><p>顺便提一下，一般我们在Linux机器上是可以查看到当前系统对应的内核的头文件的</p><blockquote><p> root][~]# grep -n ‘ethhdr’ /usr/include/linux/if_ether.h<br>107:struct ethhdr {<br>[root][~]#<br>[root][~]# grep -n ‘iphdr’ /usr/include/linux/*<br>/usr/include/linux/if_tunnel.h:32:      struct iphdr            iph;<br>/usr/include/linux/ip.h:85:struct iphdr {</p></blockquote><p><a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">从raw socket介绍中学到的东西</a></p><blockquote><p>接下来我们简单介绍一下网卡是怎么收报的，如果你对这部分已经很了解可以跳过这部分内容。网卡从线路上收到信号流，网卡的驱动程序会去检查数据帧开始的前6个字节，即目的主机的MAC地址，如果和自己的网卡地址一致它才会接收这个帧，不符合的一般都是直接无视。然后该数据帧会被网络驱动程序分解，IP报文将通过网络协议栈，最后传送到应用程序那里。往上层传递的过程就是一个校验和“剥头”的过程，由协议栈各层去实现。</p></blockquote><p>setsockopt (packet_send_sd, IPPROTO_IP, IP_HDRINCL, val, sizeof (one)) // IP_HDRINCL to tell the kernel that headers are included in the packet<br>这样设置告诉内核，ip packet的header将由我们自己添加，所以最终发送出去的内容需要完全由自己决定。</p><p>为了将一个udp包伪装成tcp包，需要一个SOCK_RAW的socket</p><blockquote><p>socket(AF_INET , SOCK_RAW , IPPROTO_TCP)</p></blockquote><p>接下来就是自己组装tcp包结构，tbd(这个不同的网卡的值是不一样的，最简单的就是抓包就可以了)</p><h2 id="python也提供了对应rawsocket的api"><a href="#python也提供了对应rawsocket的api" class="headerlink" title="python也提供了对应rawsocket的api"></a>python也提供了对应rawsocket的api</h2><blockquote><p> socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_TCP)</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.chionlab.moe/2017/04/06/kcptun-with-fake-tcp/">kcptun-raw：应对UDP QoS，重新实现kcptun的一次尝试</a><br><a href="https://github.com/linhua55/some_kcptun_tools">some_kcptun_tools</a><br><a href="https://github.com/Chion82/kcptun-raw">kcptun-raw</a><br><a href="https://coolshell.cn/articles/11609.html">tcp那些事</a> tcp协议为了对外实现可靠交付，内部实现有很多非常复杂的算法。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/SunFlowersStorm_EN-AU8863925685_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;从原始套接字 SOCK_RAW学习到的知识&lt;br&gt;
    
    </summary>
    
    
      <category term="c" scheme="https://haldir65.github.io/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>操作系统原理</title>
    <link href="https://haldir65.github.io/2019/01/10/2019-01-10-operating-system-related-topics/"/>
    <id>https://haldir65.github.io/2019/01/10/2019-01-10-operating-system-related-topics/</id>
    <published>2019-01-10T22:32:11.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p>操作系统原理的一些记录<br><img src="https://www.haldir66.ga/static/imgs/SouthMoravian_ZH-CN13384331455_1920x1080.jpg" alt=""><br><a id="more"></a></p><h2 id="操作系统是如何做好断电保护的？"><a href="#操作系统是如何做好断电保护的？" class="headerlink" title="操作系统是如何做好断电保护的？"></a>操作系统是如何做好断电保护的？</h2><p>日志文件系统（journaling file system）是一个具有故障恢复能力的文件系统，在这个文件系统中，因为对目录以及位图的更新信息总是在原始的磁盘日志被更新之前写到磁盘上的一个连续的日志上，所以它保证了数据的完整性。当发生系统错误时，一个全日志文件系统将会保证磁盘上的数据恢复到发生系统崩溃前的状态。同时，它还将覆盖未保存的数据，并将其存在如果计算机没有崩溃的话这些数据可能已经遗失的位置，这是对关键业务应用来说的一个很重要的特性。</p><h2 id="内存中段和分页的语义是什么"><a href="#内存中段和分页的语义是什么" class="headerlink" title="内存中段和分页的语义是什么"></a>内存中段和分页的语义是什么</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.cnblogs.com/huxiao-tee/p/4657851.html">从内核文件系统看文件读写过程</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;操作系统原理的一些记录&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/SouthMoravian_ZH-CN13384331455_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>java nio使用指南</title>
    <link href="https://haldir65.github.io/2019/01/10/2019-01-10-java-nio-intro/"/>
    <id>https://haldir65.github.io/2019/01/10/2019-01-10-java-nio-intro/</id>
    <published>2019-01-10T22:25:50.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p>关于java nio的一些点<br><img src="https://www.haldir66.ga/static/imgs/UmbriaCastelluccio_EN-AU8834990889_1920x1080.jpg" alt=""><br><a id="more"></a></p><p><a href="https://zhuanlan.zhihu.com/p/27625923">本文大多数内容来自知乎专栏</a>的复制粘贴，因为别人写的比我好</p><h3 id="nio及DirectByteBuffer相关操作"><a href="#nio及DirectByteBuffer相关操作" class="headerlink" title="nio及DirectByteBuffer相关操作"></a>nio及DirectByteBuffer相关操作</h3><p>nio包含了很多东西，核心的应该是selector<br>DirectBuffer这个东西很容易讲，一句话就能说清楚：这是一块在Java堆外分配的，可以在Java程序中访问的内存。<br>先来解释一下几个堆是什么。以32位系统为例（64位系统也是一样的，只是地址空间更大而已，写起来没有32位系统看上去那么简洁），操作系统会为一个进程提供4G的地址空间，换句话说，一个进程可用的内存是4G。在Linux上，又为内核空间留了1G，剩下的3G是可以供用户使用的(粗略来看是这样的)。这1G就叫做内核空间，3G被称为用户空间。<br>一个java进程下不过对于操作系统而言，肯定是一个用户进程。所以jva也就有了这3G的使用权。jvm想要使用这些内存的时候，会使用malloc方法去找操作系统去要（其实中间还隔了一个C runtime，我们不去管这个细节，只把malloc往下都看成是操作系统的功能，并不会带来太大的问题）<br>而JVM要来的这些的内存，有一块是专门供Java程序创建对象使用的，这块内存在JVM中被称为堆(heap)。堆这个词快被用烂了，操作系统有堆的概念，C runtime也有，JVM里也有，然后还有一种数据结构也叫堆.<br>我们使用普通的ByteBuffer，那么这个ByteBuffer就会在Java堆内，被JVM所管理：</p><pre><code class="java">ByteBuffer buf = ByteBuffer.allocate(1024);</code></pre><p>在执行GC的时候，JVM实际上会做一些整理内存的工作，也就说buf这个对象在内存中的实际地址是会发生变化的。有些时候，ByteBuffer里都是大量的字节，这些字节在JVM GC整理内存时就显得很笨重，把它们在内存中拷来拷去显然不是一个好主意。<br>那这时候，我们就会想能不能给我一块内存，可以脱离JVM的管理呢？在这样的背景下，就有了DirectBuffer。先看一下用法：</p><pre><code class="java">ByteBuffer buf = ByteBuffer.allocateDirect(1024);</code></pre><p>这两个函数的实现是有区别的:</p><pre><code class="java">public static ByteBuffer allocateDirect(int capacity) {        return new DirectByteBuffer(capacity);    }    public static ByteBuffer allocate(int capacity) {        if (capacity &lt; 0)            throw new IllegalArgumentException();        return new HeapByteBuffer(capacity, capacity);    }</code></pre><p>DirectByteBuffer的核心就是调用了 unsafe.allocateMemory(size)方法。<br>Java对象在Java堆里申请内存的时候，实际上是比malloc要快的，所以DirectBuffer的创建效率往往是比Heap Buffer差的。<br>但是，如果进行网络读写或者文件读写的时候，DirectBuffer就会比较快了。 <strong>说起来好笑，这个快是因为JDK故意把非DirectBuffer的读写搞慢的，我们看一下JDK的源代码</strong>。<br>share/classes/sun/nio/ch/IOUtil.java</p><pre><code class="java">static int write(FileDescriptor fd, ByteBuffer src, long position,                     NativeDispatcher nd)         throws IOException    {           if (src instanceof DirectBuffer)            return writeFromNativeBuffer(fd, src, position, nd);        // Substitute a native buffer        int pos = src.position();        int lim = src.limit();        assert (pos &lt;= lim);        int rem = (pos &lt;= lim ? lim - pos : 0);         ByteBuffer bb = Util.getTemporaryDirectBuffer(rem);        try {            bb.put(src);            bb.flip();        // ................略</code></pre><p>如果src是DirectBuffer，就直接调用writeFromNativeBuffer，如果不是，则要先创建一个临时的DirectBuffer，把src拷进去，然后再调用真正的写操作。为什么要这么干呢？还是要从DirectBuffer不会被GC移动说起。writeFromNativeBuffer的实现，最终会把Buffer的address传给操作系统，让操作系统把address开始的那一段内存发送到网络上。这就要求在操作系统进行发送的时候，这块内存是不能动的(jni调用传递的是地址，地址不能乱动)。而我们知道，GC是会乱搬Java堆里的东西的，所以无奈，我们必须得弄一块地址不会变化的内存，然后把这个地址发给操作系统。</p><p>常用的ByteBuffer本质上是一个byte[]，包括这么几个变量<br>容量（Capacity） 缓冲区能够容纳的数据元素的最大数量。容量在缓冲区创建时被设定，并且永远不能被改变。<br>上界（Limit） 缓冲区里的数据的总数，代表了当前缓冲区中一共有多少数据。<br>位置（Position） 下一个要被读或写的元素的位置。Position会自动由相应的 get( )和 put( )函数更新。<br>标记（Mark） 一个备忘位置。用于记录上一次读写的位置。一会儿，我会通过reset方法来说明这个属性的含义。<br>ByteBuffer是一个抽象类，不能new出来</p><pre><code class="java">ByteBuffer byteBuffer = ByteBuffer.allocate(256);</code></pre><p>以上的语句可以创建一个大小为256字节的ByteBuffer，此时，mark = -1, pos = 0, limit = 256, capacity = 256。capacity在初始化的时候确定了，运行时就不会再变化了，而另外三个变量是随着程序的执行而不断变化的。</p><p>由于本质上就是一个byte[]，读数据的时候position放到0, limit放到当前已经存放的数据的位置，读完为止。写数据的时候也差不多，position放到当前已经存放的数据的curIndex+1，limit放到capicity的位置，填满为止。</p><p>从读变成写可以这么干</p><pre><code class="java">byteBuffer.limit(byteBuffer.position())byteBuffer.position(0);//由于这个方法实在太频繁,jdk就帮忙封装了一个叫做flip的方法public final Buffer flip() {        limit = position;        position = 0;        mark = -1;        return this;    }</code></pre><p>显然连续调用flip会导致limit变成0，不能读也不能写了。<br>mark方法类似于打一个标记，待会儿通过reset回到这个position。</p><h3 id="java的byte数组在内存层面不一定是连续的，C语言里面是连续的"><a href="#java的byte数组在内存层面不一定是连续的，C语言里面是连续的" class="headerlink" title="java的byte数组在内存层面不一定是连续的，C语言里面是连续的"></a>java的byte数组在内存层面不一定是连续的，C语言里面是连续的</h3><p>原因是GC会挪动内存</p><h2 id="nio的channel"><a href="#nio的channel" class="headerlink" title="nio的channel"></a>nio的channel</h2><p>在Java IO中，基本上可以分为文件类和Stream类两大类。Channel 也相应地分为了FileChannel 和 Socket Channel，其中 socket channel 又分为三大类，一个是用于监听端口的ServerSocketChannel，第二类是用于TCP通信的SocketChannel，第三类是用于UDP通信的DatagramChannel。channel 最主要的作用还是用于非阻塞式读写。可以使用Channel结合ByteBuffer进行读写。<br>一个简单的client server echo程序可以这样写</p><pre><code class="java">// serverpublic class WebServer {    public static void main(String args[]) {        try {            ServerSocketChannel ssc = ServerSocketChannel.open();            ssc.socket().bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000));            SocketChannel socketChannel = ssc.accept();            ByteBuffer readBuffer = ByteBuffer.allocate(128);            socketChannel.read(readBuffer);            readBuffer.flip();            while (readBuffer.hasRemaining()) {                System.out.println((char)readBuffer.get());            }            socketChannel.close();            ssc.close();        }        catch (IOException e) {            e.printStackTrace();        }    }}// clientpublic class WebClient {    public static void main(String[] args) {        SocketChannel socketChannel = null;        try {            socketChannel = SocketChannel.open();            socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000));            ByteBuffer writeBuffer = ByteBuffer.allocate(128);            writeBuffer.put(&quot;hello world&quot;.getBytes());            writeBuffer.flip();            socketChannel.write(writeBuffer);            socketChannel.close();        } catch (IOException e) {        }    }}</code></pre><h3 id="MMAP-memory-mapped-file"><a href="#MMAP-memory-mapped-file" class="headerlink" title="MMAP(memory mapped file)"></a>MMAP(memory mapped file)</h3><p>将文件映射到内存空间的操作，懒得看原理的话，背下这段话就够了</p><blockquote><p><strong>常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高</strong></p></blockquote><p>实际上,mmap系统调用并不是完全为了用于共享内存而设计的.它本身提供了不同于一般对普通文件的访问方式,是进程可以像读写内存一样对普通文件操作.而Posix或System V的共享内存则是纯粹用于共享内存的,当然mmap实现共享内存也是主要应用之一.<br>mmap函数是unix/linux下的系统调用，mmap系统调用并不是完全为了用于共享内存而设计的,mmap实现共享内存也是其主要作用之一，事实上可以实现两个java进程之间的通信。</p><p>A进程</p><pre><code class="java">public class Main {    public static void main(String args[]){        RandomAccessFile f = null;        try {            f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;);            FileChannel fc = f.getChannel();            MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, 20);            buf.put(&quot;how are you?&quot;.getBytes());            Thread.sleep(10000);            fc.close();            f.close();        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p>B进程</p><pre><code class="java">public class MapMemoryBuffer {    public static void main(String[] args) throws Exception {        RandomAccessFile f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;);        FileChannel fc = f.getChannel();        MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size());        while (buf.hasRemaining()) {            System.out.print((char)buf.get());        }        System.out.println();    }}</code></pre><p>很多java方法本质上就是jni进行了系统调用。<br>在sun.nio.ch.FileChannelImpl里有map的具体实现：</p><pre><code class="java">try {            // If no exception was thrown from map0, the address is valid            addr = map0(imode, mapPosition, mapSize);        } catch (OutOfMemoryError x) {private native long map0(int prot, long position, long length)</code></pre><p>比如Java的这个map0函数，具体的实现在<br>solaris/native/sun/nio/ch/FileChannelImpl.c这个文件里</p><pre><code class="c">JNIEXPORT jlong JNICALLJava_sun_nio_ch_FileChannelImpl_map0(JNIEnv *env, jobject this,                                     jint prot, jlong off, jlong len){    void *mapAddress = 0;    jobject fdo = (*env)-&gt;GetObjectField(env, this, chan_fd);    jint fd = fdval(env, fdo);    int protections = 0;    int flags = 0;    if (prot == sun_nio_ch_FileChannelImpl_MAP_RO) {        protections = PROT_READ;        flags = MAP_SHARED;    } else if (prot == sun_nio_ch_FileChannelImpl_MAP_RW) {        protections = PROT_WRITE | PROT_READ;        flags = MAP_SHARED;    } else if (prot == sun_nio_ch_FileChannelImpl_MAP_PV) {        protections =  PROT_WRITE | PROT_READ;        flags = MAP_PRIVATE;    }    mapAddress = mmap64(        0,                    /* Let OS decide location */        len,                  /* Number of bytes to map */        protections,          /* File permissions */        flags,                /* Changes are shared */        fd,                   /* File descriptor of mapped file */        off);                 /* Offset into file */    if (mapAddress == MAP_FAILED) {        if (errno == ENOMEM) {            JNU_ThrowOutOfMemoryError(env, &quot;Map failed&quot;);            return IOS_THROWN;        }        return handle(env, -1, &quot;Map failed&quot;);    }    return ((jlong) (unsigned long) mapAddress);}</code></pre><p>其实就是通过jni调用了c语言api.</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>netty的作者在演讲中提到java官方的nio并不特别好，所以，生产环境用的都是netty这种。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/23488863">美团团队出的关于nio的解说</a><br>这里面有一句原话摘抄下来：</p><blockquote><p>线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。像Java的线程栈，一般至少分配512K～1M的空间，</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于java nio的一些点&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/UmbriaCastelluccio_EN-AU8834990889_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>tcp-proxy简单实现及socks协议相关</title>
    <link href="https://haldir65.github.io/2018/12/31/2018-12-31-tcp-proxy-and-socks-server-related/"/>
    <id>https://haldir65.github.io/2018/12/31/2018-12-31-tcp-proxy-and-socks-server-related/</id>
    <published>2018-12-31T18:45:38.000Z</published>
    <updated>2019-03-13T02:30:25.330Z</updated>
    
    <content type="html"><![CDATA[<p>python实现简易的tcp-proxy server及socks代理学习笔记</p><p><img src="https://www.haldir66.ga/static/imgs/MountainDayJapan_EN-AU8690491173_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>首先是基本的流程<br>本地起一个tcp代理，监听0.0.0.0的1090端口,接收到任何数据之后原封不动发送到远程服务器。接着本机或者局域网内其他机器使用telnet往这个1090端口发数据。这样的proxy其实也就是实质上的一个tcp跳板机。</p><h2 id="先介绍一下telnet的使用教程"><a href="#先介绍一下telnet的使用教程" class="headerlink" title="先介绍一下telnet的使用教程"></a>先介绍一下telnet的使用教程</h2><p>在windows上telnet好像默认关闭了。在mac上：</p><blockquote><p>telnet 127.0.0.1 1090 // 这句话类似于连接到这个port，但是还没有发送数据。接下来可以发送数据</p></blockquote><p>在mac上ctrl+]是进入命令模式，可以输入一些比较好玩的命令:<br>比如help，比如quit。<br>send ayt //原封不动发送are you there 这几个字符<br>send ? //查看可以使用send发送哪些指令，其实就是发送字符<br>telnet的输出按删除键是不会清除的，输入cls就可以了。</p><p>另外,telnet是明文发送的，ssh会加密一下<br>Telnet data is sent in clear text. It’s certainly a good idea to use SSH to access network devices especially when going through a public network like Internet. As you are probably aware SSH would encrypt all data between the client/server and even if someone gets a hand on the data it’s of no use.</p><h3 id="然后就是如何实现这个本地代理了"><a href="#然后就是如何实现这个本地代理了" class="headerlink" title="然后就是如何实现这个本地代理了"></a>然后就是如何实现这个本地代理了</h3><ol><li>本地先绑定一个socket在1090端口</li><li>1090端口每次接收到一个新的sock连接，起一个新的线程，去处理和这个新的client的一次会话</li><li>在这个会话里面，同时启动两个线程（一个从local client读数据，然后发给remote server；另一个从remote server读取数据，发给local client）</li><li>这里面每个会话的remote server都是一个一个固定的ip:port，但是local client的port是变来变去的</li></ol><p>看看第三步，其实就是一个往返，所以顺序掉个头就行了，而且彼此互相不干扰（在只有一个会话的时候，remote.recv可以认为就是对当前client.send的回应）<br>这个往返用代码描述一下就是:</p><pre><code class="python">def sock_proxy(remote, local):    local_request = local.recv(4096) ## 如果local和remote对调一下，这里就是从remote读数据    ## ....    remote.sendAll(local_request.encode()) ## 这里就是 GET / HTTP1.1 ...这种字符串，如果local和remote对调一下，就是发数据给local client</code></pre><p>省略了一些try except和socket.close的代码。上面写了4096，是说最大接收数据量是4096字节，不是一次读取4096个字节的意思。下面是python中这几个函数的定义</p><pre><code>s.recv(bufsize[,flag])接受TCP套接字的数据。数据以字符串形式返回，bufsize指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。s.send(string[,flag])发送TCP数据。将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。s.sendall(string[,flag])完整发送TCP数据。将string中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回None，失败则抛出异常。</code></pre><p>具体用什么语言来实现，其实都没什么大的差别了。用Python好在跨平台，代码量少。</p><ul><li>使用方式<blockquote><p>python tcp_proxy -l 0.0.0.0:1090 -r zhihu.com:80 -v //代码是在别人的基础上改的，直接用别人的argument parser了</p></blockquote></li></ul><p>意思就是在本地监听1090端口，任何发到本地1090端口的包都会被发到zhihu.com这个host的80端口(测试了下，知乎返回的response是正常的)</p><p>本地另外起一个telnet</p><blockquote><p>telnet 127.0.0.1 1090<br>GET / HTTP 1.1 \r\n\r\n //事实上在telnet里面输入换行符有点困难，因为按下回车的时候会顺带在后面加上换行符<br>…然后这里就会出现远程服务器的回应。</p></blockquote><p>因为直接从client的报文中提取请求信息其实挺没意思的，所以暂时在python代码里写死了发送给远程的content</p><p>发现curl原来可以直接往任意host:port发送http格式的请求</p><blockquote><p>curl localhost:1090</p></blockquote><p>在proxy一侧收到的请求报文：</p><pre><code>GET / HTTP/1.1Host: localhost:1090User-Agent: curl/7.54.0Accept: */*</code></pre><p>最后是有俩换行的</p><p>用nc(netcat)也能往1090端口发数据</p><blockquote><p>nc 127.0.0.1 1090<br>GET / HTTP 1.1 \r\n\r\n 这个可以直接打换行，更方便</p></blockquote><h3 id="接下来就是看如何处理多个client的session-sock5协议实现"><a href="#接下来就是看如何处理多个client的session-sock5协议实现" class="headerlink" title="接下来就是看如何处理多个client的session(sock5协议实现)"></a>接下来就是看如何处理多个client的session(sock5协议实现)</h3><p>以上实现的只是一个tcp proxy，就是完全不检查通信内容的代理，是直接站在tcp层的。<br>现实中还有http proxy,sock proxy，彼此之间有一些差别。</p><p>多个client或者一个client的多个port同时走这个代理去访问远程时，代理服务器不可避免要记录下client和sever之间的连线，适当的还要在packet里面塞一些标记。业内成熟的方案当然是sock5协议,对应的标准是RFC 1928和RFC 1929。</p><p>从wiki上来看sock5是在sock4版本的基础上加了鉴定、IPv6、UDP支持。</p><blockquote><p>SOCKS工作在比HTTP代理更低的层次：SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如FTP；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，CONNECT方法允许转发TCP连接；然而，SOCKS代理还可以转发UDP流量和反向代理，而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法）。</p></blockquote><p>sock5_protocol协议包括:<br>协议<br>协商<br>客户端首先向SOCKS服务器自己的协议版本号，以及支持的认证方法。SOCKS服务器向客户端返回协议版本号以及选定的认证方法。</p><p>认证<br>客户端根据服务器端选定的方法进行认证，如果选定的方法是02,则根据RFC 1929定义的方法进行认证。RFC 1929定义的密码是明文传输，安全性较差。</p><p>请求<br>一旦指定认证方法的协商过程完成, 客户端发送详细的请求信息。经常使用 SOCKS 代理服务器的同志们会发现一种现象，即使 SOCKS 代理服务器设置正确，某些网站仍然无法访问,一般来说就是DNS污染造成的。SOCKS 5是通过将域名直接提交给 SOCKS 服务器来进行远端 DNS 解析的，即 Address Type 0x03。 DNS 服务是 Internet 的基础服务，要求 DNS 解析应当尽量地快，所以浏览器默认不会使用远端 DNS 解析。在Chrome的SwitchySharp 和Firefox里面的FoxyProxy可以支持远端DNS解析，可以避开DNS污染问题。</p><p>sock5协议其实在命令行里就能用上:</p><blockquote><p>curl –sock5 127.0.0.1:1080 <a href="http://www.google.com">http://www.google.com</a></p></blockquote><p>整体的流程:</p><blockquote><p>客户端向服务器发送协议版本号及支持认证方式(在proxy server这边会收到几个字节的bind请求<br>05 01 00 xxxx)<br>服务器回应版本号及选定认证方式<br>客户端发送Connect请求<br>服务器对Connect的响应<br>客户端发送被代理的数据<br>服务器响应被代理的数据</p></blockquote><h3 id="所以最终实现的效果是实现使用代理访问知乎"><a href="#所以最终实现的效果是实现使用代理访问知乎" class="headerlink" title="所以最终实现的效果是实现使用代理访问知乎"></a>所以最终实现的效果是实现使用代理访问知乎</h3><p>因为走的是明文，这样的代理只是具有学习的性质。更多的需要参考shadowsocks的实现(tcp proxy,支持udp)。<br>另外，业内比较出名的tcp proxy有nginx，enovy以及<a href="https://github.com/google/tcpproxy">golang tcp proxy</a>的实现。</p><h2 id="udp-proxy的实现"><a href="#udp-proxy的实现" class="headerlink" title="udp proxy的实现"></a>udp proxy的实现</h2><p><a href="https://github.com/EtiennePerot/misc-scripts/blob/master/udp-relay.py">非常短的一个脚本</a></p><pre><code class="python">#!/usr/bin/env python# Super simple script that listens to a local UDP port and relays all packets to an arbitrary remote host.# Packets that the host sends back will also be relayed to the local UDP client.# Works with Python 2 and 3import sys, socketdef fail(reason):    sys.stderr.write(reason + &#39;\n&#39;)    sys.exit(1)if len(sys.argv) != 2 or len(sys.argv[1].split(&#39;:&#39;)) != 3:    fail(&#39;Usage: udp-relay.py localPort:remoteHost:remotePort&#39;)localPort, remoteHost, remotePort = sys.argv[1].split(&#39;:&#39;)try:    localPort = int(localPort)except:    fail(&#39;Invalid port number: &#39; + str(localPort))try:    remotePort = int(remotePort)except:    fail(&#39;Invalid port number: &#39; + str(remotePort))try:    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)    s.bind((&#39;&#39;, localPort))except:    fail(&#39;Failed to bind on port &#39; + str(localPort))knownClient = NoneknownServer = (remoteHost, remotePort)sys.stderr.write(&#39;All set.\n&#39;)while True:    data, addr = s.recvfrom(32768)    if knownClient is None:        knownClient = addr    if addr == knownClient:        s.sendto(data, knownServer)    else:        s.sendto(data, knownClient)</code></pre><h3 id="raw-socket-原始套接字"><a href="#raw-socket-原始套接字" class="headerlink" title="raw socket(原始套接字)"></a>raw socket(原始套接字)</h3><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>server端监听在一个端口，client端发送数据的端口变来变去。数据量大的时候单线程阻塞式的server还是会有性能问题。python中可以使用selectors模块，在server端，每次socket.accept()之后，就register一个fileno for read and write event。<br><a href="https://github.com/linhua55/some_kcptun_tools/blob/master/udpRelay/udpRelayServer.py">参考udpRelayServer</a><br>每次selector.select(这个函数是blocking的)，从端口上来看，client这边可以开多个port发数据给proxy， proxy这边只用一个port接受，对外部网络世界多个ip，开多个port。所以proxy内部应该维护一个external port &lt;======&gt; client port 的映射。<br>开始select之后，首先是select出来一个readable的client socket(port) ，读取信息，存储到一个{ clientport , [clientmessageOutList] } 的字典里。 然后根据clientmessage中暗示的remote ip和port去register一个socket， register的时候是可以带上一些自定义数据的，这里放上clientport. 当这个register的回调开始时，如果是可写，那么把刚才字典里的信息拿出来，del掉。 如果是可读，那么说明发出去的东西有回信了，这时候去自定义数据里面的port，存到一个{clientport, [messageToBeDelivedBackList] } 的字典里。在select本地port的时候，如果扫到一个writabel的client socket port，就根据这个port num 去字典里获取messageToBeDelivedBack，发送回去。到此结束一个流程。<br>任何时间段，proxy这边维持了两个字典，一头是面向client的，port =&gt; [要发送的msg1,要发送的msg2,…] , 一头是面向多个remote ip port组合的的。存储了 clientport =&gt; [要回复给client的msg1 ,要回复给client的msg2] .<br>面向client只需要做一个selector操作，面向outside需要做多个selector操作（一个外部网站一般一个就够了）。不停的轮询。但实际上只需要一个selector就行了。</p><pre><code class="python">try:    while True:        events = sel.select(timeout=1)        if events:            for key, mask in events:                service_connection(key, mask) ## key.fileobj是socket, key,data是register的时候自定义的数据</code></pre><p><a href="https://blessing.studio/why-do-shadowsocks-deprecate-ota/">ss的tcp包结构</a><br>主动探测方法<br><a href="https://loggerhead.me/posts/shadowsocks-yuan-ma-fen-xi-xie-yi-yu-jie-gou.html">协议与结构</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://ichuan.net/post/22/tcp-proxy-and-tcp-hub-in-python/">python小工具：tcp proxy和tcp hub</a><br><a href="https://rushter.com/blog/python-socks-server/">Writing a simple SOCKS server in Python</a><br><a href="https://geesun.github.io/posts/2015/09/socks5_protocol.html">SOCKS 5协议简析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;python实现简易的tcp-proxy server及socks代理学习笔记&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/MountainDayJapan_EN-AU8690491173_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="https://haldir65.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>bytecode基本解读</title>
    <link href="https://haldir65.github.io/2018/12/12/2018-12-12-sinking-your-teeth-into-ByteCode/"/>
    <id>https://haldir65.github.io/2018/12/12/2018-12-12-sinking-your-teeth-into-ByteCode/</id>
    <published>2018-12-12T11:11:02.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>python中可以使用diss module 轻易的查看byte code。那么在java中呢<br><img src="https://www.haldir66.ga/static/imgs/BadlandsBday_EN-AU10299777329_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>interpreting the talk from<br><a href="https://jakewharton.com/sinking-your-teeth-into-bytecode/">Sinking Your Teeth Into Bytecode</a></p><p>java 有一个关键字叫做goto，在java代码中好像不能用，但是其实在生成的bytecode里面有goto关键字(c语言也有)</p><p>javap -c someclas</p><p><a href="https://www.cnblogs.com/paddix/p/5326863.html">从反编译角度来看string常量池的问题</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.youtube.com/watch?v=lP4ED_dN16g">JVM bytecode engineering 101</a><br><a href="https://www.youtube.com/watch?v=rPyqB1l4gko">JVM Bytecode for Dummies (and the Rest of Us Too)</a><br><a href="https://coolshell.cn/articles/9229.html">实例分析JAVA CLASS的文件结构</a><br><a href="https://www.cnblogs.com/paddix/p/5282004.html">从字节码层面看“HelloWorld”</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;python中可以使用diss module 轻易的查看byte code。那么在java中呢&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/BadlandsBday_EN-AU10299777329_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>select、poll、epoll学习笔记</title>
    <link href="https://haldir65.github.io/2018/12/06/2018-12-06-select-poll-epoll/"/>
    <id>https://haldir65.github.io/2018/12/06/2018-12-06-select-poll-epoll/</id>
    <published>2018-12-06T08:38:54.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。<br><img src="https://www.haldir66.ga/static/imgs/OrionNebula_EN-AU10620917199_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>用户态到内核态的内存copy的开销</p><p>mac上叫做Kqueue<br><a href="https://www.zhihu.com/question/20122137">epoll或者Kqueue的原理是什么</a></p><p>在看<a href="https://realpython.com/python-sockets/">socket programming in python</a>这篇文章时发现有selector这样的操作。其实和c语言的做法很相似。</p><p><a href="https://www.jianshu.com/p/d2f4c35cb692">Windows IOCP与Linux的epoll机制对比</a><br>系统I/O模型 可分为三类：<br>第一种： 阻塞型(blocking model)，<br>应用进程发起connect请求，进入系统内核方法调用。内核负责发送SYN,等待ACK,等到ACK、SYNC到达以后，发送ACK，连接完成，return用户态的connect调用。以上过程中，应用层一直阻塞。</p><p>第二种： 非阻塞同步型(non-blocking model): “wait until any socket is available to read or write from/to buffer, then call non blocking socket function which returns immediately.”<br>可以通过设置SOCK_NONBLOCK标记创建非阻塞的socket fd，或者用fcntl也是一样的。<br>比方说c语言在linux环境下可以这么写。</p><pre><code class="c"> // client side   int socketfd = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0);   // server side - see man page for accept4 under linux    int socketfd = accept4( ... , SOCK_NONBLOCK);</code></pre><p>对非阻塞fd调用系统接口时，不需要等待事件发生而立即返回，事件没有发生，接口返回-1，此时需要通过errno的值来区分是否出错，有过网络编程的经验的应该都了解这点。不同的接口，立即返回时的errno值不尽相同，如，recv、send、accept errno通常被设置为EAGIN 或者EWOULDBLOCK，connect 则为EINPRO- GRESS 。<br>就是说，客户端程序会不停地去尝试读取数据，但是不会阻塞在那个读方法里，如果读的时候，没有读到内容，也会立即返回。这就允许我们在客户端里，读到不数据的时候可以搞点其他的事情了。</p><p>第三种： 非阻塞异步型(asynchronous aka. overlapping model): “call a socket function which returns immediately, then wait for its completion, then access the result data object”<br>IO多路复用，I/O复用(I/O multiplexing). IO多路复用是nio的核心和关键，也是实现高性能服务器的关键。<br>应用进程通过调用epoll_wait阻塞等待可读事件，等可读事件触发时，系统会回调注册的函数。</p><p>另外还有信号，async io</p><p>IOCP基于非阻塞异步模型，而epoll基于非阻塞同步模型。</p><p><a href="https://www.slideshare.net/sm9kr/iocp-vs-epoll-perfor">Windows IOCP vs Linux EPOLL Performance Comparison</a><br><a href="https://www.cnblogs.com/Anker/p/3263780.html">IO多路复用之epoll总结</a><br><a href="https://segmentfault.com/a/1190000003063859">Linux IO模式及 select、poll、epoll详解</a><br><a href="https://my.oschina.net/hosee/blog/730598">epoll浅析以及nio中的Selector</a><br><a href="https://cloud.tencent.com/developer/article/1005481">大话 Select、Poll、Epoll</a><br><a href="https://news.ycombinator.com/item?id=8526264">There is no Windows equivalent to epoll/kqueue , but there is Overlapped IO</a> 简单说就是windows在这方面设计的更优秀，只是开发者并未买账<br><a href="https://www.youtube.com/watch?v=M5-mcKh8QmY">Coroutines, Async/Await, Asyncio and the Pulsar Library</a> node, go goroutine, nginx, gui libraries ,java nio等都以各种形式采用了或实现了自己的event loop</p><p><a href="https://void-shana.moe/linux/io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-select-%E5%92%8C-poll.html">IO 多路复用 — SELECT 和 POLL</a></p><p><a href="https://www.zhihu.com/question/26943558">linux kernel aio是另一个内核提供的异步框架，但是不如epoll成熟</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/OrionNebula_EN-AU10620917199_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>tcp和udp包结构分析</title>
    <link href="https://haldir65.github.io/2018/12/03/2018-12-03-packet-structure-of-tcp-and-udp/"/>
    <id>https://haldir65.github.io/2018/12/03/2018-12-03-packet-structure-of-tcp-and-udp/</id>
    <published>2018-12-03T13:42:25.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>本文只针对ipv4网络进行分析<br><img src="https://www.haldir66.ga/static/imgs/AlanTuringNotebook_EN-AU7743633207_1920x1080.jpg" alt=""><br><a id="more"></a></p><blockquote><p>多数内容来自<a href="https://jerryc8080.gitbooks.io/understand-tcp-and-udp/chapter2.html">TCP 报文结构</a><br>同一台机器上的两个进程，可以通过管道，共享内存，信号量，消息队列等方式进行通信。通信的一个基本前提是每个进程都有唯一的标识，在同一台机器上，使用pid就可以了。两台不同的计算机之间通信，可以使用<strong>ip地址 + 协议 +协议端口号</strong> 来标识网络中的唯一进程。</p></blockquote><h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><p>tcp用16位端口号来标识一个端口，也就是两个bytes(65536就这么来的)。</p><p>以下图片盗自<a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">chinaunix一篇讲解raw socket的文章</a></p><ul><li><h3 id="这是IP-packet"><a href="#这是IP-packet" class="headerlink" title="这是IP packet"></a>这是IP packet</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-1.jpg" alt=""></p></li><li><h3 id="这是TCP-header"><a href="#这是TCP-header" class="headerlink" title="这是TCP header"></a>这是TCP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-2.jpg" alt=""></p></li><li><h3 id="这是IP-header"><a href="#这是IP-header" class="headerlink" title="这是IP header"></a>这是IP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-3.jpg" alt=""></p></li><li><h3 id="这是mac-header"><a href="#这是mac-header" class="headerlink" title="这是mac header"></a>这是mac header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-4.jpg" alt=""></p></li></ul><p>什么是报文？<br>例如一个 100kb 的 HTML 文档需要传送到另外一台计算机，并不会整个文档直接传送过去，可能会切割成几个部分，比如四个分别为 25kb 的数据段。<br>而每个数据段再加上一个 TCP 首部，就组成了 TCP 报文。<br>一共四个 TCP 报文，发送到另外一个端。<br>另外一端收到数据包，然后再剔除 TCP 首部，组装起来。<br>等到四个数据包都收到了，就能还原出来一个完整的 HTML 文档了。<br>在 OSI 的七层协议中，第二层（数据链路层）的数据叫「Frame」，第三层（网络层）上的数据叫「Packet」，第四层（传输层）的数据叫「Segment」。<br>TCP 报文 (Segment)，包括首部和数据部分。</p><p>TCP 报文段首部的前20个字节是固定的，后面有 4N 字节是根据需要而增加的。<br>TCP 的首部包括以下内容：</p><ul><li>源端口 source port</li><li>目的端口 destination port</li><li>序号 sequence number</li><li>确认号 acknowledgment number</li><li>数据偏移 offset</li><li>保留 reserved</li><li>标志位 tcp flags</li><li>窗口大小 window size</li><li>检验和 checksum</li><li>紧急指针 urgent pointer</li><li>选项 tcp options</li></ul><h3 id="连接建立过程"><a href="#连接建立过程" class="headerlink" title="连接建立过程"></a>连接建立过程</h3><p>TCP 连接的建立采用客户服务器方式，主动发起连接建立的一方叫客户端（Client），被动等待连接建立的一方叫服务器（Server）。<br>最初的时候，两端都处于 CLOSED 的状态，然后服务器打开了 TCP 服务，进入 LISTEN 状态，监听特定端口，等待客户端的 TCP 请求。<br>第一次握手： 客户端主动打开连接，发送 TCP 报文，进行第一次握手，然后进入 SYN_SEND 状态，等待服务器发回确认报文。<br>这时首部的同步位 SYN = 1，同时初始化一个序号 Sequence Number = J。<br>TCP 规定，SYN 报文段不能携带数据，但会消耗一个序号。<br>第二次握手： 服务器收到了 SYN 报文，如果同意建立连接，则向客户端发送一个确认报文，然后服务器进入 SYN_RCVD 状态。<br>这时首部的 SYN = 1，ACK = 1，而确认号 Acknowledgement Number = J + 1，同时也为自己初始化一个序号 Sequence Number = K。<br>这个报文同样不携带数据。<br>第三次握手：<br>客户端收到了服务器发过来的确认报文，还要向服务器给出确认，然后进入 ESTABLISHED 状态。<br>这时首部的 SYN 不再置为 1，而 ACK = 1，确认号 Acknowledgement Number = K + 1，序号 Sequence Number = J + 1。<br>第三次握手，一般会携带真正需要传输的数据，当服务器收到该数据报文的时候，就会同样进入 ESTABLISHED 状态。 此时，TCP 连接已经建立。<br>对于建立连接的三次握手，主要目的是初始化序号 Sequence Number，并且通信的双方都需要告知对方自己的初始化序号，所以这个过程也叫 SYN。<br>这个序号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输问题而乱序，因为TCP 会用这个序号来拼接数据。</p><h3 id="TCP-Flood-攻击"><a href="#TCP-Flood-攻击" class="headerlink" title="TCP Flood 攻击"></a>TCP Flood 攻击</h3><p>知道了 TCP 建立一个连接，需要进行三次握手。<br>但如果你开始思考「三次握手的必要性」的时候，就会知道，其实网络是很复杂的，一个信息在途中丢失的可能性是有的。<br>如果数据丢失了，那么，就需要重新发送，这时候就要知道数据是否真的送达了。<br>这就是三次握手的必要性。<br>但是再向深一层思考，你给我发信息，我收到了，我回复，因为我是君子。<br>如果是小人，你给我发信息，我就算收到了，我也不回复，你就一直等我着我的回复。<br>那么很多小人都这样做，你就要一直记住你在等待着小人1号、小人2号、小人3号……直到你的脑容量爆棚，烧坏脑袋。<br>黑客就是利用这样的设计缺陷，实施 TCP Flood 攻击，属于 DDOS 攻击的一种。</p><p><a href="https://halfrost.com/advance_tcp/">TCP进阶</a></p><h3 id="四次挥手，释放连接"><a href="#四次挥手，释放连接" class="headerlink" title="四次挥手，释放连接"></a>四次挥手，释放连接</h3><p>TCP 有一个特别的概念叫做半关闭，这个概念是说，TCP 的连接是全双工（可以同时发送和接收）的连接，因此在关闭连接的时候，必须关闭传送和接收两个方向上的连接。<br>客户端给服务器发送一个携带 FIN 的 TCP 结束报文段，然后服务器返回给客户端一个 确认报文段，同时发送一个 结束报文段，当客户端回复一个 确认报文段 之后，连接就结束了。<br>释放连接过程<br>在结束之前，通信双方都是处于 ESTABLISHED 状态，然后其中一方主动断开连接。<br>下面假如客户端先主动断开连接。<br>第一次挥手：<br>客户端向服务器发送结束报文段，然后进入 FIN_WAIT_1 状态。<br>此报文段 FIN = 1， Sequence Number = M。<br>第二次挥手：<br>服务端收到客户端的结束报文段，然后发送确认报文段，进入 CLOSE_WAIT 状态(通常来说，一个 CLOSE_WAIT 会维持至少 2 个小时的时间)。<br>此报文段 ACK = 1， Sequence Number = M + 1。<br>客户端收到该报文，会进入 FIN_WAIT_2 状态。<br>第三次挥手：<br>同时服务端向客户端发送结束报文段，然后进入 LAST_ACK 状态。<br>此报文段 FIN = 1，Sequence Number = N。<br>第四次挥手：<br>客户端收到服务端的结束报文段，然后发送确认报文段，进入 TIME_WAIT 状态，经过 2MSL 之后，自动进入 CLOSED 状态。<br>此报文段 ACK = 1, Sequence Number = N + 1。<br>服务端收到该报文之后，进入 CLOSED 状态。<br>关于 TIME_WAIT 过渡到 CLOSED 状态说明：<br>从 TIME_WAIT 进入 CLOSED 需要经过 2MSL，其中 MSL 就叫做 最长报文段寿命（Maxinum Segment Lifetime），根据 RFC 793 建议该值这是为 2 分钟，也就是说需要经过 4 分钟，才进入 CLOSED 状态。</p><h3 id="这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些"><a href="#这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些" class="headerlink" title="这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些"></a>这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些</h3><p>下面从<a href="https://www.infoq.cn/article/2018%2F03%2Fweibo-quic">QUIC 在微博中的落地思考</a>文中摘抄一部分批判tcp</p><blockquote><p>TCP 协议在建立连接时，需要经历较为漫长的三次握手行为，而在关闭时，也有稍显冗余的 4 次摆手。而 HTTPS 初始连接需要至少 2 个 RTT 交互（添加了握手缓存就会变成了 1-RTT，这里指的是 TLS 1.2），外加 TCP 自身握手流程，最少需要 3 次 RTT 往返，才能够完整建立连接。而 QUIC 协议层面界定了 1-2 个 RTT 握手流程，再次连接为 0-RTT 握手优化流程（但需要添加握手缓存）</p></blockquote><p>关于tcp read/write buffer，shadowsocks的参数优化提到了一些东西 </p><pre><code># max open filesfs.file-max = 1024000# max read buffernet.core.rmem_max = 67108864# max write buffernet.core.wmem_max = 67108864# default read buffernet.core.rmem_default = 65536# default write buffernet.core.wmem_default = 65536# max processor input queuenet.core.netdev_max_backlog = 4096# max backlognet.core.somaxconn = 4096# resist SYN flood attacksnet.ipv4.tcp_syncookies = 1# reuse timewait sockets when safenet.ipv4.tcp_tw_reuse = 1# turn off fast timewait sockets recyclingnet.ipv4.tcp_tw_recycle = 0# short FIN timeoutnet.ipv4.tcp_fin_timeout = 30# short keepalive timenet.ipv4.tcp_keepalive_time = 1200# outbound port rangenet.ipv4.ip_local_port_range = 10000 65000# max SYN backlognet.ipv4.tcp_max_syn_backlog = 4096# max timewait sockets held by system simultaneouslynet.ipv4.tcp_max_tw_buckets = 5000# TCP receive buffernet.ipv4.tcp_rmem = 4096 87380 67108864# TCP write buffernet.ipv4.tcp_wmem = 4096 65536 67108864# turn on path MTU discoverynet.ipv4.tcp_mtu_probing = 1# for high-latency networknet.ipv4.tcp_congestion_control = hybla# forward ipv4net.ipv4.ip_forward = 1</code></pre><p><a href="https://www.cyberciti.biz/files/linux-kernel/Documentation/networking/ip-sysctl.txt">内核文档对于这些参数的定义</a><br>注意，这些参数修改了会影响所有的进程，修改还是慎重一些</p><h3 id="tcp-buffer"><a href="#tcp-buffer" class="headerlink" title="tcp buffer"></a>tcp buffer</h3><p>关键字： tcp read buffer and write buffer<br>这里要分congestion window（发送方的window，对应congestion control）和receive window(接收方的window，对应flow control)<br>receive window</p><blockquote><p>Your Network Interface Card (NIC) is performing all of the necessary tasks of collecting packets and waiting for your OS to read them. Ultimately, when you do a stream read you’re pulling from the memory that your OS has reserved and constantly stores the incoming information copy into.<br>To answer your question, yes. You are definitely doing a copy. A copy of a copy, the bits are read into a buffer within your NIC, your OS puts them somewhere, and you copy them when you do a stream read.</p></blockquote><p>用wireshark抓包的话，在tcp header里面有个”window size value”，比方说这个数是2000，也就是发来这个包的一方告诉当前接受方，你下一次最多再发2000byte的数据过来，再多就装不下了。如果接收方处理速度跟不上，buffer慢慢填满，就会在ack包里调低window size，告诉对方发慢一点。<br>client处理速度够快的时候是这样的<br><img src="https://www.haldir66.ga/static/imgs/TCP-window-syn.png" alt=""></p><p>如果不够快的话,这时候就是client在ack包里告诉server自己跟不上了<br><img src="https://www.haldir66.ga/static/imgs/TCP-window-http.png" alt=""></p><h2 id="TCP-Window-Scaling"><a href="#TCP-Window-Scaling" class="headerlink" title="TCP Window Scaling"></a>TCP Window Scaling</h2><p>注意，window size是在ack包里的,另外,tcp header里面为这个window size准备的空间是2 bytes（65536 bytes,所以一个包最大也就65K?）。这样对于那些大带宽高延迟的连接来说是不利的。事实当然没这么简单，<a href="https://www.ietf.org/rfc/rfc1323.txt">RFC 1323</a> enable the TCP receive window to be increased exponentially(指数增长)。这个功能是在握手的时候互相商定了一个增长的倍数(在tcp握手的header里面有一个window size scaling factor,比如下图这样的，一次乘以4)<br><img src="https://www.haldir66.ga/static/imgs/Transmission-control-protocol-window-scaling.png" alt=""></p><blockquote><p>In the image above, the sender of this packet is advertising a TCP Window of 63,792 bytes and is using a scaling factor of four. This means that that the true window size is 63,792 x 4 (255,168 bytes). Using scaling windows allows endpoints to advertise a window size of over 1GB. To use window scaling, both sides of the connection must advertise this capability in the handshake process. If one side or the other cannot support scaling, then neither will use this function. The scale factor, or multiplier, will only be sent in the SYN packets during the handshake and will be used for the life of the connection. This is one reason why it is so important to capture the handshake process when performing TCP analysis.</p></blockquote><p>就是说4这个数只会出现在握手的syn包中，并且只有在双方都能支持scaling的前提下才会用，而且这个4将会在这条连接的生命周期中一直是这个数，所以要分析的话，逮这个syn包去抓。</p><h3 id="TCP-Zero-window"><a href="#TCP-Zero-window" class="headerlink" title="TCP Zero window"></a>TCP Zero window</h3><p><img src="https://www.haldir66.ga/static/imgs/TCP-Zero-Window-Performance-Vision.png" alt=""><br>意思就是说，这个window size变成0了。通常不会出现这种情况，一般是接收方的进程出问题了，这时候server会等着，随着client的应用层开始处理数据，client会慢慢发TCP Keep-Alive包，带上新的window size，告诉server说，自己正在处理数据，快了快了。</p><blockquote><p>The throughput of a communication is limited by two windows: the congestion window and the receive window. The congestion window tries not to exceed the capacity of the network (congestion control); the receive window tries not to exceed the capacity of the receiver to process data (flow control). The receiver may be overwhelmed by data if for example it is very busy (such as a Web server). Each TCP segment contains the current value of the receive window. If, for example, a sender receives an ack which acknowledges byte 4000 and specifies a receive window of 10000 (bytes), the sender will not send packets after byte 14000, even if the congestion window allows it.<br>总的来说，tcp传输的速度是由congestion window and the receive window控制的，前者控制发送方的发送速度，后者限制接收方的接收速度。</p></blockquote><h3 id="可靠性交付的实现到这里也就清楚了"><a href="#可靠性交付的实现到这里也就清楚了" class="headerlink" title="可靠性交付的实现到这里也就清楚了"></a>可靠性交付的实现到这里也就清楚了</h3><p>滑动窗口(sliding window)<br>超时重传<br>流量控制 (flow control)<br>拥塞控制（congestion control）</p><h2 id="一个tcp-udp或者ip包最大多大，最小多大"><a href="#一个tcp-udp或者ip包最大多大，最小多大" class="headerlink" title="一个tcp,udp或者ip包最大多大，最小多大"></a>一个tcp,udp或者ip包最大多大，最小多大</h2><p>最小我们知道<br>传送TCP数据包的時候，TCP header 占 20 bytes， IPv4 header 占 20 bytes，所以最小40byte。<br>那么最大呢<a href="https://blog.csdn.net/caoshangpa/article/details/51530685">TCP、UDP数据包大小的限制</a><br>应用层udp最大1500-20-8 = 1472 字节(多了会被分片重组，万一分片丢失导致重组失败，就会被丢包)，1500是硬件决定的,20是ip头，8是udp的头<br>结论<br>UDP 包的大小就应该是 1500 - IP头(20) - UDP头(8) = 1472(Bytes)<br>TCP 包的大小就应该是 1500 - IP头(20) - TCP头(20) = 1460 (Bytes)<br>UDP数据报的长度是指包括报头和数据部分在内的总字节数，其中报头长度固定，数据部分可变。数据报的最大长度根据操作环境的不同而各异。从理论上说，包含报头在内的数据报的最大长度为65535字节(64K)。<br>用UDP协议发送时，用sendto函数最大能发送数据的长度为：65535- IP头(20) - UDP头(8)＝65507字节。用sendto函数发送数据时，如果发送数据长度大于该值，则函数会返回错误。<br>MTU 最大传输单元（英语：Maximum Transmission Unit，缩写MTU）是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位），怎么看</p><blockquote><p>ping -l 1472 -f www.baidu.com ##根据提示去调小这个数就是了，一般1350以上是有的</p></blockquote><p>从csdn搞来的图<br><img src="https://haldir66.ga/static/imgs/tcp_and_udp_size_limit.png" alt=""><br>传输层：<br>对于UDP协议来说，整个包的最大长度为65535，其中包头长度是65535-20=65515；<br>对于TCP协议来说，整个包的最大长度是由最大传输大小（MSS，Maxitum Segment Size）决定，MSS就是TCP数据包每次能够传<br>输的最大数据分段。为了达到最佳的传输效能TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替（需<br>要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以往往MSS为1460。通讯双方会根据双方提供的MSS值得最小值<br>确定为这次连接的最大MSS值。<br>IP层：<br>对于IP协议来说，IP包的大小由MTU决定（IP数据包长度就是MTU-28（包头长度）。 MTU值越大，封包就越大，理论上可增加传送速率，但<br>MTU值又不能设得太大，因为封包太大，传送时出现错误的机会大增。一般默认的设置，PPPoE连接的最高MTU值是1492, 而以太网<br>（Ethernet）的最高MTU值则是1500,而在Internet上，默认的MTU大小是576字节</p><h3 id="协议数据单元-Protocol-Data-Unit-PDU"><a href="#协议数据单元-Protocol-Data-Unit-PDU" class="headerlink" title="协议数据单元(Protocol Data Unit, PDU)"></a>协议数据单元(Protocol Data Unit, PDU)</h3><p>应用层数据在传输过程中沿着协议栈传递，每一层协议都会往其中添加信息，这就是封装的过程。在封装过程中，每一个阶段的PDU都有不同的名字来反映它的功能。</p><p>PDU按照TCP/IP协议的命名规范：<br>数据（Data）：应用层PDU的常用术语<br>分段（Segment）：传输层PDU<br>帧（Frame）：网络层PDU<br>比特（Bits）：在介质上物理传输数据所使用的PDU。</p><p>最终发出去的数据包应该是<br>Data link Ethernet Frame Header(Destination mac address + Source mac address) +<br>Network Layer IP Packet Header(Source network:host + Destination network: host) +<br>Transport Header(port) +<br>data</p><p>https版本的握手，证书校验，change cipher<br><img src="https://www.haldir66.ga/static/imgs/https_hand_shake.jpg" alt=""><br><a href="https://mp.weixin.qq.com/s/682cugg2niNfdg_eDYHdyw">出处</a><br>证书验证完毕之后，觉得这个服务端是可信的，于是客户端计算产生随机数字Pre-master，发送Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。<br>接下来，无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的Pre-Master随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。<br>有了对称密钥，客户端就可以说：“Change Cipher Spec，咱们以后都采用协商的通信密钥和加密算法进行加密通信了。”<br>然后客户端发送一个Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。<br>同样，服务器也可以发送Change Cipher Spec，说：“没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信了”，并且也发送Encrypted Handshake Message的消息试试。<br>当双方握手结束之后，就可以通过对称密钥进行加密传输了</p><p><img src="https://www.haldir66.ga/static/imgs/tcp_packet_structure.jpg" alt=""></p><p>下面这段摘自微信公众号”刘超的通俗云计算”</p><blockquote><p>出了NAT网关，就从核心网到达了互联网。在网络世界，每一个运营商的网络成为自治系统AS。每个自治系统都有边界路由器，通过它和外面的世界建立联系。<br>对于云平台来讲，它可以被称为Multihomed AS，有多个连接连到其他的AS，但是大多拒绝帮其他的AS传输包。例如一些大公司的网络。对于运营商来说，它可以被称为Transit AS，有多个连接连到其他的AS，并且可以帮助其他的AS传输包，比如主干网。<br>如何从出口的运营商到达云平台的边界路由器？在路由器之间需要通过BGP协议实现，BGP又分为两类，eBGP和iBGP。自治系统间，边界路由器之间使用eBGP广播路由。内部网络也需要访问其他的自治系统。<br>边界路由器如何将BGP学习到的路由导入到内部网络呢？通过运行iBGP，使内部的路由器能够找到到达外网目的地最好的边界路由器。<br>网站的SLB的公网IP地址早已经通过云平台的边界路由器，让全网都知道了。于是这个下单的网络包选择了下一跳是A2，也即将A2的MAC地址放在目标MAC地址中。<br>到达A2之后，从路由表中找到下一跳是路由器C1，于是将目标MAC换成C1的MAC地址。到达C1之后，找到下一跳是C2，将目标MAC地址设置为C2的MAC。到达C2后，找到下一跳是云平台的边界路由器，于是将目标MAC设置为边界路由器的MAC地址。<br><strong>你会发现，这一路，都是只换MAC，不换目标IP地址。这就是所谓下一跳的概念。</strong><br>在云平台的边界路由器，会将下单的包转发进来，经过核心交换，汇聚交换，到达外网网关节点上的SLB的公网IP地址。<br>我们可以看到，手机到SLB的公网IP，是一个端到端的连接，连接的过程发送了很多包。所有这些包，无论是TCP三次握手，还是HTTPS的密钥交换，都是要走如此复杂的过程到达SLB的，当然每个包走的路径不一定一致。</p></blockquote><h2 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h2><p>UDP的首部只有8个字节，12 字节的伪首部是为了计算检验和临时添加的。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://jerryc8080.gitbooks.io/understand-tcp-and-udp/">TCP 报文结构</a><br><a href="https://www.google.com/search?q=tcp%E5%8C%85%E7%BB%93%E6%9E%84">tcp包结构</a><br><a href="https://accedian.com/enterprises/blog/tcp-receive-window-everything-need-know/">推广商业软件的文章，当做关于tcp协议的一整个series来看还是很好的</a> </p><p>HTTP幂等性(用CAS)避免下单两次</p><p><a href="http://www.cnblogs.com/jiunadianshi/articles/2981068.html">TCP端口状态说明ESTABLISHED、TIME_WAIT</a>FIN_WAIT2</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文只针对ipv4网络进行分析&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/AlanTuringNotebook_EN-AU7743633207_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>page-size and block size</title>
    <link href="https://haldir65.github.io/2018/12/02/2018-12-02-page-size-and-block-size/"/>
    <id>https://haldir65.github.io/2018/12/02/2018-12-02-page-size-and-block-size/</id>
    <published>2018-12-02T21:42:24.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>page size（内存相关）和block size(文件系统相关)的一些点<br><img src="https://www.haldir66.ga/static/imgs/scenery1511100718415.jpg" alt=""><br><a id="more"></a><br>wiki上说<br>Page size常由processor的架构决定的，操作系统管理内存的最小单位是一个Page size(应用程序申请分配内存时，操作系统实际分配的内存是page-size的整数倍)</p><p><a href="http://forums.justlinux.com/showthread.php?3261-Block-size-vs-page-size">Block size vs. page size</a></p><blockquote><p> block size concerns storage space on a filesystem.<br>Page size is, I believe, architecture-dependent, 4k being the size for IA-32 (x86) machines. For IA-64 architecture, I’m pretty sure you can set the page size at compile time, with 8k or 16k considered optimal. Again, I’m not positive, but I think Linux supports 4,8,16, and 64k pages.<br>Block size is a function of the filesystem in use. Many, if not all filesystems allow you to choose the block size when you format, although for some filesystems the block size is tied to/dependent upon the page size.<br>Minimun block size is usually 512 bytes, the allowed values being determined by the filesystem in question.</p></blockquote><p>unix系统中查看系统的page size</p><blockquote><p>getconf PAGESIZE ## X86架构的cpu上一般是4096byte</p></blockquote><p>一个很有意思的现象是，java BufferedInputStream的默认buffer数组大小是8192，okio 的segment的默认size也是8192，这些都是以byte为单位的。找到一个合理的<a href="https://stackoverflow.com/questions/37404068/why-is-the-default-char-buffer-size-of-bufferedreader-8192">解释</a>。大致意思是8192 = 2^13, windows和linux上这个大小正好占用两个分页文件(8kB)。</p><h2 id="block-size-硬盘块"><a href="#block-size-硬盘块" class="headerlink" title="block size(硬盘块)"></a>block size(硬盘块)</h2><p>摘抄一段来自<a href="https://zhuanlan.zhihu.com/p/26077257">深入浅出腾讯云CDN：缓存篇</a>的话：</p><blockquote><p>不管SSD盘或者SATA盘都有最小的操作单位，可能是512B，4KB，8KB。如果读写过程中不进行对齐，底层的硬件或者驱动就需要替应用层来做对齐操作，并将一次读写操作分裂为多次读写操作。</p></blockquote><p><a href="https://www.zfl9.com/c-struct.html">什么是内存对齐，为什么要对齐？</a></p><p>现代计算机中内存空间都是按照 byte 划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定变量的时候经常在特定的内存地址访问，这就需要各类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。<br>对齐的作用和原因：各个硬件平台对存储空间的处理上有很大的不同。一些平台对某些特定类型的数据只能从某些特定地址开始存取。其他平台可能没有这种情况，但是最常见的是如果不按照适合其平台的要求对数据存放进行对齐，会在存取效率上带来损失。<br>比如有些平台每次读都是从偶地址开始，如果一个 int 型（假设为32位）如果存放在偶地址开始的地方，那么一个读周期就可以读出，而如果存放在奇地址开始的地方，就可能会需要 2 个读周期，并对两次读出的结果的高低字节进行拼凑才能得到该 int 数据。显然在读取效率上下降很多，这也是空间和时间的博弈。<br>“内存对齐”应该是编译器的“管辖范围”。<br>编译器为程序中的每个“数据单元”安排在适当的位置上。<br><strong>但是C语言的一个特点就是太灵活，太强大，它允许你干预“内存对齐”</strong></p><p>对齐规则(内存相关)<br>每个特定平台上的编译器都有自己默认的“对齐系数”，我们可以通过预处理指令#pragma pack(n), n=1, 2, 4, 8, 16…来改变这一系数，这个 n 就是对齐系数</p><p>数据成员对齐规则：结构(struct)或联合(union)的数据成员，第一个数据成员放在 offset 为 0 的地方，以后的每个数据成员的对齐按照#pragma pack(n)指定的 n 值和该数据成员本身的长度 len = sizeof(type) 中，较小的那个进行，如果没有显示指定n值，则以len为准，进行对齐<br>结构/联合整体对齐规则：在数据成员对齐完成之后，结构/联合本身也要对齐，对齐按照#pragma pack(n)指定的n值和该结构/联合最大数据成员长度max_len_of_members中，较小的那个进行，如果没有显示指定n值，则以max_len_of_members为准，进行对齐<br>结合1、2可推断：当n值均超过(或等于)所有数据成员的长度时，这个n值的大小将不产生任何效果</p><h3 id="从fsize看block"><a href="#从fsize看block" class="headerlink" title="从fsize看block"></a>从fsize看block</h3><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define N 1024long fsize(FILE *fp){    fseek(fp, 0, SEEK_END);    return ftell(fp);}int main(){    printf(&quot;enter the file absolute path: \n &quot;);    char str[N];    scanf(&quot;%s&quot;,str);    printf(&quot;\n the file name you choose is: %s\n &quot;,str);    FILE *fp = fopen(str, &quot;rb&quot;);    if(fp == NULL ){        printf(&quot;error opening file \n&quot;);        exit(-1);    }    printf(&quot;len: %ld bytes\n&quot;, fsize(fp));    fclose(fp);    return 0;}</code></pre><p>简单的一个用fsize函数获取文件的bytes数的函数</p><p>./a.out sample.txt ## len: 2527 bytes<br>du sample.txt<br>4 sample.txt<br>du -b sample.txt<br>2527 sample.txt</p><p>简单的来说，fsize获取的大小和du的结果不一致。但du -b 就一样了。这事主要是因为block size的缘故,文件系统分配磁盘存储的时候是以block为单位的。所以经常看到windows里面显示一个文件的大小和“占用的磁盘空间”。就是因为block的原因。<a href="https://unix.stackexchange.com/questions/120311/why-are-there-so-many-different-ways-to-measure-disk-usage">更详细的解释在这里</a></p><blockquote><p>For files, ls -l file shows (among other things) the size of file in bytes, while du -k file shows the space occupied by file on disk (in units of 1 kB = 1204 bytes). Since disk space is allocated in blocks, the size indicated by du -k is always slightly larger than the space indicated by  ls -kl (which is the same as ls -l, but in 1 kB units).</p><p>For directories, ls -ld dir shows (among other things) the size of the list of filenames (together with a number of attributes) of the files and subdirectories in dir. This is just the list of filenames, not the files’ or subdirectories’ contents. So this size increases when you add files to dir (even when files are empty), but it stays unchanged when one of the files in dir grows.</p><p>However, when you delete files from dir the space from the list is not reclaimed immediately, but rather the entries for deleted files are marked as unused, and are later recycled (this is actually implementation-dependent, but what I described is pretty much the universal behavior these days). That’s why you may not see any changes in ls -ld output when you delete files until much later, if ever.</p><p>Finally, du -ks dir shows (an estimate of) the space occupied on disk by all files in dir, together with all files in all of dir’s subdirectories, in 1 kB = 1024 bytes units. Taking into account the description above, this has no relation whatsoever with the output of ls -kld dir.</p></blockquote><p>linux上是ext4文件系统<br>应用程序调用read()方法，系统会通过中断从用户空间进入内核处理流程，然后经过VFS(Virtual File System，虚拟文件系统)、具体文件系统、页缓存Page Cache。VFS主要是用于实现屏蔽具体的文件系统，为应用程序的操作提供一个统一的接口。<br>Page Cache(页缓存)，读文件的时候，会先看一下它是不是已经在Page Cache里面，如果命中了的话，就不会去读取磁盘。通过/proc/meminfo文件可以查看缓存的内存占用情况，当系统内存不足的时候，系统会回收这部分内存，I/O的性能就会降低。</p><p>这本应该是一篇关于操作系统原理，内核简介的文章,to be complemented</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>[ ] <a href="https://www.youtube.com/watch?v=0Rf5Jc61ArM">Paging Technique : Memory management in Operating System</a></li><li><a href="https://zhuanlan.zhihu.com/p/44267768">深入理解 ext4 等 Linux 文件系统</a></li><li><a href="https://zhuanlan.zhihu.com/p/27875337">Linux 的 EXT4 文件系统的历史、特性以及最佳实践</a></li></ul><p><a href="https://zhuanlan.zhihu.com/p/52054044">https://zhuanlan.zhihu.com/p/52054044</a><br><a href="https://zhuanlan.zhihu.com/p/35879028">https://zhuanlan.zhihu.com/p/35879028</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;page size（内存相关）和block size(文件系统相关)的一些点&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/scenery1511100718415.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>TextView测量及渲染原理</title>
    <link href="https://haldir65.github.io/2018/11/29/2018-11-29-how-is-text-drawn-on-android/"/>
    <id>https://haldir65.github.io/2018/11/29/2018-11-29-how-is-text-drawn-on-android/</id>
    <published>2018-11-29T16:11:54.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>Android上的TextView分为java层和native层，java层包括<br>Layout,Paint,Canvas<br>native层包括各种开源库，Minikin,ICU,HarfBuzz,FreeType<br>关于文字的形体,排版等信息是native层计算出来的。</p><p><img src="https://www.haldir66.ga/static/imgs/textview_architecture.png" alt=""></p><a id="more"></a><p>[tbd]</p><p>TextView是一个很重的控件，由于measure耗时通常很多，Android P提出了Precomputed Text的概念。类似的概念早几年instagram也提出过（如果只是想要展示一段文字，在一个子线程用Layout去计算。<br>我碰到的情况是：<br>layout.getDesiredwidth(“一个字”) &gt; layout.getDesiredwidth(“一”) + layout.getDesiredwidth(“个”)+ layout.getDesiredwidth(“字”)。<br>多数情况下，左边的值和右边的width之和是相等的，但是出现中英文夹杂的时候左边会小于右边。不清楚这是否是提前换行的原因。</p><p>Layout有BoringLayout(一行文字),StaticLayout(多行文字)和DynamicLayout(文字会变)这三个子类</p><p>在某些版本的Android上，TextView碰到中英文夹杂的时候，会出现提前换行(普遍的看法是Layout这个类里面处理全角符号的时候算错了)</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://stackoverflow.com/questions/27631736/meaning-of-top-ascent-baseline-descent-bottom-and-leading-in-androids-font">Textview的高度ascent,descent这些的详细解说</a><br><a href="http://ragnraok.github.io/textview-pre-render-research.html">TextView预渲染研究</a><br><a href="https://instagram-engineering.com/improving-comment-rendering-on-android-a77d5db3d82e">instagram的文章</a><br><a href="https://www.youtube.com/watch?v=x-FcOX6ErdI">Best practices for text on Android (Google I/O ‘18)</a><br><a href="https://www.youtube.com/watch?v=vXqwRhjd7b4">Use Android Text Like a Pro (Android Dev Summit ‘18)</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Android上的TextView分为java层和native层，java层包括&lt;br&gt;Layout,Paint,Canvas&lt;br&gt;native层包括各种开源库，Minikin,ICU,HarfBuzz,FreeType&lt;br&gt;关于文字的形体,排版等信息是native层计算出来的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/textview_architecture.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="android" scheme="https://haldir65.github.io/tags/android/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>浏览器indexedDb使用示例</title>
    <link href="https://haldir65.github.io/2018/11/27/2018-11-27-indexed-db-tutorial/"/>
    <id>https://haldir65.github.io/2018/11/27/2018-11-27-indexed-db-tutorial/</id>
    <published>2018-11-27T10:33:01.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>浏览器indexedDb使用方式及注意的点<br><img src="https://www.haldir66.ga/static/imgs/black-mountains.jpg" alt=""><br><a id="more"></a></p><p><a href="https://medium.com/@filipvitas/indexeddb-with-promises-and-async-await-3d047dddd313">浏览器上可供使用的数据持久化选择就这些</a></p><blockquote><p>1) Store all data on server database (SQL or NoSQL)<br>2) LocalStorage / SessionStorage - limited memory (around 5MB)<br>3) WebSQL - it has been deprecated in favor of IndexedDB<br>4) IndexedDB - designed as “one true” browser database with 50MB and more<br>tl;dr Use some library from conclusion section to make your life easier.</p></blockquote><h2 id="一些重要的概念"><a href="#一些重要的概念" class="headerlink" title="一些重要的概念"></a>一些重要的概念</h2><p>Database(通常一个app只有一个database)<br>127.0.0.1:8080和127.0.0.1：8000 是两个不同的Application<br>创建出来的数据库在Application-&gt;Storage-&gt;IndexedDB里面有</p><p>Object Stores(就像数据库里的table或者collections一样，但是同一个store中存储的数据类型不一定是相同的)</p><p>transaction（所有对IndexDb的操作必须通过transaction）</p><p>接下来是CURD的实例</p><p>db.open返回的是一个IDBRequest对象，没有promise的方式是这样使用的</p><pre><code class="js">var db;// Let us open our databasevar DBOpenRequest = window.indexedDB.open(&quot;toDoList&quot;, 4);// these two event handlers act on the database being// opened successfully, or notDBOpenRequest.onerror = function(event) {  note.innerHTML += &#39;&lt;li&gt;Error loading database.&lt;/li&gt;&#39;;};DBOpenRequest.onsuccess = function(event) {  note.innerHTML += &#39;&lt;li&gt;Database initialised.&lt;/li&gt;&#39;;  // store the result of opening the database.  db = DBOpenRequest.result;};</code></pre><h3 id="Create-创建db的代码"><a href="#Create-创建db的代码" class="headerlink" title="(Create)创建db的代码:"></a>(Create)创建db的代码:</h3><p>indexedDB.open(‘db-name’, 1) //第二个参数是数据库版本</p><h3 id="添加数据的方式"><a href="#添加数据的方式" class="headerlink" title="添加数据的方式"></a>添加数据的方式</h3><pre><code class="js">function putSomeData() {    let indexedDB = window.indexedDB || window.mozIndexedDB || window.webkitIndexedDB || window.msIndexedDB    let open = indexedDB.open(&#39;db-name&#39;, 1)    open.onupgradeneeded = function() {        let db = open.result        db.createObjectStore(&#39;objectStoreName&#39;, { autoIncrement: true })    }    open.onsuccess = function() {        let db = open.result        let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readwrite&#39;)        let store = tx.objectStore(&#39;objectStoreName&#39;)        store.put({ firstname: &#39;John&#39;, lastname: &#39;Doe&#39;, age: 33 })        tx.oncomplete = function() {            db.close()        }    }}</code></pre><p>真啰嗦，还是用第三方库吧，用<a href="https://github.com/jakearchibald/idb">idb</a>好了</p><pre><code class="js">async function putSomeData() {    let db = await idb.open(&#39;db-name&#39;, 1, upgradeDB =&gt; upgradeDB.createObjectStore(&#39;objectStoreName&#39;, { autoIncrement: true }))    let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readwrite&#39;)    let store = tx.objectStore(&#39;objectStoreName&#39;)    await store.put({ firstname: &#39;John&#39;, lastname: &#39;Doe&#39;, age: 33 })    await tx.complete    db.close()}async function getAllData() {    let db = await idb.open(&#39;db-name&#39;, 1)    let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readonly&#39;)    let store = tx.objectStore(&#39;objectStoreName&#39;)    // add, clear, count, delete, get, getAll, getAllKeys, getKey, put    let allSavedItems = await store.getAll()    console.log(allSavedItems)    db.close()}</code></pre><h3 id="扯一点关于存储的东西"><a href="#扯一点关于存储的东西" class="headerlink" title="扯一点关于存储的东西"></a>扯一点关于存储的东西</h3><p>当浏览器进入私人模式(private browsing mode，Google Chrome 上对应的应该是叫隐身模式)的时候，会创建一个新的、临时的、空的数据库，用以存储本地数据(local storage data)。当浏览器关闭时，里面的所有数据都将被丢弃。</p><p>判断方式</p><pre><code class="js">//隐身模式下和localStorage满了都会报同样的错误try {  window.localStorage.setItem(&#39;test&#39;, &#39;test&#39;)} catch (e)  {  console.log(e) //QuotaExceddedError(DOM Exception 22):The quota has been exceeded.}</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;浏览器indexedDb使用方式及注意的点&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/black-mountains.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="前端" scheme="https://haldir65.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
      <category term="javaScript" scheme="https://haldir65.github.io/tags/javaScript/"/>
    
  </entry>
  
  <entry>
    <title>cmake实用手册</title>
    <link href="https://haldir65.github.io/2018/11/26/2018-11-26-cmake-intro/"/>
    <id>https://haldir65.github.io/2018/11/26/2018-11-26-cmake-intro/</id>
    <published>2018-11-26T13:42:16.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>当我们敲下cmake命令的时候，cmake会在当前目录下找CMakeLists.txt这个文件</p><p><img src="https://www.haldir66.ga/static/imgs/fresh-sparkle-dew-drops-on-red-flower-wallpaper-53861cf580909.jpg" alt=""><br><a id="more"></a></p><p><a href="https://hulinhong.com/2018/04/21/cmake_tutorial/">CMake好在跨平台</a></p><blockquote><p>你或许听过好几种 Make 工具，例如 GNU Make ，QT 的 qmake ，微软的 MS nmake，BSD Make（pmake），Makepp，等等。这些 Make 工具遵循着不同的规范和标准，所执行的 Makefile 格式也千差万别。这样就带来了一个严峻的问题：如果软件想跨平台，必须要保证能够在不同平台编译。而如果使用上面的 Make 工具，就得为每一种标准写一次 Makefile ，这将是一件让人抓狂的工作。<br>就是针对上面问题所设计的工具：它首先允许开发者编写一种平台无关的 CMakeList.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件，如 Unix 的 Makefile 或 Windows 的 Visual Studio 工程。从而做到“Write once, run everywhere”。</p></blockquote><p>下面就是最简单的一个CMakeLists.txt的例子，project(hello_cmake)是一个函数，该函数生成了PROJECT_NAME这个变量，所以下面直接用了。add_executable（）第一个参数是要生成的可执行文件的名字，第二个参数(其实可以包括所有编译需要的源文件)</p><blockquote><p>cmake_minimum_required(VERSION 3.5)<br>project (hello_cmake)<br>add_executable(${PROJECT_NAME} main.cpp)</p></blockquote><p>这个更简单</p><blockquote><p>cmake_minimum_required(VERSION 2.8)<br>project(app_project)<br>add_executable(myapp main.c)<br>install(TARGETS myapp DESTINATION bin)</p></blockquote><p>生成Makefile<br>mkdir _build &amp;&amp; cd _build &amp;&amp; cmake .. -DCMAKE_INSTALL_PREFIX=../_install<br>生成的Makefile拿来用:<br>make &amp;&amp; make install<br>省的手写Makefile了</p><p>cmake支持In-Place Build和Out-of-Source Build。前者是直接在当前文件夹（CMAKE_BINARY_DIR）中生成一大堆文件（太乱了），后者则是在一个指定的文件夹中生成文件。<br>Out-of-source build其实很简单<br>mkdir build &amp;&amp; cd build/ &amp;&amp; cmake .. (在build文件夹中会生成一个Makefile)<br>make &amp;&amp; ./hello_cmake </p><p>一堆内置的变量供参考</p><table><thead><tr><th>Variable</th><th>Info</th></tr></thead><tbody><tr><td>CMAKE_SOURCE_DIR</td><td>The root source directory</td></tr><tr><td>CMAKE_CURRENT_SOURCE_DIR</td><td>The current source directory if using sub-projects and directories.</td></tr><tr><td>PROJECT_SOURCE_DIR</td><td>The source directory of the current cmake project.</td></tr><tr><td>CMAKE_BINARY_DIR</td><td>The root binary / build directory. This is the directory where you ran the cmake command.</td></tr><tr><td>CMAKE_CURRENT_BINARY_DIR</td><td>The build directory you are currently in.</td></tr><tr><td>PROJECT_BINARY_DIR</td><td>The build directory for the current project.</td></tr></tbody></table><h3 id="header文件的处理"><a href="#header文件的处理" class="headerlink" title="header文件的处理"></a>header文件的处理</h3><p>可以指定多个源文件</p><blockquote><p>set(SOURCES<br>    src/Hello.cpp<br>    src/main.cpp<br>)<br>add_executable(${PROJECT_NAME} ${SOURCES})<br>//或者直接把src文件夹下面的所有.cpp文件加入进来<br>file(GLOB SOURCES “src/*.cpp”)</p></blockquote><h3 id="对于include文件夹"><a href="#对于include文件夹" class="headerlink" title="对于include文件夹"></a>对于include文件夹</h3><blockquote><p>target_include_directories(target<br>    PRIVATE<br>        ${PROJECT_SOURCE_DIR}/include<br>)<br>这样编译器就会在编译参数上加上-I/directory/path这种东西</p></blockquote><h3 id="static-library的处理"><a href="#static-library的处理" class="headerlink" title="static library的处理"></a>static library的处理</h3><pre><code>cmake_minimum_required(VERSION 3.5)project(hello_library)############################################################# Create a library#############################################################Generate the static library from the library sourcesadd_library(hello_library STATIC     src/Hello.cpp //创建一个libhello_library.a 的static library)target_include_directories(hello_library    PUBLIC         ${PROJECT_SOURCE_DIR}/include)############################################################# Create an executable############################################################# Add an executable with the above sourcesadd_executable(hello_binary     src/main.cpp)# link the new hello_library target with the hello_binary targettarget_link_libraries( hello_binary    PRIVATE         hello_library)</code></pre><h3 id="shared-library的处理"><a href="#shared-library的处理" class="headerlink" title="shared library的处理"></a>shared library的处理</h3><pre><code>cmake_minimum_required(VERSION 3.5)project(hello_library)############################################################# Create a library#############################################################Generate the shared library from the library sourcesadd_library(hello_library SHARED     src/Hello.cpp  // 用传入该函数的文件创建一个 libhello_library.so Library)add_library(hello::library ALIAS hello_library)target_include_directories(hello_library //hello_library需要这个include directory    PUBLIC         ${PROJECT_SOURCE_DIR}/include  )############################################################# Create an executable############################################################# Add an executable with the above sourcesadd_executable(hello_binary    src/main.cpp)# link the new hello_library target with the hello_binary targettarget_link_libraries( hello_binary // 接下来就是Link了，这里使用了上面的一个alias    PRIVATE         hello::library)</code></pre><h3 id="接下来是make-install-将生成的可执行文件安装到系统中，似乎就是复制到-usr-bin里面"><a href="#接下来是make-install-将生成的可执行文件安装到系统中，似乎就是复制到-usr-bin里面" class="headerlink" title="接下来是make install (将生成的可执行文件安装到系统中，似乎就是复制到/usr/bin里面)"></a>接下来是make install (将生成的可执行文件安装到系统中，似乎就是复制到/usr/bin里面)</h3><p>默认情况下cmake会把生成的可执行文件安装到系统中，我们可以指定安装到特定的位置<br>cmake .. -DCMAKE_INSTALL_PREFIX=/install/location</p><pre><code>install (TARGETS cmake_examples_inst_bin    DESTINATION bin)// target cmake_examples_inst_bin target to the destination ${CMAKE_INSTALL_PREFIX}/bininstall (TARGETS cmake_examples_inst    LIBRARY DESTINATION lib) //install the shared library generated from the target cmake_examples_inst target to the destination ${CMAKE_INSTALL_PREFIX}/lib</code></pre><blockquote><p>$ ls /usr/local/bin/<br>cmake_examples_inst_bin</p><p>$ ls /usr/local/lib<br>libcmake_examples_inst.so</p><p>$ ls /usr/local/etc/<br>cmake-examples.conf</p><p>$ LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib cmake_examples_inst_bin<br>Hello Install! //把生成的bin文件复制到/sur/local/bin目录下，再修改LDPATH,就能去/usr/locallib这个目录去找生成的library了</p></blockquote><h2 id="Autoconf-Automake教程"><a href="#Autoconf-Automake教程" class="headerlink" title="Autoconf/Automake教程"></a>Autoconf/Automake教程</h2><p>GNU Autotools 一般指的是3个 GNU 工具包：Autoconf，Automake 和 Libtool (本文先介绍前两个工具，Libtool留到今后介绍)<br>它们能解决什么问题，要先从 GNU 开源软件的 Build 系统说起。一般来说。GNU 软件的安装过程都是：</p><p>解压源代码包<br>./configure<br>make<br>make install（可能要切root用户）<br>这个过程中， 需要有一个 configure 脚本，同时也需要一个 Makefile 文件。</p><p>而 Autoconf 和 Automake 就是一套自动生成 configure 脚本和 Makefile 文件的工具。</p><p>在ubuntu上安装autoconf,automake,libtool:</p><blockquote><p>sudo apt install build-essential autoconf automake libtool libtool-bin autotools-dev</p></blockquote><p>configure文件是用autoconf根据configure.ac创建出来的，而configure.ac能用autoscan自动创建出来</p><p>随便创建一个文件夹</p><p>$ ls<br>epoch.c Makefile</p><p>$ cat epoch.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;sys/time.h&gt;#include &lt;time.h&gt;#include &quot;config.h&quot;double get_epoch(){  double sec;  #ifdef HAVE_GETTIMEOFDAY     struct timeval tv;     gettimeofday(&amp;tv, NULL);     sec = tv.tv_sec;     sec += tv.tv_usec / 1000000.0;  #else     sec = time(NULL);  #endif  return sec;}int main(int argc, char* argv[]){   printf(&quot;%f\n&quot;, get_epoch());   return 0;}</code></pre><p>这么写的原因是gettimeofday()这个函数不是在所有的平台上都有，这种时候就要用time()函数了。</p><p>$ cat Makefile</p><pre><code># Makefile: A standard Makefile for epoch.call: epochclean:    rm ­f epoch</code></pre><p>这样其实已经可以直接make生成可执行文件了。但是我们用autoconf来生成试一下</p><ol><li>生成config.h文件<br>config.h文件是configure命令根据config.h.in文件生成的，config.h.in文件是由autoheader（C的source code）中生成的（总之也是自动的）<br>$ ls<br>epoch.c Makefile<br>$ autoscan<br>$ ls<br>autoscan.log  configure.scan  epoch.c  Makefile<br>$  mv configure.scan configure.ac<br>$ ls<br>autoscan.log  configure.ac  epoch.c  Makefile<br>$ autoheader<br>$ ls<br>autom4te.cache  autoscan.log  config.h.in  configure.ac  epoch.c  Makefile<br>$  mv Makefile Makefile.in<br>$ autoconf<br>$ ls<br>autom4te.cache  autoscan.log  config.h.in  configure  configure.ac  epoch.c  Makefile.in<br>$ ./configure<br>checking for gcc… gcc<br>checking whether the C compiler works… yes<br>checking for C compiler default output file name… a.out<br>checking for suffix of executables…<br>checking whether we are cross compiling… no<br>checking for suffix of object files… o<br>checking whether we are using the GNU C compiler… yes<br>checking whether gcc accepts -g… yes<br>checking for gcc option to accept ISO C89… none needed<br>checking how to run the C preprocessor… gcc -E<br>checking for grep that handles long lines and -e… /bin/grep<br>checking for egrep… /bin/grep -E<br>checking for ANSI C header files… yes<br>checking for sys/types.h… yes<br>checking for sys/stat.h… yes<br>checking for stdlib.h… yes<br>checking for string.h… yes<br>checking for memory.h… yes<br>checking for strings.h… yes<br>checking for inttypes.h… yes<br>checking for stdint.h… yes<br>checking for unistd.h… yes<br>checking sys/time.h usability… yes<br>checking sys/time.h presence… yes<br>checking for sys/time.h… yes<br>checking for gettimeofday… yes<br>configure: creating ./config.status<br>config.status: creating Makefile<br>config.status: creating config.h<br>$  ls<br>autom4te.cache  autoscan.log  config.h  config.h.in  config.log  config.status  configure  configure.ac  epoch.c  Makefile  Makefile.in<br>$ make<br>$ ls<br>autom4te.cache  config.h     config.log     configure     epoch    Makefile<br>autoscan.log    config.h.in  config.status  configure.ac  epoch.c  Makefile.in<br>$  ./epoch<br>1544345416.704451</li></ol><p>//到此结束（这样做的意义在于一份代码就能够拥有多平台兼容性）</p><p>另一种方式<br>手动创造“Makefile.am”文件<br>$ cat Makefile.am</p><h1 id="Makefile-am-for-epoch-c"><a href="#Makefile-am-for-epoch-c" class="headerlink" title="Makefile.am for epoch.c"></a>Makefile.am for epoch.c</h1><p>bin_PROGRAMS=epoch<br>epoch_SOURCES=epoch.c</p><p>$ ls<br>epoch.c  Makefile.am</p><p>$ autoscan<br>$  mv configure.scan configure.ac<br>$ autoheader<br>$ ls<br>autom4te.cache  autoscan.log  config.h.in  configure.ac  epoch.c  Makefile.am<br>$ vim configure.ac<br>改成这样</p><pre><code>#                                               -*- Autoconf -*-# Process this file with autoconf to produce a configure script.AC_PREREQ([2.69])AC_INIT([FULL-PACKAGE-NAME], [VERSION], [BUG-REPORT-ADDRESS])AM_INIT_AUTOMAKEAC_CONFIG_SRCDIR([epoch.c])AC_CONFIG_HEADERS([config.h])# Checks for programs.AC_PROG_CC# Checks for libraries.# Checks for header files.AC_CHECK_HEADERS([sys/time.h])# Checks for typedefs, structures, and compiler characteristics.AC_HEADER_TIME# Checks for library functions.AC_CHECK_FUNCS([gettimeofday])AC_CONFIG_FILES([Makefile])AC_OUTPUT</code></pre><p>其实就是加了AM_INIT_AUTOMAKE这一行还有AC_HEADER_TIME<br>$ aclocal<br>$ automake ­­add­missing ­­copy<br>$ autoconf<br>$ ./configure 在这一步因为没有生成Makefile.in所以停下来了</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://mirkokiefer.com/cmake-by-example-f95eb47d45b1">cmake的教程，非常好</a><br><a href="https://github.com/ttroy50/cmake-examples">Useful CMake Examples</a>本文来自这里的实例<br><a href="http://www.lugod.org/presentations/autotools/presentation/autotools.pdf">autotools教程</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当我们敲下cmake命令的时候，cmake会在当前目录下找CMakeLists.txt这个文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/fresh-sparkle-dew-drops-on-red-flower-wallpaper-53861cf580909.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="C" scheme="https://haldir65.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>opengl学习笔记</title>
    <link href="https://haldir65.github.io/2018/11/15/2018-11-15-opengl-related-topics/"/>
    <id>https://haldir65.github.io/2018/11/15/2018-11-15-opengl-related-topics/</id>
    <published>2018-11-15T22:53:55.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p>topics relating opengl stuff<br><img src="https://www.haldir66.ga/static/imgs/scenery151110074347.jpg" alt=""></p><a id="more"></a><p><a href="https://github.com/doggycoder/AndroidOpenGLDemo">本文多数代码来自这个系列</a></p><p>首先，<a href="https://medium.com/@wrongway4you/opengl-learning-in-2018-d556d96d7e7">不要学旧的版本</a>。<br>It is much better to start from the “modern” OpenGL versions: Learn OpenGL &gt;3.0.</p><p>opengl device support on android</p><ul><li>OpenGL ES 1.0 &amp; 1.1 since Android 1.0 (API 4)</li><li>OpenGL ES 2.0 since Android 2.2 (API 8)</li><li>OpenGL ES 3.0 since Android 4.3 (API 18) (almost)</li><li>OpenGL ES 3.1 since Android 5.0 (API 21)</li></ul><p>OpenGL ES is a variant of OpenGL’s specifications for embedded system. </p><blockquote><p>Graphics progamming for OpenGL ES 2.0 and 3.0 is largely similar, with version 3.0 representing a superset of the 2.0 API with additional features. Programming for the OpenGL ES 1.0/1.1 API versus OpenGL ES 2.0 and 3.0 differs significantly(2.0和3.0的语法差不多，3.0就是加了点特性。1.0和他俩的语法不同，不要学)<br>总的来讲，2.0和3.0要比1.0的性能好，能够对硬件有更自由的掌控（the API provides a great deal of control over the graphics rendering pipeline.），但是语法要复杂些。</p></blockquote><h2 id="Android提供了很多用于和OPENGL环境交互的class"><a href="#Android提供了很多用于和OPENGL环境交互的class" class="headerlink" title="Android提供了很多用于和OPENGL环境交互的class"></a>Android提供了很多用于和OPENGL环境交互的class</h2><p>开发者使用java环境  -&gt; 描述绘制图形 -&gt; graphics rendering pipeline<br>最简单的View是GLSurfaceView，实现渲染的逻辑在GLSurfaceView.Renderer中。如果想要只在view的布局一部分中使用gl功能的请使用TextureView，For real, do-it-yourself developers, it is also possible to build up an OpenGL ES view using SurfaceView, but this requires writing quite a bit of additional code。</p><p>GLSurfaceView.Renderer</p><pre><code class="java">    public interface Renderer {        void onSurfaceCreated(GL10 gl, EGLConfig config);        void onSurfaceChanged(GL10 gl, int width, int height);        void onDrawFrame(GL10 gl);    }</code></pre><p>render就这么三个方法，这三个方法都在一条叫做GLThread的线程上被调用</p><h2 id="检查当前设备的opengles版本"><a href="#检查当前设备的opengles版本" class="headerlink" title="检查当前设备的opengles版本:"></a>检查当前设备的opengles版本:</h2><p>在GLSurfaceView.Renderer的onSurfaceCreated中添加</p><pre><code class="java">// Create a minimum supported OpenGL ES context, then check:String version = gl.glGetString(GL10.GL_VERSION);Log.w(TAG, &quot;Version: &quot; + version );// The version format is displayed as: &quot;OpenGL ES &lt;major&gt;.&lt;minor&gt;&quot;// followed by optional content provided by the implementation.</code></pre><p>我在一台5.1的设备上打印出来的是”OpenGL ES 3.1”这么几个字。</p><h2 id="坐标系"><a href="#坐标系" class="headerlink" title="坐标系"></a>坐标系</h2><blockquote><p>By default, OpenGL ES assumes a coordinate system where [0,0,0] (X,Y,Z) specifies the center of the GLSurfaceView frame, [1,1,0] is the top right corner of the frame and [-1,-1,0] is bottom left corner of the frame<br>opengl使用三维坐标系，右手坐标，屏幕中心为原点，z轴垂直于屏幕，往上是正数。屏幕中心往右走是x轴正轴，屏幕中心往上走是y轴正轴。</p></blockquote><h2 id="culling"><a href="#culling" class="headerlink" title="culling"></a>culling</h2><p>（就是告诉opengl完全忽略掉背面，不要浪费时间去渲染看不见的地方）<br>Face culling is an option for the OpenGL environment which allows the rendering pipeline to ignore (not calculate or draw) the back face of a shape, saving time, memory and processing cycles:（好处就是节省时间和运算量）<br>比方说完全忽略掉背面</p><pre><code class="java">// enable face culling featuregl.glEnable(GL10.GL_CULL_FACE);// specify which faces to not drawgl.glCullFace(GL10.GL_BACK);</code></pre><p>还有，默认的作图顺序是<strong>逆时针</strong>的</p><h2 id="Texture-compression"><a href="#Texture-compression" class="headerlink" title="Texture compression"></a>Texture compression</h2><p>能够极大的节约内存，并充分利用内存带宽提升性能<br>包括这么几个:<br>ETC1 compression format(但不支持有alpha channel，就是带透明度的)<br>The ETC2/EAC texture compression formats (支持带alpha channel)</p><p>查看当前设备支持的OpenGL extensions(entension就是标准之外的，部分厂商硬件支持的特性)</p><pre><code class="java"> // Get the list of extensions.        String extensionList = GLES10.glGetString(GLES10.GL_EXTENSIONS);        if (!TextUtils.isEmpty(extensionList)) {            // The list of extensions comes from the driver separated by spaces.            // Split them apart and add them into a Set for deduping purposes.            for (String extension : extensionList.split(&quot; &quot;)) {                glExtensions.add(extension);            }        }</code></pre><p><a href="https://blog.csdn.net/junzia/article/details/52793354">OpenGL ES 2.0过程及理解</a><br>OpenGL ES 2.0渲染过程为：<br>读取顶点数据——执行顶点着色器——组装图元——光栅化图元——执行片元着色器——写入帧缓冲区——显示到屏幕上。<br>OpenGL作为本地库直接运行在硬件上，没有虚拟机，也没有垃圾回收或者内存压缩。在Java层定义图像的数据需要能被OpenGL存取，因此，需要把内存从Java堆复制到本地堆。<br>顶点着色器是针对每个顶点都会执行的程序，是确定每个顶点的位置。同理，片元着色器是针对每个片元都会执行的程序，确定每个片元的颜色。<br>着色器需要进行编译，然后链接到OpenGL程序中。一个OpenGL的程序就是把一个顶点着色器和一个片段着色器链接在一起变成单个对象。</p><h3 id="定义shape"><a href="#定义shape" class="headerlink" title="定义shape"></a>定义shape</h3><p>点，线，三角形，这三个是opengl的图形基础，其他任何集合图形都可以用三角形拼凑出来。<br><a href="https://developer.android.com/training/graphics/opengl/shapes">根据官方文档</a>，开发者需要往opengl传一个float的array作为要绘制的对象的坐标，在java里用ArrayBuffer比较好(这部分内存是传到硬件层的)。<br>官方文档上这样定义了一个三角形</p><pre><code class="java">public class Triangle {    private FloatBuffer vertexBuffer;    // number of coordinates per vertex in this array    static final int COORDS_PER_VERTEX = 3;    static float triangleCoords[] = {   // in counterclockwise order:             0.0f,  0.622008459f, 0.0f, // top            -0.5f, -0.311004243f, 0.0f, // bottom left             0.5f, -0.311004243f, 0.0f  // bottom right    }; //逆时针走向    // Set color with red, green, blue and alpha (opacity) values    float color[] = { 0.63671875f, 0.76953125f, 0.22265625f, 1.0f };    public Triangle() {        // initialize vertex byte buffer for shape coordinates        ByteBuffer bb = ByteBuffer.allocateDirect(                // (number of coordinate values * 4 bytes per float)                triangleCoords.length * 4);        // use the device hardware&#39;s native byte order        bb.order(ByteOrder.nativeOrder()); //字节序        // create a floating point buffer from the ByteBuffer        vertexBuffer = bb.asFloatBuffer();        // add the coordinates to the FloatBuffer        vertexBuffer.put(triangleCoords);        // set the buffer to read the first coordinate        vertexBuffer.position(0);    }}</code></pre><p>正方形就可以由两个三角形拼在一起组成</p><pre><code class="java">public class Square {    private FloatBuffer vertexBuffer;    private ShortBuffer drawListBuffer;    // number of coordinates per vertex in this array    static final int COORDS_PER_VERTEX = 3;    static float squareCoords[] = {            -0.5f,  0.5f, 0.0f,   // top left            -0.5f, -0.5f, 0.0f,   // bottom left             0.5f, -0.5f, 0.0f,   // bottom right             0.5f,  0.5f, 0.0f }; // top right    private short drawOrder[] = { 0, 1, 2, 0, 2, 3 }; // order to draw vertices    public Square() {        // initialize vertex byte buffer for shape coordinates        ByteBuffer bb = ByteBuffer.allocateDirect(        // (# of coordinate values * 4 bytes per float)                squareCoords.length * 4);        bb.order(ByteOrder.nativeOrder());        vertexBuffer = bb.asFloatBuffer();        vertexBuffer.put(squareCoords);        vertexBuffer.position(0);        // initialize byte buffer for the draw list        ByteBuffer dlb = ByteBuffer.allocateDirect(        // (# of coordinate values * 2 bytes per short)                drawOrder.length * 2);        dlb.order(ByteOrder.nativeOrder());        drawListBuffer = dlb.asShortBuffer();        drawListBuffer.put(drawOrder);        drawListBuffer.position(0);    }}</code></pre><h3 id="绘制定义的shape"><a href="#绘制定义的shape" class="headerlink" title="绘制定义的shape"></a>绘制定义的shape</h3><p>首先在onSurfaceCreated里面创建要绘制的shape对象</p><pre><code class="java">   private Triangle mTriangle;    private Square   mSquare;    public void onSurfaceCreated(GL10 unused, EGLConfig config) {        ...        // initialize a triangle        mTriangle = new Triangle();        // initialize a square        mSquare = new Square();    }</code></pre><p>接下来就是比较麻烦的地方了，必须要定义这几样东西</p><ul><li>Vertex Shader - OpenGL ES graphics code for rendering the vertices of a shape.（顶点着色器）</li><li>Fragment Shader - OpenGL ES code for rendering the face of a shape with colors or textures.(片元着色器)</li><li>Program - An OpenGL ES object that contains the shaders you want to use for drawing one or more shapes.</li></ul><p>至少需要一个vertex shader去画shape，一个fragment shader去画shape的颜色，这俩被编译并添加到opengles program中，后者将被用来画这个shape</p><pre><code class="java">public class Triangle {    private final String vertexShaderCode =        &quot;attribute vec4 vPosition;&quot; +        &quot;void main() {&quot; +        &quot;  gl_Position = vPosition;&quot; +        &quot;}&quot;;    private final String fragmentShaderCode =        &quot;precision mediump float;&quot; +        &quot;uniform vec4 vColor;&quot; +        &quot;void main() {&quot; +        &quot;  gl_FragColor = vColor;&quot; +        &quot;}&quot;;    ...}public static int loadShader(int type, String shaderCode){    // create a vertex shader type (GLES20.GL_VERTEX_SHADER)    // or a fragment shader type (GLES20.GL_FRAGMENT_SHADER)    int shader = GLES20.glCreateShader(type);    // add the source code to the shader and compile it    GLES20.glShaderSource(shader, shaderCode);    GLES20.glCompileShader(shader); //编译shader并link program很耗费cpu，所以只要做一次，一般放在shape的构造函数里面    return shader;}</code></pre><p>所以最后Triangle的代码变成这样</p><pre><code class="js">// number of coordinates per vertex in this arrayconst val COORDS_PER_VERTEX = 3var triangleCoords = floatArrayOf(     // in counterclockwise order:    0.0f, 0.622008459f, 0.0f,      // top    -0.5f, -0.311004243f, 0.0f,    // bottom left    0.5f, -0.311004243f, 0.0f      // bottom right)class Triangle {    // Set color with red, green, blue and alpha (opacity) values    val color = floatArrayOf(0.63671875f, 0.76953125f, 0.22265625f, 1.0f)    private var vertexBuffer: FloatBuffer =    // (number of coordinate values * 4 bytes per float)        ByteBuffer.allocateDirect(triangleCoords.size * 4).run {            // use the device hardware&#39;s native byte order            order(ByteOrder.nativeOrder())            // create a floating point buffer from the ByteBuffer            asFloatBuffer().apply {                // add the coordinates to the FloatBuffer                put(triangleCoords)                // set the buffer to read the first coordinate                position(0)            }        }    private var mProgram: Int    private val vertexShaderCode =        &quot;attribute vec4 vPosition;&quot; +                &quot;void main() {&quot; +                &quot;  gl_Position = vPosition;&quot; +                &quot;}&quot;    private val fragmentShaderCode =        &quot;precision mediump float;&quot; +                &quot;uniform vec4 vColor;&quot; +                &quot;void main() {&quot; +                &quot;  gl_FragColor = vColor;&quot; +                &quot;}&quot;    private val vertexCount: Int = triangleCoords.size / COORDS_PER_VERTEX    private val vertexStride: Int = COORDS_PER_VERTEX * 4 // 4 bytes per vertex    init {        val vertexShader: Int = loadShader(GLES20.GL_VERTEX_SHADER, vertexShaderCode)        val fragmentShader: Int = loadShader(GLES20.GL_FRAGMENT_SHADER, fragmentShaderCode)        // create empty OpenGL ES Program        mProgram = GLES20.glCreateProgram().also {            // add the vertex shader to program            GLES20.glAttachShader(it, vertexShader)            // add the fragment shader to program            GLES20.glAttachShader(it, fragmentShader)            // creates OpenGL ES program executables            GLES20.glLinkProgram(it)        }    }    private var mPositionHandle: Int = 0    private var mColorHandle: Int = 0    fun loadShader(type: Int, shaderCode: String): Int {        // create a vertex shader type (GLES20.GL_VERTEX_SHADER)        // or a fragment shader type (GLES20.GL_FRAGMENT_SHADER)        return GLES20.glCreateShader(type).also { shader -&gt;            // add the source code to the shader and compile it            GLES20.glShaderSource(shader, shaderCode)            GLES20.glCompileShader(shader)        }    }    fun draw() {        // Add program to OpenGL ES environment        GLES20.glUseProgram(mProgram)        // get handle to vertex shader&#39;s vPosition member        mPositionHandle = GLES20.glGetAttribLocation(mProgram, &quot;vPosition&quot;).also {            // Enable a handle to the triangle vertices            GLES20.glEnableVertexAttribArray(it)            // Prepare the triangle coordinate data            GLES20.glVertexAttribPointer(                it,                COORDS_PER_VERTEX,                GLES20.GL_FLOAT,                false,                vertexStride,                vertexBuffer            )            // get handle to fragment shader&#39;s vColor member            mColorHandle = GLES20.glGetUniformLocation(mProgram, &quot;vColor&quot;).also { colorHandle -&gt;                // Set color for drawing the triangle                GLES20.glUniform4fv(colorHandle, 1, color, 0)            }            // Draw the triangle            GLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0, vertexCount)            // Disable vertex array            GLES20.glDisableVertexAttribArray(it)        }    }}</code></pre><h3 id="接下来是-Apply-projection-and-camera-views"><a href="#接下来是-Apply-projection-and-camera-views" class="headerlink" title="接下来是 Apply projection and camera views"></a>接下来是 Apply projection and camera views</h3><p>Projection 就是根据设备的实际屏幕尺寸调节绘制坐标<br>Camera View 就是根据一个假想的camera视角调节坐标</p><h3 id="着色器语言GLSL"><a href="#着色器语言GLSL" class="headerlink" title="着色器语言GLSL"></a>着色器语言GLSL</h3><p>写到这里，基本的流程就是在onSurfaceCreated中去loadShader，而shaderCode一般是这样的。</p><pre><code class="s">uniform mat4 vMatrix;varying vec4 vColor;attribute vec4 vPosition;void main(){    gl_Position=vMatrix*vPosition;    if(vPosition.z!=0.0){        vColor=vec4(0.0,0.0,0.0,1.0);    }else{        vColor=vec4(0.9,0.9,0.9,1.0);    }}</code></pre><p>这是一门高级的图形化编程语言，其源于应用广泛的C语言，主要特性包括:</p><ul><li>GLSL是一种面向过程的语言，和Java的面向对象是不同的。</li><li>GLSL的基本语法与C/C++基本相同。</li><li>它完美的支持向量和矩阵操作。</li><li>它是通过限定符操作来管理输入输出类型的。</li><li>GLSL提供了大量的内置函数来提供丰富的扩展功能。</li></ul><h3 id="顶点着色器的内建变量"><a href="#顶点着色器的内建变量" class="headerlink" title="顶点着色器的内建变量"></a>顶点着色器的内建变量</h3><p>gl_Position：顶点坐标<br>gl_PointSize：点的大小，没有赋值则为默认值1，通常设置绘图为点绘制才有意义。</p><h3 id="片元着色器的内建变量"><a href="#片元着色器的内建变量" class="headerlink" title="片元着色器的内建变量"></a>片元着色器的内建变量</h3><p>输入变量<br>gl_FragCoord：当前片元相对窗口位置所处的坐标。<br>gl_FragFacing：bool型，表示是否为属于光栅化生成此片元的对应图元的正面。<br>输出变量<br>gl_FragColor：当前片元颜色<br>gl_FragData：vec4类型的数组。向其写入的信息，供渲染管线的后继过程使用。</p><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数:"></a>内置函数:</h3><p>纹理采样函数<br>纹理采样函数有texture2D、texture2DProj、texture2DLod、texture2DProjLod、textureCube、textureCubeLod及texture3D、texture3DProj、texture3DLod、texture3DProjLod等。</p><p>向量在GPU中由硬件支持运算，比CPU快的多。<br><a href="https://blog.csdn.net/junzia/article/details/52830604">总的来说这门语言要比其他编程语言简单些</a></p><h3 id="用OpenGL-ES显示图片"><a href="#用OpenGL-ES显示图片" class="headerlink" title="用OpenGL ES显示图片"></a>用OpenGL ES显示图片</h3><p>纹理(texture):<br>在理解纹理映射时，可以将纹理看做应用在物体表面的像素颜色。在真实世界中，纹理表示一个对象的颜色、图案以及触觉特征。纹理只表示对象表面的彩色图案，它不能改变对象的几何形式。更进一步的说，它只是一种高强度的计算行为。</p><p>比如一张矩形的图片是由两个三角形拼起来的，左下 -&gt; 左上 -&gt; 右下 -&gt; 右上 的顺序就能得到图片的纹理<br>下面这段代码也不是很懂，照着注释看吧</p><pre><code class="java">  @Override    public void onDrawFrame(GL10 gl) {        GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT|GLES20.GL_DEPTH_BUFFER_BIT);        GLES20.glUseProgram(mProgram);        onDrawSet(); // 在这里添加模糊，暖色调，冷色调等滤镜效果        GLES20.glUniform1i(hIsHalf,isHalf?1:0);        GLES20.glUniform1f(glHUxy,uXY);        GLES20.glUniformMatrix4fv(glHMatrix,1,false,mMVPMatrix,0);        GLES20.glEnableVertexAttribArray(glHPosition);        GLES20.glEnableVertexAttribArray(glHCoordinate);        GLES20.glUniform1i(glHTexture, 0);        textureId=createTexture();        GLES20.glVertexAttribPointer(glHPosition,2,GLES20.GL_FLOAT,false,0,bPos);        GLES20.glVertexAttribPointer(glHCoordinate,2,GLES20.GL_FLOAT,false,0,bCoord);        GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP,0,4);    }    public abstract void onDrawSet();    public abstract void onDrawCreatedSet(int mProgram);    private int createTexture(){        int[] texture=new int[1];        if(mBitmap!=null&amp;&amp;!mBitmap.isRecycled()){            //生成纹理            GLES20.glGenTextures(1,texture,0);            //生成纹理            GLES20.glBindTexture(GLES20.GL_TEXTURE_2D,texture[0]);            //设置缩小过滤为使用纹理中坐标最接近的一个像素的颜色作为需要绘制的像素颜色            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_MIN_FILTER,GLES20.GL_NEAREST);            //设置放大过滤为使用纹理中坐标最接近的若干个颜色，通过加权平均算法得到需要绘制的像素颜色            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D,GLES20.GL_TEXTURE_MAG_FILTER,GLES20.GL_LINEAR);            //设置环绕方向S，截取纹理坐标到[1/2n,1-1/2n]。将导致永远不会与border融合            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_S,GLES20.GL_CLAMP_TO_EDGE);            //设置环绕方向T，截取纹理坐标到[1/2n,1-1/2n]。将导致永远不会与border融合            GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_T,GLES20.GL_CLAMP_TO_EDGE);            //根据以上指定的参数，生成一个2D纹理            GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, mBitmap, 0);             return texture[0];        }        return 0;    }</code></pre><p>显示图片的关键代码:<br>GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, mBitmap, 0);</p><p>滤镜这些特效本质上是在onDrawFrame里面去调用这两个函数</p><pre><code class="java">GLES20.glUniform1i(hChangeType,filter.getType());GLES20.glUniform3fv(hChangeColor,1,filter.data(),0);</code></pre><p>所以，滤镜(filter)效果对应的片元着色器可以这样写:<br>GLSL语言</p><pre><code class="c">precision mediump float;uniform sampler2D vTexture;uniform int vChangeType;uniform vec3 vChangeColor;uniform int vIsHalf;uniform float uXY;      //屏幕宽高比varying vec4 gPosition;varying vec2 aCoordinate;varying vec4 aPos;void modifyColor(vec4 color){    color.r=max(min(color.r,1.0),0.0);    color.g=max(min(color.g,1.0),0.0);    color.b=max(min(color.b,1.0),0.0);    color.a=max(min(color.a,1.0),0.0);}void main(){    vec4 nColor=texture2D(vTexture,aCoordinate);    if(aPos.x&gt;0.0||vIsHalf==0){        if(vChangeType==1){    //黑白图片            float c=nColor.r*vChangeColor.r+nColor.g*vChangeColor.g+nColor.b*vChangeColor.b;            gl_FragColor=vec4(c,c,c,nColor.a);        }else if(vChangeType==2){    //简单色彩处理，冷暖色调、增加亮度、降低亮度等            vec4 deltaColor=nColor+vec4(vChangeColor,0.0);            modifyColor(deltaColor);            gl_FragColor=deltaColor;        }else if(vChangeType==3){    //模糊处理            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.r,aCoordinate.y-vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.r,aCoordinate.y+vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.r,aCoordinate.y-vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.r,aCoordinate.y+vChangeColor.r));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.g,aCoordinate.y-vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.g,aCoordinate.y+vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.g,aCoordinate.y-vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.g,aCoordinate.y+vChangeColor.g));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.b,aCoordinate.y-vChangeColor.b));            nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.b,aCoordinate.y+vChangeColor.b));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.b,aCoordinate.y-vChangeColor.b));            nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.b,aCoordinate.y+vChangeColor.b));            nColor/=13.0;            gl_FragColor=nColor;        }else if(vChangeType==4){  //放大镜效果            float dis=distance(vec2(gPosition.x,gPosition.y/uXY),vec2(vChangeColor.r,vChangeColor.g));            if(dis&lt;vChangeColor.b){                nColor=texture2D(vTexture,vec2(aCoordinate.x/2.0+0.25,aCoordinate.y/2.0+0.25));            }            gl_FragColor=nColor;        }else{            gl_FragColor=nColor;        }    }else{        gl_FragColor=nColor;    }</code></pre><h3 id="相机预览"><a href="#相机预览" class="headerlink" title="相机预览"></a>相机预览</h3><p>利用OpenGLES显示图片处理图片。视频每一帧其实也是一张图片，Camera预览时，每一帧自然也是一幅图片，我们可以把每张图片按照时间顺序显示出来，就完成了Camera预览的实现。<br>当然不可能把相机每一帧的数据转成一个bitmap来操作，GLES20提供了绑定纹理贴图的函数。<br>GLES20.java</p><pre><code> // C function void glTexImage2D ( GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, const GLvoid *pixels )    public static native void glTexImage2D(        int target,        int level,        int internalformat,        int width,        int height,        int border,        int format,        int type,        java.nio.Buffer pixels    );</code></pre><p>完全就是c函数的包装<br>虽然OpenGLES给我们提供的入口是传入Buffer，然而，它却限制了Buffer的格式为单一通道，或者是RGBA、RGB等格式，而Camera的帧数据却只能为NV21或者YV21的<br>Android的Camera及Camera2都允许使用SurfaceTexture作为预览载体，但是它们所使用的SurfaceTexture传入的OpenGL texture object name必须为GLES11Ext.GL_TEXTURE_EXTERNAL_OES。这种方式，实际上就是两个OpenGL Thread共享一个Texture，不再需要数据导入导出，从Camera采集的数据直接在GPU中完成转换和渲染。<br>关键函数是surfaceTexture.updateTexImage()，每当摄像头有新的数据来时，我们需要通过surfaceTexture.updateTexImage()更新预览上的图像。</p><h3 id="图片处理"><a href="#图片处理" class="headerlink" title="图片处理"></a>图片处理</h3><p>冷色调、暖色调、复古、黑白这些滤镜效果其实就是把hex color的ARGB channel调整一下。</p><pre><code class="xml">&lt;color name=&quot;bg_color&quot;&gt;#FF88269F&lt;/color&gt;</code></pre><p>黑白图片是怎么来的？<br>黑白图片上，每个像素点的RGB三个通道值应该是相等的。知道了这个，将彩色图片处理成黑白图片就非常简单了。我们直接获取像素点的RGB三个通道，相加然后除以3作为处理后每个通道的值就可以得到一个黑白图片了。这是均值的方式是常见黑白图片处理的一种方法。类似的还有权值方法（给予RGB三个通道不同的比例）、只取绿色通道等方式。<br>与之类似的，冷色调的处理就是单一增加蓝色通道的值，暖色调的处理可以增加红绿通道的值。还有其他复古、浮雕等处理也都差不多。</p><p>类似的滤镜效果还有：<br>胶片效果：<br>就是把RGBA的A,R,G,B全部用255减掉<br>即：<br>A = 255 - A<br>R = 255 -R<br>G = 255 - G<br>B = 255 - B</p><p>但是实际上用取反操作符(~)就可以了<br>因为ARGB正好是4个byte(1个int)<br>比方说<br>1111， 取反(位非)之后变成11111110 11111110 11111110 11111110<br>也就是255减去的效果</p><p><a href="https://en.wikipedia.org/wiki/RGBA_color_space">这个RGBA的顺序不能搞错</a><br>In OpenGL and Portable Network Graphics (PNG), the RGBA (byte-order) is used, where the colors are stored in memory such that R is at the lowest address, G after it, B after that, and A last. On a little endian architecture this is equivalent to ABGR (word-order).</p><p>就是说，opengl和png数据中,byte array的顺序从内存低地址到高地址依次是RGBA，在小端上会掉头</p><p><a href="https://www.jianshu.com/p/12f06da0a4ec">Android 关于美颜/滤镜 从OpenGl录制视频的一种方案</a>有这样的操作byte[]的代码，需要指出的是。<br>java平台上，因为有jvm的存在，所以是大端。所以这下面的代码才成立</p><pre><code class="java"> int[] pixelData = new int[width * height];                int offset = 0;                int index = 0;                for (int i = 0; i &lt; height; ++i) {                    for (int j = 0; j &lt; width; ++j) {                        int pixel = 0;                        pixel |= (data[offset] &amp; 0xff) &lt;&lt; 16;     // R                        pixel |= (data[offset + 1] &amp; 0xff) &lt;&lt; 8;  // G                        pixel |= (data[offset + 2] &amp; 0xff);       // B                        pixel |= (data[offset + 3] &amp; 0xff) &lt;&lt; 24; // A                        pixelData[index++] = pixel;                        offset += pixelStride;                    }                    offset += rowPadding;                }</code></pre><p>图片模糊<br>图片模糊处理相对上面的色调处理稍微复杂一点，通常图片模糊处理是采集周边多个点，然后利用这些点的色彩和这个点自身的色彩进行计算，得到一个新的色彩值作为目标色彩。模糊处理有很多算法，类似高斯模糊、径向模糊等等。</p><h3 id="YUV格式解释-相机返回的是YUV格式的图像数据"><a href="#YUV格式解释-相机返回的是YUV格式的图像数据" class="headerlink" title="YUV格式解释(相机返回的是YUV格式的图像数据)"></a>YUV格式解释(相机返回的是YUV格式的图像数据)</h3><blockquote><p>RGB图像大家都了解，RGB图像分为了三个颜色分量，R红色分量，G绿色分量，B蓝色分量。而YUV图像，也是分为了三个分量，Y亮度分量，用来表示明亮度，也叫灰阶值，U分量和V分量是色值分量，用来表示图像色彩与饱和度，其中U分量也叫Cb，表示的图像蓝色偏移量，V分量也叫Cr，用来表示图像红色部分偏移量，所以YUV有时也写作YCbCr。<br>YUV图像把亮度和色度分开了，避免了亮度和色度的相互干扰，可以在降低色度采样率的情况下，保持图像的视觉质量。<br>```<br>RGB转YUV:</p></blockquote><p>Y = 0.299 R + 0.587 G + 0.114 B</p><p>U = - 0.1687 R - 0.3313 G + 0.5 B + 128</p><p>V = 0.5 R - 0.4187 G - 0.0813 B + 128</p><p>YUV转RGB:</p><p>R = Y + 1.402 (V - 128)</p><p>G = Y - 0.34414 (U - 128) - 0.71414 (V - 128)</p><p>B = Y + 1.772 (U - 128)</p><pre><code>Camera可以通过setPreviewFormat()方法来设置预览图像的数据格式，推荐选择的有ImageFormat.NV21和ImageFormat.YV12，默认是NV21。NV21属于YUV图像.[Android Camera2 API YUV_420_888 to JPEG](https://stackoverflow.com/questions/40090681/android-camera2-api-yuv-420-888-to-jpeg)[YuvImage.compressToJpeg](https://developer.android.com/reference/android/graphics/YuvImage.html#compressToJpeg(android.graphics.Rect,%20int,%20java.io.OutputStream)) android sdk提供了将yuv转为jpg的方法</code></pre><p>public boolean compressToJpeg (Rect rectangle,<br>                int quality,<br>                OutputStream stream)<br>```<br>将一个YuvImage压缩成jpeg，存到一个outputStream中。<strong>这个方法借助Android的JNI，实现了非常高效率的JPEG格式文件写入（比Bitmap.compress()效率都要高不少）</strong></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://developer.android.com/guide/topics/graphics/opengl">opengles guide on android</a><br><a href="https://blog.csdn.net/junzia/article/details/77924629">Android利用硬解硬编和OpenGLES来高效的处理MP4视频</a><br><a href="https://github.com/aiyaapp/AiyaEffectsAndroid">第三方实例</a><br><a href="https://blog.csdn.net/tanningzhong/article/details/77989686">利用 FFmpeg 在 Android 上做视频编辑</a><br><a href="https://github.com/JimSeker/opengl">2018年还在更新的</a><br><a href="https://www.polarxiong.com/archives/Android-MediaCodec%E8%A7%86%E9%A2%91%E6%96%87%E4%BB%B6%E7%A1%AC%E4%BB%B6%E8%A7%A3%E7%A0%81-%E9%AB%98%E6%95%88%E7%8E%87%E5%BE%97%E5%88%B0YUV%E6%A0%BC%E5%BC%8F%E5%B8%A7-%E5%BF%AB%E9%80%9F%E4%BF%9D%E5%AD%98JPEG%E5%9B%BE%E7%89%87-%E4%B8%8D%E4%BD%BF%E7%94%A8OpenGL.html">硬件解码视频范例</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;topics relating opengl stuff&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/scenery151110074347.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="opengl" scheme="https://haldir65.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>python中多进程、多线程以及GIL记录</title>
    <link href="https://haldir65.github.io/2018/11/11/2018-11-11-python-gil-and-what-you-can-do-about-it/"/>
    <id>https://haldir65.github.io/2018/11/11/2018-11-11-python-gil-and-what-you-can-do-about-it/</id>
    <published>2018-11-11T22:21:52.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/1102533137-5.jpg" alt=""></p><ul><li>If your code has a lot of I/O or Network usage:<br>Multithreading is your best bet because of its low overhead</li><li>If you have a GUI<br>Multithreading so your UI thread doesn’t get locked up</li><li>If your code is CPU bound:<br>You should use multiprocessing (if your machine has multiple cores)</li></ul><a id="more"></a><p>Python Global Interpreter Lock(GIL)<br>对于CPython，所有的python bytecode在执行前都需要获得interpreter的lock,one vm thread at a time。(java实现的python似乎没有这个烦恼)<br>GIL的出现似乎是历史原因（为了方便的直接使用当时现有的c extension）。而没有在python3中被移除的原因是因为这会造成单线程的程序在python3中跑的反而比python2中慢。</p><p>因为GIL的存在，python中的线程并不能实现cpu的并发运行(同时只能有一条线程在运行)。但对于I/O intensive的任务来说，cpu都在等待I/O操作完成，所以爬虫这类操作使用多线程是合适的。根据<a href="https://www.youtube.com/watch?v=7SSYhuk5hmc">A Jesse Jiryu Davis</a>在pycon2017上的演讲，在多线程python程序中，如果某条线程开始进行I/O操作，就会主动放弃GIL(这是在socket module的源码中)，或者在cpu-intensive程序中，一条线程连续执行1000次(python2中是一个常数)后就会被夺走gil。<a href="https://github.com/python/cpython/blob/master/Modules/socketmodule.c">socket里面找关键字Py_BEGIN_ALLOW_THREADS和Py_END_ALLOW_THREADS</a> 这是两个macro，自己写python c entension的时候可能会用得上</p><h2 id="多线程以及一些同步的问题"><a href="#多线程以及一些同步的问题" class="headerlink" title="多线程以及一些同步的问题"></a>多线程以及一些同步的问题</h2><p>单线程的版本</p><pre><code class="python"># single_threaded.pyimport timefrom threading import ThreadCOUNT = 50000000def countdown(n):    while n&gt;0:        n -= 1start = time.time()countdown(COUNT)end = time.time()print(&#39;Time taken in seconds -&#39;, end - start)</code></pre><p>多线程的版本<br>多线程下总会对公共资源的操作是需要考虑race condition的，并且这种问题很难通过测试测出来。</p><pre><code class="python"># multi_threaded.pyimport timefrom threading import ThreadCOUNT = 50000000def countdown(n):    while n&gt;0:        n -= 1t1 = Thread(target=countdown, args=(COUNT//2,))t2 = Thread(target=countdown, args=(COUNT//2,))start = time.time()t1.start()t2.start()t1.join()t2.join()end = time.time()print(&#39;Time taken in seconds -&#39;, end - start)</code></pre><p>多线程虽然同一时刻只能有一条线程运行，但牵涉到数据共享的时候还是要加锁<br><img src="https://haldir66.ga/static/imgs/lockExplanation.jpg" alt=""></p><p>比如这个例子，照说打印出来的应该是0，但实际操作中可能打出来正数</p><pre><code class="python">import time, threading# 假定这是你的银行存款:balance = 0def change_it(n):    # 先存后取，结果应该为0:    global balance    balance = balance + n    balance = balance - ndef run_thread(n):    for i in range(1000000):        change_it(n)t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print(balance)</code></pre><p>上述过程的原因在于<br>balance = balance + n<br>这一步其实需要至少两条cpu语句：<br>x = balance +n<br>balance = x </p><p>正常顺序是t1 (+5,-5) t2 (+8, -8) 这样的顺序<br>不正常的顺序</p><pre><code>初始值 balance = 0t1: x1 = balance + 5  # x1 = 0 + 5 = 5t2: x2 = balance + 8  # x2 = 0 + 8 = 8t2: balance = x2      # balance = 8t1: balance = x1      # balance = 5t1: x1 = balance - 5  # x1 = 5 - 5 = 0t1: balance = x1      # balance = 0t2: x2 = balance -8 # x2 =-8t2: balance = x2 # balance = -8结果 balance = -8</code></pre><p>所以是有可能打印出-8这样的错误的结果的</p><p>这种情况下只要加锁就可以了</p><pre><code class="python">import time, threadingbalance = 0lock = threading.Lock()def change_it(n):    global balance    balance = balance + n    balance = balance - ndef run_thread(n):    for i in range(1000000):        lock.acquire()        try:            change_it(n)        finally:            lock.release()t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print(balance)</code></pre><p>改成每一次对共享变量进行操作都需要加锁之后，打印结果就正常了<br><a href="https://hackernoon.com/synchronization-primitives-in-python-564f89fee732">多进程之间的同步方式包括queue,Event,Semaphores，Conditions等</a></p><p>从bytecode来看，<a href="https://www.youtube.com/watch?v=7SSYhuk5hmc&amp;t=890s">increment这一操作并不是atomic的</a><br>python里面很方便<br>incremnt-is-not-atomic.py</p><pre><code class="python">def foo():    global n    n += 1import disdis.dis(foo)</code></pre><p>python incremnt-is-not-atomic.py</p><pre><code> 3           0 LOAD_GLOBAL              0 (n)              2 LOAD_CONST               1 (1)              4 INPLACE_ADD              6 STORE_GLOBAL             0 (n)              8 LOAD_CONST               0 (None)             10 RETURN_VALUE</code></pre><h3 id="多线程环境下对资源的操作需要考虑线程安全问题"><a href="#多线程环境下对资源的操作需要考虑线程安全问题" class="headerlink" title="多线程环境下对资源的操作需要考虑线程安全问题"></a>多线程环境下对资源的操作需要考虑线程安全问题</h3><p>有些操作不是原子性的<br><a href="https://www.youtube.com/watch?v=Bv25Dwe84g0">Thinking about Concurrency, Raymond Hettinger, Python core developer</a><br>java中最初的设计是有kill thread的method的，但是后来被deprecated了（假设你kill了一个获取了锁的线程，程序将进入死锁状态）。 python中理论上是可以kill一个线程的，但是kill一个线程这件事本身就是不应该的。</p><p>一个最简单的多线程资源竞争的例子</p><pre><code class="python">import threadingcounter = 0def worker():    global counter    counter += 1     print(&#39;The count is %d&#39; % counter)    print(&#39;------------&#39;)print(&#39;Starting up --------&#39;)for i in range(10):    threading.Thread(target=worker).start()print(&#39;Finishing up&#39;)</code></pre><p>输出</p><pre><code>Starting up --------The count is 1------------The count is 2------------The count is 3------------The count is 4------------The count is 5------------The count is 6------------The count is 7------------The count is 8------------The count is 9------------The count is 10------------Finishing up</code></pre><p>数据量比较小的时候不容易发现这里存在的race condition。如果在每一次对资源进行操作之间都插入一段thread.sleep，问题就出来了</p><pre><code class="python">import threading,time, randomFUZZ = Truedef fuzz():    if FUZZ:        time.sleep(random.random())counter = 0def worker():    global counter    fuzz()    oldcnt = counter    fuzz()    counter = oldcnt +1    fuzz()    print(&#39;The count is %d&#39; % counter)    fuzz()    print(&#39;------------&#39;)    fuzz()print(&#39;Starting up --------\n&#39;)fuzz()for i in range(10):    t = threading.Thread(target=worker)    t.start()    fuzz()print(&#39;Finishing up&#39;)  fuzz()</code></pre><p>资源竞争场景下，问题就出来了</p><pre><code>Starting up --------The count is 1------------The count is 2The count is 3------------------------The count is 5The count is 5------------------------The count is 5------------Finishing upThe count is 7The count is 8------------------------The count is 8------------The count is 8------------</code></pre><p>多线程之间的同步问题，一种是加锁，另一种是使用atomic message queue.<br>python中有些module内部已经加了锁，logging,decimal(thread local),databases(reader locks and writer locks),email(atomic message queue)。<br>锁在写operating system的时候非常有用，但是其他时候不要用。<br>所有的资源都应该只能同时被一条线程操作。<br>threading中的join就属于一种barrier（主线程调用t.join，就是等t跑完了之后，主线程再去干接下来的事情） </p><p><strong>Raymond Hettinger提到message queue的task_done方法是他created的。</strong><br>(还是atomic measge queue, 好像是内部加了锁，操作queue中资源的只有那么一条线程，当然不存在并发问题). 其实raymod也提到了，你也可以用RabbitMQ等,ZEROMQ 甚至是database（内部有read write lock）</p><pre><code class="python">def worker():    while True:        item = q.get()        do_work(item)        q.task_done()q = Queue()for i in range(num_worker_threads):     t = Thread(target=worker)     t.daemon = True     t.start()for item in source():    q.put(item)q.join()       # block until all tasks are done</code></pre><p>爬虫简单的多线程版本是每个线程创建的时候，就给出一个args = [someurl] ，然后有多少任务就创建多少线程。但是这样做迟早会碰上操作系统对最大线程数的设置[据说400+]，于是又想到用threadPool,自己实现threadpool的也是大有人在（内部持有一个任务队列，不停去队列里获取任务）。(<a href="https://www.shanelynn.ie/using-python-threading-for-multiple-results-queue/">https://www.shanelynn.ie/using-python-threading-for-multiple-results-queue/</a>)</p><pre><code>error: can&#39;t start new threadFile &quot;/usr/lib/python2.5/threading.py&quot;, line 440, in start    _start_new_thread(self.__bootstrap, ())</code></pre><p>那么比较实用的使用场景是，spawn 10条线程去进行while not queue.empty() -&gt; requests.get()操作，各自在完成之后丢到一个通用的容器中，再由message queue独立完成所有response的processing.<br>到这里还只是停留在<strong>多线程</strong>的阶段。</p><h2 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h2><p>人们很容易想到多进程的版本，可以不用顾虑GIL的存在</p><pre><code class="python">from multiprocessing import Poolimport timeCOUNT = 50000000def countdown(n):    while n&gt;0:        n -= 1if __name__ == &#39;__main__&#39;:    pool = Pool(processes=2)    start = time.time()    r1 = pool.apply_async(countdown, [COUNT//2])    r2 = pool.apply_async(countdown, [COUNT//2])    pool.close()    pool.join()    end = time.time()    print(&#39;Time taken in seconds -&#39;, end - start)</code></pre><p>多进程之间内存不共享，同步方式是使用Queue(fifo)</p><pre><code class="python">#!/usr/bin/env python3import multiprocessingimport timeimport randomimport osfrom multiprocessing import Queueq = Queue()def hello(n):    time.sleep(random.randint(1,3))    q.put(os.getpid())    print(&quot;[{0}] Hello!&quot;.format(n))processes = [ ]for i in range(10):    t = multiprocessing.Process(target=hello, args=(i,))    processes.append(t)    t.start()for one_process in processes:    one_process.join()mylist = [ ]while not q.empty():    mylist.append(q.get())print(&quot;Done!&quot;)print(len(mylist))print(mylist)</code></pre><p>更加Pythonic的方式是使用asyncio</p><h2 id="Asyncio"><a href="#Asyncio" class="headerlink" title="Asyncio"></a>Asyncio</h2><p>优点包括</p><ul><li>Based on futures</li><li>Faster than threads</li><li>Massive I/O concurrency</li></ul><pre><code class="python">async def fetch_url(url):        return await aiohttp.request(&#39;GET&#39; , url) ## you get the future, the function is not executed immediatedlyasync def fetch_two(url_a,url_b):        future_a = fetch_url(url_a)        future_b = fetch_url(url_b)        a ,b = await asyncio.gather(future_a, future_b)  ## 一旦开始await这个future,这个coroutine才会被加入event loop        return a, b</code></pre><p>上述代码虽然还是在同一个进程中运行，还受到GIL制约，但是由于是I/O操作，所以也没什么问题。只是在process返回的结果是，就会受到GIL的影响了。（实际操作中你会发现coroutine还没执行就timeout了）</p><p>@asyncio.coroutine这个decorator是3.4出现的，3.5之后直接使用async await关键字。这个decorator也就过时了</p><pre><code class="python">import asyncioimport timeasync def speak_async():     print(&#39;starting====&#39;)     r = await asyncio.sleep(1) ##这里不能使用time.sleep(1)    print(&#39;OMG asynchronicity!&#39;)loop = asyncio.get_event_loop()  loop.run_until_complete(speak_async())  loop.close()</code></pre><p>对于阻塞式的io调用，不是说加一个await函数就能实现异步了<br>To use requests (or any other blocking libraries) with asyncio, you can use BaseEventLoop.run_in_executor to run a function in another thread and yield from it to get the result.<br>asyncio毕竟只有一条线程，所以request这种阻塞式的函数不能直接拿来用，需要run_in_executor或者用线程池、进程包装一下</p><pre><code class="python">import timeimport requestsimport asyncioasync def getUrlBlocking(url):    print(&quot;starting request to %s &quot; % url)    loop = asyncio.get_event_loop()    response = await loop.run_in_executor(None, requests.get, url)    print(response.status_code)    return responseasync def gotResponse(url):    res = await getUrlBlocking(url)    print(res.text)    return resif __name__ == &quot;__main__&quot;:    s = time.perf_counter()    loop = asyncio.get_event_loop()    tasks = [gotResponse(&quot;https://jsonplaceholder.typicode.com/posts/%s&quot; % i) for i in range(100)]    loop.run_until_complete(asyncio.wait(tasks))    loop.close()    elapsed = time.perf_counter() - s    print(f&quot;{__file__} executed in {elapsed:0.2f} seconds.&quot;)</code></pre><p>async await要求await的东西是<a href="https://docs.python.org/3/reference/datamodel.html#awaitable-objects">awaitable的</a></p><h3 id="asyncio中创建任务的语法有好几种"><a href="#asyncio中创建任务的语法有好几种" class="headerlink" title="asyncio中创建任务的语法有好几种"></a>asyncio中创建任务的语法有好几种</h3><pre><code class="python">import asyncio  async def doit(i):    print(&quot;Start %d&quot; % i)    await asyncio.sleep(3)    print(&quot;End %d&quot; % i)    return iif __name__ == &#39;__main__&#39;:    loop = asyncio.get_event_loop()    #futures = [asyncio.ensure_future(doit(i), loop=loop) for i in range(10)]    #futures = [loop.create_task(doit(i)) for i in range(10)]    futures = [doit(i) for i in range(10)]    result = loop.run_until_complete(asyncio.gather(*futures))    print(result)</code></pre><p>以上这三种创造出来的task全部都是无序执行的。不过python3.7以后官方更推荐使用asyncio.create_task (3.7+添加的)而不是ensure_future(3.7之前)去创建任务。</p><p>所以一般的将async tasks添加到event loop的套路是这样的。main函数是async 的，3.5-3.6麻烦一点，3.7最简单<br>python3.5-3.6</p><pre><code class="python">loop = asyncio.get_event_loop()try:    loop.run_until_complete(main())finally:    loop.close()</code></pre><p>python 3.7</p><pre><code class="python">asyncio.run(main())  # Python 3.7+</code></pre><pre><code>Generator functions are, as it so happens, the foundation of async IO (regardless of whether you declare coroutines with async def rather than the older @asyncio.coroutine wrapper). Technically, await is more closely analogous to yield from than it is to yield. (But remember that yield from x() is just syntactic sugar to replace for i in x(): yield i.)</code></pre><p><strong>generator函数(无论是用asyc def创建的还是用@asyncio.coroutine的docorator)是asyncio的基础。从技术层面来讲,await ≈≈ yield from (但是记住yield from x() 只是一个语法糖而已)</strong></p><h2 id="Mulitiprocessing-is-good-asyncio-is-great-Why-not-both"><a href="#Mulitiprocessing-is-good-asyncio-is-great-Why-not-both" class="headerlink" title="Mulitiprocessing is good , asyncio is great, Why not both"></a>Mulitiprocessing is good , asyncio is great, Why not both</h2><p>也就是说，I/O操作用asyncio，数据处理使用multi-processing，这几乎是完美的解决方案了<br>正常情况下，一个async event是跑在一条线程，一个cpu core上就足够了。<a href="https://www.youtube.com/watch?v=0kXaLh8Fz3k">John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018</a> 这里讲述了如何在多个core之间跑一个event loop<br>由于coroutine和multi-processing是两个相对独立的模块，所以需要自己把两者结合起来。用多进程进行数据处理，每个进程中各自有独立的coroutine在运行。</p><pre><code class="python">async def run_loop(tx, rx):        ... ## real work here         limit = 10        pending = set()        while True:                while len(pending) &lt; limit:                        task = tx.get_nowait()                        fn ,args, kwargs = task                        pending.add(fn(args,kwargs))                done, pending = await asyncio.wait(pending, ..)                        for future in done:                        rx.put_nowait(await future)def bootstrap(tx, rx):        loop = asyncio.new_event_loop()        asyncio.set_event_loop(loop)        loop.run_untile_complete(run_loop(tx, rx))def main():                p = multiprocessing.Process(target = bootstrap, args = (tx, rx))        p.start()</code></pre><p>实际操作可能看起来像这样</p><pre><code class="python">async def fetch_url(url):        return await aiohttp.request(&#39;GET&#39; , url) def fetch_all(urls):       tx, rx = Queue(), Queue()       Process(               target=bootstrap,               args=(tx,rx)       ).start()       for url in urls:           task = fetch_url,(url,), {}           tx.put_nowait(task)</code></pre><p><strong>已经开源</strong><br><a href="https://github.com/dano/aioprocessing">aioprocessing</a></p><blockquote><p> pip install aiomultiprocess</p></blockquote><h2 id="关于协程"><a href="#关于协程" class="headerlink" title="关于协程"></a>关于协程</h2><p>coroutine是一个在很多编程语言中都有的概念，在python中coroutine一般指的是generator based coroutines。<br>首先，因为协程是一种能暂停的函数，那么它暂停是为了什么？一般是等待某个事件，比如说某个连接建立了；某个 socket 接收到数据了；某个计时器归零了等。而这些事件应用程序只能通过轮询的方式得知是否完成，<strong>但是操作系统（所有现代的操作系统）可以提供一些中断的方式通知应用程序，如 select, epoll, kqueue 等等</strong>。<br><a href="https://lotabout.me/2017/understand-python-asyncio/">understand-python-asyncio</a></p><p>基础是generator(任何包含yield expression的函数)</p><pre><code>$ &gt;&gt;&gt;def gen_fn():        print(&#39;start&#39;)        yiled 1        print(&#39;middle&#39;)        yield 2        print(&#39;done&#39;)$ &gt;&gt;&gt; gen = gen_fn()$ &gt;&gt;&gt; gen$ &lt;generator object gen_fn at 0x7f83cddc0b48&gt;&gt;&gt;&gt; gen.gi_code.co_code //对应的bytecodeb&#39;t\x00d\x01\x83\x01\x01\x00d\x02V\x00\x01\x00t\x00d\x03\x83\x01\x01\x00d\x04V\x00\x01\x00t\x00d\x05\x83\x01\x01\x00d\x00S\x00&#39;&gt;&gt;&gt; len(gen.gi_code.co_code)40&gt;&gt;&gt; gen.gi_frame.f_lasti //instruction pointer , 说明当前执行到哪个指令了，-1说明还没有开始执行-1&gt;&gt;&gt; next(gen)start1&gt;&gt;&gt; ret = next(gen)middle&gt;&gt;&gt; ret2 // next方法返回的是yield里面的值&gt;&gt;&gt; next(gen)doneTraceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;StopIteration // 这是正常的，说明generator执行完毕&gt;&gt;&gt; import dis&gt;&gt;&gt; dis.dis(gen)  2           0 LOAD_GLOBAL              0 (print)              2 LOAD_CONST               1 (&#39;start&#39;)              4 CALL_FUNCTION            1              6 POP_TOP  3           8 LOAD_CONST               2 (1)             10 YIELD_VALUE             12 POP_TOP  4          14 LOAD_GLOBAL              0 (print)             16 LOAD_CONST               3 (&#39;middle&#39;)             18 CALL_FUNCTION            1             20 POP_TOP  5          22 LOAD_CONST               4 (2)             24 YIELD_VALUE             26 POP_TOP  6          28 LOAD_GLOBAL              0 (print)             30 LOAD_CONST               5 (&#39;done&#39;)             32 CALL_FUNCTION            1             34 POP_TOP             36 LOAD_CONST               0 (None)             38 RETURN_VALUE&gt;&gt;&gt;</code></pre><p>python3.3中开始出现yield关键字，python3.4中开始引入asyncio标准库，python 3.5标准库中出现的async await关键字只是基于generator的sytatic sugar，那么<a href="https://stackoverflow.com/questions/8389812/how-are-generators-and-coroutines-implemented-in-cpython">generator是如何实现的</a>.</p><ul><li>The yield instruction takes the current executing context as a closure, and transforms it into an own living object. This object has a <strong>iter</strong> method which will continue after this yield statement.<br>So the call stack gets transformed into a heap object.</li></ul><p><a href="https://hackernoon.com/the-magic-behind-python-generator-functions-bc8eeea54220">解释generator实现原理的文章</a></p><p><a href="https://snarky.ca/how-the-heck-does-async-await-work-in-python-3-5/">python 2.5开始，generator能够返回数据，这之前还只是iteratble的</a> 还可以通过gen.send函数往generator传参数<br><a href="https://github.com/AndreLouisCaron/a-tale-of-event-loops">event-loop的实现原理简述</a></p><p>python中event loop是plugable的，也就是说完全可以提供自己开发的版本。所以就有了<a href="https://github.com/MagicStack/uvloop">uvloop</a>这种跑分特别高的。asyncio包默认只提供了两种eventLoop的实现，分别是<br>class asyncio.SelectorEventLoop(unix和windows上)<br>class asyncio.ProactorEventLoop(windows上)<br>查看windows_events.py中，默认的asyncio.get_event_loop()获得的就是SelectorEventLoop</p><p>基于asyncio的有名的库包括aiohttp和aiofile。二者都是对i/o进行操作 。<br>更多的还有aio-redis, aio-lrucache….</p><h2 id="牵涉到一些celery的点"><a href="#牵涉到一些celery的点" class="headerlink" title="牵涉到一些celery的点"></a>牵涉到一些celery的点</h2><p>celery能够利用好多进程<br>todo</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://codewithoutrules.com/2018/09/04/python-multiprocessing/">多进程还可以牵涉到进程池的概念</a><br><a href="https://realpython.com/python-gil/">What is the Python Global Interpreter Lock (GIL)?</a><br><a href="https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/">multiprocessing-vs-multithreading-in-python-what-you-need-to-know</a><br><a href="https://emptysqua.re/blog/links-for-how-python-coroutines-work/">A. Jesse Jiryu Davis</a><br><a href="https://www.youtube.com/watch?v=7sCu4gEjH5I">How Do Python Coroutines Work</a><br><a href="https://www.youtube.com/watch?v=7SSYhuk5hmc">A Jesse Jiryu Davis Grok the GIL Write Fast And Thread Safe Python PyCon 2017</a> the only thing two threads cann’t do in once in Python is run python<br><a href="https://engineering.mongodb.com/post/the-saga-of-concurrent-dns-in-python-and-the-defeat-of-the-wicked-mutex-troll/">Behold, my friends, the getaddrinfo lock in Python’s socketmodule.c:</a>  A. Jesse Jiryu Davis关于python中parallel dns query的文章也很好<br><a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">uvloop跑分</a><br><a href="https://realpython.com/async-io-python/">asyncio in python</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/1102533137-5.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If your code has a lot of I/O or Network usage:&lt;br&gt;Multithreading is your best bet because of its low overhead&lt;/li&gt;
&lt;li&gt;If you have a GUI&lt;br&gt;Multithreading so your UI thread doesn’t get locked up&lt;/li&gt;
&lt;li&gt;If your code is CPU bound:&lt;br&gt;You should use multiprocessing (if your machine has multiple cores)&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="python" scheme="https://haldir65.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>tcpdump和wireshark使用手册</title>
    <link href="https://haldir65.github.io/2018/11/10/2018-11-10-tcpdump-and-wireshark-etc/"/>
    <id>https://haldir65.github.io/2018/11/10/2018-11-10-tcpdump-and-wireshark-etc/</id>
    <published>2018-11-10T20:57:53.000Z</published>
    <updated>2019-03-13T02:30:25.326Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/osi-model.png" alt=""><br><a href="http://packetlife.net/media/library/13/Wireshark_Display_Filters.pdf">wireshark expression cheetsheet</a><br><a href="http://packetlife.net/media/library/12/tcpdump.pdf">tcpdump cheet</a><br>wireshark能抓tcp,arp,http,dns,udp,icmp,dhcp…</p><a id="more"></a><p>先从wireshark说起，在win10上安装wireshark需要顺带装上winpacp，不过现在的安装包默认都会提示去安装，所以也都很简单<br>tcpdump在Linux上比较容易安装，类似于wireshark的command line tool</p><h3 id="wireshark的filter"><a href="#wireshark的filter" class="headerlink" title="wireshark的filter"></a>wireshark的filter</h3><p>现在wireshark的filter都会自动提示了，所以基本上随手敲几个就行了</p><p>http ##只看http的<br>http.request<br>tcp.dstport == 443 ## 只看https的<br>tcp.port == 113 ## 不管是source还是destination，只要是port 113的都筛出来(113是一个特殊的端口 Identification Protocol, Ident)<br>udp.port== 53 ## 筛选出所有的dns查询<br>ip.addr eq 192.168.1.3 and ip.addr eq 192.168.1.1 //假设本机ip是192.168.1.3并且路由器是192.168.1.1的话，这个可以筛选出所有的ipv4包<br>ip.src == 192.168.1.3 &amp;&amp; tcp.port == 80 //两个命令串联起来也是可以的<br>ip.addr //既包含src也包含dst<br>udp ||http // udp或者http的包<br>frame.len &lt;=128 //显示所有体积小于128个字节的包</p><p>//如果一开始就只对特定协议感兴趣<br>capture -&gt; filters 里面可以选择只抓某些协议的包。因为默认是什么都抓，这样会少很多</p><h3 id="一些有用的操作"><a href="#一些有用的操作" class="headerlink" title="一些有用的操作"></a>一些有用的操作</h3><p>选中一个column，右键 -&gt; follow -&gt;tcpstream ，可以查看这个packet的来回信息。（如果是http的话，request和response都给出来了）<br>菜单栏上的Statistics -&gt; conversatitons （查看所有的会话）<br>wireshark的结果可以save成.cap文件，下次可以打开<br>菜单栏上的Statistics -&gt; protocol Hierarchy(查看所有的协议)<br>菜单栏view -&gt; coloring rule（直接将特定的协议变成特定颜色的背景，方便识别）<br>view -&gt; time displayformat(格式化packet的时间显示成便于识别的时间，因为默认的显示单位是毫秒)<br>Statistics -&gt; endpoints // 查看所有连接过的ip</p><p>Statistics -&gt; packet length //查看所有的packet length（多数时候包的大小在40-79和1280-2559这个区间里面，没有小于40的，因为最少得40个字节）</p><ul><li>arp(addression resolution protocol)<br>一台电脑在发出去一个包之前，已经知道dest的ip地址，但是不知道这个ip地址对于的mac地址是多少，于是会发出一份arp request。<br>在局域网内部，是这样的</li><li>who has 192.168.1.1 ? Tell 192.168.1.7  //电脑发出arp请求</li><li>192.168.1.1 is at 00:xx:00:xe:b5 //很快得到了回应</li></ul><p><a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol">arp包结构</a></p><p>一个ipv4地址需要32个bit表示,192.168.1.1这种写法叫做base10<br>一般情况下，192.168这俩一般表示的是network address, .1.1这俩一般表示的是Host address(physical computer)<br>net mask(255.255.0.0) 192.168.1/16。</p><h3 id="选中一个tcp包，查看Internet-Protocol-Version4-这里就是第三层-network层了-。"><a href="#选中一个tcp包，查看Internet-Protocol-Version4-这里就是第三层-network层了-。" class="headerlink" title="选中一个tcp包，查看Internet Protocol Version4 ..(这里就是第三层,network层了)。"></a>选中一个tcp包，查看Internet Protocol Version4 ..(这里就是第三层,network层了)。</h3><p><img src="https://haldir66.ga/static/imgs/wire_shark_internet_protocol_version4.png" alt=""><br>从上到下依次是<br>version: 4<br>Header length 20bytes<br>Differentiated Services Filed(不懂)<br>Total Length(这个是包含了)<br>Identification(类似于id)<br>Flags : 0x4000, Dont’t fragment(这个牵涉到mtu,maximum transmission unit size, 这个数值在ethernet上是1500bytes。假如一个包大小超过这个数，切成两个,也就是fragment.这个Flags里面可以看到More fragment: not set （0），意思就是说这个包没有被切成两个。有两种情况下这个标志设为0，一是没有分包，而是这个包恰好是最后一个)<br>Fragment offset：0 (假如被切成两个了，这里就表示当前这个包是被切完之后的第一个还是第二个，就当是index吧)。<br>这个包是访问google时留下的</p><p>有一个Time to live:128 (就是说这个包最多走128hop，就是最多经手128个router就丢掉)</p><h3 id="再看第四层（Transport-layer），也就是tcp-udp这类了。"><a href="#再看第四层（Transport-layer），也就是tcp-udp这类了。" class="headerlink" title="再看第四层（Transport layer），也就是tcp,udp这类了。"></a>再看第四层（Transport layer），也就是tcp,udp这类了。</h3><p>还是上面这个包<br><img src="https://haldir66.ga/static/imgs/wire_shark_capture_transmission_control_protocol.png" alt=""><br>从上到下依次是<br>Source Port<br>Destination Port :443 //https无疑<br>stream index: 4<br>sequence number 496 //确保数据没有丢失<br>Acknowledgement number : 4043 //下一个包的sequence number<br>Flags(urg:urgent,push:push,rst:reset,sin&amp;fin(finished))这张图里面写的是Acknowledgment(显然是ack包)<br>window size value: 2053(这个是tcp receiver buffer，单位是byte，这个数值变来变去的)<br>checksum(检查数据完整)</p><h2 id="说一说handshake"><a href="#说一说handshake" class="headerlink" title="说一说handshake"></a>说一说handshake</h2><p>tcp packets始于一个handshake<br>检查端口，发送一个sequence number(随机的),客户端会发送一个syn packet到接受方。接受方会返回一个syn ack packet,接下来客户端发送一个ack packet。上述步骤每一次sequence number都会+1<br><img src="https://haldir66.ga/static/imgs/wireshark_tcp_handshake.png" alt=""></p><pre><code>1. Client 发送 SYN 包（seq: x），告诉 Server：我要建立连接；Client 进入SYN-SENT状态；2. Server 收到 SYN 包后，发送 SYN+ACK 包（seq: y; ack: x+1），告诉它：好的；Server 进入SYN-RCVD状态；3. Client 收到 SYN+ACK 包后，发现 ack=x+1，于是进入ESTABLISHED状态，同时发送 ACK 包（seq: x+1; ack: y+1）给 Server；Server 发现 ack=y+1，于是也进入ESTABLISHED状态；接下来就是互相发送数据、接收数据了……</code></pre><h3 id="tcp-teardown-四次挥手告别"><a href="#tcp-teardown-四次挥手告别" class="headerlink" title="tcp teardown(四次挥手告别)"></a>tcp teardown(四次挥手告别)</h3><p>host发送给destination一个fin acknowledge packet<br>destination发挥一个ack packet和一个fin ack packet<br>host再发送一个ack(这些都可以从flags里面看到)<br><img src="https://haldir66.ga/static/imgs/wireshark_tcp_wave.png" alt=""></p><pre><code>注意，可以是连接的任意一方主动 close，这里假设 Client 主动关闭连接：1. Client 发送 FIN 包，告诉 Server：我已经没有数据要发送了；Client 进入FIN-WAIT-1状态；2. Server 收到 FIN 包后，回复 ACK 包，告诉 Client：好的，不过你需要再等会，我可能还有数据要发送；Server 进入CLOSE-WAIT状态；而 Client 收到 ACK 包后，继续等待 Server 做好准备， Client 进入FIN-WAIT-2状态；3. Server 准备完毕后，发送 FIN 包，告诉 Client：我也没有什么要发送了，准备关闭连接吧；Server 进入LAST-ACK状态；4. Client 收到 FIN 包后，知道 Server 准备完毕了，于是给它回复 ACK 包，告诉它我知道了，于是进入TIME-WAIT状态；而 Server 收到 ACK 包后，即进入CLOSED状态；Client 等待 2MSL 时间后，没有再次收到 Server 的 FIN 包，于是确认 Server 收到了 ACK 包并且已关闭，于是 Client 也进入CLOSED状态；</code></pre><p>MSL即报文最大生存时间，RFC793 中规定 MSL 为 2 分钟，但这完全是从工程上来考虑，对于现在的网络，MSL=2分钟可能太长了一些。实际应用中常用的是 30 秒、1 分钟、2 分钟等；可以修改/etc/sysctl.conf内核参数，来缩短TIME_WAIT的时间，避免不必要的资源浪费。</p><p>所以整个tcp传输的过程看起来像这样<br><img src="https://haldir66.ga/static/imgs/wireshark_tcp_handwave.jpg" alt=""></p><p>有时候会看到rest，意味着连接突然中断了（tcp会断掉这个sequence的所有packet，把flags里面的reset设置为1）</p><h3 id="DHCP-Dynamic-Host-Configuration-Protocol-这个位于第7层"><a href="#DHCP-Dynamic-Host-Configuration-Protocol-这个位于第7层" class="headerlink" title="DHCP (Dynamic Host Configuration Protocol)这个位于第7层"></a>DHCP (Dynamic Host Configuration Protocol)这个位于第7层</h3><h3 id="DNS包结构"><a href="#DNS包结构" class="headerlink" title="DNS包结构"></a>DNS包结构</h3><p>DNS走的是udp的53端口，发出去的请求的dst.port=53，收到的response的src.port = 53.<br>在局域网内,dst就是路由ip(192.168.1.1)</p><p>访问tmall主页<br><img src="https://haldir66.ga/static/imgs/dns_query_round_trip.png" alt=""><br>一来一回的</p><p>先看request<br><img src="https://haldir66.ga/static/imgs/dns_query_request_detail.png" alt=""><br>在Domain Name System query的<br>Flags下有一个opcode(这个值可能是standard query，也可能是authoritated answers,如果response是从name server回来的话)<br>Flags下面还有一个Truncated(意思就是你发出的这个包是不是太大了，太大了塞不进一个packet)<br>还有Recursion desire:Do query recursively(这意味着servername支持recursive query，就是当前dns server找不到的话，会往上继续查找)</p><p>再来看response<br><img src="https://haldir66.ga/static/imgs/dns_query_response_detail.png" alt=""><br>结果在Answers里面</p><h3 id="https结构"><a href="#https结构" class="headerlink" title="https结构"></a>https结构</h3><p>wireshark上显示成tlsv1.2<br>找application data，在secure socket layer里面有encrypted Application Data(加密过的)<br>如果是http的话，在hypertext transfer protocol里面最底下会显示html encoded的post的data</p><h3 id="tcp-retransmission"><a href="#tcp-retransmission" class="headerlink" title="tcp retransmission"></a>tcp retransmission</h3><p>网速慢的时候(latency高)tcp会发现这些问题，重发<br>如果一个packet始终没有收到ack(在限定的时间内)，重发<br>两个packet之间的时间叫做round-trip time,每当出现retransmission的时候，z这个packet的rto直接double（windows上默认尝试5次，linux上有的达到15次），一直这样double的操作超过5次后，直接丢包</p><p>如果找到一个retransmission的包<br>rto time在transmission control protocol下面的expert info，里面有个<br>(the rto for this segment was: 0.220 seconds)<br>如果这次重发还不成功,0.44s后,0.88秒后。直到超过5次尝试</p><h3 id="tcp-duplicates"><a href="#tcp-duplicates" class="headerlink" title="tcp  duplicates"></a>tcp  duplicates</h3><p>duplicate ack，这通常出现在receiver收到了out of order packet。<br>所有的tcp连接都有一个isn( initial sequence number)，就是初始序列号了。后续的packet会在这个数字的基础上,data payload传递了多少，这个数就加多少。比方说src这边的isn是1000，发送了200bytes的数据，那么我收到的ack应该是1200.</p><p>上述是一切正常的情况，但是假如src这边的isn是1000，发出去200bytes，dst那边返回1200的sequence number的ack。此时，src这边出了问题，发出去一个1400的packet，dst那边就会认为，你这不对，重来一遍（发回一个1200的ack，一直尝试3次，直到src终于反应过来发出1200的包，这个正确的包叫做fast retransmission）。<br>在wireshark里面，dst发回来的重复的ack会显示为tcp dup ack。src最后一次正确的packet显示为tcp fast retransmission</p><p>所以一旦出现了skip isn的情况，要么dst发回dup ack，要么src发出fast retransmission</p><h3 id="tcp-flow-control"><a href="#tcp-flow-control" class="headerlink" title="tcp flow control"></a>tcp flow control</h3><p>即sliding window mechanism，原理是调整retransmission的速度（根据dst的recive window），因为dst那边是有一个tcp buffer space的，万一这个buffer溢出，就会造成丢包<br>wireshark中，在transmission control protocol下面，有一个window size.<br>比方说，src发送了一个isn =1的packet，window size = 8760。dst返回一个ack number = 2921的ack,同时window size变成5840.<br>这么来来回回，这个window迟早被消耗玩，tcp zero window（正常情况下dst的应用层能够读走这部分数据，但是如果接收方读取速度跟不上的话，会发送一个ack包，告诉src发送慢一点,src接收到了之后，就会一直发keep-alive packet(非常小的包，66byte).如果dst那边还没处理好的话，会一直返回Tcp Zero window 的ack，这样往返数次）。这个专门的名词叫做Zero Window Probe<br>在wireshark里面,tcp zero window的ack包里面会显示window size value: 0<br><strong>只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。（关于这方面的攻击，大家可以移步看一下Wikipedia的SockStress词条）</strong></p><h3 id="high-latency"><a href="#high-latency" class="headerlink" title="high latency"></a>high latency</h3><p>这个主要的标志是time这一栏超过1秒，延迟的原因很多。可以分析是去程慢还是返程慢。也有可能是服务器处理很慢。<br>network baseline(正常的延迟是多少，比如国内到美国一般150ms以上是起码的，这是物理决定的)</p><h2 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h2><p>安装</p><blockquote><p>sudo apt-get install tcpdump</p></blockquote><p>使用<br>sudo tcpdump -i wlan0 ##i的意思是指定某个网络接口，输出非常多<br>sudo tcpdump -D ##哪些接口可用<br>sudo tcpdump -i 2 ##只看-D显示的第二个设备<br>sudo tcpdump -v -A ## A的意思是ASCII，至少内容容易辨识<br>sudo tcpdump -i 2 -c 4 ##只抓4个包<br>sudo tcpdump -i 2 -c -4 -n arp ##只抓arp的包,n的意思是supress host name,也能用来指定协议<br>sudo tcpdump -i 2 -c -4 -n tcp ##只抓4个tcp<br>sudo tcpdump -i 2 -c -4 -n icmp ##只抓4个icmp<br>sudo tcpdump -i 2 -c -4 src 192.168.1.1 ##指定src</p><p>sudo tcpdump -i 2 -c -4 -w filename.pcap ##保存到文件,这个文件用tcpdump打开也是可以的<br>sudo tcpdump -r  filename.pcap ##读取这个文件</p><p>可以和egrep一起用<br>sudo tcpdump -A -i 2 | egrep -i ‘pass=|pwd=|password=|username=’ –color=auto –line-buffered<br>//比方说抓到了md5过的密码，随便找个解密网站，就能解出来了</p><p><a href="https://segmentfault.com/a/1190000009562333">ARP欺骗</a> arp cache poisoning attack<br><a href="http://packetlife.net/media/library/23/common_ports.pdf">常用的端口号</a><br><a href="https://github.com/chrissanders/packets">各种可能的pcap文件</a><br><a href="https://www.zfl9.com/c-socket.html">本文大量文字图片出处</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/osi-model.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;a href=&quot;http://packetlife.net/media/library/13/Wireshark_Display_Filters.pdf&quot;&gt;wireshark expression cheetsheet&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://packetlife.net/media/library/12/tcpdump.pdf&quot;&gt;tcpdump cheet&lt;/a&gt;&lt;br&gt;wireshark能抓tcp,arp,http,dns,udp,icmp,dhcp…&lt;/p&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
</feed>
