<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Haldir的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://haldir65.github.io/"/>
  <updated>2019-08-12T11:39:32.310Z</updated>
  <id>https://haldir65.github.io/</id>
  
  <author>
    <name>Haldir</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hexo部署个人博客记录</title>
    <link href="https://haldir65.github.io/2217/01/08/2017-01-08-trouble-shooting-with-my-blog/"/>
    <id>https://haldir65.github.io/2217/01/08/2017-01-08-trouble-shooting-with-my-blog/</id>
    <published>2217-01-08T18:01:01.000Z</published>
    <updated>2019-08-12T11:39:32.310Z</updated>
    
    <content type="html"><![CDATA[<p>使用 hexo 写博客以来，记录下来的问题越来越多。只希望下次再碰到同样的问题时，不要再去浪费时间去查找。如果想要给自己的 blog 一个值得置顶的文章的话，我觉得一篇记录使用 hexo 过程中的一些解决问题的方法的文章是再合适不过的了。</br><br><img src="https://haldir66.ga/static/imgs/40164340_40164340_1414330224938_mthumb.jpg" alt=""></p><a id="more"></a><h2 id="1-经常更新-yilia-的-theme"><a href="#1-经常更新-yilia-的-theme" class="headerlink" title="1. 经常更新 yilia 的 theme"></a>1. 经常更新 yilia 的 theme</h2><p><a href="https://github.com/litten/hexo-theme-yilia">yilia</a>主题经常会更新，及时更新 theme 会发现很多新的特性及 bug fix</p><h2 id="2-部署相关"><a href="#2-部署相关" class="headerlink" title="2. 部署相关"></a>2. 部署相关</h2><ul><li>部署到 github</li></ul><pre><code class="javascript">hexo clean //清除缓存hexo g -d //一步到位 = hexo g + hexo dhexo s //localost:4000本地预览</code></pre><ul><li>部署过程中出现的一些错误</li></ul><pre><code class="javascript">$ hexo g -dINFO  Start processingERROR Process failed: _posts/2016-12-10-adb-command.mdYAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 3, column 11:    categories:  [技术]              ^    at generateError (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:162:10)    at throwError (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:168:9)    at readBlockMapping (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1040:9)    at composeNode (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1326:12)    at readDocument (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1488:3)    at loadDocuments (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1544:5)    at Object.load (D:\Blog\github\node_modules\hexo\node_modules\js-yaml\lib\js-yaml\loader.js:1561:19)    at parseYAML (D:\Blog\github\node_modules\hexo\node_modules\hexo-front-matter\lib\front_matter.js:80:21)    at parse (D:\Blog\github\node_modules\hexo\node_modules\hexo-front-matter\lib\front_matter.js:56:12)    at D:\Blog\github\node_modules\hexo\lib\plugins\processor\post.js:52:18    at tryCatcher (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\util.js:16:23)    at Promise._settlePromiseFromHandler (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:507:35)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:567:18)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at PromiseArray._resolve (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:125:19)    at PromiseArray._promiseFulfilled (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:143:14)    at PromiseArray._iterate (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:113:31)    at PromiseArray.init [as _init] (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:77:10)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:564:21)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at PromiseArray._resolve (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:125:19)    at PromiseArray._promiseFulfilled (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise_array.js:143:14)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:572:26)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at Promise._resolveCallback (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:431:57)    at Promise._settlePromiseFromHandler (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:522:17)    at Promise._settlePromise (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:567:18)    at Promise._settlePromise0 (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:612:10)    at Promise._settlePromises (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:691:18)    at Promise._fulfill (D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\promise.js:636:18)    at D:\Blog\github\node_modules\hexo\node_modules\bluebird\js\release\nodeback.js:42:21    at D:\Blog\github\node_modules\hexo\node_modules\hexo-fs\node_modules\graceful-fs\graceful-fs.js:78:16    at tryToString (fs.js:455:3)    at FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:442:12)INFO  Files loaded in 1.48 sINFO  Generated: sitemap.xmlINFO  Generated: atom.xmlINFO  Generated: 2017/01/08/2017-01-08-trouble-shooting-with-my-blog/index.htmlINFO  Generated: index.htmlINFO  4 files generated in 2.26 sINFO  Deploying: git</code></pre><p>找了好久，有说”_config.xml” 文件 有空格的，有说 title 被乱改的，试了好长时间，改成这样就不再报错了。所以，<strong>冒号后面一定要加空格，英文半角的</strong></p><pre><code>---title: adb常用命令手册date: 2016-12-10 21:14:14tags: - android - adb---</code></pre><p>tags 有两种写法，一种是上面这样前面加横杠另一种长这样，写成数组形式</p><pre><code>---title: my awesometitledate: 2017-05-07 16:48:01categories: blogtags: [linux,python]---</code></pre><h2 id="3-一些功能的实现"><a href="#3-一些功能的实现" class="headerlink" title="3. 一些功能的实现"></a>3. 一些功能的实现</h2><ul><li>置顶功能将 node_modules/hexo-generator-index/lib/generator.js 的文件内容替换成以下内容</li></ul><pre><code class="javascript">&quot;use strict&quot;;var pagination = require(&quot;hexo-pagination&quot;);module.exports = function(locals) {  var config = this.config;  var posts = locals.posts;  posts.data = posts.data.sort(function(a, b) {    if (a.top &amp;&amp; b.top) {      // 两篇文章top都有定义      if (a.top == b.top)        return b.date - a.date; // 若top值一样则按照文章日期降序排      else return b.top - a.top; // 否则按照top值降序排    } else if (a.top &amp;&amp; !b.top) {      // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233）      return -1;    } else if (!a.top &amp;&amp; b.top) {      return 1;    } else return b.date - a.date; // 都没定义按照文章日期降序排  });  var paginationDir = config.pagination_dir || &quot;page&quot;;  return pagination(&quot;&quot;, posts, {    perPage: config.index_generator.per_page,    layout: [&quot;index&quot;, &quot;archive&quot;],    format: paginationDir + &quot;/%d/&quot;,    data: {      __index: true    }  });};</code></pre><ul><li>同时在文章开头添加 top : 1 即可 ，实际排序按照这个数字从大到小排序</li></ul><p>另一种做法是手动将date改大，日期越靠后的越在前面。</p><pre><code class="java"> title: Hexo置顶文章date: 2016-11-11 23:26:22tags:[置顶]categories: Hexotop: 0 # 0或者1</code></pre><p>个人建议：置顶不要太多</p><h2 id="4-SublimeText-的一些快捷键"><a href="#4-SublimeText-的一些快捷键" class="headerlink" title="4. SublimeText 的一些快捷键"></a>4. SublimeText 的一些快捷键</h2><p>由于文章大部分都是使用 SublimeText 写的，Typroa 这种所见即所得的编辑器也不错，但对于掌握 MardkDown 语法没有帮助。这里摘录一些 SubLimeText 的快捷键。</p><blockquote><p><strong>Ctrl+Shift+P：打开命令面板</strong><br>Ctrl+P：搜索项目中的文件<br>Ctrl+G：跳转到第几行<br>Ctrl+W：关闭当前打开文件 CTRL+F4 也可以<br>Ctrl+Shift+W：关闭所有打开文件<br>Ctrl+Shift+V：粘贴并格式化<br>Ctrl+D：选择单词，重复可增加选择下一个相同的单词<br><strong>Ctrl+L：选择行，重复可依次增加选择下一行</strong><br><strong>Alt+Shift+数字：分屏显示</strong><br><strong>Ctrl+Shift+L：选择多行</strong><br><strong>Ctrl+Shift+D：复制粘贴当前行</strong><br><strong>Ctrl+X：删除当前行</strong><br><strong>Ctrl+Shift+左箭头 往左边选择内容</strong><br><strong>Shift+向左箭头 向左选择文本</strong><br><strong>Ctrl+B 编译，markDown 生成 html 文件</strong><br><strong>Alt+2 切换到第二个 Tab（打开的文件，记得 chrome 是 ctrl+2）</strong><br><strong>Ctrl+R：前往 对应的方法的实现*</strong><br><strong>快速加上[] 选中单词按 [ 即可</strong><br><strong>批量更改当前页面相同的单词 alt+F3 </strong><br><strong>Ctrl+Enter 在下一行插入新的一行</strong><br><strong>Ctrl+Shift+Enter 在上一行插入新的一行</strong><br><strong>Shift+ 向上箭头 向上选中多行</strong></p></blockquote><blockquote><p>Ctrl+Shift+D：复制粘贴当前行 Ctrl+Shift+Enter：在当前行前插入新行<br>Ctrl+M：跳转到对应括号<br>Ctrl+U：软撤销，撤销光标位置<br>Ctrl+J：选择标签内容<br>Ctrl+F：查找内容<br>Ctrl+Shift+F：查找并替换<br>Ctrl+H：替换<br>Ctrl+N：新建窗口<br>Ctrl+K+B：开关侧栏<br>Ctrl+Shift+M：选中当前括号内容，重复可选着括号本身<br>Ctrl+F2：设置/删除标记<br>Ctrl+/：注释当前行<br>Ctrl+Shift+/：当前位置插入注释<br>Ctrl+Alt+/：块注释，并 Focus 到首行，写注释说明用的<br>Ctrl+Shift+A：选择当前标签前后，修改标签用的<br>F11：全屏<br>Shift+F11：全屏免打扰模式，只编辑当前文件<br>Alt+F3：选择所有相同<br>Alt+.：闭合标签<br>Shift+右键拖动：光标多不，用来更改或插入列内容<br>Alt+数字：切换打开第 N 个文件鼠标的前进后退键可切换 Tab 文件按 Ctrl，依次点击或选取，可需要编辑的多个位置按 Ctrl+Shift+上下键，可替换行</p></blockquote><p>vscode的快捷键最重要的一个是ctrl+shift+p(相当于sublime里面的命令模式),ctrl+p只是在全局查找文件</p><h2 id="5-title-不能以-开头"><a href="#5-title-不能以-开头" class="headerlink" title="5. title 不能以[]开头"></a>5. title 不能以[]开头</h2><p>前面加上###确实能够让字号变大，但不要写 4 个#，后面的字母会大小写不分的</p><h2 id="6-markdown-语法"><a href="#6-markdown-语法" class="headerlink" title="6. markdown 语法"></a>6. markdown 语法</h2><p>MarkDown 页面内部跳转<br><a href="http://www.cnblogs.com/JohnTsai/p/4027229.html">MarkDown 技巧：两种方式实现页内跳转</a></p><blockquote><p><em>一个星星包起来是斜体字</em><br><strong>两个星星包起来是粗体字</strong><br><strong><em><em>那么三个星星呢</em></em></strong></p></blockquote><p>“—“ 三根横杠是分割线</p><h2 id="我是分割线上面"><a href="#我是分割线上面" class="headerlink" title="我是分割线上面"></a>我是分割线上面</h2><p>我在分割线下面</p><p><code>键盘ESC下面那个键按两下是code的意思</code> 和<code>一个html code tag</code> 同样的效果</p><p>彩色的字</p><font color="red">0</font>、<font color="orange">10</font>、<font color="green">20</font>、<font color="blue">30</font>、<font color="Purple">40</font><h2 id="7-github-提交-commit-的时候显示-Emoji"><a href="#7-github-提交-commit-的时候显示-Emoji" class="headerlink" title="7.github 提交 commit 的时候显示 Emoji"></a>7.github 提交 commit 的时候显示 Emoji</h2><p>链接<a href="https://www.webpagefx.com/tools/emoji-cheat-sheet/">在此</a></p><h2 id="8-换电脑了怎么办"><a href="#8-换电脑了怎么办" class="headerlink" title="8.换电脑了怎么办"></a>8.换电脑了怎么办</h2><p>亲测，把整个目录下所有文件全部复制粘贴到新电脑上，装上 node，然后装上 hexo，记得勾选添加到 PATH,然后就可以了。需要注意的是小文件比较多，所以复制粘贴可能要十几分钟。</p><h2 id="9-有时候写的代码会给你在每一行前面加上-true"><a href="#9-有时候写的代码会给你在每一行前面加上-true" class="headerlink" title="9. 有时候写的代码会给你在每一行前面加上 true"></a>9. 有时候写的代码会给你在每一行前面加上 true</h2><p>比如写一段 css 的代码时候，很多时候预览会给每一行前面加上一个 true，解决办法：用 TAB 键缩进即可</p><h2 id="10-markdown-live-是一个非常好用的-node-module"><a href="#10-markdown-live-是一个非常好用的-node-module" class="headerlink" title="10. markdown-live 是一个非常好用的 node module"></a>10. markdown-live 是一个非常好用的 node module</h2><p><a href="https://www.npmjs.com/package/markdown-live">项目地址</a><br><strong>前提是安装了 node</strong></p><blockquote><p>npm install -g markdown-live</p></blockquote><blockquote><p>md-live</p></blockquote><p><br><br><strong><em>编辑md文件的同时，保存就会同步刷新网页预览，非常好用</em></strong></p><h2 id="11-如果运行-hexo-g-生成的-index-html-是空的"><a href="#11-如果运行-hexo-g-生成的-index-html-是空的" class="headerlink" title="11. 如果运行 hexo g 生成的 index.html 是空的"></a>11. 如果运行 hexo g 生成的 index.html 是空的</h2><p>输出</p><blockquote><p>WARN No layout: tags/service/index.html<br>原因是 themes/文件夹下没有 clone 对应的主题</p></blockquote><p>换成travis之后，在travis.yml文件中，添加了</p><pre><code class="config">cache:  yarn: true  directories:  - node_modules  - themes</code></pre><p>cahe也就意味着后续，所有对于themes文件夹中的_config.yml文件的修改都不会生效。这也就是我一遍遍尝试更改theme文件夹中_config文件不生效的原因。<br>所以要么去掉cache ，要么自己写bash script一行行的改。</p><h2 id="12-markdown写表格"><a href="#12-markdown写表格" class="headerlink" title="12. markdown写表格"></a>12. markdown写表格</h2><p>直接在atom下面敲table，就会自动提示出来的</p><table><thead><tr><th>一个普通标题</th><th>一个普通标题</th><th>一个普通标题</th></tr></thead><tbody><tr><td>短文本</td><td>中等文本</td><td>稍微长一点的文本</td></tr><tr><td>稍微长一点的文本</td><td>短文本</td><td>中等文本</td></tr></tbody></table><p>中间的虚线左边的冒号表示下面的单元格左对齐，冒号放右边就右对齐，左右都放一个就表示居中</p><p>vscode的返回上一个文件快捷键是ctrl + -</p><h2 id="13-travis-ci自动部署的一些问题"><a href="#13-travis-ci自动部署的一些问题" class="headerlink" title="13 . travis ci自动部署的一些问题"></a>13 . travis ci自动部署的一些问题</h2><p><a href="https://github.com/travis-ci/travis.rb/issues/437">travis ci加密文件无法在travis以外的地方解密，因为key,value都存在travis的数据库了</a></p><p><a href="https://github.com/travis-ci/travis-ci/issues/9668">travis加密文件后用openssl解密出现iv undefined的错误</a></p><p>iv undefined</p><blockquote><p>travis env list<br>encrypted_476ad15a8e52_key=[secure]<br>encrypted_476ad15a8e52_iv=[secure]<br>明明是存在的</p></blockquote><p>在linux 里面运行travis endpoint<br>果然是 API endpoint: <a href="https://api.travis-ci.org/">https://api.travis-ci.org/</a><br>而新的endpoint应该是 <a href="https://api.travis-ci.com/">https://api.travis-ci.com/</a><br>于是travis encrypt-file –help</p><blockquote><p>–pro  short-cut for –api-endpoint ‘<a href="https://api.travis-ci.com/&#39;">https://api.travis-ci.com/&#39;</a><br>–org short-cut for –api-endpoint ‘<a href="https://api.travis-ci.org/&#39;">https://api.travis-ci.org/&#39;</a></p></blockquote><p>所以</p><blockquote><p>travis encrypt-file super_secret.txt 应该改成<br>travis encrypt-file super_secret.txt –pro</p></blockquote><p>因为默认的$encrypted_476ad15a8e52_key其实已经存储在travis-ci.org上了<br>所以在travis-ci.com上的项目当然找不到</p><p><a href="https://github.com/openwrtio/openwrtio.github.io/blob/mkdocs/.travis.yml">自动部署的另一个实例</a></p><h2 id="14-hexo-server本地预览出现的问题"><a href="#14-hexo-server本地预览出现的问题" class="headerlink" title="14. hexo server本地预览出现的问题"></a>14. hexo server本地预览出现的问题</h2><p><a href="Refused to execute script from" title="http://localhost:4000/slider.e37972.js&#39; because its MIME type (&#39;text/html">hexo s 本地预览样式加载失败</a> is not executable, and strict MIME type checking is enabled.)</p><p>hexo server的意思是类似于express的serve static功能，<a href="https://hexo.io/zh-cn/docs/server.html">默认只处理public文件下的文件，所以如果本地运行hexo s 出现404的话，直接copy到public文件夹下就可以了</a>注意hexo clear会删掉public文件夹</p><p>[Refused to Execute Script From Because Its MIME Type (Text/plain) Is Not Executable, and Strict MIME Type Checking Is Enabled]这句话的意思,这其实是我本地跑hexo server的时候，没有找到一个xx.js文件，所以express返回了一个类似于404的plain text（而不是js文件），所以就出这个问题了。</p><h2 id="15-yilia的主题里面badjs-report的问题"><a href="#15-yilia的主题里面badjs-report的问题" class="headerlink" title="15. yilia的主题里面badjs report的问题"></a>15. yilia的主题里面badjs report的问题</h2><p>yilia的主题里面有一个badjs的report，去掉的方法：<br>cd 到themes/yilia里面,rm -rf source/ , 然后把source-src里面的report.js里面的东西删掉。yarn install ,yarn dist ,然后回到上层目录。hexo clean , hexo g就可以了。<br>其实看下里面，就是一个webpack的配置，自己重新编译一下就好了。编译后会在source里面重新生成需要的js文件。<br>奇怪的是在windows上编译失败，在linux上编译失败，在mac上终于成功了。</p><h2 id="16-hexo-server"><a href="#16-hexo-server" class="headerlink" title="16. hexo server"></a>16. hexo server</h2><p><a href="https://stackoverflow.com/questions/22475849/node-js-what-is-enospc-error-and-how-to-solve">enospc的解决方式</a><br>由于需要监听多个文件，所以linux下允许监听的文件数有个上限，这里修改一下就可以了</p><h2 id="17-hexo自带的代码高亮有一些不是很好的地方"><a href="#17-hexo自带的代码高亮有一些不是很好的地方" class="headerlink" title="17. hexo自带的代码高亮有一些不是很好的地方"></a>17. hexo自带的代码高亮有一些不是很好的地方</h2><p>改用highlightjs就可以了。<br>首先要把最外面的_config.yml里面的高亮关掉</p><pre><code>highlight:  enable: false</code></pre><p>由于最终生成的html文件中引用的是theme中webpack -p 打出来的js文件，所以照着highlightjs的说明修改一下yilia的源码，source-src目录，npm install highlight.js –save重新yarn dist就好了。yilia的theme修改还算简单。</p><h2 id="18-hexo渲染md文件时有些特定字符串是不能写的"><a href="#18-hexo渲染md文件时有些特定字符串是不能写的" class="headerlink" title="18. hexo渲染md文件时有些特定字符串是不能写的"></a>18. hexo渲染md文件时有些特定字符串是不能写的</h2><p>hexo本质上是一个js模板渲染工具，和jinja，handlerbars这一类模板一样，经常会用花括号包起来表示一个变量<br>下面这个，美元符号加一个花括号抱起来的井号就不能单独拿出来写</p><pre><code>${#} </code></pre><p>报的错大概长这样</p><pre><code>Template render error: (unknown path) [Line 101, Column 142]  unexpected token: }}</code></pre><p><a href="https://github.com/hexojs/hexo/issues/2384#issuecomment-277494121">原因是这种看上去像是引用一个变量的东西是某些js库的保留syntax</a></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="http://yanhuili.github.io/2016/11/21/hexo%E5%8D%9A%E6%96%87%E7%BD%AE%E9%A1%B6%E6%8A%80%E5%B7%A7/">Hexo 博文置顶技巧</a></li><li><a href="http://www.daqianduan.com/4820.html">SublimeText 快捷键</a></li><li><a href="http://itmyhome.com/markdown/article/syntax/emphasis.html">MarkDown 语法学起来很快的</a></li><li><a href="https://blessing.studio/deploy-hexo-blog-automatically-with-travis-ci/">travis 自动部署</a></li><li><a href="https://docs.travis-ci.com/user/legacy-services-to-github-apps-migration-guide/">Legacy GitHub Services to GitHub Apps Migration Guide 2018年10月1号之后不再支持 Legacy GitHub Service</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 hexo 写博客以来，记录下来的问题越来越多。只希望下次再碰到同样的问题时，不要再去浪费时间去查找。如果想要给自己的 blog 一个值得置顶的文章的话，我觉得一篇记录使用 hexo 过程中的一些解决问题的方法的文章是再合适不过的了。&lt;/br&gt;&lt;br&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/40164340_40164340_1414330224938_mthumb.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="blog" scheme="https://haldir65.github.io/categories/blog/"/>
    
    
      <category term="置顶" scheme="https://haldir65.github.io/tags/%E7%BD%AE%E9%A1%B6/"/>
    
      <category term="hexo" scheme="https://haldir65.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>即刻备忘录</title>
    <link href="https://haldir65.github.io/2046/12/18/2017-12-18-random-new-thoughts/"/>
    <id>https://haldir65.github.io/2046/12/18/2017-12-18-random-new-thoughts/</id>
    <published>2046-12-18T22:58:14.000Z</published>
    <updated>2019-08-12T11:39:32.322Z</updated>
    
    <content type="html"><![CDATA[<p>一个待办事项的仓库<br><img src="https://haldir66.ga/static/imgs/girlfriend lake green nature water cold.jpg" alt=""></p><a id="more"></a><h3 id="期待能够完成的"><a href="#期待能够完成的" class="headerlink" title="期待能够完成的"></a>期待能够完成的</h3><ul><li><a href="https://juejin.im/post/5a0c1956f265da430a501f51">个人分享–web 前端学习资源分享</a></li><li><a href="https://huangxuan.me/2017/02/09/nextgen-web-pwa/">PWA 所代表的 Web 开发应是未来</a>据说Electron要被PWA干掉</li><li><a href="https://segmentfault.com/a/1190000003818163">js 循环闭包的解决方法</a></li><li>动态类型一时爽，代码重构火葬场</li><li>iview，elementUi</li><li>[ ] shadowsocks-android源码（据说是起了一个c进程守护）</li><li>[ ] chromium net移植到Android平台<a href="https://github.com/GoogleChromeLabs/cronet-sample">cronet是最简单的方式</a> <a href="https://console.cloud.google.com/storage/browser/chromium-cronet?pli=1">更多下载仓库</a></li><li><a href="https://css-tricks.com/NetMag/FluidWidthVideo/Article-FluidWidthVideo.php">embeed video with iframe</a></li><li>[ ] Paul Irish from google</li><li>[ ] <a href="http://lokeshdhakar.com/projects/lightbox2/">lightbox一个很好看的js图片查看库</a></li><li>[ ] <a href="https://github.com/wangpengfei15975/skPlayer/">一个很好看的h5音乐播放器</a></li><li>[ ] <a href="https://www.js-css.cn/a/jscode/album/2014/0915/1319.html">仿门户网站js相册</a>， <a href="https://www.js-css.cn/a/jscode/album/2014/0914/1318.html">js相册2</a></li><li>[ ] <a href="http://python.jobbole.com/82270/">八大排序算法的python实现</a></li><li>[ ] Redux和Flux很像,react context api</li><li>[ ] <a href="https://www.jianshu.com/p/a4ab102fa4ac">一个展示如何在宿主App中提取一个apk文件并加载代码和资源</a></li><li>[ ] nodejs ,go ,protobuf rpc(proto更多的是作为一种协议来进行rpc数据传输)</li><li>[ ]一致性哈希原理</li><li>[ ] <a href="http://afghl.github.io/2018/06/17/distributed-lock-and-granarity.html">使用redis实现低粒度的分布式锁</a></li><li>[ ] Coordinator behavior以及scroll原理</li><li>[ ] instagram好像通过注解的方式自己写了一个json解析器<a href="https://github.com/Instagram/ig-json-parser">ig-json-parser</a></li><li>[ ] when it comes to design , how do we translate px, pt, em  into sp,dp and others(设计方面的，各种单位之间的转换)?</li><li>[ ] learning how textView works is painful yet necessary</li><li>[ ] linux环境下多进程通讯方式(管道，共享内存，信号,unix domian socket)</li><li>[ ] mqtt接入实践<a href="https://github.com/mcxiaoke/mqtt">mqtt是建立在tcp基础上的应用层协议</a>，<a href="https://github.com/netty/netty">netty</a>也做了实现</li><li>[ ] play around with xposed</li><li>[ ] python gui编程</li><li>[ ] <a href="https://www.youtube.com/watch?v=jYuK1qzFrJg">Kotlin Coroutines Tutorial (STABLE VERSION) </a></li><li>[ ] 宇宙第一ide熟悉使用</li><li>[ ] js的闭包等面试常谈</li><li>[ ] java的aspectJ教程，Spring AOP 与AspectJ 实现原理上并不完全一致，但功能上是相似的</li><li>[ ] code generator(代码生成器)</li><li>[ ]<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers">content-disposition</a></li><li>[ ] 用正则检测或者解析json(jQuery源码里有) 在线正则检测网站</li><li>[ ] awk，正则表达式还有数据库这些也算一门编程语言</li><li>[ ] 来来来，<a href="https://www.youtube.com/watch?v=DUNkdl0Jhgs">手写一个vm</a></li><li>[ ] <a href="https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md#System-requirements">chromium提供了如何在windows上编译chromium的教程</a></li><li>[ ]<a href="https://www.youtube.com/watch?v=M8LiOANu3Nk">How the JVM compiles bytecode into machine code</a></li><li>[ ] WebSocket协议及数据帧</li><li>[ ]Lua脚本是一个很轻量级的脚本，也是号称性能最高的脚本。路由器上都有运行环境，语法和c语言差不多</li><li><a href="https://juejin.im/post/5baf8ae8f265da0ae92a7df5">腾讯的mmkv是shared preference的有效替代品</a> mmap的使用值得学习</li><li><a href="https://www.jianshu.com/p/5f9a7bc902e1">简单的组件化方案</a></li><li><a href="https://www.tianmaying.com/tutorial/AndroidMVC">mvc,mvp,mvvm</a>这些关键术语的掌握还是必要的</li><li>Parcelable 是怎么实现跨进程的? ipc并不仅限于后台，客户端不同进程间也会有类似的概念。</li><li>jdk8 standard Library implementation detail(java代码的实现 –&gt; hotspot代码的c语言实现)</li><li><a href="https://segmentfault.com/a/1190000017864721">后端面试题</a></li><li>thrift 源码解析，rpc框架（比方说人脸识别应用就可以用java调用python服务）这种rpc过程肯定要考虑字节序的问题。</li><li>Perl被称为脚本语言中的瑞士军刀，正则多一点</li></ul><h3 id="已完成"><a href="#已完成" class="headerlink" title="已完成"></a>已完成</h3><ul><li>用 express 转接一个知乎 Api，添加 Access-control-allow-origin,或许还可以用 redis 缓存数据结果（一个就好）由此想到一篇文章”How to use Python to build a restful Web Service”.只不过用的是 Tornado</li><li>git hook (github travis 持续集成，git push 会触发服务器的一系列操作)</li><li>基于前后端分离的理念，后台只负责提供数据，render page 的任务应该交给前端。（所以用 express-handlebars 写页面的方式写着很累）</li><li>集成 travis-ci，记得 after-success script 的结果并不会影响 build 的结果（即，after-success 执行脚本发生了错误，在日志里有输出 error，但实际显示的 build result 仍为 success），还有 travis 的输出 log 需要默认是折叠的，要展开才能看清楚，但在 afterSuccess 里面的指令的输出一定是有的。</li><li>随便放一个文件到/usr/bin/就可以直接调用这个文件名来起这个命令了吗？（实际操作只需要建立一个symbolic link就好了）</li><li>单个网卡最多65535个端口，c10K。<a href="https://www.zhihu.com/question/66553828">65536其实不是操作系统限制的，而是tcp协议就只给port留了2个bytes给source port，只留了2个bytes给destination port</a>端口号写在tcp包里，ip地址不是，ip地址是ip层的事情</li><li>oAuth2原理，其实流程上和很多客户端的微信登陆，新浪微博登陆很像的</li><li>在Android手机上尝试用一个unix domain socket用于localhost进程间ipc(其实就是保证端口号一致，给网络权限就好了)</li><li>写 groovy 用intelij全家桶就可以了，groovy的<a href="https://www.tutorialspoint.com/groovy/groovy_closures.htm">语法</a>其实没什么，主要是了解编译的流程和基本原理，这个需要看<a href="https://docs.gradle.org/current/userguide/build_lifecycle.html#sec:build_phases">official doc</a></li><li><a href="https://github.com/JLLK/gradle-android-maindexlist-plugin">开发gradle plugin优化MultiDex</a>。长远来看，5.0以后的手机越来越多，MultiDex也不值得过于关注。</li><li>intelij 点击run 实际调用的command line是两个，一个是javac，编译出来的class文件放到了target文件夹，紧接着用java命令带上一大串classpath去调用主函数</li><li><a href="https://fucknmb.com/2017/05/11/Android-Studio-Library%E6%A8%A1%E5%9D%97%E4%B8%ADNative%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8Cdebug%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/">Android Studio 编译过程</a>，其实就是gradle assembleXXX 好了之后adb push到手机上，再安装，最后起主界面</li><li><a href="http://mouxuejie.com/blog/2016-06-21/multidex-compile-and-dex-source-analysis/">Android 编译及 Dex 过程源码分析</a></li><li><a href="http://www.wangyuwei.me/">如何调试 Android 打包流程？</a>，一个remote的事</li><li><a href="https://github.com/chenenyu/img-optimizer-gradle-plugin">一个用于优化 png 图片的 gradle 插件</a>，用来看 groovy 语法挺好的。以及 <a href="http://yuanfentiank789.github.io/2017/09/20/%E5%9C%A8AndroidStudio%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89Gradle%E6%8F%92%E4%BB%B6/">How to write gradle plugin</a></li><li>XSS 攻击,DOM based和Stored XSS,基本上就是不要相信用户的输入，除了合法输入以外一律过滤掉</li></ul><ul><li>Websocket nodejs，局限性就是前后台都得用socket.io的库。前端是浏览器的话还好，app的话java,Android都有对应的实现.[其实就是socket io] </li><li>[使用Spring boot后台提供protobuf接口实现客户端通信] 不要使用protobf-gradle-plugin了。直接写脚本用protoc去生成文件，指定生成文件的路径要和proto里面写的包名对的上。另外就是客户端和server端依赖的protobuf版本以及protoc工具的版本得一致，比如都是3.5。还有就是protoc的语法，什么import的比较烦。</li><li>[X] 使用jinja2生成文件。<a href="https://github.com/guokr/swagger-py-codegen">一个比较好玩的代码生成器</a></li><li>[X] URL Encoding,就是那个在网址里把字符转成百分号加上UTF-8的<a href="http://www.ruanyifeng.com/blog/2010/02/url_encoding.html">找到了阮一峰老师的解释</a></li><li>[X] 通过file input上传图片，原生ajax以及Ajax，自己搭建上传服务器<a href="https://zhuanlan.zhihu.com/p/24513281?refer=flask">大概能猜到暴风影音的局域网传输实现了</a>用flask的话自己搭建好后台最简单了，最多再使用flask-wtf和flask-upload规范操作</li><li>[X]Promise 链式调用与终止，异常处理(只是一个工具而已)</li><li>[X] Android 应用接入bugly热修复，上线之后就不用背锅了（有兴趣看看sevenZip.jar，暂时没看）</li><li>[X] <a href="http://normanmaurer.me/blog/2013/11/09/The-hidden-performance-costs-of-instantiating-Throwables/">简直碉堡了的博客</a>以及jvm 的inline等优化</li><li>[ ] <a href="https://seisman.github.io/how-to-write-makefile/introduction.html">如何写makefile</a>其实<a href="http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/">这个更加friendly</a></li><li>[X] <a href="https://www.jianshu.com/p/534741f5151c">libmp3lame移植到Android</a>,该教程针对的lame版本是3.99.5</li><li><a href="https://sspai.com/post/31500">scheme 这东西算跨客户端平台的</a>，比如在 App 中调起支付宝(用的是 alipayqr://)。其实就是一个系统内跨应用调用。<a href="http://blog.csdn.net/qq_23547831/article/details/51685310">用法</a><br>这个主要是ios app之间通信的协议，以及快速跳转某个app某个页面的功能实现，还有x-callback-URL这样类似的协议。不过有了3d-touch之后，很多app都能长按图标进入页面，所以url scheme这个功能只能说是不复往日辉煌了</li><li>[X]linux的sed命令(文本替换比较常用)</li><li><a href="https://juejin.im/post/59fffdb76fb9a0450a66bd58">nio</a> 还是netty好。也可以看点别的<a href="http://ifeve.com/java-nio%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E5%8D%81%E5%85%AD%EF%BC%89-java-nio-files/">并发编程网</a></li><li>[X]js 的async await,就是一个async修饰一个method，里面随便写await</li><li>[X] Linux下TCP延迟确认机制</li><li>[X]c语言的<a href="https://yq.aliyun.com/articles/413601">libevent使用教程</a> eventloop，添加回调，大致的流程就是这样</li><li>[X] <a href="http://www.ruanyifeng.com/blog/2018/07/indexeddb.html">indexed DB</a>,浏览器端数据库，还是用第三方库好</li><li>[X] <a href="http://forums.justlinux.com/showthread.php?3261-Block-size-vs-page-size">block size vs page size</a> Page是内存相关，block是硬盘相关的</li><li>[X] python 的asyncio(eventloop , generator, coroutine)</li><li>[X]<a href="https://vim.rtorr.com/">Vim cheet sheet</a> vim多用用就熟悉了。</li><li>[X] python dunder class复习。知道有python descriptor这回事就行了。</li><li>[X] form表单可以跨域一个是历史原因要保持兼容性（就是说跨域这件事，一个域名的 JS ，在未经允许的情况下，不得读取另一个域名的内容。但浏览器并不阻止你向另一个域名发送请求。所以post的表单可以发出去，但是别指望能够拿到response）</li><li>[X] a new article on open-gl intro(在Android平台上要和MediaCodec相关的音视频格式结合着来一起看)</li><li>[X] JavaScript中new FileReader(属于html5的东西)，以及canvas api(lineTo,quardTo这些都是相近的),以及<a href="https://juejin.im/post/5a98c5c26fb9a028d82b34ee">js进行图片缩放和裁剪</a> </li><li>[X] tcp-proxy实用教程 </li><li>[X]Exoplayer and the MediaCodec api<a href="https://medium.com/androiddevelopers/building-a-video-player-app-in-android-part-3-5-19543ea9d416">building-a-video-player-app-in-android</a> </li><li><a href="https://www.youtube.com/watch?v=g3F7Imjcd4k">AC2016腾讯前端技术大会 1 1 1 H5直播那些事</a></li><li>[X] tcp-proxy实用教程(tcp replay or udp relay)</li><li>[X] render-script utility</li><li>[X]C语言fork进程以及进程之间通信的套路</li><li>[X] flex,grid. css的box-size真是坑人</li><li>[X] rxjava是如何切换线程的以及源码解析，ObserveOnObserver和ObservableSubscribeOn实例是桥梁</li><li>[X] jdk7开始提供fork join pool方法，将任务分配到多个线程上处理(不适合io密集型操作)</li><li>[X] <a href="https://github.com/keerath/openjdk-8-source/blob/master/jdk/src/windows/native/java/net/SocketOutputStream.c">openjdk的C语言实现可以随便调几处来看看</a></li><li>[X] 安装并使用MAT 分析java应用内存。</li></ul><h3 id="Good-For-Nothing"><a href="#Good-For-Nothing" class="headerlink" title="Good For Nothing"></a>Good For Nothing</h3><ul><li>[ ] 用GDB调试程序</li><li>[ ] npm install graphql(mostly a server side javascript stuff)</li><li>使用 express 模拟网络延迟</li><li><a href="https://juejin.im/post/5a157b7a5188257bfe457ff0">基于 Docker 打造前端持续集成开发环境</a></li><li>vS Code Vender Prefix plugin =&gt; auto prefix loader</li><li>前后端分离</li><li>sql漏洞</li><li><a href="https://cloud.tencent.com/developer/article/1004755">深入浅出腾讯云 CDN：缓存篇</a>不管SSD盘或者SATA盘都有最小的操作单位，可能是512B，4KB，8KB。如果读写过程中不进行对齐，底层的硬件或者驱动就需要替应用层来做对齐操作，并将一次读写操作分裂为多次读写操作。</li><li>Android进程的<a href="https://juejin.im/post/5a646211f265da3e3f4cc997">加载流程</a></li><li>前后端同构</li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-with-ssl-as-a-reverse-proxy-for-jenkins">install nginx , jenkin ci, deploying nginx in docker(Http Load Balaning with Docker and nginx)</a></li><li>[ ] 网易云音乐API</li><li>[X] Django部署个人网站(Gunicorn，Nginx)。django写template就不是前后端分离了</li><li>[ ] Docker<a href="https://medium.com/@elye.project/intro-to-docker-building-android-app-cb7fb1b97602">intro-to-docker-building-android-app</a> 这篇文章其实是两件事，一个是Build docker image(docker build xxxx),另一个是run (docker run xxx)</li><li>[ ] <a href="https://blog.csdn.net/u013553529/article/details/53856800">和网页类似，Activity也有一个referer的概念</a>，用于判断当前页面是由谁发起请求的<br>OpenType® is a cross-platform font file format developed jointly by Adobe and Microsoft.</li><li>[ ]<a href="https://blog.securem.eu/serverside/2015/08/25/setting-up-owncloud-server-in-a-docker-container/">deploying owncloud using docker</a></li><li><a href="https://doc.owncloud.org/server/10.0/admin_manual/installation/docker/">owncloud官方的配合docker安装教程</a>网盘这种东西看个人喜好了</li><li>[ ]CloudFlare cdn解析以及DNS防护 </li><li>[ ] <a href="https://www.tutorialspoint.com/python/python_further_extensions.htm">python c extension</a> </li><li>[ ] <a href="https://github.com/elliotforbes/tutorialedge-rest-api">最简单的一个用go写出来的rest api大概长这样</a></li><li>[ ]<a href="https://lxneng.com/posts/201">分词器</a></li><li>[ ]<a href="http://www.wklken.me/posts/2015/04/26/elk-for-nginx-log.html">LOGSTASH+ELASTICSEARCH+KIBANA处理NGINX访问日志</a>ELK全家桶, logstash接管软件日志</li><li>[ ] <a href="https://gist.github.com/quexer/3619237">如何编写 jQuery 插件</a></li><li>netfilter框架(imbedded in linux server)</li></ul><p><a href="https://jsonplaceholder.typicode.com/">jsonplaceholder</a>懒得自己写api的话<br>就用这个吧</p><script>console.log("hey there")</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一个待办事项的仓库&lt;br&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/girlfriend lake green nature water cold.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>maven的一些东西</title>
    <link href="https://haldir65.github.io/2019/08/11/2019-08-11-maven-related-topics/"/>
    <id>https://haldir65.github.io/2019/08/11/2019-08-11-maven-related-topics/</id>
    <published>2019-08-11T11:13:17.000Z</published>
    <updated>2019-08-12T11:39:32.330Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/FreshSalt_ZH-CN12818759319_1920x1080.jpg" alt=""></p><p>maven的一些东西</p><p>maven官网提供的通过命令行创建一个maven项目的方法</p><pre><code>mvn -B archetype:generate -DarchetypeGroupId=org.apache.maven.archetypes -DgroupId=com.mycompany.app -DartifactId=my-appmvn compile ##开始编译</code></pre><p><a href="https://maven.apache.org/guides/getting-started/index.html#How_do_I_make_my_first_Maven_project">maven getting started是很友好的教程</a></p><p>看完这俩再不会就是蠢<br><a href="https://www.youtube.com/watch?v=pt3uB0sd5kY">jetbrain在youtube上的教程</a><br><a href="https://www.packtpub.com/mapt/book/application_development/9781785286124/2/ch02lvl1sec24/creating-a-new-maven-project-in-intellij-idea">Creating a new Maven project in IntelliJ IDEA</a></p><p>create from archetype可以选择org.apache.maven.archetypes:maven-archetype-quickstart(真的只有一个hello world)<br><a href="https://start.spring.io/">如果是spring的话，直接用这个网站更加方便</a></p><p>intelij idea里面默认的maven源有<br><code>https://repo.maven.apache.org/maven2</code><br>和<code>http://download.java.net/maven/1</code><br>这俩网站国内似乎被墙，最好<a href="https://stackoverflow.com/questions/1784132/intellij-community-cant-use-http-proxy-for-maven/26483623#26483623">加代理</a> 就是在.m2/settings.xml中指定本地proxy。如果你的代理够快的话，修改pom.xml的同时，应该能够很快的开始下载新的依赖</p><h3 id="给maven加代理"><a href="#给maven加代理" class="headerlink" title="给maven加代理"></a>给maven加代理</h3><p>intelij内置了maven, 由于网速的原因，不想浪费时间的话还是给Maven加代理:<br>在~/.m2/settings.xml中找到这一段，这一段原本是被注释掉的，端口和host根据代理设置。~/.m2/settings.xml这个文件如果不存在，就去intelij的安装目录里面copy一个出来</p><pre><code class="xml"> &lt;proxies&gt;    &lt;proxy&gt;      &lt;id&gt;optional&lt;/id&gt;      &lt;active&gt;true&lt;/active&gt;      &lt;protocol&gt;http&lt;/protocol&gt;      &lt;host&gt;127.0.0.1&lt;/host&gt;      &lt;port&gt;1080&lt;/port&gt;      &lt;nonProxyHosts&gt;local.net|some.host.com&lt;/nonProxyHosts&gt;    &lt;/proxy&gt;  &lt;/proxies&gt;</code></pre><p>实际操作中，使用阿里云的maven镜像似乎更快</p><p>打开项目后，在Intellij 右侧有个Maven projects，点开后，有个Lifecycle，再点开，可以看到clean , validate, compile, ….，右击clean，选中Run ‘project[clean]’，这里的project是我们的项目实际的名字。<br>如果下载失败了的话，可以选择clean，然后就会开始自己重新下载</p><p>GroupId类似于你的包名，ArtifictId类似于你的applicationName</p><h2 id="maven是如何解决版本冲突的-同一个package，不同版本同时存在"><a href="#maven是如何解决版本冲突的-同一个package，不同版本同时存在" class="headerlink" title="maven是如何解决版本冲突的(同一个package，不同版本同时存在)"></a>maven是如何解决版本冲突的(同一个package，不同版本同时存在)</h2><p>tbd<br>gradle也有一套解决方案，ivy也有<br>java 9 的module系统没有</p><p>maven 中使用jar包的多个版本容易造成依赖问题，解决问题的方式可以将使用jar包的版本排除掉，比如dubbo使用netty 4.0.33版本可以将dubbo排除掉netty依赖，这样其他jar包就不会引用到netty4.0.33版本了。</p><pre><code class="xml">&lt;dependency&gt;            &lt;groupId&gt;com.jd&lt;/groupId&gt;            &lt;artifactId&gt;jsf&lt;/artifactId&gt;            &lt;version&gt;1.6.0&lt;/version&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;groupId&gt;io.netty&lt;/groupId&gt;                    &lt;artifactId&gt;netty-all&lt;/artifactId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/FreshSalt_ZH-CN12818759319_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;maven的一些东西&lt;/p&gt;
&lt;p&gt;maven官网提供的通过命令行创
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>各种编程语言与c、c++的交互</title>
    <link href="https://haldir65.github.io/2019/07/31/2019-07-31-interops-between-c-and-other-languages/"/>
    <id>https://haldir65.github.io/2019/07/31/2019-07-31-interops-between-c-and-other-languages/</id>
    <published>2019-07-31T22:11:55.000Z</published>
    <updated>2019-08-12T11:39:32.330Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/SutherlandFalls_ZH-CN4602884079_1920x1080.jpg" alt=""><br><a id="more"></a></p><h2 id="1-cpython"><a href="#1-cpython" class="headerlink" title="1. cpython"></a>1. cpython</h2><h3 id="1-1-python中调用C、C-代码"><a href="#1-1-python中调用C、C-代码" class="headerlink" title="1.1 python中调用C、C++代码"></a>1.1 python中调用C、C++代码</h3><p>方法一：<br>Python中的ctypes模块可能是调用C方法最简单的一种。ctypes模块提供了和C语言兼容的数据类型了函数来加载dll或者so文件。</p><p>c语言代码: add.c</p><pre><code class="c">#include &lt;stdio.h&gt;int add_int(int, int);float add_float(float, float);int add_int(int num1, int num2){    return num1 + num2;}float add_float(float num1, float num2){    return num1 + num2;}</code></pre><p>下面的命令生成一个adder.so的文件</p><p>#For Linux<br>$  gcc -shared -Wl,-soname,adder -o adder.so -fPIC add.c</p><p>#For Mac<br>$ gcc -shared -Wl,-install_name,adder.so -o adder.so -fPIC add.c</p><p>python代码</p><pre><code class="python">from ctypes import *#load the shared object fileadder = CDLL(&#39;./adder.so&#39;)#Find sum of integersres_int = adder.add_int(4,5)print &quot;Sum of 4 and 5 = &quot; + str(res_int)#Find sum of floatsa = c_float(5.5)b = c_float(4.1)add_float = adder.add_floatadd_float.restype = c_floatprint &quot;Sum of 5.5 and 4.1 = &quot;, str(add_float(a, b))</code></pre><p>方法二：Python/C API（c python extension  ）<br>其实就是自己写python c extension了</p><pre><code class="python">#Though it looks like an ordinary python import, the addList module is implemented in Cimport addListl = [1,2,3,4,5]print &quot;Sum of List - &quot; + str(l) + &quot; = &quot; +  str(addList.add(l))</code></pre><pre><code class="c">//Python.h has all the required function definitions to manipulate the Python objects#include &lt;Python.h&gt;//This is the function that is called from your python codestatic PyObject* addList_add(PyObject* self, PyObject* args){    PyObject * listObj;    //The input arguments come as a tuple, we parse the args to get the various variables    //In this case it&#39;s only one list variable, which will now be referenced by listObj    if (! PyArg_ParseTuple( args, &quot;O&quot;, &amp;listObj ))        return NULL;    //length of the list    long length = PyList_Size(listObj);    //iterate over all the elements    int i, sum =0;    for (i = 0; i &lt; length; i++) {        //get an element out of the list - the element is also a python objects        PyObject* temp = PyList_GetItem(listObj, i);        //we know that object represents an integer - so convert it into C long        long elem = PyInt_AsLong(temp);        sum += elem;    }    //value returned back to python code - another python object    //build value here converts the C long to a python integer    return Py_BuildValue(&quot;i&quot;, sum);}//This is the docstring that corresponds to our &#39;add&#39; function.static char addList_docs[] =&quot;add(  ): add all elements of the list\n&quot;;/* This table contains the relavent info mapping -   &lt;function-name in python module&gt;, &lt;actual-function&gt;,   &lt;type-of-args the function expects&gt;, &lt;docstring associated with the function&gt; */static PyMethodDef addList_funcs[] = {    {&quot;add&quot;, (PyCFunction)addList_add, METH_VARARGS, addList_docs},    {NULL, NULL, 0, NULL}};/*   addList is the module name, and this is the initialization block of the module.   &lt;desired module name&gt;, &lt;the-info-table&gt;, &lt;module&#39;s-docstring&gt; */PyMODINIT_FUNC initaddList(void){    Py_InitModule3(&quot;addList&quot;, addList_funcs,            &quot;Add all ze lists&quot;);}</code></pre><h3 id="1-2-C、C-调用python代码"><a href="#1-2-C、C-调用python代码" class="headerlink" title="1.2 C、C++调用python代码"></a>1.2 C、C++调用python代码</h3><p>参考上面的python c extension方法，可以在c语言中操作python对象</p><h3 id="1-3-python调用系统方法"><a href="#1-3-python调用系统方法" class="headerlink" title="1.3 python调用系统方法"></a>1.3 python调用系统方法</h3><pre><code class="py">##　第一种os.system(command)## 第二种import subprocesssubprocess.Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0)subprocess.call([&quot;cmd&quot;, &quot;arg1&quot;, &quot;arg2&quot;],shell=True)</code></pre><p>目前python官方推荐的调用方法的方式还是subprocess。</p><p>cython(python c extension)和cpython(c语言实现的python）是两件事</p><h2 id="2-javascript"><a href="#2-javascript" class="headerlink" title="2. javascript"></a>2. javascript</h2><h3 id="2-1-javascript调用C、C-代码"><a href="#2-1-javascript调用C、C-代码" class="headerlink" title="2.1 javascript调用C、C++代码"></a>2.1 javascript调用C、C++代码</h3><p>首先，在浏览器中运行c语言的代码，似乎可以将C编成webassembly在浏览器中运行。<br>而在Node js中，可以使用<a href="https://nodejs.org/api/n-api.html">n-api</a>这个module。</p><blockquote><p>N-API (pronounced N as in the letter, followed by API) is an API for building native Addons. It is independent from the underlying JavaScript runtime (for example, V8) and is maintained as part of Node.js itself. This API will be Application Binary Interface (ABI) stable across versions of Node.js. It is intended to insulate Addons from changes in the underlying JavaScript engine and allow modules compiled for one major version to run on later major versions of Node.js without recompilation. </p></blockquote><p>就是说保持了binary compatibility，比如说在node6上编译通过之后，假如后面出了node10，不需要重新编译也能继续运行。</p><p>下面看如何使用:<br><a href="https://medium.com/@tarkus/how-to-call-c-c-code-from-node-js-86a773033892">how-to-call-c-c-code-from-node-js</a><br>很多大型js项目都有一个binging.gyp文件（一定是这个名字）</p><p>gyp其实是一个用来生成项目文件的工具，一开始是设计给chromium项目使用的，后来大家发现比较好用就用到了其他地方。生成项目文件后就可以调用GCC, vsbuild, xcode等编译平台来编译。至于为什么要有node-gyp，是由于node程序中需要调用一些其他语言编写的工具甚至是dll，需要先编译一下，否则就会有跨平台的问题，例如在windows上运行的软件copy到mac上就不能用了，但是如果源码支持，编译一下，在mac上还是可以用的。</p><h3 id="2-2-C、C-调用javascript代码"><a href="#2-2-C、C-调用javascript代码" class="headerlink" title="2.2 C、C++调用javascript代码"></a>2.2 C、C++调用javascript代码</h3><h3 id="2-3-javascript调用系统方法"><a href="#2-3-javascript调用系统方法" class="headerlink" title="2.3 javascript调用系统方法"></a>2.3 javascript调用系统方法</h3><p>在node js 中可以使用<a href="https://nodejs.org/api/child_process.html#child_process_child_process_execfile_file_args_options_callback">child_process模块</a></p><pre><code class="c">// myProgram.c#include &lt;stdio.h&gt;int main(void){    puts(&quot;4&quot;);    return 0;}</code></pre><p>gcc -o myProgram myProgram.c</p><pre><code class="js">const { exec } = require(&quot;child_process&quot;);exec(&quot;./myProgram&quot;, (error, stdout, stderr) =&gt; console.log(stdout));</code></pre><h2 id="3-java"><a href="#3-java" class="headerlink" title="3. java"></a>3. java</h2><h3 id="3-1-java调用C、C-代码"><a href="#3-1-java调用C、C-代码" class="headerlink" title="3.1 java调用C、C++代码"></a>3.1 java调用C、C++代码</h3><p>就是jni了</p><h3 id="3-2-C、C-调用java代码"><a href="#3-2-C、C-调用java代码" class="headerlink" title="3.2 C、C++调用java代码"></a>3.2 C、C++调用java代码</h3><p>c、c++层调用java也是可以的</p><h3 id="3-3-java调用系统方法"><a href="#3-3-java调用系统方法" class="headerlink" title="3.3 java调用系统方法"></a>3.3 java调用系统方法</h3><p>java有一个Process api</p><h3 id="38-java中Process的Api"><a href="#38-java中Process的Api" class="headerlink" title="38. java中Process的Api"></a>38. java中Process的Api</h3><p>关键词：ProcessBuilder , java9提供了新的Api。另外还有Runtime.exec这个方法<br>亲测，下面的命令可以在mac上执行uname -a 命令</p><pre><code class="java">//用ProcessBuilder是一种做法 try {            Runtime r = Runtime.getRuntime();            Process p = r.exec(&quot;uname -a&quot;);            p.waitFor();            BufferedReader b = new BufferedReader(new InputStreamReader(p.getInputStream()));            String line = &quot;&quot;;            while ((line = b.readLine()) != null) {                System.out.println(line);            }            b.close();        }catch (IOException | InterruptedException e){        }//  下面这个也行String s = null;        try {            // run the Unix &quot;ps -ef&quot; command            // using the Runtime exec method:            Process p = Runtime.getRuntime().exec(&quot;ps -ef&quot;);            BufferedReader stdInput = new BufferedReader(new                    InputStreamReader(p.getInputStream()));            BufferedReader stdError = new BufferedReader(new                    InputStreamReader(p.getErrorStream()));            // read the output from the command            System.out.println(&quot;Here is the standard output of the command:\n&quot;);            while ((s = stdInput.readLine()) != null) {                System.out.println(s);            }            // read any errors from the attempted command            System.out.println(&quot;Here is the standard error of the command (if any):\n&quot;);            while ((s = stdError.readLine()) != null) {                System.out.println(s);            }            System.exit(0);        }        catch (IOException e) {            System.out.println(&quot;exception happened - here&#39;s what I know: &quot;);            e.printStackTrace();            System.exit(-1);        }</code></pre><p>只不过很少见过用java去调用系统接口的</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/SutherlandFalls_ZH-CN4602884079_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>堆外内存，weakHashMap以及四种引用类型的研究</title>
    <link href="https://haldir65.github.io/2019/07/28/2019-07-28-from-directByteBuffer-to-PhantomReference/"/>
    <id>https://haldir65.github.io/2019/07/28/2019-07-28-from-directByteBuffer-to-PhantomReference/</id>
    <published>2019-07-28T22:34:37.000Z</published>
    <updated>2019-08-12T11:39:32.330Z</updated>
    
    <content type="html"><![CDATA[<p>DiectByteBuffer（堆外内存）是分配在jvm以外的内存，这个java对象本身是受jvm gc控制的，但是其指向的堆外内存是如何回收的<br><img src="https://www.haldir66.ga/static/imgs/JovianCloudscape_EN-AU11726040455_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>java中有四种引用</p><p>Strong Reference<br>Soft Reference （软引用）<br>Weak Reference （弱引用）<br>PhantomReference Reference（虚引用）</p><p>除了强引用，另外三个class都继承自Reference这个父类，其构造函数有两个</p><pre><code class="java">//referent 为引用指向的对象Reference(T referent) {    this(referent, null);}//ReferenceQueue对象，可以简单理解为一个队列//GC 在检测到appropriate reachability changes之后，//会把引用对象本身添加到这个queue中，便于清理引用对象本身Reference(T referent, ReferenceQueue&lt;? super T&gt; queue) {    this.referent = referent;    this.queue = (queue == null) ? ReferenceQueue.NULL : queue;}</code></pre><p>调用虚引用的get方法，总会返回null，与软引用和弱引用不同的是，虚引用被enqueued时，GC 并不会自动清理虚引用指向的对象，只有当指向该对象的所有虚引用全部被清理（enqueued后）后或其本身不可达时，该对象才会被清理。</p><p>如果一个对象只具有虚引用，那么它就和没有任何引用一样，任何时候都可能被gc回收。<br>软（弱、虚）引用必须和一个引用队列（ReferenceQueue）一起使用，当gc回收这个软（弱、虚）引用引用的对象时，会把这个软（弱、虚）引用放到这个引用队列中。<br>比如，上述的Entry是一个弱引用，它引用的对象是key，当key被回收时，Entry会被放到queue中。</p><h2 id="WeakHashMap"><a href="#WeakHashMap" class="headerlink" title="WeakHashMap"></a>WeakHashMap</h2><pre><code class="java">public class WeakHashMap&lt;K,V&gt;    extends AbstractMap&lt;K,V&gt;    implements Map&lt;K,V&gt; {        private final ReferenceQueue&lt;Object&gt; queue = new ReferenceQueue&lt;&gt;();    /**     * Constructs a new, empty &lt;tt&gt;WeakHashMap&lt;/tt&gt; with the default initial     * capacity (16) and load factor (0.75).     */    public WeakHashMap() {        this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);    }    //这是openjdk1.8的源码    //至少从构造函数可以看出来，默认的容量是16。    }</code></pre><p>值得注意的是内部有一个ReferenceQueue。<br>WeakHashMap的核心定义是： 一旦key不再被外部持有，这个Entry将在未来的某一时刻被干掉。<br><a href="https://docs.oracle.com/javase/8/docs/api/java/util/WeakHashMap.html">oracle java doc for weakHashMap</a>中提到，WeakHashMap的key最好是那种equals是直接使用==的，当然使用String这种equals是比较实际内容的也可以。但会带来一些confusing的现象。</p><blockquote><p>This class is intended primarily for use with key objects whose equals methods test for object identity using the == operator. Once such a key is discarded it can never be recreated, so it is impossible to do a lookup of that key in a WeakHashMap at some later time and be surprised that its entry has been removed. This class will work perfectly well with key objects whose equals methods are not based upon object identity, such as String instances. With such recreatable key objects, however, the automatic removal of WeakHashMap entries whose keys have been discarded may prove to be confusing.</p></blockquote><p>在内部结构方面，和jdk1.7的HashMap差不多，都是拉链法来解决哈希冲突<br>WeakHashMap奇怪的点看下面这个例子就知道了</p><pre><code class="java">public class TestWeakHashMap{    private String str1 = new String(&quot;newString1&quot;); //this entry will be removed soon    private String str2 = &quot;literalString2&quot;;    private String str3 = &quot;literalString3&quot;;    private String str4 = new String(&quot;newString4&quot;); //this entry will be removed soon    private Map map = new WeakHashMap();     void testGC() throws IOException    {        map.put(str1, new Object());        map.put(str2, new Object());        map.put(str3, new Object());        map.put(str4, new Object());        /**         * Discard the strong reference to all the keys         */        str1 = null;        str2 = null;        str3 = null;        str4 = null;        while (true) {            System.gc();            /**             * Verify Full GC with the -verbose:gc option             * We expect the map to be emptied as the strong references to             * all the keys are discarded.             */            System.out.println(&quot;map.size(); = &quot; + map.size() + &quot;  &quot; + map);            // map.size(); = 2  {literalString3=java.lang.Object@266474c2, literalString2=java.lang.Object@6f94fa3e}        }    }    public static void main(String[] args) {        try {            new TestWeakHashMap().testGC();        } catch (IOException e) {            e.printStackTrace();        }    }}</code></pre><p>这里提一句，如果是用string.intern搞出来的key，那么永远都不会被移除。</p><p>WeakHashMap看上去就像有一条专门的线程在后台悄悄的清理那些key已经没有其他引用的Entry。<br>这个清理Entry的方法叫做expungeStaleEntries，就是专门用于清除那些失效的Entry的。WeakHashmap中的key被包进一个WeakReference中，<strong>当这个reference出现在ReferenceQueue中的时候，就意味着这个key已经没有地方用到了</strong>。但是这个WeakReference对象还要干掉，expungeStaleEntries就是从queue中取出所有的WeakReference(Entry)，这里当然不会调用WeakReference的get方法，而是使用hash，找到其在tables中的位置，再从链表中找到这个entry，null掉value(因为value被entry强引用，这一步只是帮助gc)，将这个entry从链表中移除。(那么这个WeakReference对象就彻底没有任何引用了，后面gc会free掉这部分的memory)</p><p>这个方法会在很多方法里直接或者间接调用到<br>put,get,size,remove几乎所有的crud方法都会在方法的最开头调用这个方法来移除stale的Entry。</p><p>上面说到<strong>好像有一条线程专门在后台悄悄的把不用的reference放到queue里面</strong>，这条线程是存在的。<br>java.lang.ref.Reference.ReferenceHandler,是Reference的private static 内部class</p><pre><code class="java"> /* High-priority thread to enqueue pending References     */private static class ReferenceHandler extends Thread {   public void run() {            while (true) {                tryHandlePending(true);            }        }}//上面的注释提到high priority，多高的优先级呢。//这段话写在Reference.java里面 static {        ThreadGroup tg = Thread.currentThread().getThreadGroup();        for (ThreadGroup tgn = tg;             tgn != null;             tg = tgn, tgn = tg.getParent());        Thread handler = new ReferenceHandler(tg, &quot;Reference Handler&quot;);        /* If there were a special system-only priority greater than         * MAX_PRIORITY, it would be used here         */        handler.setPriority(Thread.MAX_PRIORITY); //总之就是很高的优先级        handler.setDaemon(true); // 守护线程一般在程序运行的时候在后台提供一种通用服务的线程        handler.start();}</code></pre><h2 id="重点"><a href="#重点" class="headerlink" title="重点:"></a>重点:</h2><p>四种状态(出处见参考)</p><p>每一时刻，Reference对象都处于下面四种状态中。这四种状态用Reference的成员变量queue与next（类似于单链表中的next）来表示。</p><blockquote><p>ReferenceQueue&lt;? super T&gt; queue;<br>Reference next;</p></blockquote><ul><li><font color="red">Active</font>。新创建的引用对象都是这个状态，在 GC 检测到引用对象已经到达合适的reachability时，GC 会根据引用对象是否在创建时制定ReferenceQueue参数进行状态转移，如果指定了，那么转移到Pending，如果没指定，转移到Inactive。在这个状态中</li></ul><blockquote><p>//如果构造参数中没指定queue，那么queue为ReferenceQueue.NULL，否则为构造参数中传递过来的queue<br>queue = ReferenceQueue || ReferenceQueue.NULL<br>next = null</p></blockquote><ul><li><font color="orange">Pending</font>。pending-Reference列表中的引用都是这个状态，它们等着被内部线程ReferenceHandler处理（会调用ReferenceQueue.enqueue方法）。没有注册的实例不会进入这个状态。在这个状态中</li></ul><blockquote><p>//构造参数参数中传递过来的queue<br>queue = ReferenceQueue<br>next = 该queue中的下一个引用，如果是该队列中的最后一个，那么为this</p></blockquote><ul><li><p><font color="green">Enqueued</font>。调用ReferenceQueue.enqueued方法后的引用处于这个状态中。没有注册的实例不会进入这个状态(就是没有走两个参数的构造函数的那种)。在这个状态中</p><blockquote><p>queue = ReferenceQueue.ENQUEUED<br>next = 该queue中的下一个引用，如果是该队列中的最后一个，那么为this</p></blockquote></li><li><p><font color="blue">Inactive</font>。最终状态，处于这个状态的引用对象，状态不会再改变。在这个状态中</p><blockquote><p>queue = ReferenceQueue.NULL<br>next = this</p></blockquote></li></ul><p>有了这些约束，GC 只需要检测next字段就可以知道是否需要对该引用对象采取特殊处理</p><blockquote><p>如果next为null，那么说明该引用为Active状态<br>如果next不为null，那么 GC 应该按其正常逻辑处理该引用（就是走加入queue那一套）。</p></blockquote><h3 id="如果构造函数中指定了ReferenceQueue，那么事后程序员可以通过该队列清理引用"><a href="#如果构造函数中指定了ReferenceQueue，那么事后程序员可以通过该队列清理引用" class="headerlink" title="如果构造函数中指定了ReferenceQueue，那么事后程序员可以通过该队列清理引用"></a>如果构造函数中指定了ReferenceQueue，那么事后程序员可以通过该队列清理引用</h3><h3 id="如果构造函数中没有指定了ReferenceQueue，那么-GC-会自动清理引用"><a href="#如果构造函数中没有指定了ReferenceQueue，那么-GC-会自动清理引用" class="headerlink" title="如果构造函数中没有指定了ReferenceQueue，那么 GC 会自动清理引用"></a>如果构造函数中没有指定了ReferenceQueue，那么 GC 会自动清理引用</h3><p><strong><em>tryHandlePending会将当前的static的一个Reference(pending)加入到r.queue里面,同时设置pending为pending.discovered。(这个discovered是vm赋值的，gc给java层留了个口子，将没有其他引用的Reference赋值到这里了，前提是Reference是调用带ReferenceQueue的构造函数创建的)</em></strong><br>这里头肯定有jni调用，具体原理不清楚。</p><p>tryHandlePending判断提取出来的Reference是否是Cleaner这个class，<br>如果是的话，直接调用Cleaner.clean（）<br>否则执行将这个Reference加入到Queue（这个Reference的Queue）里面</p><pre><code class="java">public class Cleaner    extends PhantomReference&lt;Object&gt;{    // cleaner一般用这种静态函数创建出来可以认为是提供一个回调了    public static Cleaner create(Object ob, Runnable thunk) {        if (thunk == null)            return null;        return add(new Cleaner(ob, thunk));    }}</code></pre><p>至于为什么tryHandlePending这个方法从这个链表里面捞元素的时候会捞出来一个Cleaner呢，因为Cleaner都是这么创建出来的，都是用带Queue的构造函数创建的。</p><pre><code class="java">private Cleaner(Object referent, Runnable thunk) {    super(referent, dummyQueue); //这个Super是PhantomReference，再往上是Reference    this.thunk = thunk;}</code></pre><p>PhantomReference是最弱的引用了。<br>DirectByteBuffer是这样创建Cleaner的：</p><blockquote><p>cleaner = Cleaner.create(this, new Deallocator(base, size, cap));</p></blockquote><p>Deallocator的run方法里面就是调用unSafe的方法根据address去free内存<br>，这就是nio的DirectByteBuffer是如何管理堆外内存的原理了。</p><h3 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h3><ol><li>WeakHashMap的key倾向于使用那种equals是直接比较==的，而不是自己实现hashCode的那一套</li><li>debug的时候有时候会看见“Reference Handler”这么一条线程，就是负责迭代引用链表的</li><li>Reference的构造函数如果传入了ReferenceQueue，相当于给这个Reference的gc事件挂了个钩子,大致相当于reference.addWillGCListener，DirectByteBuffer就是这么干的。很熟悉是吗，finalizer（只是更加轻量级）。</li><li>WeakHashMap的value是强引用，不要去持有key。</li></ol><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>从注释里面可以看出来，java.lan.ref这下面的很多class是Mark Reinhold写的。</p><p>Mark Reinhold is Chief Architect of the Java Platform Group at Oracle. His past contributions to the platform include character-stream readers and writers, reference objects, shutdown hooks, the NIO high-performance I/O APIs, library generification, and service loaders. Mark was the lead engineer for the JDK 1.2 and 5.0 releases, the JCP specification lead for Java SE 6, and both the project and specification lead for JDK 7 (Java SE 7) and JDK 8 (Java SE 8). He currently leads the JDK 9 and Jigsaw projects in the OpenJDK Community, where he also serves on the Governing Board. Mark holds a Ph.D. in computer science from the Massachusetts Institute of Technology.</p><p>Brian Goetz is the Java Language Architect at Oracle, and was the specification lead for JSR-335 (Lambda Expressions for the Java Programming Language.) He is the author of the best-selling Java Concurrency in Practice, as well as over 75 articles on Java development, and has been fascinated by programming since Jimmy Carter was President.</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://liujiacai.net/blog/2015/09/27/java-weakhashmap/">java WeakHashMap</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DiectByteBuffer（堆外内存）是分配在jvm以外的内存，这个java对象本身是受jvm gc控制的，但是其指向的堆外内存是如何回收的&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/JovianCloudscape_EN-AU11726040455_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>Tomcat部分源码解析</title>
    <link href="https://haldir65.github.io/2019/07/28/2019-07-28-tomcat-source-code-grep/"/>
    <id>https://haldir65.github.io/2019/07/28/2019-07-28-tomcat-source-code-grep/</id>
    <published>2019-07-28T21:50:29.000Z</published>
    <updated>2019-08-12T11:39:32.330Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/apache/tomcat">Tomcat</a>源码解析</p><p><img src="https://www.haldir66.ga/static/imgs/LetchworthSP_EN-AU14482052774_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>tomcat的使用很简单，windows下双击那个startup.bat或者cd 到bin目录，运行catlina run就可以了。配置的话，用xml文件就可以了，静态文件放在webapp/目录下。。</p><p>从Spring-boot支持的embedded servlet container就能看出来，tomcat的替代品有不少<br>spring-boot-starter-undertow,<br>spring-boot-starter-jetty,<br>spring-boot-starter-tomcat </p><p><strong><font color="red">源码版本tomcat 9.0.21</font></strong></p><h2 id="从main函数开始吧"><a href="#从main函数开始吧" class="headerlink" title="从main函数开始吧"></a>从main函数开始吧</h2><p>tomcat的主函数在org.apache.catalina.startup.Bootstrap这个文件中</p><pre><code class="java">public final class Bootstrap {    public static void main(String args[]) {        Bootstrap bootstrap = new Bootstrap();        try {            bootstrap.init();        } catch (Throwable t) {            t.printStackTrace();            return;        }        //接下来就是根据不同的command执行对应的start,stop等命令          try {            String command = &quot;start&quot;;            if (args.length &gt; 0) {                command = args[args.length - 1];            }            if (command.equals(&quot;startd&quot;)) {                args[args.length - 1] = &quot;start&quot;;                daemon.load(args);                daemon.start();            } else if (command.equals(&quot;stopd&quot;)) {                args[args.length - 1] = &quot;stop&quot;;                daemon.stop();            } else if (command.equals(&quot;start&quot;)) {                daemon.setAwait(true);                daemon.load(args);                daemon.start();                if (null == daemon.getServer()) {                    System.exit(1);                }            } else if (command.equals(&quot;stop&quot;)) {                daemon.stopServer(args);            } else if (command.equals(&quot;configtest&quot;)) {                daemon.load(args);                if (null == daemon.getServer()) {                    System.exit(1);                }                System.exit(0);            } else {                log.warn(&quot;Bootstrap: command \&quot;&quot; + command + &quot;\&quot; does not exist.&quot;);            }        }    }}</code></pre><h2 id="init的调用栈"><a href="#init的调用栈" class="headerlink" title="init的调用栈"></a>init的调用栈</h2><p>Tomcat能够处理ajp(不常用，无视)和http协议。<br>默认情况下，Server只有一个Service组件，Service组件先后对Engine、Connector进行初始化。而Engine组件并不会在初始化阶段对子容器进行初始化，Host、Context、Wrapper容器的初始化是在start阶段完成的。tomcat默认会启用HTTP1.1和AJP的Connector连接器，这两种协议默认使用Http11NioProtocol、AJPNioProtocol进行处理</p><blockquote><p>Connector的主要功能，是接收连接请求，创建Request和Response对象用于和请求端交换数据；然后分配线程让Engine（也就是Servlet容器）来处理这个请求，并把产生的Request和Response对象传给Engine。当Engine处理完请求后，也会通过Connector将响应返回给客户端。</p></blockquote><p>ProtocolHandler是处理HTTP1.1协议的类(实际上是一个接口)，实现的子类有两个，AbstractProtocol和Http11NioProtocol（继承于AbstractProtocol）<br>AbstractProtocol是基本的实现，可以认为这个类把主要的活都干了，而NIO默认使用的是Http11NioProtocol。</p><p>在AbstractProtocol的init方法中，调用了endpoint.init();endPoint是抽象类，实现类包括NioEndpoint和Nio2Endpoint。Endpoint的主要工作是完成端口和地址的绑定监听。</p><pre><code class="java">// NioEndPoint.javaprivate volatile ServerSocketChannel serverSock = null;// ServerSocketChannel是nio的一个类，用于监听外来请求的protected void initServerSocket() throws Exception {serverSock = ServerSocketChannel.open();        socketProperties.setProperties(serverSock.socket()); // 这里面设了是否要setReuseAddress，设置setSoTimeout为多少        InetSocketAddress addr = new InetSocketAddress(getAddress(), getPortWithOffset());        serverSock.socket().bind(addr,getAcceptCount()); //这里就是socket.bind的地方了}// Nio2Endpoint.java@Overridepublic void bind() throws Exception {    serverSock = AsynchronousServerSocketChannel.open(threadGroup);    socketProperties.setProperties(serverSock);    InetSocketAddress addr = new InetSocketAddress(getAddress(), getPortWithOffset());    serverSock.bind(addr, getAcceptCount());}</code></pre><p>可以看出来NioEndPoint和Nio2EndPoint在绑定socket的时候的区别是后者用的是jdk1.7的AsynchronousServerSocketChannel，而ServerSocketChannel是jdk1.4就有的。java的io操作分为bio,nio,nio2，tomcat8.5开始去掉了bio（就是那种阻塞式io）的支持。</p><p>在 socketProperties.setProperties里面，设置了socket的超时时间，很好奇到底是多少<br>在Constants.java中</p><pre><code class="java">public static final int DEFAULT_CONNECTION_TIMEOUT = 60000; </code></pre><p><strong>所以是1分钟?</strong></p><p>接着NioEndPoint.java的Bind方法来看，走到了selectorPool.open(getName());<br>这里面就是启动了一条线程,NioBlockingSelector.BlockPoller继承自Thread。对应的run方法中使用的是selector那一套(selector.selectedKeys()获得一个Iterator<SelectionKey> ，根据是read,write还是connect的形式去判断)。注意，此刻已经开始select了。select自身是阻塞的，但是一旦有io事件到来，就会将事件交给线程池去处理，所以并发性能是可以的。</p><p><a href="https://www.cnblogs.com/kismetv/p/7806063.html">参考</a></p><font color="red">Tomcat处理请求的过程：在accept队列中接收连接（当客户端向服务器发送请求时，如果客户端与OS完成三次握手建立了连接，则OS将该连接放入accept队列）；在连接中获取请求的数据，生成request；调用servlet容器处理请求；返回response。</font><p>线程池的配置是可以通过server.xml配置的</p><pre><code class="xml">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix =&quot;catalina-exec-&quot; maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot; /&gt;&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; acceptCount=&quot;1000&quot; /&gt;</code></pre><p><font color="red">Connector中的几个参数功能如下：</font></p><ul><li><p>acceptCount<br>accept队列的长度；当accept队列中连接的个数达到acceptCount时，队列满，进来的请求一律被拒绝。默认值是100。<br>关于这个100，我记得2017年的时候，公司后端老大在一次内部技术分享的点评环节提问一帮后端这个参数是多少，其当时还提到这个Executor“就是接客”的(原话如此)。两年后回过头来再来看这段，挺有趣的。</p></li><li><p>maxConnections<br>Tomcat在任意时刻接收和处理的最大连接数。当Tomcat接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomcat接收的连接数小于maxConnections。如果设置为-1，则连接数不受限制。</p></li><li><p>maxThreads<br>请求处理线程的最大数量。默认值是200（Tomcat7和8都是的）。如果该Connector绑定了Executor，这个值会被忽略，因为该Connector将使用绑定的Executor，而不是内置的线程池来执行任务。<br>maxThreads规定的是最大的线程数目，并不是实际running的CPU数量；实际上，maxThreads的大小比CPU核心数量要大得多。这是因为，处理请求的线程真正用于计算的时间可能很少，大多数时间可能在阻塞，如等待数据库返回数据、等待硬盘读写数据等。因此，在某一时刻，只有少数的线程真正的在使用物理CPU，大多数线程都在等待；因此线程数远大于物理核心数才是合理的。<br>换句话说，Tomcat通过使用比CPU核心数量多得多的线程数，可以使CPU忙碌起来，大大提高CPU的利用率。<br>默认值与连接器使用的协议有关：NIO的默认值是10000，APR/native的默认值是8192，而BIO的默认值为maxThreads（如果配置了Executor，则默认值是Executor的maxThreads）。<br>在windows下，APR/native的maxConnections值会自动调整为设置值以下最大的1024的整数倍；如设置为2000，则最大值实际是1024。</p></li></ul><hr><p><font color="red">Executor的主要属性包括：</font></p><ul><li>name：该线程池的标记</li><li>maxThreads：线程池中最大活跃线程数，默认值200（Tomcat7和8都是）</li><li>minSpareThreads：线程池中保持的最小线程数，最小值是25</li><li>maxIdleTime：线程空闲的最大时间，当空闲超过该值时关闭线程（除非线程数小于minSpareThreads），单位是ms，默认值60000（1分钟）</li><li>daemon：是否后台线程，默认值true</li><li>threadPriority：线程优先级，默认值5</li><li>namePrefix：线程名字的前缀，线程池中线程名字为：namePrefix+线程编号</li></ul><hr><p>这些参数的调优有一些经验:<br>（1）maxThreads的设置既与应用的特点有关，也与服务器的CPU核心数量有关。通过前面介绍可以知道，maxThreads数量应该远大于CPU核心数量；而且CPU核心数越大，maxThreads应该越大；应用中CPU越不密集（IO越密集），maxThreads应该越大，以便能够充分利用CPU。当然，maxThreads的值并不是越大越好，如果maxThreads过大，那么CPU会花费大量的时间用于线程的切换，整体效率会降低。<br>（2）maxConnections的设置与Tomcat的运行模式有关。<del/>如果tomcat使用的是BIO，那么maxConnections的值应该与maxThreads一致</del>；如果tomcat使用的是NIO，maxConnections值应该远大于maxThreads。<br>（3）通过前面的介绍可以知道，虽然tomcat同时可以处理的连接数目是maxConnections，但服务器中可以同时接收的连接数为maxConnections+acceptCount 。acceptCount的设置，与应用在连接过高情况下希望做出什么反应有关系。如果设置过大，后面进入的请求等待时间会很长；如果设置过小，后面进入的请求立马返回connection refused。</p><p>走到这里，是从BootStrap.init -&gt; Catalina.init-&gt; …总之中间封了很多层组件… -&gt; 方法的调用栈</p><h2 id="start方法的调用栈"><a href="#start方法的调用栈" class="headerlink" title="start方法的调用栈"></a>start方法的调用栈</h2><p>和init一样,bootStrap的start方法被代理给了catalina的start方法<br>Catalina.java</p><pre><code class="java">public void start() {    try {        getServer().start();    } catch (LifecycleException e) {        //....        return;    }    if (shutdownHook == null) {        shutdownHook = new CatalinaShutdownHook();    }    //用于安全的关闭服务    Runtime.getRuntime().addShutdownHook(shutdownHook);     if (await) { //这个是true            await(); //其目的在于让tomcat在shutdown端口阻塞监听关闭命令            stop();    }}</code></pre><p>上面的getServer返回的是server的默认实现StandardServer，后者的startInternal中又会走到StandardService，的startInternal，这里面会</p><ol><li>调用Engine.start</li><li>启动线程池</li><li>启动Connector</li></ol><p>一个个来看<br>Engine<br>StandardEngine、StandardHost、StandardContext、StandardWrapper各个容器存在父子关系，一个父容器包含多个子容器，并且一个子容器对应一个父容器。Engine是顶层父容器，它不存在父容器。默认情况下，StandardEngine只有一个子容器StandardHost，一个StandardContext对应一个webapp应用，而一个StandardWrapper对应一个webapp里面的一个 Servlet。<br><a href="https://blog.csdn.net/Dwade_mia/article/details/79244157">参考</a><br>StandardEngine的startInternal调用到父类ContainerBase的startInternal方法。具体实现就是给一个线程池去跑所有child的启动任务。当前线程通过Future.get方法阻塞等待所有child初始化完毕。<br>一个child(StandardHost)就是一个webapp，可以添加多个，初始化的时候，有一个线程池，并发去初始化各个webapp<br><strong>server.xml</strong></p><pre><code class="xml">&lt;Host name=&quot;localhost&quot;  appBase=&quot;webapps&quot;            unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot; startStopThreads=&quot;4&quot;&gt;  &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;         prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot;         pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;&lt;/Host&gt;</code></pre><p>然后启动PipeLine（Pipeline是管道组件，用于封装了一组有序的Valve，便于Valve顺序地传递或者处理请求，就是处理请求的前后拦截器）。<br>Valve包括</p><ul><li>AccessLogValve(默认开启，用于记录请求日志)，</li><li>RemoteAddrValve，可以做访问控制，比如限制IP黑白名单 </li><li>RemoteIpValve，主要用于处理 X-Forwarded-For 请求头，用来识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段</li></ul><p>加载子容器的方法是在HostConfig(实现了LifecycleListener，在start中启动Context容器)处理的。<br>HostConfig.java</p><pre><code class="java">    protected void deployApps() {        File appBase = host.getAppBaseFile();        File configBase = host.getConfigBaseFile();        String[] filteredAppPaths = filterAppPaths(appBase.list());        // Deploy XML descriptors from configBase        deployDescriptors(configBase, configBase.list());        // Deploy WARs        deployWARs(appBase, filteredAppPaths);        // Deploy expanded folders        deployDirectories(appBase, filteredAppPaths);    }</code></pre><p>deployWARs也是丢(submit)N个任务到线程池中，然后调用future.get使得当前线程阻塞直到拿到结果。这个任务其实就是解压war文件(war就是zip文件改了个后缀),这个任务包括，调用java处理压缩文件的API(JarEntry)去获取文件内容，还有一些其他的<br>deployDirectories方法的注释是（Deploy exploded webapps.），就是说解压完成之后做的事情。这里面又是executor.submit，然后future.get那一套东西(tomcat里似乎很多用这种方式等待多个任务完成)。<br>deployWars和deployDirectories中都出现了</p><blockquote><p>context = (Context) digester.parse(xml); //所以Context是对xml文件的描述？</p></blockquote><h2 id="NioEndPoint和NioEndPoint2这俩是如何实现从socket接受请求并将其转化为http请求的？"><a href="#NioEndPoint和NioEndPoint2这俩是如何实现从socket接受请求并将其转化为http请求的？" class="headerlink" title="NioEndPoint和NioEndPoint2这俩是如何实现从socket接受请求并将其转化为http请求的？"></a>NioEndPoint和NioEndPoint2这俩是如何实现从socket接受请求并将其转化为http请求的？</h2><h3 id="NioEndPoint"><a href="#NioEndPoint" class="headerlink" title="NioEndPoint"></a>NioEndPoint</h3><p>来看NioEndPoint的注释<br>NIO tailored thread pool, providing the following services:</p><ul><li>Socket acceptor thread</li><li>Socket poller thread</li><li>Worker threads pool<br>When switching to Java 5, there’s an opportunity to use the virtual machine’s thread pool.（这段似乎是使用了System.inheritedChannel这个方法，关于这个方法的介绍非常少）</li></ul><pre><code class="java">public class NioEndpoint extends AbstractJsseEndpoint&lt;NioChannel,SocketChannel&gt; {}// SocketChannel,ByteChannel,ScatteringByteChannel,GatheringByteChannel是nio的classpublic class NioChannel implements ByteChannel, ScatteringByteChannel, GatheringByteChannel {}</code></pre><p>从注释来看,NioEndPoint的功能包括(监听socket的线程，poll的线程，以及一个工作分发的线程池)<br>监听是这一段:</p><pre><code class="java">serverSock = ServerSocketChannel.open();serverSock.socket().bind(addr,getAcceptCount()); //bind方法的第二个参数是requested maximum length of the queue of incoming connections.就是连接等待队列的最大长度</code></pre><p>poll在这里，只有一条线程</p><pre><code class="java">protected static class BlockPoller extends Thread {    //线程名字叫做 “”    poller.setName(name + &quot;-BlockPoller&quot;);    // 结果一般是 NioBlockingSelector.BlockPoller    public void run() {        while (run &amp;&amp; iterator != null &amp;&amp; iterator.hasNext()) {                    SelectionKey sk = iterator.next();                    NioSocketWrapper socketWrapper = (NioSocketWrapper) sk.attachment();                    try {                        iterator.remove();                        sk.interestOps(sk.interestOps() &amp; (~sk.readyOps()));                        if (sk.isReadable()) {                            countDown(socketWrapper.getReadLatch()); //这里就是通知在等待的Poller线程，可以开始读了                        }                        if (sk.isWritable()) { //这里是通知在等待的Poller线程，可以开始写了                            countDown(socketWrapper.getWriteLatch());                        }                    } catch (CancelledKeyException ckx) {                        sk.cancel();                        countDown(socketWrapper.getReadLatch());                        countDown(socketWrapper.getWriteLatch());                    }                }    }}</code></pre><p>所以BlockPoller（线程名NioBlockingSelector.BlockPoller）这条线程的作用主要就是循环监听是否有事情发生，有事情发生之后使用CountDownLatch.countDown，让正在等待的线程开始读。<br>那么是哪条线程在等待？线程是什么时候开始等待的？<br>在Http11InputBuffer.fill方法中</p><pre><code class="java">nRead = socketWrapper.read(block, byteBuffer); // 此时运行在线程池中，也就是工作线程//这个方法调用到了NioBlockingSelector.read方法 while (!timedout) {        if (keycount &gt; 0) { //only read if we were registered for a read            read = socket.read(buf);            if (read != 0) {                break; //如果读取到了一些东西，那么直接跳出循环，不走下面那一套            }        }        try {            if (att.getReadLatch()==null || att.getReadLatch().getCount()==0) {            att.startReadLatch(1); //创建一个CountDownLatch(1)            }            poller.add(att,SelectionKey.OP_READ, reference); //注册一下感兴趣的事件            att.awaitReadLatch(AbstractEndpoint.toTimeout(readTimeout), TimeUnit.MILLISECONDS);             //在这里开始等待        } catch (InterruptedException ignore) {            // Ignore        }}//至于这里为什么要这么写，作为一个读方法，那么如果没有读取到东西，是不是就需要写一个while循环，这会浪费很多cpu cycle，还不如注册一下事件，把轮询的任务交给os。</code></pre><p>所以等待的是线程池中的线程，创建了一个CountDownLatch(1)，等在那里。于此同时BlockPoller线程一直在跑，发现新的Read事件，从attachMent(SocketWrapper中获取这个CountDownLatch，countDown一下，这里就能够恢复继续执行)</p><p>processKey -&gt; AbstractEndPoint.processSocket -&gt; Executor.execute(SocketProcessorBase)(在这里开始分发到工作线程池) -&gt; NioEndPoint.SocketProcessor.doRun -&gt; AbstractProtocol.ConnectionHandler.process -&gt; Processor.process -&gt; AbstractProcessorLight.process -&gt; Http11Processor.service(SocketWrapperBase&lt;?&gt; socketWrapper) -&gt; Http11InputBuffer.parseRequestLine(这里就开始读取Http1.1请求，比较复杂)</p><p>走到Http11InputBuffer说明一定是http1.1的请求格式了(但这有可能是webSocket或者http2的upgrade请求)，在哪里判断是交给http1.1还是http2.0还是ajp协议？在AbstractProcessorLight.process中判断了如果socket.status == SocketEvent.OPEN_READ(就是说这是一个连接上的，刚刚准备好可以读的连接，所以默认直接交给http1.1去处理了，就算是http2后面还是可以upgrade的)</p><p>上面提到NioSocketWrapper是一个attachMent，这个类的实例的创建是在Acceptor中发生的。<br>在NioEndPoint.java的startInternal方法中，有这么一段</p><pre><code class="java"> // Start poller threadpoller = new Poller(); //这个Poller和上面的BlockingPoller不一样Thread pollerThread = new Thread(poller, getName() + &quot;-ClientPoller&quot;);pollerThread.setPriority(threadPriority);pollerThread.setDaemon(true);pollerThread.start();startAcceptorThread();</code></pre><pre><code class="java">protected void startAcceptorThread() {    acceptor = new Acceptor&lt;&gt;(this);     String threadName = getName() + &quot;-Acceptor&quot;;    acceptor.setThreadName(threadName);    Thread t = new Thread(acceptor, threadName);    t.setPriority(getAcceptorThreadPriority());    t.setDaemon(getDaemon());    t.start();}</code></pre><p>所以至少又拉起了两条线程。先来看Acceptor这个线程,在run中做的事情：</p><pre><code class="java">socket = endpoint.serverSocketAccept();endpoint.setSocketOptions() //NioEndpoint.setSocketOptionsNioSocketWrapper socketWrapper = new NioSocketWrapper(channel, this);channel.setSocketWrapper(socketWrapper);socketWrapper.setReadTimeout(getConnectionTimeout());socketWrapper.setWriteTimeout(getConnectionTimeout());socketWrapper.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests());socketWrapper.setSecure(isSSLEnabled());poller.register(channel, socketWrapper); //这里面设定了NioSockertWrapper的interestOps为SelectionKey.OP_READ//NioEndpoint.Poller.registerPollerEvent r = null;r = new PollerEvent(socket, OP_REGISTER); // PollerEvent实现了runnable，在run里面addEvent(r); //往一个SynchronizedQueue里面offer事件</code></pre><p>总结一下，Acceptor这条线程就是不断地接受新的Socket，并创建NioSockertWrapper对象，注册NioSockertWrapper的interestOps为SelectionKey.OP_REGISTER（但这里还没有调用系统api去注册，注意这里是OP_REGISTER）</p><p>再来看ClientPoller这条线程:<br>ClientPoller是先于Acceptor线程跑起来的，看一下run方法的实现<br>NioEndPoint.Poller.run</p><pre><code class="java"> public void run() {   while (true) {    hasEvents = events();     int keyCount = selector.select(selectorTimeout);     while (iterator != null &amp;&amp; iterator.hasNext()) {                    SelectionKey sk = iterator.next();                    NioSocketWrapper socketWrapper = (NioSocketWrapper) sk.attachment();                    // Attachment may be null if another thread has called                    // cancelledKey()                    if (socketWrapper == null) {                        iterator.remove();                    } else {                        iterator.remove();                        processKey(sk, socketWrapper); //这里是处理具体的事件的，会将业务逻辑分发给线程池                    }                }    // Process timeouts    timeout(keyCount,hasEvents);   } }   //从SynchronizedQueue里面取出PollEvent，一个个执行public boolean events() {            boolean result = false;            PollerEvent pe = null;            for (int i = 0, size = events.size(); i &lt; size &amp;&amp; (pe = events.poll()) != null; i++ ) {                try {                    pe.run();                    pe.reset();                } catch ( Throwable x ) {                    log.error(sm.getString(&quot;endpoint.nio.pollerEventError&quot;), x);                }            }            return result;}//PollEvent的run方法里面就有调用java nio系统api了PollEvent.run```java @Overridepublic void run() {    if (interestOps == OP_REGISTER) {        try {            socket.getIOChannel().register(socket.getSocketWrapper().getPoller().getSelector(), SelectionKey.OP_READ, socket.getSocketWrapper()); //这里就是调用了nio的api        } catch (Exception x) {            log.error(sm.getString(&quot;endpoint.nio.registerFail&quot;), x);        }    }else {        // 。。    }    }// 具体调用的系统方法是:AbstractSelectableChannel.register(Selector sel, int ops,                                       Object att)    //三个参数，最后一个是attachMent，也就是上面BlockPoller在run方法中提取出来的attachment//回到timeout方法里，注释说该方法在Poller的每一个loop中都会被调用。protected void timeout(int keyCount, boolean hasEvents) {        long now = System.currentTimeMillis();    // This method is called on every loop of the Poller. Don&#39;t process    // timeouts on every loop of the Poller since that would create too    // much load and timeouts can afford to wait a few seconds.    // However, do process timeouts if any of the following are true:    // - the selector simply timed out (suggests there isn&#39;t much load)    // - the nextExpiration time has passed    // - the server socket is being closed    //这里面主要的判断是否是读超时或者写超时了，如果是的话，CancelKey}</code></pre><p>ClientPoller线程就是负责执行Selector那一套，出现事件之后就分发给工作线程（SocketProcessor），工作线程的名字是这么起的:</p><blockquote><p>TaskThreadFactory tf = new TaskThreadFactory(getName() + “-exec-“, daemon, getThreadPriority());</p></blockquote><p>所以在断点里面能够看到http-nio-8080-exec-1 ,http-nio-8080-exec-2…这个线程池就是主要的处理业务逻辑的线程。</p><p>tbd</p><h2 id="tomcat类加载器-重点"><a href="#tomcat类加载器-重点" class="headerlink" title="tomcat类加载器(重点)"></a>tomcat类加载器(重点)</h2><h2 id="tomcat支持开启sendFile"><a href="#tomcat支持开启sendFile" class="headerlink" title="tomcat支持开启sendFile"></a>tomcat支持开启sendFile</h2><p><a href="https://httpd.apache.org/docs/2.4/mod/core.html#enablesendfile">apache支持zero-copy</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/Dwade_mia/column/info/18882">tomcat源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/apache/tomcat&quot;&gt;Tomcat&lt;/a&gt;源码解析&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/LetchworthSP_EN-AU14482052774_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>Python中的集合类</title>
    <link href="https://haldir65.github.io/2019/07/26/2019-07-26-python-colletcions/"/>
    <id>https://haldir65.github.io/2019/07/26/2019-07-26-python-colletcions/</id>
    <published>2019-07-26T22:21:38.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>很多高级语言都有成熟的集合类，比如Java有很优秀的集合（自动扩容，快速失败，并发集合类），Python也不例外。<br><img src="https://www.haldir66.ga/static/imgs/WorldWaterDay_EN-AU11747740536_1920x1080.jpg" alt=""><br><a id="more"></a></p><h2 id="1-namedtuple"><a href="#1-namedtuple" class="headerlink" title="1. namedtuple()"></a>1. namedtuple()</h2><pre><code class="python">plain_tuple = (10,11,12,13)plain_tuple[0]##10plain_tuple[3]##13</code></pre><p>普通的tuple只能根据下标来获取元素<br>namedtuple使得外部能够以自定义的key获取value</p><pre><code class="python">from collections import namedtuplefruit = namedtuple(&#39;fruit&#39;,&#39;number variety color&#39;)guava = fruit(number=2,variety=&#39;HoneyCrisp&#39;,color=&#39;green&#39;)apple = fruit(number=5,variety=&#39;Granny Smith&#39;,color=&#39;red&#39;)##guava.color##&#39;green&#39;##apple.variety##&#39;Granny Smith&#39;</code></pre><h2 id="2-Counter"><a href="#2-Counter" class="headerlink" title="2. Counter"></a>2. Counter</h2><p>Counter是dict的子类</p><pre><code class="python">from collections import Counterc = Counter(&#39;abcacdabcacd&#39;)print(c)## Counter({&#39;a&#39;: 4, &#39;c&#39;: 4, &#39;b&#39;: 2, &#39;d&#39;: 2}) 其实就是计算每一个字母出现了几次lst = [5,6,7,1,3,9,9,1,2,5,5,7,7]c = Counter(lst)print(c)## Counter({5: 3, 7: 3, 1: 2, 9: 2, 6: 1, 3: 1, 2: 1})s = &#39;the lazy dog jumped over another lazy dog&#39;words = s.split()print(Counter(words).most_common(3))##[(&#39;lazy&#39;, 2), (&#39;dog&#39;, 2), (&#39;the&#39;, 1)] most_common是counter的一个方法，给出前n个出现次数最多的</code></pre><h2 id="3-defaultdict"><a href="#3-defaultdict" class="headerlink" title="3. defaultdict"></a>3. defaultdict</h2><pre><code class="python">d = {}print(d[&#39;A&#39;]) ##   print(d[&#39;A&#39;]) KeyError: &#39;A&#39;   from collections import defaultdicts = [(&#39;yellow&#39;, 1), (&#39;blue&#39;, 2), (&#39;yellow&#39;, 3), (&#39;blue&#39;, 4), (&#39;red&#39;, 1)]d = defaultdict(list) ## 将一个list转成dict的方式for k, v in s:    d[k].append(v)sorted(d.items())</code></pre><h2 id="4-OrderedDict"><a href="#4-OrderedDict" class="headerlink" title="4.OrderedDict"></a>4.OrderedDict</h2><p>OrderedDict是dictionary的子类，迭代顺序与初始insert顺序保持一致。关于python的dictionary，2.x的时候是有序的，3.0-3.5的时候是无序的，3.6开始又变得有序了。<a href="https://www.youtube.com/watch?v=p33CVV29OG8">Modern Dictionaries by Raymond Hettinger</a></p><pre><code class="python">d = {&#39;banana&#39;: 3, &#39;apple&#39;: 4, &#39;pear&#39;: 1, &#39;orange&#39;: 2}for k,v in d.items():    print(&quot;key = {0}, value = {1}&quot;.format(k,v))##key = banana, value = 3# key = apple, value = 4# key = pear, value = 1# key = orange, value = 2    d = OrderedDict(sorted(d.items(), key=lambda t: t[0]))for k,v in d.items():    print(&quot;key = {0}, value = {1}&quot;.format(k,v))  # key = apple, value = 4# key = banana, value = 3# key = orange, value = 2# key = pear, value = 1</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://towardsdatascience.com/pythons-collections-module-high-performance-container-data-types-cb4187afb5fc">python collections</a><br><a href="https://docs.python.org/zh-cn/3/library/collections.html">official docs for python builtin collections</a></p><p><a href="https://docs.python.org/zh-cn/3/library/collections.html">official docs</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很多高级语言都有成熟的集合类，比如Java有很优秀的集合（自动扩容，快速失败，并发集合类），Python也不例外。&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/WorldWaterDay_EN-AU11747740536_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="https://haldir65.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>docker学习笔记</title>
    <link href="https://haldir65.github.io/2019/07/21/2019-07-21-docker-cheatsheet/"/>
    <id>https://haldir65.github.io/2019/07/21/2019-07-21-docker-cheatsheet/</id>
    <published>2019-07-21T20:18:17.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>docker相关的知识点<br><img src="https://haldir66.ga/static/imgs/ship_docking_along_side_bay.jpg" alt=""><br><a id="more"></a></p><blockquote><p>sudo apt install docker-compose</p></blockquote><p>首先的首先，docker命令用sudo权限运行，会少很多麻烦<br>docker image 是snapshot, 而container是docker image的运行实例</p><p>youtube 上有人在 Digital Ocean 的 vps 上安装 docker，主要作用就是将一个复杂的操作系统打包成一个下载即用的容器。进入容器中，可以像在实际的操作系统中一样运行指令。所以虚拟化的机器随时可以使用其他操作系统。<a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04">how-to-install-and-use-docker-on-ubuntu-16-04</a></p><p>docker常用的命令有那么几条</p><blockquote><p>docker run hello-world<br>docker search ubuntu<br>docker pull ubuntu<br>docker run ubuntu ## 进入ubuntu这个container<br>docker images<br>docker run -it ubuntu<br>exit</p></blockquote><h2 id="docker-compose"><a href="#docker-compose" class="headerlink" title="docker-compose"></a>docker-compose</h2><p>使用docker-compose.yml的方式要比输入docker命令来的简单的多。就是将参数写入docker-compose.yml这个文件，然后运行docker-compose up -d命令的方式。</p><p>docker run -p 3000:3000 -ti dummy-app ## 每次都需要输入一大段命令行参数很烦人的，所以把配置写在一个docker-compose.yml文件里面，每次只需要docker-compose up就可以了。</p><h2 id="这两条命令用于自己在本地打一个docker-image"><a href="#这两条命令用于自己在本地打一个docker-image" class="headerlink" title="这两条命令用于自己在本地打一个docker image"></a>这两条命令用于自己在本地打一个docker image</h2><p>docker build -t <your username>/node-web-app .<br>docker build -t packsdkandroiddocker.image -f ./scripts/PackSdkDockerfile .</p><h2 id="注意你修改了Dockerfile之后要重新跑一遍docker-build-t-node-web-app"><a href="#注意你修改了Dockerfile之后要重新跑一遍docker-build-t-node-web-app" class="headerlink" title="注意你修改了Dockerfile之后要重新跑一遍docker build -t /node-web-app ."></a>注意你修改了Dockerfile之后要重新跑一遍docker build -t <your username>/node-web-app .</h2><p><a href="https://stackoverflow.com/questions/18804124/docker-updating-image-along-when-dockerfile-changes">每次修改之后重新打image</a></p><p>docker会在/var/lib/docker文件夹里吃掉大量空间，释放空间的话</p><blockquote><p>docker system prune -a</p></blockquote><p><a href="https://nodejs.org/en/docs/guides/nodejs-docker-webapp/">用docker host一个node js app</a>。实测下来image大小在600MB左右，内存占用200MB左右。</p><p><a href="https://medium.com/@kahana.hagai/docker-compose-with-node-js-and-mongodb-dbdadab5ce0a">用docker运行一个node mongodb应用</a> 亲测有效<br><a href="https://hub.docker.com/r/mhart/alpine-node/">node的官方image太大了，alpine-node占用的磁盘空间更小</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://linuxconfig.org/how-to-launch-containers-with-docker-compose">how-to-launch-containers-with-docker-compose</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;docker相关的知识点&lt;br&gt;&lt;img src=&quot;https://haldir66.ga/static/imgs/ship_docking_along_side_bay.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>openjdk源码解析[一]</title>
    <link href="https://haldir65.github.io/2019/07/13/2019-07-13-openjdk-codegrep_01/"/>
    <id>https://haldir65.github.io/2019/07/13/2019-07-13-openjdk-codegrep_01/</id>
    <published>2019-07-13T21:06:23.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/AdoptOpenJDK/openjdk-jdk8u/blob/master/jdk/src/windows/native/java/net/SocketOutputStream.c">openjdk</a>部分源码解析(文件IO),java层以及c语言层的分析<br><img src="https://www.haldir66.ga/static/imgs/BlueShark_EN-AU12265881842_1920x1080.jpg" alt=""></p><a id="more"></a><h2 id="File-IO"><a href="#File-IO" class="headerlink" title="File IO"></a>File IO</h2><p>IOUtils<br>FileChannel</p><h2 id="回顾一下C语言提供的操作文件的api"><a href="#回顾一下C语言提供的操作文件的api" class="headerlink" title="回顾一下C语言提供的操作文件的api"></a>回顾一下C语言提供的操作文件的api</h2><p>1 .读写(创建)文件</p><pre><code class="c">#include &lt;stdio.h&gt; FILE *fopen( const char * filename, const char * mode ); //定义在标准中的，所以是跨平台的int fclose( FILE *fp ); //关闭文件</code></pre><table><thead><tr><th>模式</th><th>描述</th></tr></thead><tbody><tr><td>r</td><td>打开一个已有的文本文件，允许读取文件。</td></tr><tr><td>w</td><td>打开一个文本文件，允许写入文件。如果文件不存在，则会创建一个新文件。在这里，您的程序会从文件的开头写入内容。如果文件存在，则该会被截断为零长度，重新写入。</td></tr><tr><td>a</td><td>打开一个文本文件，以追加模式写入文件。如果文件不存在，则会创建一个新文件。在这里，您的程序会在已有的文件内容中追加内容。</td></tr><tr><td>r+</td><td>打开一个文本文件，允许读写文件。</td></tr><tr><td>w+</td><td>打开一个文本文件，允许读写文件。如果文件已存在，则文件会被截断为零长度，如果文件不存在，则会创建一个新文件。</td></tr><tr><td>a+</td><td>打开一个文本文件，允许读写文件。如果文件不存在，则会创建一个新文件。读取会从文件的开头开始，写入则只能是追加模式。</td></tr></tbody></table><pre><code class="c">int fputs( const char *s, FILE *fp ); //将字符串s写入文件中char *fgets( char *buf, int n, FILE *fp ); //从fp指向的输入流中读取n-1个字符，并且自动追加一个 null 字符来终止字符串</code></pre><p>回到java这一端，创建一个文件File file = new File(“c:\somefile.txt”) 只是创建了一个java object。<br>File的一些方法代理给了FileSystem这个抽象类，在unix平台上的实现是UnixFileSystem.java。</p><p>例如File.exists方法，最终进入FileSystem.getBooleanAttributes0。这是一个native方法,对应的实现在<a href="https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/solaris/native/java/io/UnixFileSystem_md.c">UnixFileSystem_md.c</a>中</p><pre><code class="c">static jbooleanstatMode(const char *path, int *mode){    struct stat64 sb;    if (stat64(path, &amp;sb) == 0) {        *mode = sb.st_mode;        return JNI_TRUE;    }    return JNI_FALSE;}JNIEXPORT jint JNICALLJava_java_io_UnixFileSystem_getBooleanAttributes0(JNIEnv *env, jobject this,                                                  jobject file){    jint rv = 0;    WITH_FIELD_PLATFORM_STRING(env, file, ids.path, path) {        int mode;        if (statMode(path, &amp;mode)) {            int fmt = mode &amp; S_IFMT;            rv = (jint) (java_io_FileSystem_BA_EXISTS                  | ((fmt == S_IFREG) ? java_io_FileSystem_BA_REGULAR : 0)                  | ((fmt == S_IFDIR) ? java_io_FileSystem_BA_DIRECTORY : 0));        }    } END_PLATFORM_STRING(env, path);    return rv;}// S_IFMT是一个掩码， S_IFREG表示是一个普通文件， S_IFDIR表示是一个目录。返回值是一个int（其中4位被分别用于存储BA_HIDDEN，BA_DIRECTORY，BA_REGULAR，BA_EXISTS），足以表达文件的这几种常用属性。java层获取对应的属性后，进行位运算就能知道这个文件的属性了。</code></pre><p>文件读写以及FileDescriptor<br>文件描述符在unix系统上是非负的int，用于代表一个文件。java层的FileDescriptor中包裹了一个int fd。<br>读写文件都需要通过FileInputStream进行，构造函数中有一个open方法，对应c语言的方法在<br><a href="https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/share/native/java/io/FileInputStream.c">FileInputStream.c</a>中</p><pre><code class="c">JNIEXPORT void JNICALLJava_java_io_FileInputStream_open(JNIEnv *env, jobject this, jstring path) {    fileOpen(env, this, path, fis_fd, O_RDONLY);}</code></pre><p>fileOpen的实现在<a href="https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/solaris/native/java/io/io_util_md.c">io_util_md.c</a>中</p><pre><code class="c">voidfileOpen(JNIEnv *env, jobject this, jstring path, jfieldID fid, int flags){    WITH_PLATFORM_STRING(env, path, ps) {        FD fd;#if defined(__linux__) || defined(_ALLBSD_SOURCE)        /* Remove trailing slashes, since the kernel won&#39;t */        char *p = (char *)ps + strlen(ps) - 1;        while ((p &gt; ps) &amp;&amp; (*p == &#39;/&#39;))            *p-- = &#39;\0&#39;;#endif        fd = JVM_Open(ps, flags, 0666);         if (fd &gt;= 0) {            SET_FD(this, fd, fid);        } else {            throwFileNotFoundException(env, path);        }    } END_PLATFORM_STRING(env, ps);}</code></pre><p>JVM_OPEN是jvm的方法，不属于jdk了，要去hotSpot里面查看对应的实现：<br>//  在/hotspot/src/share/vm/prims/jvm.cpp （cpp我不熟，据说这里面最终走的是 open64方法）</p><p><strong>这里要提一句，jvm不止oracle一家</strong>，还包括OpenJDK，SUN JVM，IBM JVM，都是对java specification的implementation。</p><h3 id="文件读写"><a href="#文件读写" class="headerlink" title="文件读写"></a>文件读写</h3><p>java这边读取文件用的是FileInputStream，下面方法表示读取一个Byte</p><pre><code class="java">private native int read0() throws IOException; </code></pre><p>对应openjdk的实现在<a href="https://github.com/AdoptOpenJDK/openjdk-jdk8u/blob/master/jdk/src/share/native/java/io/FileInputStream.c">FileInputStream.c</a>文件中</p><pre><code class="c">JNIEXPORT jint JNICALLJava_java_io_FileInputStream_read0(JNIEnv *env, jobject this) {    return readSingle(env, this, fis_fd);}</code></pre><p><a href="https://github.com/AdoptOpenJDK/openjdk-jdk8u/blob/master/jdk/src/share/native/java/io/io_util.c">readSingle在io_util.c中</a></p><pre><code class="c">jintreadSingle(JNIEnv *env, jobject this, jfieldID fid) {    jint nread;    char ret;    FD fd = GET_FD(this, fid);    if (fd == -1) {        JNU_ThrowIOException(env, &quot;Stream Closed&quot;);        return -1;    }    nread = IO_Read(fd, &amp;ret, 1);    if (nread == 0) { /* EOF */        return -1;    } else if (nread == -1) { /* error */        JNU_ThrowIOExceptionWithLastError(env, &quot;Read error&quot;);    }    return ret &amp; 0xFF;}// IO_Read指向io_util_md.c中的handleRead方法ssize_thandleRead(FD fd, void *buf, jint len){    ssize_t result;    RESTARTABLE(read(fd, buf, len), result);    return result;}</code></pre><blockquote><p>c语言的read方法:</p><pre><code>头文件：#include &lt;unistd.h&gt;定义函数：ssize_t read(int fd, void * buf, size_t count);函数说明：read()会把参数fd 所指的文件传送count 个字节到buf 指针所指的内存中. 若参数count 为0, 则read()不会有作用并返回0. 返回值为实际读取到的字节数, 如果返回0, 表示已到达文件尾或是无可读取的数据,此外文件读写位置会随读取到的字节移动.</code></pre></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://fansunion.blog.csdn.net/article/details/13252309">openjdk是如何读取.class文件的</a><br><a href="https://hunterzhao.io/">openjdk源码分析</a><br><a href="https://github.com/openjdk-mirror/jdk7u-hotspot">hotspot源码</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/AdoptOpenJDK/openjdk-jdk8u/blob/master/jdk/src/windows/native/java/net/SocketOutputStream.c&quot;&gt;openjdk&lt;/a&gt;部分源码解析(文件IO),java层以及c语言层的分析&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/BlueShark_EN-AU12265881842_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>AbstractQueuedSynchronizer源码分析</title>
    <link href="https://haldir65.github.io/2019/07/05/2019-07-05-abstractQueuedSynchronizer/"/>
    <id>https://haldir65.github.io/2019/07/05/2019-07-05-abstractQueuedSynchronizer/</id>
    <published>2019-07-05T08:59:54.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>关于java.util.concurrent.locks.AbstractQueuedSynchronizer,这个类是juc的基础。ReentrantLock中，ThreadPoolExecutor中，CountDownLatch中都有用到。<br><img src="https://www.haldir66.ga/static/imgs/CapeBretonSunset_EN-AU10231293487_1920x1080.jpg" alt=""><br><a id="more"></a></p><p>先看java doc中是怎样描述的吧:<br><strong>Provides a framework for implementing blocking locks and related synchronizers (semaphores, events, etc) that rely on first-in-first-out (FIFO) wait queues. </strong></p><!--more--><p>通常使用ReentrantLock的时候，都是这样的</p><pre><code class="java">reentrantLock.lock();try {    // 执行代码...} finally {// 释放锁reentrantLock.unlock();}</code></pre><p>来看看内部实现<br>ReentrantLock.lock方法</p><pre><code class="java"> public void lock() {        sync.lock();}/**    * Sync object for non-fair locks     默认是非公平的Sync，非常短，主要的逻辑都在父类AQS中*/static final class NonfairSync extends Sync {    /**        * Performs lock.  Try immediate barge, backing up to normal        * acquire on failure.        */    final void lock() {        if (compareAndSetState(0, 1))            setExclusiveOwnerThread(Thread.currentThread());        else            acquire(1);    }    protected final boolean tryAcquire(int acquires) {        return nonfairTryAcquire(acquires);    }}static final class FairSync extends Sync {        final void lock() {            acquire(1);        }    public final void acquire(int arg) {        if (!tryAcquire(arg) &amp;&amp;            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))            selfInterrupt();    }}</code></pre><p><a href="https://javadoop.com/post/AbstractQueuedSynchronizer">acquire这个方法主要在这篇文章里，写的非常好</a>。这篇文章分析的是FairSync,但NonFairSync的区别并不大，比方说公平锁遵守先来后到（所有的线程都会争着去排队到tail），非公平锁则是上来就试着用cas抢锁(抢成功的话就setExclusiveOwner)，不成功的话才走排队那一套</p><p>挂起线程和唤醒线程使用的是<br>LockSupport.park(this);<br>LockSupport.unpark(s.thread);<br>根据网上的分析，在native层使用的是cpp的pthread_mutex，不是可以重入的(也就是不要乱来，lock和unlock一定要配对使用)</p><p>使用到了AbstractQueuedSynchronizer的类包括reentrantLock中的Sync, ThreadPoolExecutor中的worker，CountDownLatch中的Sync,Semaphore.Sync。以下分别展开这些类的叙述</p><h2 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h2><p>非常常见的锁，注意的是一定要在finally里面释放掉锁。内部包含一个Sync静态类。<br>上述已经提到了ReentrantLock是如何通过Sync完成lock以及后续节点的唤醒的</p><h2 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h2><p>主线程启动几条线程同时起跑，希望主线程不要急着退出，等其他线程跑完，主线程再恢复运行，这种场景用CountDownLatch可以，用CyclicBarrier可以，用Phaser也可以。参考<a href="https://www.javadoop.com/post/phaser-tutorial">Phaser 使用介绍</a>中的示例代码</p><p>使用CountDownLatch的话</p><pre><code class="java">// 1. 设置 count 为 1CountDownLatch latch = new CountDownLatch(1);for (int i = 0; i &lt; 10; i++) {    new Thread(() -&gt; {        try {            // 2. 每个线程都等在栅栏这里，等待放开栅栏，不会因为有些线程先启动就先跑路了            latch.await();            // doWork();        } catch (InterruptedException ignore) {        }    }).start();}doSomethingELse(); // 确保在下面的代码执行之前，上面每个线程都到了 await() 上。// 3. 放开栅栏latch.countDown();</code></pre><p>CountDownLatch.java</p><pre><code class="java">public void await() throws InterruptedException {    sync.acquireSharedInterruptibly(1);}public void countDown() {    sync.releaseShared(1);}</code></pre><p>await中使当前线程停下来的方法在doAcquireSharedInterruptibly中，而唤醒线程的方法在releaseShared中。CountDownLatch因为有一个count的概念，所以在调用releaseShared之前总是会判断当前count是否已经到达了0。因为一旦到达了0，那么在等待的线程(调用了await的线程就可以恢复运行)。</p><blockquote><p>CountDoownLatch的原理： <strong>AQS 共享模式的典型使用，构造函数中的 1 是设置给 AQS 的 state 的。latch.await() 方法会阻塞，而 latch.countDown() 方法就是用来将 state– 的，减到 0 以后，唤醒所有的阻塞在 await() 方法上的线程。</strong></p></blockquote><h3 id="CyclicBarrier-来实现这种几条线程同步的方法更简单"><a href="#CyclicBarrier-来实现这种几条线程同步的方法更简单" class="headerlink" title="CyclicBarrier 来实现这种几条线程同步的方法更简单"></a>CyclicBarrier 来实现这种几条线程同步的方法更简单</h3><pre><code class="java">// 1. 构造函数中指定了 10 个 partiesCyclicBarrier barrier = new CyclicBarrier(10);for (int i = 0; i &lt; 10; i++) {    executorService.submit(() -&gt; {        try {            // 2. 每个线程&quot;报告&quot;自己到了，            //    当第10个线程到的时候，也就是所有的线程都到齐了，一起通过            barrier.await();            // doWork()        } catch (InterruptedException | BrokenBarrierException ex) {            ex.printStackTrace();        }    });}</code></pre><h3 id="Phaser其实是用到的比较少的"><a href="#Phaser其实是用到的比较少的" class="headerlink" title="Phaser其实是用到的比较少的"></a>Phaser其实是用到的比较少的</h3><pre><code class="java">Phaser phaser = new Phaser();// 1. 注册一个 partyphaser.register();for (int i = 0; i &lt; 10; i++) {    phaser.register();    executorService.submit(() -&gt; {        // 2. 每个线程到这里进行阻塞，等待所有线程到达栅栏        phaser.arriveAndAwaitAdvance();        // doWork()    });}phaser.arriveAndAwaitAdvance();</code></pre><p>上述代码中phaser.register被调用了11次，就像开会一样，所有人都到齐了才能开始</p><h2 id="ThreadPoolExecutor-Worker"><a href="#ThreadPoolExecutor-Worker" class="headerlink" title="ThreadPoolExecutor.Worker"></a>ThreadPoolExecutor.Worker</h2><h2 id="Semaphere"><a href="#Semaphere" class="headerlink" title="Semaphere"></a>Semaphere</h2><p>Semaphere的构造函数中可以传一个int参数,用于标识同时最多有几条线程可以获得permit（也就是同时最多有几条线程进入acquire和release之间的代码块中）</p><pre><code class="java">semaphere.acquire();// 操作数据semaphere.release();</code></pre><p>假如构造函数中传入了1，那么这个semaphore实际上是一个lock或者说mutex，如果大于一，那么同时进入这段代码块里的线程就有多个了，就需要实现自己的同步逻辑。（race condition，往往要加一段sleep就能快速重现，比如两条线程同时对一个int 0 自增，那么极有可能得到的结果是1而不是预期的2，因为各自看到的都是0）</p><h2 id="Exchanger"><a href="#Exchanger" class="headerlink" title="Exchanger"></a>Exchanger</h2><p>Exchanger是成双成对使用的，支持泛型，两条线程同时开跑，先到的会等着，两个都到了之后，互相交换泛型的数据</p><h2 id="Mutex"><a href="#Mutex" class="headerlink" title="Mutex"></a>Mutex</h2><p>juc里面没有c语言那样的mutex，不过Reentrantlock这种实际上就发挥了mutex的作用。</p><h2 id="tbd"><a href="#tbd" class="headerlink" title="tbd"></a>tbd</h2><p>使用AQS的普遍方式是自己继承实现一个Sync（写一个试试看？,Tomcat里面就有）</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://javadoop.com/post/AbstractQueuedSynchronizer-2">一行一行源码分析清楚 AbstractQueuedSynchronizer</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于java.util.concurrent.locks.AbstractQueuedSynchronizer,这个类是juc的基础。ReentrantLock中，ThreadPoolExecutor中，CountDownLatch中都有用到。&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/CapeBretonSunset_EN-AU10231293487_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>算法-数组全排列</title>
    <link href="https://haldir65.github.io/2019/04/03/2019-04-03-algorithm-array-permutation/"/>
    <id>https://haldir65.github.io/2019/04/03/2019-04-03-algorithm-array-permutation/</id>
    <published>2019-04-03T13:44:25.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>问题描述<br><a id="more"></a></p><p>全排列表示把集合中元素的所有按照一定的顺序排列起来，使用P(n, n) = n!表示n个元素全排列的个数。P(n, n)中的第一个n表示元素的个数，第二个n表示取多少个元素进行排列。<br>比方说[1,2,3]这个数组，全排列就有这6种结果</p><pre><code>[1,2,3][1,3,2][2,1,3][2,3,1][3,1,2][3,2,1]</code></pre><p>给定一个n个元素数组，其全排列的过程可以描述如下：<br>（1）任意取一个元素放在第一个位置，则有n种选择；<br>（2）再剩下的n-1个元素中再取一个元素放在第二个位置则有n-1种选择，此时可以看做对n-1个元素进行全排列；<br>（3）重复第二步，直到对最后一个元素进行全排列，即最后一个元素放在最后一个位置，全排列结束。</p><p>以数组{1,2,3}为例，其全排列的过程如下：<br>（1）1后面跟（2,3）的全排列；<br>（2）2后面跟（1,3）的全排列；<br>（3）3后面跟（1,2）的全排列。</p><h2 id="递归版本的实现"><a href="#递归版本的实现" class="headerlink" title="递归版本的实现"></a>递归版本的实现</h2><pre><code class="CPP">#include &lt;iostream&gt;using namespace std;int sum=0; //全排列个数//打印数组内容void print(int array[],int len){    printf(&quot;{&quot;);    for(int i=0; i&lt;len;++i)        cout&lt;&lt;array[i]&lt;&lt;&quot; &quot;;    printf(&quot;}\n&quot;);}//实现两数交换void swap(int* o,int i,int j){    int tmp = o[i];    o[i] = o[j];    o[j] = tmp;}//递归实现数组全排列并打印void permutation(int array[],int len,int index){    if(index==len){//全排列结束        ++sum;        print(array,len);    }    else        for(int i=index;i&lt;len;++i){            //将第i个元素交换至当前index下标处            swap(array,index,i);            //以递归的方式对剩下元素进行全排列            permutation(array,len,index+1);            //将第i个元素交换回原处            swap(array,index,i);        }}int main(){    int array[3]={1,2,3};    permutation(array,3,0);    cout&lt;&lt;&quot;sum:&quot;&lt;&lt;sum&lt;&lt;endl;    getchar();}</code></pre><h3 id="考虑数组元素中有重复的元素"><a href="#考虑数组元素中有重复的元素" class="headerlink" title="考虑数组元素中有重复的元素"></a>考虑数组元素中有重复的元素</h3><p>对于[1,2,2]这种数组，把第一个数1和第二个数2互换得到[2,1,2],接下来第一个数1与第三个数2互换就没有必要了。再考虑[2,1,2]，第二个数与第三个数互换得到[2,2,1],至此全排列结束。</p><font color="red">这样我们也得到了在全排列中去掉重复的规则——去重的全排列就是从第一个数字起每个数分别与它后面非重复出现的数字交换。</font><p>修改代码如下:</p><pre><code class="cpp">//是否交换bool isSwap(int array[],int len,int index){        for(int i=index+1;i&lt;len;++i)//从这个index开始，往后一旦出现了和该数字重复的，不用互换了            if(array[index]==array[i])                return false;        return true;}//递归实现有重复元素的数组全排列void permutation(int array[],int len,int index){    if(index==len){//全排列结束        ++sum;        print(array,len); //如果只有一个的话，那必然已是全排列完成了的    }    else        for(int i=index;i&lt;len;++i){            if(isSwap(array,len,i)){ //新增判断是否交换                //将第i个元素交换至当前index下标处                swap(array,index,i);                //以递归的方式对剩下元素进行全排列                permutation(array,len,index+1);//固定当前的首位元素，递归求剩下的全排列种类                //将第i个元素交换回原处                swap(array,index,i);            }        }}</code></pre><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://blog.csdn.net/k346k346/article/details/51154786">数组的全排列</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;问题描述&lt;br&gt;
    
    </summary>
    
    
      <category term="算法" scheme="https://haldir65.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>算法-Top-K问题</title>
    <link href="https://haldir65.github.io/2019/03/30/2019-03-30-algorithm-top-K/"/>
    <id>https://haldir65.github.io/2019/03/30/2019-03-30-algorithm-top-K/</id>
    <published>2019-03-30T22:17:37.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>10亿个数中找出最大的10000个数（top K问题）</p><a id="more"></a><h2 id="1-直接排序然后取最大的K个数"><a href="#1-直接排序然后取最大的K个数" class="headerlink" title="1. 直接排序然后取最大的K个数"></a>1. 直接排序然后取最大的K个数</h2><p>总的时间复杂度为O(N<em>logN)+O(K)=O(N</em>logN)。该算法存在以下问题：</p><p>快速排序的平均复杂度为O(N*logN)，但最坏时间复杂度为O(n2)，不能始终保证较好的复杂度<br>只需要前k大或k小的数,，实际对其余不需要的数也进行了排序，浪费了大量排序时间</p><h2 id="2-利用快速排序的特点"><a href="#2-利用快速排序的特点" class="headerlink" title="2. 利用快速排序的特点"></a>2. 利用快速排序的特点</h2><p>在数组中随机找一个元素key，将数组分成两部分Sa和Sb，其中Sa的元素&gt;=key，Sb的元素&lt;key</p><p>若Sa中元素的个数大于或等于k，则在Sa中查找最大的k个数<br>若Sa中元素的个数小于k，其个数为len，则在Sb中查找k-len个数字</p><pre><code class="java">public static int findTopK(int[] array, int left, int right, int k) {    int index = -1;    if (left &lt; right) {        int pos = partition(array, left, right);        int len = pos - left + 1;        if (len == k) {            index = pos;        } else if (len &lt; k) {//Sa中元素个数小于K，到Sb中查找k-len个数字            index = findTopK(array, pos + 1, right, k - len);        } else {//Sa中元素的个数大于或等于k            index = findTopK(array, left, pos - 1, k);        }    }    return index;}/** * 按基准点划分数组，左边的元素大于基准点，右边的元素小于基准点 * * @param array * @param left * @param right * @return */public static int partition(int[] array, int left, int right) {    int x = array[left];//基准点，随机选择    do {        while (array[right] &lt; x &amp;&amp; left &lt; right)//从后向前扫描，找到第一个比基准点大的元素            right--;        if (left &lt; right) {            array[left] = array[right];//大元素前移            left++;         }        while (array[left] &gt;= x &amp;&amp; left &lt; right) //从前向后扫描，找到第一个比基准点小的元素            left++;        if (left &lt; right) {            array[right] = array[left];//小元素后移            right--;        }    } while (left &lt; right);    array[left] = x;    return left;}</code></pre><h2 id="3-小顶堆"><a href="#3-小顶堆" class="headerlink" title="3. 小顶堆"></a>3. 小顶堆</h2><p>堆排序在处理海量数据的时候十分有效<br>查找最大的K个数，其实就是建立一个大小为K的小顶堆，每次出现比顶部大的元素时，替换，并重新调整堆<br>代码实现如下<br>下面这个是找出最小的K个元素，并且是构建大顶堆</p><pre><code class="java">public static int[] findTopK(int[] array, int k) {    int heapArray[] = new int[k];    for (int i = 0; i &lt; k; i++) {        heapArray[i] = array[i];    }    buildMaxHeap(heapArray);    for (int i = k; i &lt; array.length; i++) {        if (array[i] &lt; heapArray[0]) {            heapArray[0] = array[i];//更新堆顶            adjustMaxHeap(heapArray, 0, heapArray.length);        }    }    return heapArray;}/** * 构建小顶堆 * * @param array */public static void buildMaxHeap(int[] array) {    for (int i = array.length / 2 - 1; i &gt;= 0; i--) {        adjustMaxHeap(array, i, array.length);    }}/** * 调整堆结构 * * @param array * @param root   根节点 * @param length */public static void adjustMaxHeap(int[] array, int root, int length) {    int left = root * 2 + 1; //左节点下标，数组下标从0开始，所以加1    int right = left + 1; //右节点下标    int largest = root;// 存放三个节点中最大节点的下标    if (left &lt; length &amp;&amp; array[left] &gt; array[root]) { //左节点大于根节点，更新最大节点的下标        largest = left;    }    if (right &lt; length &amp;&amp; array[right] &gt; array[largest]) {//右节点大于根节点，最大节点的下标        largest = right;    }    if (root != largest) {        swap(array, largest, root);        adjustMaxHeap(array, largest, length);    }}/** * 交换 * * @param arr * @param i * @param j */public static void swap(int[] arr, int i, int j) {    int temp = arr[i];    arr[i] = arr[j];    arr[j] = temp;}</code></pre><p>算法的时间复杂度为O(N * logk)</p><h2 id="4-假如数据的最大值和最小值差距不大，都是整数的话，可以考虑申请一个数组，存放每个元素出现的次数，结束后对这个数组从后往前统计，碰到count大于0的说明出现过，统计到了K个就结束"><a href="#4-假如数据的最大值和最小值差距不大，都是整数的话，可以考虑申请一个数组，存放每个元素出现的次数，结束后对这个数组从后往前统计，碰到count大于0的说明出现过，统计到了K个就结束" class="headerlink" title="4. 假如数据的最大值和最小值差距不大，都是整数的话，可以考虑申请一个数组，存放每个元素出现的次数，结束后对这个数组从后往前统计，碰到count大于0的说明出现过，统计到了K个就结束"></a>4. 假如数据的最大值和最小值差距不大，都是整数的话，可以考虑申请一个数组，存放每个元素出现的次数，结束后对这个数组从后往前统计，碰到count大于0的说明出现过，统计到了K个就结束</h2><pre><code class="java">public static List&lt;Integer&gt; findTopK(int[] array, int k) {    int max = array[0];    for (int i = 0; i &lt; array.length; i++) {        if (max &lt; array[i]) {            max = array[i];        }    }    int count[] = new int[max + 1];    for (int i = 0; i &lt; array.length; i++) {        count[array[i]] += 1;    }    List&lt;Integer&gt; topKList = new ArrayList&lt;&gt;();    for (int sumCount = 0, j = count.length - 1; j &gt;= 0; j--) {        int c = count[j];        sumCount += c;        if (c &gt; 0) {            for (int i = 0; i &lt; c; i++) {                topKList.add(j);            }        }        if (sumCount &gt;= k) {            break;        }    }    return topKList;}</code></pre><p>该算法还可以用bitmap算法优化，用一个int表示32个整数。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;10亿个数中找出最大的10000个数（top K问题）&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法" scheme="https://haldir65.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>从setContentView开始谈的渲染流程</title>
    <link href="https://haldir65.github.io/2019/03/29/2019-03-29-from-setcontentview-to-rendering/"/>
    <id>https://haldir65.github.io/2019/03/29/2019-03-29-from-setcontentview-to-rendering/</id>
    <published>2019-03-29T09:25:01.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>谈一谈View的渲染流程吧<br><img src="https://www.haldir66.ga/static/imgs/TamarackCones_EN-AU12178466392_1920x1080.jpg" alt=""></p><a id="more"></a><h3 id="Activity"><a href="#Activity" class="headerlink" title="Activity"></a>Activity</h3><p>不负责控制视图，它主要控制生命周期和处理事件。Activity中通过持有PhoneWindow来控制视图,而事件则是通过WindowCallback来传达给Activity的<br>Window（唯一实现类是PhoneWindow）。PhoneWindow是在activity的attach中new出来的，并且设置了PhoneWindow.setCallback(this)。大致代码如下</p><pre><code class="java">//activity.javafinal void attach(Context context, ActivityThread aThread,        Instrumentation instr, IBinder token, int ident,        Application application, Intent intent, ActivityInfo info,        CharSequence title, Activity parent, String id,        NonConfigurationInstances lastNonConfigurationInstances,        Configuration config, String referrer, IVoiceInteractor voiceInteractor,        Window window, ActivityConfigCallback activityConfigCallback) {    attachBaseContext(context);    mWindow = new PhoneWindow(this, window, activityConfigCallback);//创建一个window    mWindow.setWindowControllerCallback(this);    mWindow.setCallback(this); //用于向activity分发点击或者状态改变事件    mWindow.setOnWindowDismissedCallback(this);    mWindow.setWindowManager(    (WindowManager)context.getSystemService(Context.WINDOW_SERVICE),    mToken, mComponent.flattenToString(),    (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != 0);//设置windowManager对象    }</code></pre><p>PhoneWindow中持有了DecorView，DecorView是最顶层的视图</p><h3 id="PhoneWindow和mContentParent"><a href="#PhoneWindow和mContentParent" class="headerlink" title="PhoneWindow和mContentParent"></a>PhoneWindow和mContentParent</h3><p>DecorView继承自FrameLayout，内部只有一个LinearLayout的child（mContentParent）,这个linearLayout从上到下依次是ViewStub(actionBar)，一个FrameLayout(标题栏),一个android.R.id.content的FrameLayout.<br>Activity的setContentView走到了PhoneWindow的setContentView中</p><pre><code class="java">// PhoneWindow.java  @Override    public void setContentView(int layoutResID) {        installDecor();        //有所删减        mLayoutInflater.inflate(layoutResID, mContentParent);    }    private void installDecor() {         if (mDecor == null) {            mDecor = generateDecor(-1); //new一个DecorView出来        }         if (mContentParent == null) {            mContentParent = generateLayout(mDecor); //根据不同的theme创建DecorView的child        }    }    protected DecorView generateDecor(int featureId) {        return new DecorView(context, featureId, this, getAttributes());//DecorView也就持有了window对象    }    protected ViewGroup generateLayout(DecorView decor) {        // Inflate the window decor.        int layoutResource;        //根据不同的theme，可能出现的layoutResource有        layoutResource = R.layout.screen_swipe_dismiss;        layoutResource = R.layout.screen_title_icons;        layoutResource = R.layout.screen_progress;        layoutResource = R.layout.screen_custom_title;        layoutResource = a.getResourceId(                    R.styleable.Window_windowActionBarFullscreenDecorLayout,                    R.layout.screen_action_bar);        layoutResource = R.layout.screen_title;        layoutResource = R.layout.screen_simple_overlay_action_mode;        layoutResource = R.layout.screen_simple;        //这些可能的layoutResource就是DecorView的child的布局文件        mDecor.onResourcesLoaded(mLayoutInflater, layoutResource); //这里面直接layoutInflater这个布局文件，deocorView去add这个View        ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT);//在这个新创建的布局中找android.R.id.content    }    //installDecor走完这个mContentParent也就找到了    //上面说道PhoneWindow的setContentView大致两句话，installDecor()和mLayoutInflater.inflate(layoutResID, mContentParent);    //于是mLayoutInflater.inflate(layoutResID, mContentParent);就是把开发者写的layoutRes文件对应的view创建出来并且添加到mContentParent中</code></pre><p><img src="https://www.haldir66.ga/static/imgs/window_manager_02.png" alt=""></p><p>到这里我们自己写的view也就被添加到android.R.id.content这个FrameLayout里了，这时应该在onCreate里面。根据ActivityThread在<a href="http://androidxref.com/6.0.1_r10/xref/frameworks/base/core/java/android/app/ActivityThread.java#handleLaunchActivity">6.0的代码</a></p><pre><code class="java">//ActivityThread.javaprivate void handleLaunchActivity(ActivityClientRecord r, Intent customIntent) {   Activity a = performLaunchActivity(r, customIntent);      if (a != null) {         handleResumeActivity(r.token, false, r.isForward,!r.activity.mFinished &amp;&amp; !r.startsNotResumed);      }}final void handleResumeActivity(IBinder token,boolean clearHide, boolean isForward, boolean reallyResume) {      ActivityClientRecord r = performResumeActivity(token, clearHide);//这里面就是正常的onResume      if (r.window == null &amp;&amp; !a.mFinished &amp;&amp; willBeVisible) {        r.window = r.activity.getWindow();        View decor = r.window.getDecorView();//拿到decorView        decor.setVisibility(View.INVISIBLE);//改为不可见        ViewManager wm = a.getWindowManager();        WindowManager.LayoutParams l = r.window.getAttributes();        a.mDecor = decor;        l.type = WindowManager.LayoutParams.TYPE_BASE_APPLICATION;        l.softInputMode |= forwardBit;        if (a.mVisibleFromClient) {            a.mWindowAdded = true;            wm.addView(decor, l); //通过windowManager去addView,l是windowManager的layoutparameters，ViewRootImpl也就是从这里创建        }      }    // The window is now visible if it has been added, we are not        // simply finishing, and we are not starting another activity. //上面设置INVISIBLE的原因，这里也说了，如果没有finish，也没有正在起另一个activity的话，就可以让这个activity变得可见了    if (!r.activity.mFinished &amp;&amp; willBeVisible            &amp;&amp; r.activity.mDecor != null &amp;&amp; !r.hideForNow) {       if (r.activity.mVisibleFromClient) {            r.activity.makeVisible();        }    }}//activity.javavoid makeVisible() {    if (!mWindowAdded) {        ViewManager wm = getWindowManager();        wm.addView(mDecor, getWindow().getAttributes());        mWindowAdded = true;    }    mDecor.setVisibility(View.VISIBLE);//重新改成visible}</code></pre><p>到这里（onResume走完），DecorView就被WindowManager调用addView了。下面开始讲调用WindowManager的addView这个IPC需要准备的参数和远端如何接收这个收到的参数</p><h3 id="WindowManagerGlobal"><a href="#WindowManagerGlobal" class="headerlink" title="WindowManagerGlobal"></a>WindowManagerGlobal</h3><p>WindowManager是一个接口，其addView和removeView是由WindowManagerImpl去调用WindowManagerGlobal做的（设计模式：代理模式。WindowManagerGlobal是app进程中的单例）<br>WindowManagerGlobal和WMS交互调用的是IWindowManager在WMS中的对应实现<br>WindowManagerGlobal.sWindowSession是app进程中所有viewRootImpl的IWindowSession</p><pre><code class="java">//WindowManagerGlobal.java public void addView(View view, ViewGroup.LayoutParams params, Display display, Window parentWindow) {        final WindowManager.LayoutParams wparams = (WindowManager.LayoutParams) params;        if (parentWindow != null) {            parentWindow.adjustLayoutParamsForSubWindow(wparams);//这里将activity的token设置到了WindowManager.layoutParams中        }        ViewRootImpl root;        root = new ViewRootImpl(view.getContext(), display);        view.setLayoutParams(wparams);        // do this last because it fires off messages to start doing things        try {            root.setView(view, wparams, panelParentView);        } catch (RuntimeException e) {            // BadTokenException or InvalidDisplayException, clean up.            if (index &gt;= 0) {                removeViewLocked(index, true);            }            throw e;        }}</code></pre><p>到这里，我们从activity.setContentView -&gt; 创建DecorView和DecorView的child，以及找到android.R.id.content，往里面添加自定义布局 -&gt; handleResumeActivity(通过windowManager.addView，然后makeVisible) ，这些都是一个message中处理的。WindowManager.addView转入ViewRootImpl的setView方法,把decorView添加进去了</p><h3 id="ViewRootImpl"><a href="#ViewRootImpl" class="headerlink" title="ViewRootImpl"></a>ViewRootImpl</h3><pre><code class="java">//viewRootImpl.java//首先需要声明ViewRootImpl不是Viewpublic final class ViewRootImpl implements ViewParent,        View.AttachInfo.Callbacks, ThreadedRenderer.DrawCallbacks {}public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) {    //这里的view是DecorView     int res; /* = WindowManagerImpl.ADD_OKAY; */    // Schedule the first layout -before- adding to the window    // manager, to make sure we do the relayout before receiving    // any other events from the system.    requestLayout();    //和windowManagerService打交道的ipc就在这里了    res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes,                        getHostVisibility(), mDisplay.getDisplayId(), mWinFrame,                        mAttachInfo.mContentInsets, mAttachInfo.mStableInsets,                        mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel);    // mWindowSession是WindowManagerGlobal提供的，全局唯一的static变量                        // mWindowSession是IWindowSession对象，IWindowSession.aidl中定义了这个ipc的一系列方法    //这个mWindow其实是ViewRootImpl.W extends IWindow.Stub，也就是WMS远程调用进入app进程中的代理     // Set up the input pipeline.这些stage是责任链模式处理事件，每一个持有前一个的引用    CharSequence counterSuffix = attrs.getTitle();    mSyntheticInputStage = new SyntheticInputStage();    InputStage viewPostImeStage = new ViewPostImeInputStage(mSyntheticInputStage); //这个是处理native层传来的inputEvent的    InputStage nativePostImeStage = new NativePostImeInputStage(viewPostImeStage,            &quot;aq:native-post-ime:&quot; + counterSuffix);    InputStage earlyPostImeStage = new EarlyPostImeInputStage(nativePostImeStage);    InputStage imeStage = new ImeInputStage(earlyPostImeStage,            &quot;aq:ime:&quot; + counterSuffix);    InputStage viewPreImeStage = new ViewPreImeInputStage(imeStage);    InputStage nativePreImeStage = new NativePreImeInputStage(viewPreImeStage,            &quot;aq:native-pre-ime:&quot; + counterSuffix);    mFirstInputStage = nativePreImeStage;    mFirstPostImeInputStage = earlyPostImeStage;    mPendingInputEventQueueLengthCounterName = &quot;aq:pending:&quot; + counterSuffix;                    }</code></pre><p>下面开始关注这个ipc</p><h3 id="IWindowSession-addToDisplay做了什么"><a href="#IWindowSession-addToDisplay做了什么" class="headerlink" title="IWindowSession.addToDisplay做了什么"></a>IWindowSession.addToDisplay做了什么</h3><p><a href="https://www.jianshu.com/p/dbbc07218ac1">参考《深入理解Android卷 I》- 第八章 - Surface- 读书笔记-part2</a></p><h2 id="下面这些都运行在system-server进程"><a href="#下面这些都运行在system-server进程" class="headerlink" title="下面这些都运行在system_server进程"></a>下面这些都运行在system_server进程</h2><p><code>frameworks/base/services/core/java/com/android/server/wm/Session.java</code></p><pre><code class="java">final class Session extends IWindowSession.Stub{    @Override    public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs,        int viewVisibility, int displayId, Rect outContentInsets, Rect outStableInsets,        Rect outOutsets, InputChannel outInputChannel) {    return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId,            outContentInsets, outStableInsets, outOutsets, outInputChannel);    }}</code></pre><p><code>frameworks/base/services/core/java/com/android/server/wm/WindowManagerService.java</code></p><p>WMS的成员变量包括</p><pre><code class="java">mSessions:ArraySet&lt;Session&gt; //All currently active sessions with clients.一个app只有一个sessionmWindowMap:HashMap&lt;IBinder,WindowState&gt; // Mapping from an IWindow IBinder to the server&#39;s Window object.Key是IWindowmTokenMap:HashMap&lt;IBinder,WindowToken&gt; //Mapping from a token IBinder to a WindowToken object.key应该是IApplicationToken，是从WindowManager.LayoutParams.token跨ipc传入的，value是windowToken。一个windowToken(背后对应唯一activity)，下面包含多个windowState(一个activity可以有多个窗口，比如Dialog)</code></pre><p>一个windowToken中存有多个WindowState(token.windows),而一般的，一个WindowState就对应一个window.<br>就像WMS要管理多个app(WindowToken)，每个app有多个窗口(WindowState，在app端就是ViewRootImpl.W)，</p><pre><code class="java">//windowManagerService.java public int addWindow(Session session, IWindow client, int seq,            WindowManager.LayoutParams attrs, int viewVisibility, int displayId,            Rect outContentInsets, Rect outStableInsets, Rect outOutsets,            InputChannel outInputChannel) {         if (token == null) {             //这就是系统要求TYPE_APPLICATION类型的窗口，要求必须有activity的token,否则会抛出BadTokenException异常。Dialog的type是TYPE_APPLICATION,所以必须要在layoutParams中填上activity的token                if (type &gt;= FIRST_APPLICATION_WINDOW &amp;&amp; type &lt;= LAST_APPLICATION_WINDOW) { //1-99之间 ,TYPE_APPLICATION=2                    Slog.w(TAG, &quot;Attempted to add application window with unknown token &quot;                          + attrs.token + &quot;.  Aborting.&quot;);                    return WindowManagerGlobal.ADD_BAD_APP_TOKEN;                }            }                // 这里包括一系列的检查        // 1. 窗口类型必须是合法范围内的，应用窗口，子窗口，或者系统窗口        // 2. 如果是系统窗口，需要进行权限检查。TYPE_TOAST,TYPE_WALLPAPER等不需要权限        // 3. 如果是应用窗口，先用attrs里面的token检索出来WindowToken，必须不能为null，而且还得是Activity的mAppToken，同时该Activity还必须没有被finish。在Activity启动的时候，会先通过WMS的addAppToken方法添加一个AppWindowToken(IApplicationToken.Stub appToken)到mTokenMap中（ActivityStack.startActivityLocked），其中key就用到了IApplicationToken。而这个mAppToken就是在activity的attach方法里面赋值的，具体来自AMS.(所以就是system_server进程在启动一个activity的时候往WMS的一个map里放了一个new WindowToken对象。app进程在handleLaunchActivity的时候会拿到这个appToken，于是app进程拿着这个mAppToken通过ipc到WMS中去问，有没有这个mAppToken存过东西)        WindowState win = new WindowState(this, session, client, token,  attachedWindow, appOp[0], seq, attrs, viewVisibility, displayContent);            //后续会将这个WindowState添加到WMS的成员中, token.windows.add(i, win);        // ...        // tokenMap里面没有找到        token = new WindowToken(this, attrs.token, -1, false);        //attrs就是layoutParams.token就通过binder call传入wms进程，所以token就是activity的token，token是绑定在window上，也就是一个activity有一个        // ..        if (addToken) {            mTokenMap.put(attrs.token, token);//mTokenMap保存所有的WindowToken对象,key是        }        win.attach(); //将session添加到mSessions中        mWindowMap.put(client.asBinder(), win);//这个client是IWindow，其实就是ViewRootImpl.W类对象为key,windowState作为value。这不就是一个ViewRootImpl对应一个WindowState嘛}// WindowState.javavoid attach() {    if (WindowManagerService.localLOGV) Slog.v(        TAG, &quot;Attaching &quot; + this + &quot; token=&quot; + mToken        + &quot;, list=&quot; + mToken.windows);    mSession.windowAddedLocked();}        //Session.javavoid windowAddedLocked() {        if (mSurfaceSession == null) {            mSurfaceSession = new SurfaceSession();            mService.mSessions.add(this);// windowState.attach -&gt; Session.windowAddedLocked -&gt; WMS.msession.add(session)        }        mNumWindow++;    } // windowToken.java//windowToken似乎有用的方法就这么一个，也说明一个windowToken实际上有多个Window void removeAllWindows() {        for (int winNdx = windows.size() - 1; winNdx &gt;= 0; --winNdx) {            WindowState win = windows.get(winNdx);            if (WindowManagerService.DEBUG_WINDOW_MOVEMENT) Slog.w(WindowManagerService.TAG,                    &quot;removeAllWindows: removing win=&quot; + win);            win.mService.removeWindowLocked(win);        }        windows.clear();    }      </code></pre><p><img src="https://www.haldir66.ga/static/imgs/window_manager_01.jpeg" alt=""><br>一般的，每一个window都对应一个WindowState对象，<br>该对象的成员中mClient(final IWindow mClient;)用于跟应用端交互<br>成员变量mToken(WindowToken mToken;)用于跟AMS交互</p><p>ViewRootImpl中有针对远程返回的res判断的逻辑,结合这WindowManagerService的addView方法查看更加清楚</p><pre><code class="java">//ViewRootImpl.java switch (res) {                case WindowManagerGlobal.ADD_BAD_APP_TOKEN:                case WindowManagerGlobal.ADD_BAD_SUBWINDOW_TOKEN:                    throw new WindowManager.BadTokenException(                            &quot;Unable to add window -- token &quot; + attrs.token                            + &quot; is not valid; is your activity running?&quot;);                case WindowManagerGlobal.ADD_NOT_APP_TOKEN:                    throw new WindowManager.BadTokenException(                            &quot;Unable to add window -- token &quot; + attrs.token                            + &quot; is not for an application&quot;);                case WindowManagerGlobal.ADD_APP_EXITING:                    throw new WindowManager.BadTokenException(                            &quot;Unable to add window -- app for token &quot; + attrs.token                            + &quot; is exiting&quot;);}//windowManagerService.java public int addWindow(Session session, IWindow client,xxx) {     //从一个HashMap&lt;IBinder,WindowToken&gt;中去get(LayoutParams.attr.token)  WindowToken token = displayContent.getWindowToken(                    hasParent ? parentWindow.mAttrs.token : attrs.token);  //如果发现没有windowToken(一个WindowToken有多个windowState,也就是有多个window)，开始报错   if (token == null) {        if (rootType &gt;= FIRST_APPLICATION_WINDOW &amp;&amp; rootType &lt;= LAST_APPLICATION_WINDOW) { // 1-99之间，多数是这里            Slog.w(TAG_WM, &quot;Attempted to add application window with unknown token &quot;                    + attrs.token + &quot;.  Aborting.&quot;);            return WindowManagerGlobal.ADD_BAD_APP_TOKEN; // 这里回到app进程就抛is your activity running?        }    }else {            // ..省略....         if (atoken == null) {                Slog.w(TAG_WM, &quot;Attempted to add window with non-application token &quot;                        + token + &quot;.  Aborting.&quot;);                return WindowManagerGlobal.ADD_NOT_APP_TOKEN;            } else if (atoken.removed) {                Slog.w(TAG_WM, &quot;Attempted to add window with exiting application token &quot;                        + token + &quot;.  Aborting.&quot;);                return WindowManagerGlobal.ADD_APP_EXITING;                //这里抛出什么错，在ViewRootImpl里面就有对应的解释    }}</code></pre><p><code>添加View到WMS的流程</code><br><img src="https://www.haldir66.ga/static/imgs/window_manager_05.png" alt=""></p><p><code>从WMS中RemoveView的流程</code><br><img src="https://www.haldir66.ga/static/imgs/window_manager_04.png" alt=""></p><h3 id="回到ViewRootImpl的setView方法-session-addToDisplay"><a href="#回到ViewRootImpl的setView方法-session-addToDisplay" class="headerlink" title="回到ViewRootImpl的setView方法,session.addToDisplay"></a>回到ViewRootImpl的setView方法,session.addToDisplay</h3><pre><code class="java">//ViewRootImpl.javares = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes,                    getHostVisibility(), mDisplay.getDisplayId(), mWinFrame,                    mAttachInfo.mContentInsets, mAttachInfo.mStableInsets,                    mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel);//app端到服务端//调用服务端通过IWindowSession,// IWindowSession在server端的实现是Sessionfinal IWindowSession mWindowSession;final class Session extends IWindowSession.Stub{    //运行在system_server进程，是system_server的binder服务端}//服务端到app端//控制app端通过IWindow，app端提供的实现就是W。final W mWindow;static class W extends IWindow.Stub{    //运行在app进程，是app端的ViewRootImpl.W服务的binder代理对象    //这个W的构造函数把ViewRootImpl用weakReference包起来了，远程有消息到达的时候就去调用viewRootImpl的对应方法}                    </code></pre><p>app端通过IWindowSession调用WMS端的方法，WMS端通过IWindow(WindowState.mClient)调用app端的方法<br><img src="https://www.haldir66.ga/static/imgs/window_manager_07.png" alt=""></p><h3 id="Window调用过程中涉及到的IPC服务"><a href="#Window调用过程中涉及到的IPC服务" class="headerlink" title="Window调用过程中涉及到的IPC服务"></a>Window调用过程中涉及到的IPC服务</h3><table><thead><tr><th>Binder服务端</th><th>接口</th><th>所在进程</th></tr></thead><tbody><tr><td>WindowManagerService</td><td>IWindowManager</td><td>system_server</td></tr><tr><td>Session</td><td>IWindowSession</td><td>system_server</td></tr><tr><td>ViewRootImpl.W</td><td>IWindow</td><td>app进程</td></tr><tr><td>ActivityRecord.Token</td><td>IApplicationToken</td><td>system_server</td></tr></tbody></table><p>ActivityRecord.Token:StartActivity通过binder call进入systemServer进程，在AMS中创建相应的ActivityRecord.Token的成员变量appToken，然后将该对象传递到ActivityThread.</p><p>Token这个东西在几处出现了，<br>Activity（performLaunchActivity中的attach赋值，对应AMS中的ActivityRecord）<br>Window(attach方法里的PhoneWindow.setWindowManager去赋值)<br>WindowManager.LayoutParams.token(用于IPC)<br>ViewRootImpl, View, View.AttachInfo（都是在dispatchAttachToWindow的时候去设置到attachInfo的）。所以任意的View只要被添加了，那么就会有attachInfo，也就有了token(attachInfo里的token都是ViewRootImpl给的，也就是ViewRootImpl.W这个class的实例)</p><h3 id="ViewRootImpl的traversal"><a href="#ViewRootImpl的traversal" class="headerlink" title="ViewRootImpl的traversal"></a>ViewRootImpl的traversal</h3><p>上面才讲到handleResumeActivity之后创建了一个ViewRootImpl<br>根据<a href="http://androidxref.com/6.0.1_r10/xref/frameworks/base/core/java/android/app/ActivityThread.java#handleResumeActivity">6.0的代码</a></p><pre><code class="java">//ActivityThread.java public void handleResumeActivity(IBinder token, boolean finalStateRequest, boolean isForward,            String reason) {      if (r.window == null &amp;&amp; !a.mFinished &amp;&amp; willBeVisible) {                r.window = r.activity.getWindow();//这些东西都是在onCreate里面去创建出来的                View decor = r.window.getDecorView();                decor.setVisibility(View.INVISIBLE);                ViewManager wm = a.getWindowManager();                WindowManager.LayoutParams l = r.window.getAttributes();                a.mDecor = decor;                l.type = WindowManager.LayoutParams.TYPE_BASE_APPLICATION;                l.softInputMode |= forwardBit;                if (a.mVisibleFromClient) {                    a.mWindowAdded = true;                    wm.addView(decor, l);//这里走进WindowManagerGlobal.addView                }            // If the window has already been added, but during resume            // we started another activity, then don&#39;t yet make the            // window visible.            } else if (!willBeVisible) {                if (localLOGV) Slog.v(                    TAG, &quot;Launch &quot; + r + &quot; mStartedActivity set&quot;);                r.hideForNow = true;            } } }</code></pre><p>好像还没有scheduleTraversal呢。接着看，在WindowManagerGlobal的addView里面创建了ViewRootImpl，后者在setView的时候:</p><pre><code class="java">//WindowManagerGlobal.javaroot = new ViewRootImpl(view.getContext(), display);view.setLayoutParams(wparams);//这里面直接一个requestLayout//ViewRootImpl.java/ Schedule the first layout -before- adding to the windowpublic void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) {       // Schedule the first layout -before- adding to the window    // manager, to make sure we do the relayout before receiving    // any other events from the system.    requestLayout(); //这里又进行了一次requestLayout    //这后面才是去ipc    res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes,        getHostVisibility(), mDisplay.getDisplayId(), mWinFrame,        mAttachInfo.mContentInsets, mAttachInfo.mStableInsets,        mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel);}//来看看ViewRootImpl的requestLayout，这个方法是ViewParent接口的@Overridepublic void requestLayout() {    if (!mHandlingLayoutInLayoutRequest) {        checkThread();        mLayoutRequested = true;        scheduleTraversals();//直接scheduleTraversal了    }}</code></pre><p>scheduleTraversals里面就是</p><pre><code class="java">//ViewRootImpl.javavoid scheduleTraversals() {    if (!mTraversalScheduled) {        mTraversalScheduled = true;        mTraversalBarrier = mHandler.getLooper().getQueue().postSyncBarrier();//PostSyncBarrier，这之后只有异步消息才能通过！        mChoreographer.postCallback(                Choreographer.CALLBACK_TRAVERSAL, mTraversalRunnable, null); // mDisplayEventReceiver.scheduleVsync();请求硬件系统VSync信号    }}</code></pre><p>接下来就是mDisplayEventReceiver.onVsync的时候去doFrame</p><pre><code class="java">//Choreographer.java try {        Trace.traceBegin(Trace.TRACE_TAG_VIEW, &quot;Choreographer#doFrame&quot;);        AnimationUtils.lockAnimationClock(frameTimeNanos / TimeUtils.NANOS_PER_MS);        mFrameInfo.markInputHandlingStart();        doCallbacks(Choreographer.CALLBACK_INPUT, frameTimeNanos); //最先处理INPUT        mFrameInfo.markAnimationsStart();        doCallbacks(Choreographer.CALLBACK_ANIMATION, frameTimeNanos);//随后是animation        mFrameInfo.markPerformTraversalsStart();        doCallbacks(Choreographer.CALLBACK_TRAVERSAL, frameTimeNanos);//第三个是ViewRootImpl.doTraversal，在这里ViewRootImpl会解除postSyncBarrier        doCallbacks(Choreographer.CALLBACK_COMMIT, frameTimeNanos);    } finally {        AnimationUtils.unlockAnimationClock();        Trace.traceEnd(Trace.TRACE_TAG_VIEW);    }</code></pre><p>这样看来，在第一次handleResumeActivity的时候，Choreographer会主动设定一次traversal，后续的measure,layout,draw也就顺理成章了</p><h3 id="Dialog"><a href="#Dialog" class="headerlink" title="Dialog"></a>Dialog</h3><p>子窗口的话,典型的例子是dialog。直接使用Activity的windowManager和WMS交互<br>Dialog的构造函数中</p><pre><code class="java">//Dialog.java Dialog(@NonNull Context context, @StyleRes int themeResId, boolean createContextThemeWrapper) {    mWindowManager = (WindowManager) context.getSystemService(Context.WINDOW_SERVICE);     // 此时拿到的是Activity的windowManager    final Window w = new PhoneWindow(mContext);    mWindow = w;    w.setCallback(this);    w.setWindowManager(mWindowManager, null, null);//这一段是为这个new出来的PhoneWindow设置一个windownManager。    //也就是说Dialog的显示其实是使用了Activity的windowManager去调用WMS的服务的，而Dialog自身的window由于没有token，所以这个window并不能用于和WMS交互。更多的是用于持有DecorView(新的window的DecorView),等到iput事件来到时，会通过ViewRootImpl传递到DecorView(新的window的DecorView)，DecorView再交给WindowCallback. } //Activity.java void attach(){      mWindow.setWindowManager(                (WindowManager)context.getSystemService(Context.WINDOW_SERVICE),                mToken, mComponent.flattenToString(),                (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != 0); } //Activity.java  @Override    public Object getSystemService(@ServiceName @NonNull String name) {        if (WINDOW_SERVICE.equals(name)) {            return mWindowManager; //..Activity直接在这里让Dialog获取到自己的windowManager（其对应的window已经填充好mAppToken了）        }        return super.getSystemService(name);    }</code></pre><p><strong>如果没有token的话，ViewRootImpl.setView方法会在远程失败。在Dialog.show中调用了mWindowManager.addView(mDecor, l);这个mWindowManager其实已经是Activity的mWindowManager了。所以对这个mWindowManager(内部用mParentWindow，即Activity的window)调用addView方法。在WindowManagerGlobal的addView中有adjustLayoutParamsForSubWindow这个方法，这里最重要的就是给WindowManager.LayoutParams.token赋值。<br>mWindowManager.addView(mDecor, l); -&gt; WindowManagerGlobal.addView -&gt; Window.adjustLayoutParamsForSubWindow(就是在这里从Activity的window中取出token赋值给layoutParams的)</strong></p><p>WindowManager.LayoutParams中有三种窗口类型type</p><ol><li>应用程序窗口：FIRST_APPLICATION_WINDOW - LAST_APPLICATION_WINDOW (1-99)。 Activity的window,Dialog的window</li><li>子窗口: FIRST_SUB_WINDOW - LAST_SUB_WINDOW (1000-1999). 例如PopupWindow，ContextMenu，optionMenu。子窗口必须要有一个父窗口，父窗口可以是应用程序窗口，也可以是其他任意类型。父窗口的不可见时，子窗口不可见</li><li>系统窗口: FIRST_SYSTEM_WINDOW - LAST_SYSTEM_WINDOW (2000 -2999) Toast，输入法等等。系统窗口不需要对应Activity，比如TYPE_SYSTEM_ALERT，状态栏，来电显示，屏保等</li></ol><pre><code class="java">// Window.java 当前实例是Activity的PhoneWindow，其成员变量mAppToken在activity的attach中就初始化了，debug发现是BinderProxy实例void adjustLayoutParamsForSubWindow(WindowManager.LayoutParams wp) {     if (wp.type &gt;= WindowManager.LayoutParams.FIRST_SUB_WINDOW &amp;&amp;                wp.type &lt;= WindowManager.LayoutParams.LAST_SUB_WINDOW) {            //1000-1999 //            if (wp.token == null) {                View decor = peekDecorView();                if (decor != null) {                    wp.token = decor.getWindowToken();//从mAttachInfo.mWindowToken获取                }            }        } else if (wp.type &gt;= WindowManager.LayoutParams.FIRST_SYSTEM_WINDOW &amp;&amp;                wp.type &lt;= WindowManager.LayoutParams.LAST_SYSTEM_WINDOW) {            //系统window 2000-2999        } else {            //dialog的type因为是2，所以走到这里            if (wp.token == null) {                wp.token = mContainer == null ? mAppToken : mContainer.mAppToken;//Dialog会走到这里，mAppToken不为null            }        }}</code></pre><h3 id="PopupWindow"><a href="#PopupWindow" class="headerlink" title="PopupWindow"></a>PopupWindow</h3><pre><code class="java">//popupwindow的LayoutParams.type默认是private int mWindowLayoutType = WindowManager.LayoutParams.TYPE_APPLICATION_PANEL;// 1000//可以修改的//PopupWindow.javapublic void showAsDropDown(View anchor, int xoff, int yoff, int gravity) {     final WindowManager.LayoutParams p =                createPopupLayoutParams(anchor.getApplicationWindowToken());}public void showAtLocation(View parent, int gravity, int x, int y) {    mParentRootView = new WeakReference&lt;&gt;(parent.getRootView());    showAtLocation(parent.getWindowToken(), gravity, x, y);}</code></pre><p>可以发现无论是showAsDropDown还是showAtLocation全都是需要从anchorView拿到windowToken的   </p><pre><code class="java">  private void invokePopup(WindowManager.LayoutParams p) {        mWindowManager.addView(decorView, p); //这时候的p已经填充了token    }</code></pre><h3 id="Toast"><a href="#Toast" class="headerlink" title="Toast"></a>Toast</h3><p>用IPC往NotificationManagerService的一个队列中添加一个runnable，系统全局所有应用的Toast请求都被添加到这里，排队，一个个来，远程再回调app进程的Toast.TN(extends ITransientNotification.Stub)的handleShow方法去添加一个type为WindowManager.LayoutPrams.TYPE_TOAST的view。<br>当然，时间到了远程还会回调cancelToast去用WMS移除View。</p><h2 id="doTraversal"><a href="#doTraversal" class="headerlink" title="doTraversal"></a>doTraversal</h2><p>ViewRootImpl中的doTraversal可以分成三件事</p><p>mView.performMeasure<br>mView.performLayout<br>mView.performDraw</p><p>这里的mView也就是DecorView了</p><h3 id="measure"><a href="#measure" class="headerlink" title="measure"></a>measure</h3><pre><code class="java">//onMeasure里的两个参数witdthMeasureSpec和heightMeasureSpec是怎么来的  @Override    protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) {    }//ViewGroup.java中有这么一段protected void measureChildWithMargins(View child,        int parentWidthMeasureSpec, int widthUsed,        int parentHeightMeasureSpec, int heightUsed) {    final MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams();    final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec,            mPaddingLeft + mPaddingRight + lp.leftMargin + lp.rightMargin                    + widthUsed, lp.width);    final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec,            mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin                    + heightUsed, lp.height);    child.measure(childWidthMeasureSpec, childHeightMeasureSpec);}//ViewGroup.javapublic static int getChildMeasureSpec(int spec, int padding, int childDimension) { //这个childDimension就是lp.width或者lp.height    int specMode = MeasureSpec.getMode(spec);    int specSize = MeasureSpec.getSize(spec);    int size = Math.max(0, specSize - padding);     //所以这个size就是当前这个viewGroup的measureSpec中的size-viewgroup的padding-child.lp.margin之后的值    int resultSize = 0;    int resultMode = 0;    switch (specMode) {    // Parent has imposed an exact size on us    case MeasureSpec.EXACTLY:        if (childDimension &gt;= 0) { //如果自己是EXACTLY，child的lp.width或者lp.height&gt;0的话，生成一个size为dimension只，mode为EXACTLY的 spec            resultSize = childDimension;            resultMode = MeasureSpec.EXACTLY;        } else if (childDimension == LayoutParams.MATCH_PARENT) {            // Child wants to be our size. So be it.            resultSize = size;            resultMode = MeasureSpec.EXACTLY;        } else if (childDimension == LayoutParams.WRAP_CONTENT) {            // Child wants to determine its own size. It can&#39;t be            // bigger than us.            resultSize = size;            resultMode = MeasureSpec.AT_MOST;        }        break;    // Parent has imposed a maximum size on us    case MeasureSpec.AT_MOST:        if (childDimension &gt;= 0) {            // Child wants a specific size... so be it            resultSize = childDimension;            resultMode = MeasureSpec.EXACTLY;        } else if (childDimension == LayoutParams.MATCH_PARENT) {            // Child wants to be our size, but our size is not fixed.            // Constrain child to not be bigger than us.            resultSize = size;            resultMode = MeasureSpec.AT_MOST;        } else if (childDimension == LayoutParams.WRAP_CONTENT) {            // Child wants to determine its own size. It can&#39;t be            // bigger than us.            resultSize = size;            resultMode = MeasureSpec.AT_MOST;        }        break;    return MeasureSpec.makeMeasureSpec(resultSize, resultMode);}</code></pre><h3 id="layout"><a href="#layout" class="headerlink" title="layout"></a>layout</h3><p>这里就是调用onLayout方法了，FrameLayout会根据child的Gravity横向或者纵向摆放。LinearLayout会根据自己的orientation，从上到下或者从左到右进行摆放。</p><h3 id="draw"><a href="#draw" class="headerlink" title="draw"></a>draw</h3><pre><code class="java">public void draw(Canvas canvas) {  . . .   // 绘制背景，只有dirtyOpaque为false时才进行绘制，下同  int saveCount;  if (!dirtyOpaque) {    drawBackground(canvas);  }  . . .   // 绘制自身内容  if (!dirtyOpaque) onDraw(canvas);  // 绘制子View  dispatchDraw(canvas);   . . .  // 绘制滚动条等  onDrawForeground(canvas);}</code></pre><p>draw的基本流程是这样，这个canvas是ViewRootImpl中的canvas = mSurface.lockCanvas(dirty);获得的。个人理解Canvas是存储了一系列的指令，再交给surface</p><h3 id="Choregrapher"><a href="#Choregrapher" class="headerlink" title="Choregrapher"></a>Choregrapher</h3><p>Choregrapher里面有一个内部类FrameDisplayEventReceiver(继承自DisplayEventReceiver，DisplayEventReceiver是一个没有抽象方法的抽象类)，主要提供两个方法nativeScheduleVsync和onVsync。<br>FrameDisplayEventReceiver在onVsync的时候会post一个异步(也就是说不受syncBarrier阻拦)的消息到主线程上去调用Choregrapher的doFrame（这里面就是把之前所有通过Choregrapher.postCallback添加到队列的事件拿出来，到期了就执行）</p><p>主线程的MessageQueue被syncBarrier堵住的显著特征是msg.target==null(也就是对应的handler为null).  ViewRootImpl在scheduleTraversals的时候会postSyncBarrier一次，也就是说，这个doTraversal是高优先级的，这一刻起后面的所有丢到主线程上的msg都要等到我doTraversal完成后才执行(异步消息例外，所以上面onVsync的消息得是异步的)。从时间顺序上来讲，<br>ViewRootImpl.scheduleTraversal -&gt; mChoreographer.postCallback -&gt; Choreographer开始scheduleFrameLocked（假如时间到了，直接调用nativeScheduleVsync，否则发送的msg全都是异步的，就是为了跨过之前的barrier.）同样，在onVsync的时候，由于此时的barrier还没移除，所以发出的消息还得是异步的。doFrame里面，严格按照input -&gt; animation -&gt; traversal的类型去执行。也就是viewRootImpl在scheduleTraversals的时候post的callback要老老实实在第三组被执行。而在轮到这个doTraversal执行的时候，终于可以去移除barrier了。</p><p>需要指明的是，每一次scheduleTraversal都要触发measure -&gt; layout -&gt; draw这一套，所以，耗时是很严重的。vsync信号也不是系统主动发出的，而是需要通过nativeScheduleVsync请求，才会有一次onVsync的相应的。看了一下，ViewRootImpl里面的setLayoutParams，invalidate,requestLayout,requestFitSystemWindows等方法里面都会触发scheduleTraversal。 显然在onCreate的setContentView里面会至少调用一次。然后就是熟悉的performTraversal(measure,layout,draw)。</p><p>人们常说在onCreate里面获取一个View的宽高有四种方式：<br>onPreDraw,onLayoutChange,view.measure.<br>第四种就是直接在setContentView后面跟着post一个msg，原理就是前面有一个barrier，这个barrier解除之后执行的第一个msg大概率就是这个msg(不考虑别的线程这么巧也插进来)，这时候，performTraversals刚刚走完，draw也走完了,最后绘制数据都缓存到Surface上。但是systemServer那边，windowManagerService和surfaceFlinger那边还没来得及处理这些刚draw的数据（surfaceFlinger那边还要compose，没那么快吧）。</p><h3 id="surfaceFlinger"><a href="#surfaceFlinger" class="headerlink" title="surfaceFlinger"></a>surfaceFlinger</h3><p>Android是通过系统级进程中的SurfaceFlinger服务来把真正需要显示的数据渲染到屏幕上。SurfaceFlinger的主要工作是：<br><img src="https://www.haldir66.ga/static/imgs/window_manager_06.png" alt=""><br>响应客户端事件，创建Layer与客户端的Surface建立连接。<br>接收客户端数据及属性，修改Layer属性，如尺寸、颜色、透明度等。<br>将创建的Layer内容刷新到屏幕上。<br>维持Layer的序列，并对Layer最终输出做出裁剪计算。<br>因应用层和系统层分别是两个不同进程，需要一个跨进程的通信机制来实现数据传输，在Android的显示系统中，使用了Android的匿名共享内存：SharedClient。每一个应用和SurfaceFlinger之间都会创建一个SharedClient，每个SharedClient中，最多可以创建31个SharedBufferStack，每个Surface都对应一个SharedBufferStack，也就是一个window。这意味着一个Android应用程序最多可以包含31个窗口，同时每个SharedBufferStack中又包含两个(&lt;4.1)或三个(&gt;=4.1)缓冲区。<br>应用层绘制到缓冲区，SurfaceFlinger把缓存区数据渲染到屏幕，两个进程之间使用Android的匿名共享内存SharedClient缓存需要显示的数据。</p><p>WMS跟surfaceFlinger交互的过程是，WMS建立SurfaceComposerClient，然后会在SF中创建Client与之对应，后续通过ISurfaceComposerClient与SF通信</p><p>APP可以没有Activty,PhoneWindow,DecorView，例如带悬浮窗的service。</p><p><img src="https://www.haldir66.ga/static/imgs/window_manager_03.jpeg" alt=""></p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://cloud.tencent.com/developer/article/1070984">图片出自Bugly</a><br><a href="https://www.jianshu.com/p/060b5f68da79">深入理解Android之View的绘制流程</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;谈一谈View的渲染流程吧&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/TamarackCones_EN-AU12178466392_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="android" scheme="https://haldir65.github.io/tags/android/"/>
    
  </entry>
  
  <entry>
    <title>ndk入门笔记</title>
    <link href="https://haldir65.github.io/2019/02/13/2019-02-13-ndk-related-topics/"/>
    <id>https://haldir65.github.io/2019/02/13/2019-02-13-ndk-related-topics/</id>
    <published>2019-02-13T18:25:01.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>android中ndk及jni编写注意事项（本文主要讲CMake）<br><img src="https://www.haldir66.ga/static/imgs/ShanwangpingKarst_EN-AU5360258756_1920x1080.jpg" alt=""><br><a id="more"></a><br>一些小窍门</p><blockquote><p>cmake最终执行的命令在这个文件里面.externalNativeBuild/cmake/debug/{abi}/cmake_build_command.txt<br>cmake生成的.so文件在”\app\build\intermediates\cmake\debug\obj\arm64-v8a”这个路径下。<br>CMake 一共有2种编译工具链 - clang 和 gcc，gcc 已经废弃，clang 是默认的。</p></blockquote><p><a href="https://developer.android.com/ndk/guides/">ndk官方入门指南</a></p><p>cpu架构</p><pre><code>armeabiarmeabi­v7aarm64­v8ax86x86_64mipsmips64</code></pre><p>cmake交叉编译</p><h3 id="abi-application-binary-interface"><a href="#abi-application-binary-interface" class="headerlink" title="abi(application binary interface)"></a>abi(application binary interface)</h3><p><a href="https://developer.android.com/ndk/guides/abis">abis</a><br>ndk支持的abi包括<br>armeabi，armeabi-v7a，arm64-v8a，x86，x86_64，mips，mips64</p><p><strong><em>NDK 17 不再支持 ABI: armeabi、mips、mips64</em></strong></p><p>x86设备上，libs/x86目录中如果存在.so文件的话，会被安装，如果不存在，则会选择armeabi-v7a中的.so文件，如果也不存在，则选择armeabi目录中的.so文件。</p><p>x86设备能够很好的运行ARM类型函数库，但并不保证100%不发生crash，特别是对旧设备。</p><p>64位设备（arm64-v8a, x86_64, mips64）能够运行32位的函数库，但是以32位模式运行，在64位平台上运行32位版本的ART和Android组件，将丢失专为64位优化过的性能（ART，webview，media等等）。<br>所有的x86/x86_64/armeabi-v7a/arm64-v8a设备都支持armeabi架构的.so文件，因此似乎移除其他ABIs的.so文件是一个减少APK大小的好技巧。</p><h3 id="abiFilter"><a href="#abiFilter" class="headerlink" title="abiFilter"></a>abiFilter</h3><p><a href="https://developer.android.com/studio/projects/gradle-external-native-builds">只想让cmake打arm64-v8a一种arch的包怎么办</a></p><blockquote><p>In most cases, you only need to specify abiFilters in the ndk block, as shown above, because it tells Gradle to both build and package those versions of your native libraries. However, if you want to control what Gradle should build, independently of what you want it to package into your APK, configure another abiFilters flag in the defaultConfig.externalNativeBuild.cmake block (or defaultConfig.externalNativeBuild.ndkBuild block). Gradle builds those ABI configurations but only packages the ones you specify in the defaultConfig.ndk block.</p></blockquote><p>翻译过来就是</p><pre><code>android {  ...  defaultConfig {    ...    externalNativeBuild {      cmake {          abiFilters &quot;arm64-v8a&quot; //只帮我打这个架构的就好了      }      // or ndkBuild {...}    }    // Similar to other properties in the defaultConfig block,    // you can configure the ndk block for each product flavor    // in your build configuration.    ndk {      // Specifies the ABI configurations of your native      // libraries Gradle should build and package with your APK.      abiFilters &#39;x86&#39;, &#39;x86_64&#39;, &#39;armeabi&#39;, &#39;armeabi-v7a&#39;,                   &#39;arm64-v8a&#39; //这些架构的包我全部都要打进apk里面    //当然，如果 externalNativeBuild里面只打了arm64-v8a的so文件，这种写法导致最终生成的apk里面装了x86，x86_64..的so文件夹，但其实里面放的都是arm64-v8a的so，当然是不行的。    //默认情况下，不写abiFilter的话，所有支持的abi对应的so文件都会打出来，大小略有差异    }  }  buildTypes {...}  // Use this block to link Gradle to your CMake or ndk-build script.似乎只是用来告诉gradle CMakeList.txt的位置在哪里  externalNativeBuild {       cmake {            path &#39;CMakeLists.txt&#39; //这个是说明CMakeLists.txt这个文件在哪里的，studio 里面link project with c++ program就是干这个的        }  }}</code></pre><p><a href="https://rangaofei.github.io/2018/02/22/shell脚本生成安卓全abi动态库与静态库">所以现在看来这种手动调用cmake的方式也没有太大必要了</a></p><h3 id="abi支持缺失导致的crash"><a href="#abi支持缺失导致的crash" class="headerlink" title="abi支持缺失导致的crash"></a>abi支持缺失导致的crash</h3><p>android第三方 sdk是以aar形式提供的,甚至是远程aar，如果这个sdk对abi的支持比较全，可能会包含armeabi, armeabi-v7a,x86, arm64-v8a,x86_64五种abi,而你应用的其它so只支持armeabi,armeabi-v7a，x86三种，直接引用sdk的aar,会自动编译出支持5种abi的包。但是应用的其它so缺少对其它两种abi的支持，那么如果应用运行于arm64-v8a,x86_64为首选abi的设备上时，就会CRASH。<br>所以解决方法就分两种<br>第一种：</p><pre><code>productFlavors {      necess {          ndk {              abiFilters &quot;armeabi-v7a&quot;              abiFilters &quot;x86&quot;              abiFilters &quot;armeabi&quot;          }      }      abiall {          ndk {              abiFilters &quot;armeabi-v7a&quot;              abiFilters &quot;x86&quot;              abiFilters &quot;armeabi&quot;              abiFilters &quot;arm64-v8a&quot;              abiFilters &quot;x86_64&quot;          }      }  }  </code></pre><p>第二种：<br>app/build.gradle中这句话的意思是指让生成的apk中包含下面三种abi的so文件</p><pre><code class="gradle">defaultConfig {    ndk {        abiFilters &quot;armeabi&quot;, &quot;armeabi-v7a&quot;, &quot;arm64-v8a&quot;    }}</code></pre><p>在apk文件中，so文件放在lib/armeabi-v7a lib/x86_64 lib/x86 lib/arm64-v8a这些文件夹下面</p><h3 id="添加prebuilt-library"><a href="#添加prebuilt-library" class="headerlink" title="添加prebuilt library"></a>添加prebuilt library</h3><p>Add other prebuilt libraries<br>在CMakeLists.txt中添加<br>add_library( imported-lib<br>             SHARED<br>             IMPORTED )<br>关键词IMPORTED ，就拿ffmepg来说，首先在linux上编译出不同abi的so文件，ffmpeg有好几个so文件，比方说libavcodec.so这个文件。</p><pre><code>Some libraries provide separate packages for specific CPU architectures, or Application Binary Interfaces (ABI), and organize them into separate directories. This approach helps libraries take advantage of certain CPU architectures while allowing you to use only the versions of the library you want. To add multiple ABI versions of a library to your CMake build script, without having to write multiple commands for each version of the library, you can use the ANDROID_ABI path variable. This variable uses a list of the default ABIs that the NDK supports, or a filtered list of ABIs you manually configure Gradle to use. </code></pre><p>有些第三方库针对不同的cpu架构提供了不同的so文件</p><pre><code># 添加库——外部引入的库# 库名称：avcodec（不需要包含前缀lib）# 库类型：SHARED，表示动态库，后缀为.so（如果是STATIC，则表示静态库，后缀为.a）# IMPORTED表明是外部引入的库set(distribution_DIR ../../../../libs) //这个libs文件夹名字随便取，下面要包含armeabi-v7a,x86,x86_64等你想要支持的架构对应的so文件（在Linux上编出来的）add_library( avcodec        SHARED        IMPORTED)set_target_properties( avcodec        PROPERTIES IMPORTED_LOCATION        ${distribution_DIR}/${ANDROID_ABI}/libavcodec.so) //最终gradle编译的时候会把abiFilter中指定的cpu架构一个个去对应的文件夹去找so文件，找不到就会报错include_directories( avcodec/include/ )//告诉cmake，把这个目录下面的文件当做头文件拿进来，不用自己一个个去copy了，注意这个不是recursive的，也就是照顾不到子文件夹//这一步就是Link了target_link_libraries( native-lib //这个是我们自己的lib的名字        avcodec        avfilter        avformat        avutil        swresample        swscale        -landroid        ${log-lib} )        </code></pre><h3 id="预先编译好的so文件放置的目录要告诉gradle"><a href="#预先编译好的so文件放置的目录要告诉gradle" class="headerlink" title="预先编译好的so文件放置的目录要告诉gradle"></a>预先编译好的so文件放置的目录要告诉gradle</h3><blockquote><p>f you want Gradle to package prebuilt native libraries with your APK, modify the default source set configuration to include the directory of your prebuilt .so files, as shown below. Keep in mind, you don’t need to do this to include artifacts of CMake build scripts that you link to Gradle.</p></blockquote><pre><code>android {    ...    sourceSets {        main {            jniLibs.srcDirs &#39;imported-lib/src/&#39;, &#39;more-imported-libs/src/&#39;        }    }}</code></pre><h3 id="调用ndk的api"><a href="#调用ndk的api" class="headerlink" title="调用ndk的api"></a>调用ndk的api</h3><p>比方说这种头文件</p><pre><code class="c">#include &lt;android/native_window_jni.h&gt;#include &lt;android/cpu-features.h&gt;#include &lt;android/multinetwork.h&gt;</code></pre><p>native_window_jni 在ndk 的libandroid.so库中，需要在CMakeLists.txt中引入android库，像这样</p><pre><code>target_link_libraries( my-lib        ...        -landroid        ${log-lib} )</code></pre><p>从<a href="https://www.jianshu.com/p/7a165b9f9fad">fmpeg+native_window实现万能视频播放器播放本地视频</a>抄来一段cpp代码</p><pre><code class="cpp"> extern &quot;C&quot; {    //编码    #include &quot;libavcodec/avcodec.h&quot;    //封装格式处理    #include &quot;libavformat/avformat.h&quot;    //像素处理    #include &quot;libswscale/swscale.h&quot;    //native_window_jni 在ndk 的libandroid.so库中，需要在CMakeLists.txt中引入android库    #include &lt;android/native_window_jni.h&gt;    #include &lt;unistd.h&gt;//sleep用的头文件    }    /**        *将任意格式的视频在手机上进行播放，使用native进行绘制        * env:虚拟机指针        * inputStr：视频文件路径        * surface: 从java层传递过来的SurfaceView的surface对象         */    void ffmpegVideoPlayer(JNIEnv *env, char *inputStr, jobject surface) {        // 1.注册各大组件，执行ffmgpe都必须调用此函数        av_register_all();        //2.得到一个ffmpeg的上下文（上下文里面封装了视频的比特率，分辨率等等信息...非常重要）        AVFormatContext *pContext = avformat_alloc_context();        //3.打开一个视频        if (avformat_open_input(&amp;pContext, inputStr, NULL, NULL) &lt; 0) {            LOGE(&quot;打开失败&quot;);            return;        }        //4.获取视频信息（将视频信息封装到上下文中）        if (avformat_find_stream_info(pContext, NULL) &lt; 0) {            LOGE(&quot;获取信息失败&quot;);            return;        }        //5.用来记住视频流的索引        int video_stream_idx = -1;        //从上下文中寻找找到视频流        for (int i = 0; i &lt; pContext-&gt;nb_streams; ++i) {            LOGE(&quot;循环  %d&quot;, i);            //codec：每一个流 对应的解码上下文            //codec_type：流的类型            if (pContext-&gt;streams[i]-&gt;codec-&gt;codec_type == AVMEDIA_TYPE_VIDEO) {                //如果找到的流类型 == AVMEDIA_TYPE_VIDEO 即视频流，就将其索引保存下来                video_stream_idx = i;            }        }        //获取到解码器上下文        AVCodecContext *pCodecCtx = pContext-&gt;streams[video_stream_idx]-&gt;codec;        //获取解码器（加密视频就是在此处无法获取）        AVCodec *pCodex = avcodec_find_decoder(pCodecCtx-&gt;codec_id);        LOGE(&quot;获取视频编码 %p&quot;, pCodex);        //6.打开解码器。 （ffempg版本升级名字叫做avcodec_open2）        if (avcodec_open2(pCodecCtx, pCodex, NULL) &lt; 0) {            LOGE(&quot;解码失败&quot;);            return;        }        //----------------------解码前准备--------------------------------------        //准备开始解码时需要一个AVPacket存储数据（通过av_malloc分配内存）        AVPacket *packet = (AVPacket *) av_malloc(sizeof(AVPacket));        av_init_packet(packet);//初始化结构体        //解封装需要AVFrame        AVFrame *frame = av_frame_alloc();        //声明一个rgb_Frame的缓冲区        AVFrame *rgb_Frame = av_frame_alloc();        //rgb_Frame  的缓冲区 初始化        uint8_t *out_buffer = (uint8_t *) av_malloc(                avpicture_get_size(AV_PIX_FMT_RGBA, pCodecCtx-&gt;width, pCodecCtx-&gt;height));        //给缓冲区进行替换        int re = avpicture_fill((AVPicture *) rgb_Frame, out_buffer, AV_PIX_FMT_RGBA, pCodecCtx-&gt;width,                                pCodecCtx-&gt;height);        LOGE(&quot;宽 %d  高 %d&quot;, pCodecCtx-&gt;width, pCodecCtx-&gt;height);        //格式转码需要的转换上下文（根据封装格式的宽高和编码格式，以及需要得到的格式的宽高）        //pCodecCtx-&gt;pix_fmt 封装格式文件的上下文        //AV_PIX_FMT_RGBA ： 目标格式 需要跟SurfaceView设定的格式相同        //SWS_BICUBIC ：清晰度稍微低一点的算法（转换算法，前面的算法清晰度高效率低，下面的算法清晰度低效率高）         //NULL,NULL,NULL ： 过滤器等        SwsContext *swsContext = sws_getContext(pCodecCtx-&gt;width, pCodecCtx-&gt;height, pCodecCtx-&gt;pix_fmt,                                                pCodecCtx-&gt;width, pCodecCtx-&gt;height, AV_PIX_FMT_RGBA,                                                SWS_BICUBIC, NULL, NULL, NULL        );        int frameCount = 0;        //获取nativeWindow对象,准备进行绘制        ANativeWindow *nativeWindow = ANativeWindow_fromSurface(env, surface);        ANativeWindow_Buffer outBuffer;//申明一块缓冲区 用于绘制        //------------------------一桢一帧开始解码--------------------        int length = 0;        int got_frame;        while (av_read_frame(pContext, packet) &gt;= 0) {//开始读每一帧的数据            if (packet-&gt;stream_index == video_stream_idx) {//如果这是一个视频流                //7.解封装（将packet解压给frame，即：拿到了视频数据frame）                length = avcodec_decode_video2(pCodecCtx, frame, &amp;got_frame, packet);//解封装函数                LOGE(&quot; 获得长度   %d 解码%d  &quot;, length, frameCount++);                if (got_frame &gt; 0) {                    //8.准备绘制                    //配置绘制信息 宽高 格式(这个绘制的宽高直接决定了视频在屏幕上显示的情况，这样会平铺整个屏幕，可以根据特定的屏幕分辨率和视频宽高进行匹配)                    ANativeWindow_setBuffersGeometry(nativeWindow, pCodecCtx-&gt;width, pCodecCtx-&gt;height,                                                     WINDOW_FORMAT_RGBA_8888);                    ANativeWindow_lock(nativeWindow, &amp;outBuffer, NULL);//锁定画布(outBuffer中将会得到数据)                    //9.转码（转码上下文，原数据，一行数据，开始位置，yuv的缓冲数组，yuv一行的数据）                    sws_scale(swsContext, (const uint8_t *const *) frame-&gt;data, frame-&gt;linesize, 0,                              frame-&gt;height, rgb_Frame-&gt;data,                              rgb_Frame-&gt;linesize                    );                    //10.绘制                    uint8_t *dst = (uint8_t *) outBuffer.bits; //实际的位数                    int destStride = outBuffer.stride * 4; //拿到一行有多少个字节 RGBA                    uint8_t *src = (uint8_t *) rgb_Frame-&gt;data[0];//像素数据的首地址                    int srcStride = rgb_Frame-&gt;linesize[0]; //实际内存一行的数量                    for (int i = 0; i &lt; pCodecCtx-&gt;height; ++i) {                        //将rgb_Frame缓冲区里面的数据一行一行copy到window的缓冲区里面                        //copy到window缓冲区的时候进行一些偏移设置可以将视频播放居中                        memcpy(dst + i * destStride, src + i * srcStride, srcStride);                    }                    ANativeWindow_unlockAndPost(nativeWindow);//解锁画布                    usleep(1000 * 16);//可以根据帧率休眠16ms                }            }            av_free_packet(packet);//释放        }        ANativeWindow_release(nativeWindow);//释放window        av_frame_free(&amp;frame);        av_frame_free(&amp;rgb_Frame);        avcodec_close(pCodecCtx);        avformat_free_context(pContext);        free(inputStr);    }</code></pre><h3 id="ffmpeg移植到Android上（多个abi）"><a href="#ffmpeg移植到Android上（多个abi）" class="headerlink" title="ffmpeg移植到Android上（多个abi）"></a>ffmpeg移植到Android上（多个abi）</h3><p><a href="https://github.com/ejoker88/FFmpeg-3.4-Android">首先是编译不同架构的ffmpeg library</a><br>这个库使用了FFmpeg 3.4 和 NDK r16b stable. 版本搭配真的很重要，这个脚本还要调用python创建不同abi的toolchain。<br>使用ndk编译ffmpeg满满的都是坑</p><pre><code>In file included from libavfilter/aeval.c:26:0:./libavutil/avassert.h:30:20: fatal error: stdlib.h: No such file or directory #include &lt;stdlib.h&gt;                    ^出现这个错误是因为使用最新版的NDK造成的，最新版的NDk将头文件和库文件进行了分离，我们指定的sysroot文件夹下只有库文件，而头文件放在了NDK目录下的sysroot内，只需在--extra-cflags中添加 &quot;-isysroot $NDK/sysroot&quot; 即可，还有有关汇编的头文件也进行了分离，需要根据目标平台进行指定 &quot;-I$NDK/sysroot/usr/include/arm-linux-androideabi&quot;，将 &quot;arm-linux-androideabi&quot; 改为需要的平台就可以，终于可以顺利的进行编译了</code></pre><pre><code>nasm/yasm not found or too old. use --disable-x86asm for a crippled build</code></pre><p>这是汇编工具没有安装导致的<br>sudo apt install yasm</p><p><a href="https://github.com/coopsrc/FFPlayerDemo">找到一个编译不同abi的so文件的脚本</a><br>armeabi-v7a arm64-v8a x86 x86_64这么几个host每个都要花上10分钟，所以这个脚本跑起来之后可以去喝杯茶了</p><pre><code class="bash">#!/bin/shPREFIX=android-buildHOST_PLATFORM=linux-x86_64COMMON_OPTIONS=&quot;\    --target-os=android \    --disable-static \    --enable-shared \    --enable-small \    --disable-programs \    --disable-ffmpeg \    --disable-ffplay \    --disable-ffprobe \    --disable-doc \    --disable-symver \    --disable-asm \    --enable-decoder=vorbis \    --enable-decoder=opus \    --enable-decoder=flac     &quot;build_all(){    for version in armeabi-v7a arm64-v8a x86 x86_64; do        echo &quot;======== &gt; Start build $version&quot;        case ${version} in        armeabi-v7a )            ARCH=&quot;arm&quot;            CPU=&quot;armv7-a&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/arm-linux-androideabi-4.9/prebuilt/$HOST_PLATFORM/bin/arm-linux-androideabi-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-arm/&quot;            EXTRA_CFLAGS=&quot;-march=armv7-a -mfpu=neon -mfloat-abi=softfp -mvectorize-with-neon-quad&quot;            EXTRA_LDFLAGS=&quot;-Wl,--fix-cortex-a8&quot;        ;;        arm64-v8a )            ARCH=&quot;aarch64&quot;            CPU=&quot;armv8-a&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/aarch64-linux-android-4.9/prebuilt/$HOST_PLATFORM/bin/aarch64-linux-android-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-arm64/&quot;            EXTRA_CFLAGS=&quot;&quot;            EXTRA_LDFLAGS=&quot;&quot;        ;;        x86 )            ARCH=&quot;x86&quot;            CPU=&quot;i686&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/x86-4.9/prebuilt/$HOST_PLATFORM/bin/i686-linux-android-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-x86/&quot;            EXTRA_CFLAGS=&quot;&quot;            EXTRA_LDFLAGS=&quot;&quot;        ;;        x86_64 )            ARCH=&quot;x86_64&quot;            CPU=&quot;x86_64&quot;            CROSS_PREFIX=&quot;$NDK_HOME/toolchains/x86_64-4.9/prebuilt/$HOST_PLATFORM/bin/x86_64-linux-android-&quot;            SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-x86_64/&quot;            EXTRA_CFLAGS=&quot;&quot;            EXTRA_LDFLAGS=&quot;&quot;        ;;        esac        echo &quot;-------- &gt; Start clean workspace&quot;        make clean        echo &quot;-------- &gt; Start config makefile&quot;        configuration=&quot;\            --prefix=${PREFIX} \            --libdir=${PREFIX}/libs/${version}            --incdir=${PREFIX}/includes/${version} \            --pkgconfigdir=${PREFIX}/pkgconfig/${version} \            --arch=${ARCH} \            --cpu=${CPU} \            --cross-prefix=${CROSS_PREFIX} \            --sysroot=${SYSROOT} \            --extra-ldexeflags=-pie \            ${COMMON_OPTIONS}            &quot;        echo &quot;-------- &gt; Start config makefile with ${configuration}&quot;        ./configure ${configuration}        echo &quot;-------- &gt; Start make ${version} with -j8&quot;        make j8        echo &quot;-------- &gt; Start install ${version}&quot;        make install        echo &quot;++++++++ &gt; make and install ${version} complete.&quot;    done}echo &quot;-------- Start --------&quot;build_allecho &quot;-------- End --------&quot;</code></pre><p><a href="https://blog.csdn.net/u011485531/article/details/55804380">如何把ffmpeg生成的so文件压缩大小</a></p><p>然后才是交叉编译</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://developer.android.com/studio/projects/configure-cmake">configure-cmake</a><br><a href="https://github.com/googlesamples/android-ndk">googlesamples/android-ndk</a><br><a href="https://www.jianshu.com/p/6332418b12b1">Android NDK开发扫盲及最新CMake的编译使用</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;android中ndk及jni编写注意事项（本文主要讲CMake）&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/ShanwangpingKarst_EN-AU5360258756_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="android" scheme="https://haldir65.github.io/tags/android/"/>
    
  </entry>
  
  <entry>
    <title>C语言中多进程之间通信的方式</title>
    <link href="https://haldir65.github.io/2019/01/30/2019-01-30-ipc-in-c-programming-language/"/>
    <id>https://haldir65.github.io/2019/01/30/2019-01-30-ipc-in-c-programming-language/</id>
    <published>2019-01-30T07:57:28.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p><strong><em>进程是资源分配的最小单位，线程是CPU调度的最小单位</em></strong><br><img src="https://www.haldir66.ga/static/imgs/Prayercard_ZH-CN13472871640_1920x1080.jpg" alt=""></p><p>本文多数来自<a href="https://www.zfl9.com/c-multi-proc.html">c语言多进程编程</a></p><p>当Linux启动的时候，init是系统创建的第一个进程，这一进程会一直存在，直到我们关闭计算机；虽然后面systemd取代了init进程。后面的所有进程都是init进程fork出来的,linux下使用pstree可以看到所有的进程都是以systemd为根节点的<br>当进程调用fork的时候，Linux在内存中开辟出一片新的内存空间给新的进程，并将老的进程空间中的内容复制到新的空间中，此后两个进程同时运行；老进程成为新进程的父进程(parent process)，而相应的，新进程就是老进程的子进程(child process)；</p><a id="more"></a><h2 id="fork的最简单实例"><a href="#fork的最简单实例" class="headerlink" title="fork的最简单实例"></a>fork的最简单实例</h2><p>fork是系统调用，会有两次返回，分别是父进程和子进程。</p><pre><code class="C">#include &lt;stdint.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;void print_process_message(){    __pid_t myprocess_id = getpid();    __uid_t uid = getuid();    __gid_t ugid = getgid();    printf(&quot;getpid = %d getuid= %d  getgid= %d \n&quot;,myprocess_id,uid, ugid);}int main(int argc, char const *argv[]){    int n =0;    printf(&quot;before fork: n = %d\n&quot;,n);    __pid_t fpid =fork();    if(fpid &lt;0 )    {        perror(&quot;fork error&quot;);        exit(EXIT_FAILURE);    }else if (fpid == 0)    {        n++;        printf(&quot;child_proc(%d, ppid=%d): n= %d\n&quot;,getpid(),getppid(),n);    } else    {        n--;        printf(&quot;parent_proc(%d): n= %d\n&quot;,getpid(),n);    }    print_process_message();    printf(&quot;quit_proc(%d) ...\n&quot;,getpid());    return 0;}</code></pre><h3 id="fork和vfrok"><a href="#fork和vfrok" class="headerlink" title="fork和vfrok"></a>fork和vfrok</h3><p>fork创建子进程，把父进程数据空间、堆和栈复制一份；<br>vfork创建子进程，与父进程内存数据共享；<br>但是后来的fork也学聪明了，不是一开始调用fork就复制数据，而是只有在子进程要修改数据的时候，才进行复制，即copy-on-write；<br>所以我们现在也很少去用vfork，因为vfork的优势已经不复存在了；</p><h2 id="孤儿进程和僵尸进程以及wait"><a href="#孤儿进程和僵尸进程以及wait" class="headerlink" title="孤儿进程和僵尸进程以及wait"></a>孤儿进程和僵尸进程以及wait</h2><p>正常的操作流程：子进程终结时会通知父进程，并通过return code告诉内核自己的退出信息，父进程知道后，有责任对该子进程使用<strong><em>wait</em></strong>系统调用，这个wait函数能够从内核中取出子进程的退出信息，并清空该信息在内核中所占据的空间；</p><p><strong><em>不正常的流程：</em></strong><br>父进程早于子进程挂掉，那么子进程就成了孤儿进程</p><p>如果程序写的糟糕，父进程忘记对子进程调用wait，子进程就成为僵尸(zombie)进程。（在htop里面看到state是Z）<br>当进程退出，释放大多数资源和它的父进程收集它的返回值、释放剩余资源这两段时间之间，子进程处于一个特殊状态，被称为僵尸进程；<br>每个进程都会经过一个短暂的僵尸状态，僵尸进程的最大危害就是会占用宝贵的PID资源，如果不及时清理，会导致无法再创建新的进程；</p><p><strong><em>解决僵尸进程的方法是干掉僵尸进程的父进程</em></strong>，僵尸进程也就变成了孤儿进程，最终被init进程接管，init进程会负责wait这些孤儿进程，释放占用的资源。</p><h2 id="wait和waitpid函数"><a href="#wait和waitpid函数" class="headerlink" title="wait和waitpid函数"></a>wait和waitpid函数</h2><p>pid_t wait(int <em>status);：等待任意子进程退出，并捕获退出状态<br>pid_t waitpid(pid_t pid, int </em>status, int options);：等待子进程退出，并捕获退出状态<br>这两个函数返回的都是退出的子进程的id</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;wait.h&gt;int main(int argc, char const *argv[],char *envp[]){    pid_t fpid = fork(), pid;    if(fpid &lt; 0)    {        perror(&quot;fork error&quot;);        exit(EXIT_FAILURE);    }    else if(fpid ==0 )    {        sleep(5);        exit(5);    } else {        int stat;        for(;;){            pid = waitpid(fpid,&amp;stat,WNOHANG); //stat用于记录子进程的返回结果            if(pid&gt;0) {                break;            }else {                printf(&quot;wait child proc ... \n&quot;);                sleep(1);            }        }        if(WIFEXITED(stat))//这个函数如果子进程正常退出的话就返回真        {            printf(&quot;child_proc(%d): exit_code :%d\n&quot;,pid,WEXITSTATUS(stat));        }    }    return 0;}</code></pre><p><strong>处理子进程的退出有以下两种方式：</strong><br>第一种：通过信号处理函数signal()，如可以忽略子进程的SIGCHLD信号来防止僵尸进程的产生：signal(SIGCHLD, SIG_IGN);<br>第二种：通过调用wait()、waitpid()函数，来回收子进程，防止产生僵尸进程，占用<strong>PID等宝贵的系统资源</strong>；</p><p>经常在parent process中看到wait(NULL)的操作，意思就是让父进程等child process 返回exit status。<br><a href="https://stackoverflow.com/questions/42426816/how-does-waitnull-exactly-work?rq=1">wait(NULL)是什么意思</a></p><pre><code>wait(NULL) will block parent process until any of its children has finished. If child terminates before parent process reaches wait(NULL) then the child process turns to a zombie process until its parent waits on it and its released from memory.If parent process doesn&#39;t wait for its child, and parent finishes first, then the child process becomes orphan and is assigned to init as its child. And init will wait and release the process entry in the process table.In other words: parent process will be blocked until child process returns an exit status to the operating system which is then returned to parent process. If child finishes before parent reaches wait(NULL) then it will read the exit status, release the process entry in the process table and continue execution until it finishes as well.</code></pre><h3 id="exec系列函数"><a href="#exec系列函数" class="headerlink" title="exec系列函数"></a>exec系列函数</h3><p><strong>fork出来一个新的进程当然是要干活的</strong>，就要用到exec系统调用<br>exec系统调用是以新的进程空间替换现在的进程空间，但是pid不变，还是原来的pid，相当于换了个身体，但是名字不变；<br>调用exec后，系统会申请一块新的进程空间来存放被调用的程序，然后当前进程会携带pid跳转到新的进程空间，并从main函数开始执行，旧的进程空间被回收；<br>exec用被执行的程序完全替换调用它的程序的影像。fork创建一个新的进程就产生了一个新的PID，<br>exec启动一个新程序，替换原有的进程，因此这个新的被exec执行的进程的PID不会改变，</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main(int arg,char **args){    char *argv[]={&quot;ls&quot;,&quot;-al&quot;,&quot;/usr/include/linux&quot;,NULL};//传递给执行文件的参数数组，这里包含执行文件的参数     char *envp[]={0,NULL};//传递给执行文件新的环境变量数组    execve(&quot;/bin/ls&quot;,argv,envp);}</code></pre><p>这个函数的参数</p><pre><code>int   execve( char *pathname,char *argv[],char *envp[])</code></pre><h3 id="exit-可以注册进程退出的时候的回调函数"><a href="#exit-可以注册进程退出的时候的回调函数" class="headerlink" title="exit(可以注册进程退出的时候的回调函数)"></a>exit(可以注册进程退出的时候的回调函数)</h3><p>exit是系统调用级别的，用于进程运行的过程中，随时结束进程；<br>return是语言级别的，用于调用堆栈的返回，返回上一层调用；<br>在main函数中调用exit(0)等价于return 0；<br>_exit()函数的作用最为简单：直接使进程停止运行，清除其使用的内存空间，并销毁其在内核中的各种数据结构；<br>exit()函数则在这些基础上作了一些包装，在执行退出之前加了若干道工序；<br>exit()函数与_exit()函数最大的区别就在于exit()要检查文件的打开情况，把文件缓冲区中的内容写回文件，就是”清理I/O缓冲”；</p><p>按照ANSI C的规定，一个进程可以登记至多32个函数，这些函数将由exit自动调用；（也就是说在调用exit的时候会调用这些回调函数）<br>分为atexit和on_exit</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;signal.h&gt;void func1(void){    printf(&quot;&lt;atexit&gt; func1 getpid = %d \n&quot;,getpid());}void func2(void){    printf(&quot;&lt;atexit&gt; func2 getpid = %d \n&quot;,getpid());}void func3(void){    printf(&quot;&lt;atexit&gt; func3 getpid = %d \n&quot;,getpid());}void func(int status, void *str){    printf(&quot;&lt;on_exit&gt; exit_code: %d, arg: %s getpid = %d \n&quot;, status, (char *)str,getpid());}int main(void){    signal(SIGCHLD, SIG_IGN);    on_exit(func, &quot;on_exit3&quot;);    on_exit(func, &quot;on_exit2&quot;);    on_exit(func, &quot;on_exit1&quot;);    atexit(func3);    atexit(func2);    atexit(func1);    pid_t pid;    pid = fork();    if(pid &lt; 0){        perror(&quot;fork error&quot;);        exit(EXIT_FAILURE);    }else if(pid == 0){        exit(0);    }else{        sleep(3);    }    return 0;}</code></pre><p><strong><em>输出：</em></strong></p><pre><code>&lt;atexit&gt; func1 getpid = 13508&lt;atexit&gt; func2 getpid = 13508&lt;atexit&gt; func3 getpid = 13508&lt;on_exit&gt; exit_code: 0, arg: on_exit1 getpid = 13508&lt;on_exit&gt; exit_code: 0, arg: on_exit2 getpid = 13508&lt;on_exit&gt; exit_code: 0, arg: on_exit3 getpid = 13508&lt;atexit&gt; func1 getpid = 13507&lt;atexit&gt; func2 getpid = 13507&lt;atexit&gt; func3 getpid = 13507&lt;on_exit&gt; exit_code: 0, arg: on_exit1 getpid = 13507&lt;on_exit&gt; exit_code: 0, arg: on_exit2 getpid = 13507</code></pre><p>也就是说fork出来的子进程会继承父进程的终止处理函数、信号处理设置；</p><h2 id="Daemon守护进程"><a href="#Daemon守护进程" class="headerlink" title="Daemon守护进程"></a>Daemon守护进程</h2><p>Linux Daemon进程是运行在后台的一种特殊进程。<br>一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，<strong><em>所以它是一个由init继承的孤儿进程；</em></strong><br>守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理；<br>守护进程的名称通常以d结尾，比如sshd、xinetd、crond等；</p><p>头文件：unistd.h<br><strong><em>int daemon(int nochdir, int noclose);</em></strong></p><h2 id="system和popen"><a href="#system和popen" class="headerlink" title="system和popen"></a>system和popen</h2><p><strong><em>system是去执行一个shell命令</em></strong><br>system()函数调用/bin/sh来执行参数指定的命令，/bin/sh一般是一个软连接，指向某个具体的shell，比如bash；</p><pre><code class="C">system(&quot;cat /etc/sysctl.conf&quot;);；</code></pre><p>实际上system()函数执行了三步操作：<br>fork一个子进程；<br>在子进程中调用exec函数去执行command；<br>在父进程中调用wait去等待子进程结束；<br>一个不好的地方是system()，并不能获取命令执行的输出结果，只能得到执行的返回值；</p><p><strong>popen</strong><br>标准I/O函数库提供了popen函数，它启动另外一个进程去执行一个shell命令行；<br>这里我们称调用popen的进程为父进程，由popen启动的进程称为子进程；</p><p>popen函数还创建一个管道用于父子进程间通信；父进程要么从管道读信息，要么向管道写信息，至于是读还是写取决于父进程调用popen时传递的参数；</p><pre><code class="C">#include &lt;stdio.h&gt;FILE *popen(const char *command, const char *type);/*函数功能：popen()会调用fork()产生子进程，然后从子进程中调用/bin/sh -c来执行参数command的指令;          参数type可使用&quot;r&quot;代表读取，&quot;w&quot;代表写入;          依照此type值，popen()会建立管道连到子进程的标准输出设备或标准输入设备，然后返回一个文件指针;          随后进程便可利用此文件指针来读取子进程的输出设备或是写入到子进程的标准输入设备中;返回值：若成功则返回文件指针，否则返回NULL，错误原因存于errno中*/int pclose(FILE *stream);/*函数功能：pclose()用来关闭由popen所建立的管道及文件指针；参数stream为先前由popen()所返回的文件指针;返回值：若成功则返回shell的终止状态(也即子进程的终止状态)，若出错返回-1，错误原因存于errno中;*/</code></pre><p><strong>这里正式使用到了进程之间的管道通信</strong></p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 2){        fprintf(stderr, &quot;usage: %s &lt;cmd&gt;\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    char output[1024+1];    FILE *pp = popen(argv[1], &quot;r&quot;);    if(pp == NULL){        perror(&quot;popen error&quot;);        exit(EXIT_FAILURE);    }    int nread = fread(output, 1, 1024, pp); //父进程通过文件指针读取子进程的输出设备。    int status = pclose(pp);    if(status &lt; 0){        perror(&quot;pclose error&quot;);        exit(EXIT_FAILURE);    }    output[nread] = &#39;\0&#39;;    if(WIFEXITED(status)){        printf(&quot;status: %d\n%s&quot;, WEXITSTATUS(status), output);    }    return 0;}</code></pre><h2 id="signal信号"><a href="#signal信号" class="headerlink" title="signal信号"></a>signal信号</h2><p>信号(signal)是一种软中断，信号机制是进程间通信的一种方式，采用<strong>异步通信方式</strong><br>用kill -l　可以查看可以发出的信号</p><pre><code>$ kill -l           HUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM 16 CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL 30 SYS</code></pre><p>挑几个重要的:<br>SIGINT(2) 中断　（CTRL + C）<br>SIGKILL(9) kill信号（强杀，进程不能阻止）<br>SIGPIPE(13) 管道破损，没有读端的管道写数据,就是那个brokenpipe。<strong>默认是杀进程的，所以网络编程中要处理这个信号。</strong>（当服务器close一个连接时，若client端接着发数据。根据TCP协议的规定，会收到一个RST响应，client再往这个服务器发送数据时，系统会发出一个SIGPIPE信号给进程，告诉进程这个连接已经断开了，不要再写了。）<br>SIGTERM（１５）　终止信号，这个不是强制的，它可以被捕获和解释（或忽略）的过程。类似于和这个进程商量一下，让它退出。不听话的话可以用９杀掉。<br>SIGCHLD(１７) 子进程退出。　默认忽略<br>SIGSTOP（１９）　进程停止　不能被忽略、处理和阻塞<br>SIGPWR(30) 关机　默认忽略<br>进程可以注册收到信号时的处理函数</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;void handle_signal(int signum){    printf(&quot;received signal: %d\n&quot;, signum);    exit(0);}int main(void){    signal(SIGINT, handle_signal);    for(;;){        printf(&quot;running ... \n&quot;);        sleep(1);    }    return 0;}</code></pre><p>这里添一句，cpython因为是用Ｃ语言写的，在处理信号这方面几乎是一模一样。<br><a href="https://stackabuse.com/handling-unix-signals-in-python/">注册signal_handler</a></p><blockquote><p>＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝介绍进程的基础知识到此结束</p></blockquote><h2 id="进程之间的通信"><a href="#进程之间的通信" class="headerlink" title="进程之间的通信"></a>进程之间的通信</h2><h3 id="使用管道"><a href="#使用管道" class="headerlink" title="使用管道"></a>使用管道</h3><p>管道是FIFO的<br>下面是创建一个匿名管道的代码</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 3){        fprintf(stderr, &quot;usage: %s parent_sendmsg child_sendmsg\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int pipes[2];    if(pipe(pipes) &lt; 0){        perror(&quot;pipe&quot;);        exit(EXIT_FAILURE);    }    pid_t pid = fork();    if(pid &lt; 0){        perror(&quot;fork&quot;);        exit(EXIT_FAILURE);    }else if(pid &gt; 0){        char buf[BUFSIZ + 1];        int nbuf;        strcpy(buf, argv[1]);        write(pipes[1], buf, strlen(buf));        sleep(1); //这里sleep是为了让子进程有时间把管道中的数据读走，不然数据就会被底下的父进程的read读走.        //因为实质上内核中只有一个管道缓冲区，是父进程创建的，只不过子进程同时拥有了它的引用        nbuf = read(pipes[0], buf, BUFSIZ);        buf[nbuf] = 0;        printf(&quot;parent_proc(%d) recv_from_child: %s\n&quot;, getpid(), buf);        close(pipes[0]);        close(pipes[1]);    }else if(pid == 0){        char buf[BUFSIZ + 1];        int nbuf = read(pipes[0], buf, BUFSIZ);        buf[nbuf] = 0;        printf(&quot;child_proc(%d) recv_from_parent: %s\n&quot;, getpid(), buf);        strcpy(buf, argv[2]);        write(pipes[1], buf, strlen(buf));        close(pipes[0]);        close(pipes[1]);    }    return 0;}</code></pre><blockquote><p>./a.out parent_say_tochild child_say_to_parent</p></blockquote><p>实际中为了实现双向通信，应该准备两根管道，一根负责从父进程往子进程写数据（同时子进程从这里读取数据），一根负责从子进程往父进程写数据（父进程也从这里读数据）</p><p>管道默认是阻塞模式的，fcntl(fd, F_SETFL, flags | O_NONBLOCK);可以设置非阻塞的管道，这个跟socket很像。</p><h3 id="命名管道"><a href="#命名管道" class="headerlink" title="命名管道"></a>命名管道</h3><p>上面说的匿名管道要求这些进程都是由同一个祖先创建的。所以在不相干的进程之间交换数据就不方便了，为此，我们需要命名管道<br>命名管道也被称为FIFO文件<br>我们可以使用以下两个函数之一来创建一个命名管道，原型如下：</p><pre><code class="C">头文件：sys/types.h、sys/stat.hint mkfifo(const char *filename, mode_t mode);int mknod(const char *filename, mode_t mode | S_IFIFO, (dev_t)0);返回值：执行成功返回0，失败返回-1，并设置errno</code></pre><p>注意这样的方式是在文件系统中创建了一个真实的文件, 可以对其进行读写操作(注意不能同时读写)<br>sender.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 3){        fprintf(stderr, &quot;usage: %s fifo_file filename\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int fifo = open(argv[1], O_WRONLY);    if(fifo &lt; 0){        perror(&quot;open&quot;);        exit(EXIT_FAILURE);    }    FILE *fp = fopen(argv[2], &quot;rb&quot;);    if(fp == NULL){        perror(&quot;fopen&quot;);        exit(EXIT_FAILURE);    }    char buf[BUFSIZ];    int nbuf;    while((nbuf = fread(buf, 1, BUFSIZ, fp)) &gt; 0){        write(fifo, buf, nbuf);    }    fclose(fp);    close(fifo);    return 0;}</code></pre><p>receiver.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;errno.h&gt;int main(int argc, char *argv[]){    if(argc &lt; 3){        fprintf(stderr, &quot;usage: %s fifo_file filename\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int fifo = open(argv[1], O_RDONLY);    if(fifo &lt; 0){        perror(&quot;fifo&quot;);        exit(EXIT_FAILURE);    }    FILE *fp = fopen(argv[2], &quot;wb&quot;);    if(fp == NULL){        perror(&quot;fopen&quot;);        exit(EXIT_FAILURE);    }    char buf[BUFSIZ];    int nbuf;    while((nbuf = read(fifo, buf, BUFSIZ)) &gt; 0){        printf(&quot;i got something %s\n&quot;, buf);        fwrite(buf, nbuf, 1, fp);    }    close(fifo);    fclose(fp);    return 0;}</code></pre><pre><code>mkfifo fifo ##使用mkfifo这个命令创建一个管道文件./bin/sender fifo /var/log/syslog ###把/var/log/syslog这个文件里面的内容读出来，通过fifo这个文件传到另一个进程。注意到这里卡在这里了./bin/receiver fifo syslog.copy ##从管道文件中读取输出，写到syslog.copy文件中.注意到这里读完了之后前面卡住的进程成功退出了</code></pre><p>这里还要提到命名管道的安全问题，有可能存在多个进程同时往一个FIFO文件写数据，这样会存在数据顺序错乱的问题。解决方案就是每次写入的数据的大小保持在PIPE_BUF大小以内，要么全部写入，要么一个字节也不写入。</p><h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p><strong><em>概念:</em></strong></p><blockquote><p>什么是共享内存<br>顾名思义，共享内存就是允许两个不相关的进程访问同一个逻辑内存；共享内存是在两个正在运行的进程之间共享和传递数据的一种非常有效的方式；<br>不同进程之间共享的内存通常安排为同一段物理内存，进程可以将同一段共享内存连接到它们自己的地址空间中，所有进程都可以访问共享内存中的地址；<br>而如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程；<br>特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前，并无自动机制可以阻止第二个进程开始对它进行读取；所以我们通常需要用其他的机制来同步对共享内存的访问，例如信号量、互斥锁；</p></blockquote><p><strong><em>共享内存的函数接口</em></strong><br><strong><br>头文件：sys/types.h、sys/ipc.h、sys/shm.h<br>int shmget(key_t shm_key, size_t shm_size, int shm_flg);：创建共享内存<br>shm_key用来标识一块共享内存：<br>shm_size：输入参数，共享内存的大小（单位：byte）：注意内存分配的单位是页（一般为4kb，可通过getpagesize()获取）；也就是说如果shm_size为1，那么也会分配4096字节的内存；只获取共享内存时，shm_size可指定为0；</strong></p><p>程序对信号量的操作都是<code>原子操作</code>，并且只能对它进行等待和发送操作</p><h2 id="Unix-domain-socket"><a href="#Unix-domain-socket" class="headerlink" title="Unix domain socket"></a>Unix domain socket</h2><p>socket原本是为了网络通讯设计的，但是后来在socket的框架上发展出一种IPC机制，就是UNIX Domain Socket；<br>虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率：</p><ol><li>不需要经过网络协议栈；</li><li>不需要打包拆包；</li><li>不需要计算校验和；</li><li>不需要维护序号和应答；</li></ol><p>这是因为IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的；<br>UNIX Domain Socket也提供面向流和面向数据报两种API接口，类似TCP和UDP，但是面向数据报的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱；<br>使用UNIX Domain Socket的过程和网络socket十分相似，也要先调用socket()创建一个socket文件描述符，address family指定为AF_UNIX，type可以选择SOCK_STREAM或SOCK_DGRAM，protocol参数仍然指定为0即可；<br>UNIX Domain Socket与网络socket编程最明显的不同在于地址格式不同，用结构体<code>sockaddr_un</code>表示；<br>网络编程的socket地址是IP地址加端口号，而UNIX Domain Socket的地址是一个socket类型的文件在文件系统中的路径，这个socket文件由bind()调用创建，如果调用bind()时该文件已经存在，则bind()错误返回；</p><p>unix_domain_server.c</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/un.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;netdb.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;signal.h&gt;#include &lt;sys/wait.h&gt;#define SOCK_PATH &quot;/run/echo.sock&quot;#define BUF_SIZE 1024int listenfd;void handle_signal(int signo);int main(void){    signal(SIGINT, handle_signal);    signal(SIGHUP, handle_signal);    signal(SIGTERM, handle_signal);    if((listenfd = socket(AF_UNIX, SOCK_STREAM, 0)) &lt; 0){        perror(&quot;socket&quot;);        exit(EXIT_FAILURE);    }    struct sockaddr_un servaddr;    memset(&amp;servaddr, 0, sizeof(servaddr));    servaddr.sun_family = AF_UNIX;    strcpy(servaddr.sun_path, SOCK_PATH);    unlink(SOCK_PATH);    if(bind(listenfd, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) &lt; 0){ //因为这里要在/var/目录下创建一个临时文件，这个程序需要sudo运行        perror(&quot;bind&quot;);        exit(EXIT_FAILURE);    }    chmod(SOCK_PATH, 00640);    if(listen(listenfd, SOMAXCONN) &lt; 0){        perror(&quot;listen&quot;);        exit(EXIT_FAILURE);    }    int connfd, nbuf;    char buf[BUF_SIZE + 1];    for(;;){        if((connfd = accept(listenfd, NULL, NULL)) &lt; 0){            perror(&quot;accept&quot;);            continue;        }        nbuf = recv(connfd, buf, BUF_SIZE, 0);        buf[nbuf] = 0;        printf(&quot;new msg: \&quot;%s\&quot;\n&quot;, buf);        send(connfd, buf, nbuf, 0);        close(connfd);    }    return 0;}void handle_signal(int signo){    if(signo == SIGINT){        fprintf(stderr, &quot;received signal: SIGINT(%d)\n&quot;, signo);    }else if(signo == SIGHUP){        fprintf(stderr, &quot;received signal: SIGHUP(%d)\n&quot;, signo);    }else if(signo == SIGTERM){        fprintf(stderr, &quot;received signal: SIGTERM(%d)\n&quot;, signo);    }    close(listenfd);    unlink(SOCK_PATH);    exit(EXIT_SUCCESS);}</code></pre><p>unix_domain_client.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/un.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;netdb.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;signal.h&gt;#include &lt;sys/wait.h&gt;#define SOCK_PATH &quot;/run/echo.sock&quot;#define BUF_SIZE 1024int main(int argc, char *argv[]){    if(argc &lt; 2){        fprintf(stderr, &quot;usage: %s msg\n&quot;, argv[0]);        exit(EXIT_FAILURE);    }    int sockfd;    if((sockfd = socket(AF_UNIX, SOCK_STREAM, 0)) &lt; 0){        perror(&quot;socket&quot;);        exit(EXIT_FAILURE);    }    struct sockaddr_un servaddr;    memset(&amp;servaddr, 0, sizeof(servaddr));    servaddr.sun_family = AF_UNIX;    strcpy(servaddr.sun_path, SOCK_PATH);    if(connect(sockfd, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) &lt; 0){        perror(&quot;connect&quot;);        exit(EXIT_FAILURE);    }    char buf[BUF_SIZE + 1];    int nbuf;    nbuf = strlen(argv[1]);    send(sockfd, argv[1], nbuf, 0);    nbuf = recv(sockfd, buf, BUF_SIZE, 0);    buf[nbuf] = 0;    printf(&quot;echo msg: \&quot;%s\&quot;\n&quot;, buf);    close(sockfd);    return 0;}</code></pre><p>上述程序实现了通过uninx domain socket的client-server 数据传输，就像是通过/var/echo.sock这个文件传输数据。印象中uwsi也是这样实现nginx和django进程的通信。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>现在把进程之间传递信息的各种途径（包括各种IPC机制）总结如下：<br>父进程通过fork可以将打开文件的描述符传递给子进程<br>子进程结束时，父进程调用wait可以得到子进程的终止信息<br>几个进程可以在文件系统中读写某个共享文件，也可以通过给文件加锁来实现进程间同步<br>进程之间互发信号，一般使用SIGUSR1和SIGUSR2实现用户自定义功能<br>管道<br>FIFO<br>mmap函数，几个进程可以映射同一内存区<br>SYS V IPC，以前的SYS V UNIX系统实现的IPC机制，包括消息队列、信号量和共享内存，现在已经基本废弃<br>Linux内核继承和兼容了丰富的Unix系统进程间通信（IPC）机制。有传统的管道（Pipe）、信号（Signal）和跟踪（Trace），这三项通信手段只能用于父进程与子进程之间，或者兄弟进程之间；后来又增加了命令管道（Named Pipe），使得进程间通信不再局限于父子进程或者兄弟进程之间；为了更好地支持商业应用中的事务处理，在AT&amp;T的Unix系统V中，又增加了三种称为“System V IPC”的进程间通信机制，分别是报文队列（Message）、共享内存（Share Memory）和信号量（Semaphore）；后来BSD Unix对“System V IPC”机制进行了重要的扩充，提供了一种称为插口（Socket）的进程间通信机制。<br>UNIX Domain Socket是目前最广泛使用的IPC机制</strong></p><p><a href="https://www.zhihu.com/question/39440766/answer/89210950">Linux现有的所有进程间IPC方式</a></p><ol><li>管道：在创建时分配一个page大小的内存，缓存区大小比较有限；</li><li>消息队列：信息复制两次，额外的CPU消耗；不合适频繁或信息量大的通信；</li><li>共享内存：无须复制，共享缓冲区直接付附加到进程虚拟地址空间，速度快；但进程间的同步问题操作系统无法实现，必须各进程利用同步工具解决；</li><li>套接字：作为更通用的接口，传输效率低，主要用于不通机器或跨网络的通信；</li><li>信号量：常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。</li><li>信号: 不适用于信息交换，更适用于进程中断控制，比如非法内存访问，杀死某个进程等；</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.zfl9.com/c-multi-proc.html">c语言多进程编程</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;&lt;em&gt;进程是资源分配的最小单位，线程是CPU调度的最小单位&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/Prayercard_ZH-CN13472871640_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本文多数来自&lt;a href=&quot;https://www.zfl9.com/c-multi-proc.html&quot;&gt;c语言多进程编程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当Linux启动的时候，init是系统创建的第一个进程，这一进程会一直存在，直到我们关闭计算机；虽然后面systemd取代了init进程。后面的所有进程都是init进程fork出来的,linux下使用pstree可以看到所有的进程都是以systemd为根节点的&lt;br&gt;当进程调用fork的时候，Linux在内存中开辟出一片新的内存空间给新的进程，并将老的进程空间中的内容复制到新的空间中，此后两个进程同时运行；老进程成为新进程的父进程(parent process)，而相应的，新进程就是老进程的子进程(child process)；&lt;/p&gt;
    
    </summary>
    
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
      <category term="c" scheme="https://haldir65.github.io/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>编程语言中使用到的多线程基础数据结构</title>
    <link href="https://haldir65.github.io/2019/01/30/2019-01-30-concurrency-primitives-in-programing-languages/"/>
    <id>https://haldir65.github.io/2019/01/30/2019-01-30-concurrency-primitives-in-programing-languages/</id>
    <published>2019-01-30T07:53:33.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/HongKongFireworks_ZH-CN13422096721_1920x1080.jpg" alt=""><br>主要讲讲java中的notify,wait,synchronized ，unsafe等多线程基础工具的使用方式。</p><a id="more"></a><h2 id="java"><a href="#java" class="headerlink" title="java"></a>java</h2><h3 id="wait和notify"><a href="#wait和notify" class="headerlink" title="wait和notify"></a>wait和notify</h3><p>有一个异常叫做java.lang.IllegalMonitorStateException。意思就是没有在synchronized block中调用wait或者notify方法。<br>java Object中是有一个monitor对象的，wait和notify就是基于这个属性去实现的。只要在同一对象上去调用notify/notifyAll方法，就可以唤醒对应对象monitor上等待的线程了。<br>为什么jvm需要对象的头部信息呢，一是给GC，锁做标记，二是hash数据和分代年龄，三是为了从对象指针就可以会的其数据类型及动态分派的能力，四是数组类型需要有数量信息。</p><p><a href="https://javadoop.com/post/Threads-And-Locks-md">抛出异常也需要获得锁</a><br>wait方法抛出了InterruptedException异常，即使是异常，也是要获取到监视器锁了才会抛出</p><h3 id="synchronized关键字"><a href="#synchronized关键字" class="headerlink" title="synchronized关键字"></a>synchronized关键字</h3><p>从语法上讲，synchronized可以用在<br>instance　method(锁在这个instance上), static method (锁在这个class )以及method block(锁这一块代码逻辑)。<br>➜ $ cat SynchronizedSample.java </p><pre><code class="java">package com.me.harris.concurrent;public class SynchronizedSample {    public void method() {        synchronized (this) {            System.out.println(&quot;Method 1 start&quot;);        }    }}</code></pre><p>javac SynchronizedSample.java<br>javap -c SynchronizedSample</p><pre><code>Warning: Binary file SynchronizedSample contains com.me.harris.concurrent.SynchronizedSampleCompiled from &quot;SynchronizedSample.java&quot;public class com.me.harris.concurrent.SynchronizedSample {  public com.me.harris.concurrent.SynchronizedSample();    Code:       0: aload_0       1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V       4: return  public void method();    Code:       0: aload_0       1: dup       2: astore_1          3: monitorenter  ///看这里       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;       7: ldc           #3                  // String Method 1 start       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V      12: aload_1      13: monitorexit //看这里      14: goto          22      17: astore_2      18: aload_1      19: monitorexit      20: aload_2      21: athrow      22: return    Exception table:       from    to  target type           4    14    17   any          17    20    17   any}</code></pre><p>java doc是这么解释的</p><blockquote><p>Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:<br>• If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.<br>• If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.<br>• If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership.<br>看上去很像c语言里面的semctl嘛。<br>Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的，monitor对象存在于每一个java对象的对象头中(具体点是存的是指针)。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。</p></blockquote><h2 id="Java虚拟机对synchronized的优化"><a href="#Java虚拟机对synchronized的优化" class="headerlink" title="Java虚拟机对synchronized的优化"></a>Java虚拟机对synchronized的优化</h2><p>锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级</p><p><a href="https://www.jianshu.com/p/acf667ccec40">锁的实现</a><br>java中的锁一共有4种状态，级别从低到高分别是：</p><ul><li>无锁状态</li><li>偏向锁</li><li>轻量级锁</li><li>重量级锁</li></ul><h3 id="偏向锁："><a href="#偏向锁：" class="headerlink" title="偏向锁："></a>偏向锁：</h3><p>顾名思义，为了让线程获得锁的代价更低，引入了偏向锁。<br><strong>加锁</strong><br>当一个线程访问同步块并且获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程id，这样，这个线程便获取了这个对象的偏向锁，之后这个线程进入和退出就不需要通过CAS操作，也就是原子操作，来进行加锁和解锁，只需要简单的测试下对象头存储的偏向锁的线程id是否和自身的id一致，如果一致，那么已经获取锁，直接进入。否则，判断对象中是否已经存储了偏向锁，如果没有锁，那么使用CAS竞争锁，如果设置了，那么尝试使用CAS将对象头的偏向锁指向当前线程。<br><strong>解锁</strong><br>偏向锁的解锁时机是在竞争时才会释放锁,撤销时需要等待全局安全点，这个时间点没有正在执行的字节码，首先会暂停拥有偏向锁的线程，然后检查偏向锁的线程是否存活，如果不活动，那么直接设置为无锁状态。否则要么偏向其他锁，要么恢复到无锁或者标记对象不适合偏向锁。</p><h3 id="轻量锁"><a href="#轻量锁" class="headerlink" title="轻量锁"></a>轻量锁</h3><p>会自旋尝试获取锁，消耗cpu资源<br><strong>加锁</strong><br>一旦多线程发起了锁竞争，并且释放了偏向锁之后，线程通过CAS修改Mark Word，如果当前没有对象持有同步体的锁，那么直接将同步体的锁修改的轻量锁，否则，该线程将自旋获取锁，直到膨胀为重量级锁，修改同步体的Mark Word为重量级锁，然后阻塞<br><strong>解锁</strong><br>一旦有其他线程因想获取当前锁而膨胀为重量级锁，那么这个线程将会通过CAS替换Mark Word，然后失败，解锁，并且唤醒其他等待线程。</p><h3 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h3><p>会阻塞，不消耗cpu资源，但是响应时间较慢<br>synchronized<br>内部也是利用了锁。<br>每一个对象都有一个自己的monitor，必须先获取这个monitor对象才能够进入同步块或同步方法，而这个monitor对象的获取是排他的，也就是同一时刻只能有一个线程获取到这个monitor</p><p><a href="https://blog.csdn.net/javazejian/article/details/72828483">轻量级锁和偏向锁</a></p><p>类似的，synchronized修饰的instance method在编译后添加了一个ACC_SYNCHRONIZED的flag，同步是通过这个标志实现的。</p><h2 id="回顾一下用notify-wait-synchronized实现的生产者-消费者模型"><a href="#回顾一下用notify-wait-synchronized实现的生产者-消费者模型" class="headerlink" title="回顾一下用notify,wait,synchronized实现的生产者-消费者模型"></a>回顾一下用notify,wait,synchronized实现的生产者-消费者模型</h2><p>基本的思路就是生产者和消费者共同持有一个锁（随便new一个Object出来就是了），生产者和消费者都extends Thread。<br>生产者每次生产一个都会notifyAll，消费者每次消费一个都会notifyAll</p><p><a href="http://cmsblogs.com/?p=2915">在Java中，每个对象都有两个池，锁(monitor)池和等待池</a><br>锁池 :假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。<br>等待池 :假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池.</p><p>也即是被notify的线程都在锁池里(有权竞争cpu)，自己调用wait的线程都在等待池里(无权竞争cpu)。 那么什么时候竞争呢，持有锁的线程自己wait(释放锁)了，那么有权竞争的线程就开始竞争，获得锁的进入同步代码块或者同步方法。</p><p>需要注意的是<br><strong><em>notify/notifyAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。</em></strong></p><p>wait方法就是将当前线程加入object的waitSet同时释放锁（理解成一个hashset也行），notifyAll则是把waitset里面的内容全部挪到blocked队列中，在notifyAll的线程执行完毕释放锁之后，挑选一个获得锁。<a href="https://www.jianshu.com/p/f4454164c017">JVM源码分析之Object.wait/notify实现</a></p><p><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#wait(">oracle的文档上说明了,wait有一个spurious wakeup</a>) 是出于performance考虑，表现为wait的线程不需要notify也能自己醒过来。(文档中也指出了，这也就是为什么每一个wait都要包在一个while loop里面的原因)。这一现象在某些os上，包括linux上就有。<br>Effective java里面说要把wait写在一个while检查里面</p><pre><code class="java">// The standard idiom for calling the wait method in Java synchronized (sharedObject) {     while (condition) {       sharedObject.wait(); // 就是为了防止spurious wakeup    }     // do action based upon condition e.g. take or put into queue }</code></pre><p><a href="https://www.youtube.com/watch?v=Oi6-pXX11qw">how not to do java concurrency</a></p><p>以下代码验证通过</p><pre><code class="java">public class Test1 {    private static int count = 0;    private static final int FULL = 5;    private static final String LOCK = &quot;lock&quot;;    public static void main(String[] args) {        Test1 instance = new Test1();        new Thread(instance.new Producer()).start();        new Thread(instance.new Consumer()).start();    }    class Producer implements Runnable{        @Override        public void run() {            for (int i = 0; i &lt; 10; i++) {                synchronized (LOCK){                    while (count==FULL){                        try{                            System.out.println(&quot;PRODUCER WILL WAITING&quot;);                            LOCK.wait();                            System.out.println(&quot;PRODUCER END WAITING&quot;);                            // 进入 wait()方法后，当前线程释放锁。在从 wait()返回前，线程与其他线程竞争重新获得锁                        }catch (Exception e){                            e.printStackTrace();                        }                    }                    count++;                    System.out.println(Thread.currentThread().getName() + &quot;生产者生产，目前总共有&quot; + count);                    LOCK.notifyAll();//当前处在wait状态的线程不会马上获得锁                }                //退出synchronize代码块之后，程序退出 synchronized 代码块后，当前线程才会释放锁，wait所在的线程也才可以获取该对象锁            }        }    }    class Consumer implements Runnable {        @Override        public void run() {            for (int i = 0; i &lt; 10; i++) {                synchronized (LOCK){                    while (count==0){                        try {                            System.out.println(&quot;CONSUMER WILL WAITING&quot;);                            LOCK.wait();                            System.out.println(&quot;CONSUMER END WAITING&quot;);                            // 进入 wait()方法后，当前线程释放锁。在从 wait()返回前，线程与其他线程竞争重新获得锁                        } catch (InterruptedException e) {                            e.printStackTrace();                        }                    }                    count--;                    System.out.println(Thread.currentThread().getName()+&quot;消费者消费，当前还剩下&quot;+count+&quot;个&quot;);                    LOCK.notifyAll();                }            }        }    }}</code></pre><p>对应输出如下（输出结果不确定）</p><pre><code>Thread-0生产者生产，目前总共有1Thread-0生产者生产，目前总共有2Thread-0生产者生产，目前总共有3Thread-0生产者生产，目前总共有4Thread-0生产者生产，目前总共有5PRODUCER WILL WAITING        //producer线程开始wait，阻塞在这里Thread-1消费者消费，当前还剩下4个 // 消费者线程进入Synchronized代码块PRODUCER END WAITING //消费者每次在执行完synchronized代码块都会notifyAll，所以生产者又开始竞争锁，这一次居然抢到了，于是之前的wait返回Thread-0生产者生产，目前总共有5 //发现满了，重复上面的wait步骤PRODUCER WILL WAITING  //释放锁Thread-1消费者消费，当前还剩下4个 //锁被别人抢到PRODUCER END WAITING //别人notify导致我抢到了锁Thread-0生产者生产，目前总共有5PRODUCER WILL WAITINGThread-1消费者消费，当前还剩下4个PRODUCER END WAITINGThread-0生产者生产，目前总共有5PRODUCER WILL WAITINGThread-1消费者消费，当前还剩下4个PRODUCER END WAITINGThread-0生产者生产，目前总共有5PRODUCER WILL WAITINGThread-1消费者消费，当前还剩下4个PRODUCER END WAITINGThread-0生产者生产，目前总共有5 //生产者最后一次生产Thread-1消费者消费，当前还剩下4个Thread-1消费者消费，当前还剩下3个Thread-1消费者消费，当前还剩下2个Thread-1消费者消费，当前还剩下1个Thread-1消费者消费，当前还剩下0个</code></pre><p>从代码执行顺序来看，wait方法调用后，当前线程阻塞住(虽然还在一个同步代码块中，直到别的线程notify，这个wait方法才会返回)，此时另一个线程竞争获取锁开始执行同步代码块。</p><p>synchronized对于内存可见性的影响<a href="https://javadoop.com/post/java-memory-model">java内存模型</a><br>一个线程在获取到监视器锁以后才能进入 synchronized 控制的代码块，一旦进入代码块，首先，该线程对于共享变量的缓存就会失效，因此 synchronized 代码块中对于共享变量的读取需要从主内存中重新获取，也就能获取到最新的值。<br>退出代码块的时候的，会将该线程写缓冲区中的数据刷到主内存中，所以在 synchronized 代码块之前或 synchronized 代码块中对于共享变量的操作随着该线程退出 synchronized 块，会立即对其他线程可见（这句话的前提是其他读取共享变量的线程会从主内存读取最新值）。</p><h2 id="Thread-sleep并不释放锁，只是让出cpu执行时间"><a href="#Thread-sleep并不释放锁，只是让出cpu执行时间" class="headerlink" title="Thread.sleep并不释放锁，只是让出cpu执行时间"></a>Thread.sleep并不释放锁，只是让出cpu执行时间</h2><p>Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。<br>所以在同步代码块里执行sleep是一个很糟糕的做法</p><h2 id="interrupt与线程中断"><a href="#interrupt与线程中断" class="headerlink" title="interrupt与线程中断"></a>interrupt与线程中断</h2><pre><code class="java">//中断线程（实例方法）public void Thread.interrupt();//判断线程是否被中断（实例方法）public boolean Thread.isInterrupted();//判断是否被中断并清除当前中断状态（静态方法）public static boolean Thread.interrupted();</code></pre><p>这个要背下来javadoc的描述，因为不同操作系统上的实现细节可能有差异:</p><blockquote><p> /**</p><pre><code> * Interrupts this thread. * * &lt;p&gt; Unless the current thread is interrupting itself, which is * always permitted, the {@link #checkAccess() checkAccess} method * of this thread is invoked, which may cause a {@link * SecurityException} to be thrown. * * &lt;p&gt; If this thread is blocked in an invocation of the {@link * Object#wait() wait()}, {@link Object#wait(long) wait(long)}, or {@link * Object#wait(long, int) wait(long, int)} methods of the {@link Object} * class, or of the {@link #join()}, {@link #join(long)}, {@link * #join(long, int)}, {@link #sleep(long)}, or {@link #sleep(long, int)}, * methods of this class, then its interrupt status will be cleared and it * will receive an {@link InterruptedException}. * * &lt;p&gt; If this thread is blocked in an I/O operation upon an {@link * java.nio.channels.InterruptibleChannel InterruptibleChannel} * then the channel will be closed, the thread&#39;s interrupt * status will be set, and the thread will receive a {@link * java.nio.channels.ClosedByInterruptException}. * * &lt;p&gt; If this thread is blocked in a {@link java.nio.channels.Selector} * then the thread&#39;s interrupt status will be set and it will return * immediately from the selection operation, possibly with a non-zero * value, just as if the selector&#39;s {@link * java.nio.channels.Selector#wakeup wakeup} method were invoked. * * &lt;p&gt; If none of the previous conditions hold then this thread&#39;s interrupt * status will be set. &lt;/p&gt; * * &lt;p&gt; Interrupting a thread that is not alive need not have any effect. * * @throws  SecurityException *          if the current thread cannot modify this thread * * @revised 6.0 * @spec JSR-51 */</code></pre><p>概括下来就是在wait,i/o操作，或者selector操作的中间调用线程对象的interrupt方法会抛出InterruptedException，如果不是上述三种情况之一，则将重置isInterrupted的标志位。也就意味着对于这种非阻塞的线程是不会因为interrupt方法而停下来的</p></blockquote><h2 id="yield的用法"><a href="#yield的用法" class="headerlink" title="yield的用法"></a>yield的用法</h2><p>yield是让当前线程从running的状态变成runnable的状态（不过这个方法很少用到）</p><h2 id="join的用法"><a href="#join的用法" class="headerlink" title="join的用法"></a>join的用法</h2><p>和python一样，主线程调用childThread.join()就是让主线程等子线程执行完了之后再去执行后面的语句。不过从源码来看,join调用了wait。</p><pre><code class="java">public final void join() throws InterruptedException {    join(0); //这里面调用了wait方法，也就是主线程会wait住}public synchronized void start() {    //Thread的start方法中做了相应的处理，所以当join的线程执行完成以后，会自动唤醒主线程继续往下执行}</code></pre><p><a href="https://stackoverflow.com/questions/9866193/who-and-when-notify-the-thread-wait-when-thread-join-is-called">调用join的线程总得被唤醒啊</a> stackoverflow上说是在native层面调用的notify。有人翻出来openjdk的cpp源码</p><pre><code class="cpp">void JavaThread::run() {  ...  thread_main_inner();}void JavaThread::thread_main_inner() {  ...  this-&gt;exit(false);  delete this;}void JavaThread::exit(bool destroy_vm, ExitType exit_type) {  ...  // Notify waiters on thread object. This has to be done after exit() is called  // on the thread (if the thread is the last thread in a daemon ThreadGroup the  // group should have the destroyed bit set before waiters are notified).  ensure_join(this);  ...}static void ensure_join(JavaThread* thread) {  // We do not need to grap the Threads_lock, since we are operating on ourself.  Handle threadObj(thread, thread-&gt;threadObj());  assert(threadObj.not_null(), &quot;java thread object must exist&quot;);  ObjectLocker lock(threadObj, thread);  // Ignore pending exception (ThreadDeath), since we are exiting anyway  thread-&gt;clear_pending_exception();  // Thread is exiting. So set thread_status field in  java.lang.Thread class to TERMINATED.  java_lang_Thread::set_thread_status(threadObj(), java_lang_Thread::TERMINATED);  // Clear the native thread instance - this makes isAlive return false and allows the join()  // to complete once we&#39;ve done the notify_all below  java_lang_Thread::set_thread(threadObj(), NULL);  lock.notify_all(thread);  // Ignore pending exception (ThreadDeath), since we are exiting anyway  thread-&gt;clear_pending_exception();}</code></pre><p>答案就在<br>lock.notify_all(thread);这里</p><h3 id="unsafe"><a href="#unsafe" class="headerlink" title="unsafe"></a>unsafe</h3><p>这个类的源码在sun.misc这个package下，看源码的话需要导入openjdk源码<br>和多线程相关的类是LockSupport,让一个线程休眠的方法使用的是LockSupport.park（AQS中挂起线程的就是在parkAndCheckInterrupt中使用了这个方法）调用了Unsafe.park方法（这是个native方法，c++的实现似乎是使用了pthread_mutex）</p><p><a href="http://ifeve.com/图解java并发上/">图解java并发</a></p><p><a href="https://liujiacai.net/blog/2018/12/29/how-java-synchronizer-work/">pv操作</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://tech.meituan.com/2018/11/15/java-lock.html">美团博客中关于java锁的一篇文章</a></p><p><a href="https://javadoop.com/post/AbstractQueuedSynchronizer">AQS这个java并发基础类的实现原理</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/HongKongFireworks_ZH-CN13422096721_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;主要讲讲java中的notify,wait,synchronized ，unsafe等多线程基础工具的使用方式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://haldir65.github.io/tags/java/"/>
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>iptables速查手册</title>
    <link href="https://haldir65.github.io/2019/01/29/2019-01-29-iptables-cheatsheet/"/>
    <id>https://haldir65.github.io/2019/01/29/2019-01-29-iptables-cheatsheet/</id>
    <published>2019-01-29T11:46:11.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/lidongjieya_ZH-CN9263684179_1920x1080.jpg" alt=""><br>iptables是控制linux 内核netfilter的command line frontend tool，只存在于linux平台，是system admin常用的防火墙。(虽然已经被nftables取代了，学习点网络知识还是很有必要)<br><a id="more"></a></p><p>iptables的manpage这么写的</p><blockquote><p>DESCRIPTION<br>Iptables and ip6tables are used to set up, maintain, and inspect  the  tables<br>of  IPv4 and IPv6 packet filter rules in the Linux kernel.  Several different<br>tables may be defined.  Each table contains a number of built-in  chains  and<br>may also contain user-defined chains.<br>Each  chain  is  a list of rules which can match a set of packets.  Each rule<br>specifies what to do with a packet that matches.  This is called a  `target’,<br>which may be a jump to a user-defined chain in the same table.</p></blockquote><h2 id="概念"><a href="#概念" class="headerlink" title="概念:"></a>概念:</h2><p><strong>iptables命令需要root权限执行</strong><br>每个表包含有若干个不同的链，比如 filter 表默认包含有 INPUT，FORWARD，OUTPUT 三个链。iptables有四个表，分别是：raw，nat，mangle和filter，每个表都有自己专门的用处，比如最常用filter表就是专门用来做包过滤的，而 nat 表是专门用来做NAT的。</p><h2 id="Chain"><a href="#Chain" class="headerlink" title="Chain"></a>Chain</h2><p>默认的Chain包括</p><ul><li>INPUT —&gt; 所有进入这台主机的连接</li><li>FORWARD  —&gt; 借由这台主机发出的（路由器）</li><li>OUTPUT —&gt; 所有从这台主机发出去的连接</li><li>PREROUTING / POSTROUTING</li></ul><p>每一条Chain上都有一个rules的列表(用A去append,用I去Insert)</p><h2 id="table（table是一系列针对packet的同一类决策的集合）"><a href="#table（table是一系列针对packet的同一类决策的集合）" class="headerlink" title="table（table是一系列针对packet的同一类决策的集合）"></a>table（table是一系列针对packet的同一类决策的集合）</h2><p>Mangle is to change packets (Type Of Service, Time To Live etc) on traversal.<br>Nat is to put in NAT rules.<br>Raw is to be used for marking and connection tracking.<br>Filter is for filtering packets.</p><pre><code>#~ iptables -L INPUT -n -v --line-numbersChain INPUT (policy DROP)num  target     prot opt source               destination1    DROP       all  --  202.54.1.1           0.0.0.0/02    DROP       all  --  202.54.1.2           0.0.0.0/03    ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           state NEW,ESTABLISHED</code></pre><p>执行顺序(这个比较麻烦):</p><p>iptables执行规则时，是从从规则表中从上至下顺序执行的，如果没遇到匹配的规则，就一条一条往下执行，如果遇到匹配的规则后，那么就执行本规则，执行后根据本规则的动作(accept, reject, log等)，决定下一步执行的情况。<br>比如说上面这个，拉黑了202.54.1.2虽然第三条规则说全部接受，其实202.54.1.2的包是进不来的。<br>这也是很多教程建议把自己的iptables写在后面的原因，不要把系统现有规则覆盖掉。</p><blockquote><p>iptables -L -n -v //查看已添加的iptables规则</p></blockquote><p>默认是全部接受的</p><pre><code>Chain INPUT (policy ACCEPT) ## 允许进入这台电脑target     prot opt source               destinationChain FORWARD (policy ACCEPT)  ## 路由相关target     prot opt source               destinationChain OUTPUT (policy ACCEPT) ## 允许发出这台电脑target     prot opt source               destination</code></pre><h3 id="允许所有连接"><a href="#允许所有连接" class="headerlink" title="允许所有连接"></a>允许所有连接</h3><pre><code class="bash">iptables --policy INPUT ACCEPTiptables --policy OUTPUT ACCEPTiptables --policy FORWARD ACCEPT</code></pre><p>iptables后面可以跟的参数很多</p><pre><code># iptables -t mangle -X# iptables -P INPUT ACCEPT# iptables -P OUTPUT ACCEPT# iptables -P FORWARD ACCEPT</code></pre><h3 id="来解释一下这些参数的意思"><a href="#来解释一下这些参数的意思" class="headerlink" title="来解释一下这些参数的意思"></a>来解释一下这些参数的意思</h3><pre><code>-L List rules的意思-v verbose-n numeric 不走dns，直接显示ip,这样会快一点-F flushing（删除）所有的rules-X delete chain-t table_name(一般就nat和mangle两种)-P 设置policy(比如说DROP , REJECT, REDIRECT)--line-numbers //显示每条规则所在的行号-s source iP-i interface，就是eth0这些网卡设备什么的--dport destination端口 ，比方说80LOG --log-prefix &quot;IP_SPOOF A: &quot; //加日志,这个LOG关键词和DROP,ACCEPT都差不多的，跟在-j 屁股后面-m mac --mac-source //-m 我猜是metrics ，就是说根据哪种评判标准，这里是mac地址-m state --state NEW,ESTABLISHED -j ACCEPT-p tcp protocol之类的，比方说tcp,udp,icmp(ping)等等</code></pre><p>拉黑一个ip</p><blockquote><p>iptables -I INPUT -s xxx.xxx.xxx.xxx -j DROP //这个拉黑的效果是tcp,udp,icmp全部不通。对方的curl,ping全部卡住</p></blockquote><p>DROP是直接不回话了，REJECT则是会给对方发一个 ACK/RST （这跟不回应对方是有区别的）<br>REJECT differs to DROP that it does send a packet back, but the answer is as if a server is located on the IP, but does not have the port in a listening state. IPtables will sent a RST/ACK in case of TCP or with UDP an ICMP destination port unreachable.(对方收到后，看起了就像是这台http服务器没有listen在80端口上一样)<br>在互联网的服务器上，拉黑别人一般都是用DROP，因为没必要再去通知对方已被拉黑。</p><p>取消拉黑：也就是删除上面这条规则</p><blockquote><p>iptables -D INPUT -s xxx.xxx.xxx.xxx -j DROP</p></blockquote><p>比方说我不小心把202.54.1.1拉黑了，怎么挽回</p><pre><code>iptables -L OUTPUT -n --line-numbers | grep 202.54.1.1 //发现在条规则第四行iptabels -D INPUT 4 //把这个第四行的规则删掉iptables -D INPUT -s 202.54.1.1 -j DROP //这个也是一样的</code></pre><p>只允许特定ip访问某个端口</p><blockquote><p>sudo iptables -I INPUT -p tcp ! -s 200.200.200.0/24 –destination-port 1080 -j DROP</p></blockquote><p>上面说了，iptables的顺序是从上往下match，前面的如果匹配上了，后面的就不会有机会被匹配。所以假如第2条规则说全部接受，我想拉黑某个ip，就得用-I，把拉黑的规则插入到最前面（-I 1 就是插入到第一位）:<br>iptables -I 1 INPUT -s xxx.xxx.xxx.xxx -j DROP</p><pre><code class="bash">iptables -P FORWARD DROP ## 把forward 一律改为drop（走本机代理的包全部丢掉）iptables -A INPUT -s  192.168.1.3  ## A是append s是source，拒绝接受192.168.1.3的访问，就是黑名单了iptables -A INPUT -s  192.168.0.0/24 -p tcp --destination-port 25 -j DROP  ## block all devices on this network ,  p是protocol,SMTP一般是25端口iptables -A INPUT -s 192.168.0.66 -j ACCEPT  ## 白名单iptables -D INPUT 3 ##这个3是当前INPUT链的第3条规则，就是说删掉这个chain里面的第3条规则iptables -I INPUT -s 192.168.0.66 -j ACCEPT  ## 白名单，和-A不同，A是加到尾部，I是加到list的头部，顺序很重要。iptables -I INPUT -s 123.45.6.7 -j DROP       #屏蔽单个IP的命令iptables -I INPUT -s 123.0.0.0/8 -j DROP      #封整个段即从123.0.0.1到123.255.255.254的命令iptables -I INPUT -s 124.45.0.0/16 -j DROP    #封IP段即从123.45.0.1到123.45.255.254的命令</code></pre><h3 id="public-interface（对外提供服务的网卡应该把私有的ip拉黑掉）"><a href="#public-interface（对外提供服务的网卡应该把私有的ip拉黑掉）" class="headerlink" title="public interface（对外提供服务的网卡应该把私有的ip拉黑掉）"></a>public interface（对外提供服务的网卡应该把私有的ip拉黑掉）</h3><p>//假如你的某个公共网卡专门对外服务，ip嗅探没什么的，但是下面这种私有ip号段应该禁止。non-routable source addresses的包都可以被DROP掉（就是说拒绝局域网内设备192.168.x.x就不要想着访问这台主机的eth1网卡了）</p><p>具体来说，这些都是保留的私有ip地址</p><pre><code>iptables -A INPUT -i eth1 -s 192.168.0.0/24 -j DROP10.0.0.0/8 -j (A)172.16.0.0/12 (B)192.168.0.0/16 (C)224.0.0.0/4 (MULTICAST D)240.0.0.0/5 (E)127.0.0.0/8 (LOOPBACK) // See Wikipedia and RFC5735 for full list of reserved networks.</code></pre><pre><code class="bash">#允许所有本机向外的访问iptables -A OUTPUT -j ACCEPT# 允许访问22端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT#允许访问80端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT#允许访问443端口iptables -A INPUT -p tcp --dport 443 -j ACCEPT#允许FTP服务的21和20端口iptables -A INPUT -p tcp --dport 21 -j ACCEPTiptables -A INPUT -p tcp --dport 20 -j ACCEPT#如果有其他端口的话，规则也类似，稍微修改上述语句就行#允许pingiptables -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT#禁止其他未允许的规则访问iptables -A INPUT -j REJECT  #（注意：如果22端口未加入允许规则，SSH链接会直接断开。）iptables -A FORWARD -j REJECT</code></pre><h2 id="CIDR（比如说封掉facebook-com）"><a href="#CIDR（比如说封掉facebook-com）" class="headerlink" title="CIDR（比如说封掉facebook.com）"></a>CIDR（比如说封掉facebook.com）</h2><pre><code># host -t a www.facebook.comwww.facebook.com has address 69.171.228.40# whois 69.171.228.40 | grep CIDRCIDR:           69.171.224.0/19 //就是说facebook的网端在69.171.224.0/19这个范围里# iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j DROP // 这台主机没法上facebook了# ping www.facebook.comping: sendmsg: Operation not permitted(就是被发出去的包被iptables拦下来了)//上面这堆看起来挺麻烦的iptables -A OUTPUT -p tcp -d www.facebook.com -j DROP //直接搞定,但是不推荐这么干</code></pre><h3 id="根据某个mac地址指定"><a href="#根据某个mac地址指定" class="headerlink" title="根据某个mac地址指定"></a>根据某个mac地址指定</h3><pre><code># iptables -I INPUT -m mac --mac-source 3E:D7:88:A6:66:8E -j ACCEPT# iptables -I INPUT -p tcp --dport 22 -m mac --mac-source 3E:D7:88:A6:66:8E -j ACCEPT# iptables -I INPUT -p tcp --dport 22 -m mac --mac-source 3E:D7:88:A6:66:8E -j REJECT# iptables -I INPUT -p tcp --port 22 -m mac ! --mac-source 3E:D7:88:A6:66:8E -j REJECT //除了特定mac以外都不允许访问# iptables -A INPUT -m mac --mac-source 00:0F:EA:91:04:08 -j DROP</code></pre><h3 id="不允许别人ping我"><a href="#不允许别人ping我" class="headerlink" title="不允许别人ping我"></a>不允许别人ping我</h3><pre><code># iptables -A INPUT -p icmp --icmp-type echo-request -j DROP# iptables -A INPUT -i eth1 -p icmp --icmp-type echo-request -j DROPiptables -A INPUT -s 192.168.1.0/24 -p icmp --icmp-type echo-request -j ACCEPT### ** assumed that default INPUT policy set to DROP ** #############iptables -A INPUT -p icmp --icmp-type echo-reply -j ACCEPTiptables -A INPUT -p icmp --icmp-type destination-unreachable -j ACCEPTiptables -A INPUT -p icmp --icmp-type time-exceeded -j ACCEPT## ** all our server to respond to pings ** ##iptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPT</code></pre><h2 id="打log"><a href="#打log" class="headerlink" title="打log"></a>打log</h2><p>先照上面的做法把facebook给封了（所有发到facebook的包全部drop，只是我们这一次想要看日志）</p><pre><code>iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j LOG --log-prefix &quot;IP_SPOOF A: &quot;iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j DROP 我们可以简单地使用下面的命令启用iptables的日志记录。$ iptables -A INPUT -j LOG我们还可以定义哪些日志将被创建的源IP或范围。$ iptables -A INPUT -s 192.168.10.0/24 -j LOG定义我们的iptables -log 生成的日志级别。$ iptables -A INPUT -s 192.168.10.0/24 -j LOG --log-level 4我们还可以添加一些前缀生成的日志，所以它会很容易在一个巨大的文件中搜索日志。$ iptables -A INPUT -s 192.168.10.0/24 -j LOG --log-prefix &#39;** SUSPECT **&#39;</code></pre><p>在Ubuntu和Debian<br>iptables的日志由内核生成的。因此，检查以下内核日志文件。<br>查看iptables的日志<br>$ tailf /var/log/kern.log</p><h3 id="只开7000-7010端口-只允许某个网段的ip发请求"><a href="#只开7000-7010端口-只允许某个网段的ip发请求" class="headerlink" title="只开7000-7010端口,只允许某个网段的ip发请求"></a>只开7000-7010端口,只允许某个网段的ip发请求</h3><pre><code>iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 7000:7010 -j ACCEPT## only accept connection to tcp port 80 (Apache) if ip is between 192.168.1.100 and 192.168.1.200 ##iptables -A INPUT -p tcp --destination-port 80 -m iprange --src-range 192.168.1.100-192.168.1.200 -j ACCEPT## nat example ##iptables -t nat -A POSTROUTING -j SNAT --to-source 192.168.1.20-192.168.1.25Replace ACCEPT with DROP to block port:## open port ssh tcp port 22 ##iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 22 -j ACCEPT## open cups (printing service) udp/tcp port 631 for LAN users ##iptables -A INPUT -s 192.168.1.0/24 -p udp -m udp --dport 631 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -p tcp -m tcp --dport 631 -j ACCEPT## allow time sync via NTP for lan users (open udp port 123) ##iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p udp --dport 123 -j ACCEPT## open tcp port 25 (smtp) for all ##iptables -A INPUT -m state --state NEW -p tcp --dport 25 -j ACCEPT# open dns server ports for all ##iptables -A INPUT -m state --state NEW -p udp --dport 53 -j ACCEPTiptables -A INPUT -m state --state NEW -p tcp --dport 53 -j ACCEPT## open http/https (Apache) server port to all ##iptables -A INPUT -m state --state NEW -p tcp --dport 80 -j ACCEPTiptables -A INPUT -m state --state NEW -p tcp --dport 443 -j ACCEPT## open tcp port 110 (pop3) for all ##iptables -A INPUT -m state --state NEW -p tcp --dport 110 -j ACCEPT## open tcp port 143 (imap) for all ##iptables -A INPUT -m state --state NEW -p tcp --dport 143 -j ACCEPT## open access to Samba file server for lan users only ##iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 137 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 138 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 139 -j ACCEPTiptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 445 -j ACCEPT## open access to proxy server for lan users only ##iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 3128 -j ACCEPT## open access to mysql server for lan users only ##iptables -I INPUT -p tcp --dport 3306 -j ACCEPT</code></pre><h3 id="限制最大连接数"><a href="#限制最大连接数" class="headerlink" title="限制最大连接数"></a>限制最大连接数</h3><pre><code>To allow 3 ssh connections per client host, enter:(一个client最多能够连3个ssh连接过来)# iptables -A INPUT -p tcp --syn --dport 22 -m connlimit --connlimit-above 3 -j REJECThttp端口一个client最多20个连接# iptables -p tcp --syn --dport 80 -m connlimit --connlimit-above 20 --connlimit-mask 24 -j DROP</code></pre><h3 id="使用iptables阻止syn-flood"><a href="#使用iptables阻止syn-flood" class="headerlink" title="使用iptables阻止syn-flood"></a>使用iptables阻止syn-flood</h3><p>一般在路由器里面都有这么一条</p><pre><code>iptables -N syn-floodiptables -A syn-flood -m limit --limit 50/s --limit-burst 10 -j RETURNiptables -A syn-flood -j DROPiptables -I INPUT -j syn-flood</code></pre><pre><code>-N 创建一个条新的链--limit 50/s 表示每秒50次;1/m 则为每分钟一次--limit-burst 表示允许触发 limit 限制的最大包个数 (预设5)，它就像是一个容器，最多装10个，超过10个就装不下了，这些包就给后面的规则了-I INPUT -j syn-flood  把INPUT的包交给syn-flood链处理这里的--limit-burst=10相当于说最开始有10个可以匹配的包去转发，然后匹配的包的个数是根据--limit=50/s进行限制的，也就是每秒限制转发50个数据包，多余的会被下面符合要求的DROP规则去处理，进行丢弃，这样就实现了对数据包的限速问题。</code></pre><h2 id="现在来看看fail2ban是怎么拉黑一个ip的"><a href="#现在来看看fail2ban是怎么拉黑一个ip的" class="headerlink" title="现在来看看fail2ban是怎么拉黑一个ip的"></a>现在来看看fail2ban是怎么拉黑一个ip的</h2><p>一般来说要拒绝一个ip访问http,https可以这么干</p><pre><code>iptables -L INPUT -s xxx.xxx.xxx.xxx -p tcp --dport 80 -j DROPiptables -L INPUT -s xxx.xxx.xxx.xxx -p tcp --dport 443 -j DROP而事实上就是创建了一个action~ cat /etc/fail2ban/action.d/iptables.conf# Option:  actionban# Notes.:  command executed when banning an IP. Take care that the#          command is executed with Fail2Ban user rights.# Tags:    See jail.conf(5) man page# Values:  CMD#actionban = &lt;iptables&gt; -I f2b-&lt;name&gt; 1 -s &lt;ip&gt; -j &lt;blocktype&gt;</code></pre><h2 id="REDIRECT-透明代理"><a href="#REDIRECT-透明代理" class="headerlink" title="REDIRECT (透明代理)"></a>REDIRECT (透明代理)</h2><p>首先来看一个把所有走网卡eth0的数据包都转发到redSocks的规则</p><pre><code>// 新建路由转发表中的一个链 REDSOCKSsudo iptables -t nat -N REDSOCKS// 设置不需要代理转发的网段// 目的为墙外代理服务器的数据包一定不能转发sudo iptables -t nat -A REDSOCKS -d $SS_SERVER_IP -j RETURN// 目的为局域网和本地回环地址的数据包不用转发sudo iptables -t nat -A REDSOCKS -d 172.0.0.0/24 -j RETURNsudo iptables -t nat -A REDSOCKS -d 192.168.0.0/16 -j RETURN// 将数据包转发到 redsockssudo iptables -t nat -A REDSOCKS -p tcp -j REDIRECT --to-ports 12345// 将 REDSOCKS 链的规则应用到经过 eth0 网卡的数据包sudo iptables -t nat -A OUTPUT -p tcp -o eth0 -j REDSOCKS</code></pre><p>经常会看到教程如何把一台局域网linux nas或者虚拟机变成软路由的教程，首先需要设备开启ip转发</p><pre><code>cat /proc/sys/net/ipv4/ip_forward1 // 这个值默认是0</code></pre><p>比方说把所有incoming 流量(目标端口是80的)导向8080端口</p><pre><code>iptables -t nat -I PREROUTING --src 0/0 --dst 192.168.1.5 -p tcp --dport 80 -j REDIRECT --to-ports 8080</code></pre><p>然后根据v2ray的配置文件设置透明代理。<br>再接下来把所有nat表上的流量交给v2ray监听的端口</p><pre><code>openwrt在/etc/firewall.user中添加如下脚本，实现本地透明代理（其实并不完美）```shiptables -t nat -N V2RAY //在nat这个表里面创建一个V2RAY的chainiptables -t nat -A V2RAY -d x.x.x.x -j RETURN ##xxx是vps的ip地址iptables -t nat -A V2RAY -d 0.0.0.0/8 -j RETURNiptables -t nat -A V2RAY -d 10.0.0.0/8 -j RETURNiptables -t nat -A V2RAY -d 127.0.0.0/8 -j RETURNiptables -t nat -A V2RAY -d 169.254.0.0/16 -j RETURNiptables -t nat -A V2RAY -d 172.16.0.0/12 -j RETURNiptables -t nat -A V2RAY -d 192.168.0.0/16 -j RETURNiptables -t nat -A V2RAY -d 224.0.0.0/4 -j RETURNiptables -t nat -A V2RAY -d 240.0.0.0/4 -j RETURNiptables -t nat -A V2RAY -p tcp -j REDIRECT --to-ports 1060iptables -t nat -A PREROUTING -p tcp -j V2RAY//下面是把所有的udp包导到1080端口，为什么这么写我不知道ip rule add fwmark 1 table 100ip route add local 0.0.0.0/0 dev lo table 100iptables -t mangle -N V2RAY_MASKiptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -j RETURNiptables -t mangle -A V2RAY_MASK -p udp -j TPROXY --on-port 1080 --tproxy-mark 1iptables -t mangle -A PREROUTING -p udp -j V2RAY_MASK</code></pre><p><strong>亲测，透明代理的效果是可以的。只是比不上在windows上的速度,cpu占用达到50%以上，没什么意思。</strong></p><p>相比起来,shadowsocks-libev给出了这样一份transparent proxy的代码，更加清楚</p><pre><code># Create new chainiptables -t nat -N SHADOWSOCKSiptables -t mangle -N SHADOWSOCKS# Ignore your shadowsocks server&#39;s addresses# It&#39;s very IMPORTANT, just be careful.iptables -t nat -A SHADOWSOCKS -d 123.123.123.123 -j RETURN# Ignore LANs and any other addresses you&#39;d like to bypass the proxy# See Wikipedia and RFC5735 for full list of reserved networks.# See ashi009/bestroutetb for a highly optimized CHN route list.iptables -t nat -A SHADOWSOCKS -d 0.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 10.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 127.0.0.0/8 -j RETURNiptables -t nat -A SHADOWSOCKS -d 169.254.0.0/16 -j RETURNiptables -t nat -A SHADOWSOCKS -d 172.16.0.0/12 -j RETURNiptables -t nat -A SHADOWSOCKS -d 192.168.0.0/16 -j RETURNiptables -t nat -A SHADOWSOCKS -d 224.0.0.0/4 -j RETURNiptables -t nat -A SHADOWSOCKS -d 240.0.0.0/4 -j RETURN# Anything else should be redirected to shadowsocks&#39;s local portiptables -t nat -A SHADOWSOCKS -p tcp -j REDIRECT --to-ports 12345# Add any UDP rulesip route add local default dev lo table 100ip rule add fwmark 1 lookup 100iptables -t mangle -A SHADOWSOCKS -p udp --dport 53 -j TPROXY --on-port 12345 --tproxy-mark 0x01/0x01# Apply the rulesiptables -t nat -A PREROUTING -p tcp -j SHADOWSOCKSiptables -t mangle -A PREROUTING -j SHADOWSOCKS# Start the shadowsocks-redirss-redir -u -c /etc/config/shadowsocks.json -f /var/run/shadowsocks.pid</code></pre><p>代理的原理:参考<a href="https://paper.tuisec.win/detail/4f9d95db284d609">ss/ssr/v2ray/socks5 透明代理</a>里面的解释</p><blockquote><p>ss-redir 是 ss-libev、ssr-libev 中的一个工具，配合 iptables 可以在 Linux 上实现 ss、ssr 透明代理，ss-redir 的透明代理是通过 DNAT 实现的，但是 udp 包在经过 DNAT 后会无法获取原目的地址，所以 ss-redir 无法代理经过 DNAT 的 udp 包；但是 ss-redir 提供了另一种 udp 透明代理方式：xt_TPROXY 内核模块（不涉及 NAT 操作），配合 iproute2 即可实现 udp 的透明代理，但缺点是只能代理来自内网主机的 udp 流量。强调一点，利用 ss-redir 实现透明代理必须使用 ss-libev 或 ssr-libev，python、go 等实现版本没有 ss-redir、ss-tunnel 程序。当然，ss、ssr 透明代理并不是只能用 ss-redir 来实现，使用 ss-local + redsocks/tun2socks 同样可以实现 socks5（ss-local 是 socks5 服务器）全局透明代理，ss-local + redsocks 实际上是 ss-redir 的分体实现，都是通过 NAT 进行代理的，因此也不能代理本机的 udp，当然内网的 udp 也不能代理，因为 redsocks 不支持 xt_TPROXY 方式（redsocks2 支持 TPROXY 模块，但是依旧无法代理本机 udp，不考虑）。所以这里只讨论 ss-local + tun2socks，这个组合方式其实和 Android 上的 VPN 模式差不多（ss-redir 或 ss-local + redsocks 则是 NAT 模式），因为不涉及 NAT 操作，所以能够代理所有 tcp、udp 流量（包括本机、内网的 udp）。很显然，利用 tun2socks 可以实现任意 socks5 透明代理（不只是 ss/ssr，ssh、v2ray 都可以，只要能提供 socks5 本地代理）。最后再说一下 v2ray 的透明代理，其实原理和 ss/ssr-libev 一样，v2ray 可以看作是 ss-local、ss-redir、ss-tunnel 三者的合体，因为一个 v2ray 客户端可以同时充当这三个角色（当然端口要不一样）；所以 v2ray 的透明代理也有两种实现方式，一是利用对应的 ss-redir/ss-tunnel + iptables，二是利用对应的 ss-local + tun2socks（这其实就是前面说的 socks5 代理）。</p></blockquote><p>shell中全局的http代理可以这么设置</p><pre><code>export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy//如果是socks5协议的话可以改一下export http_proxy=socks5://127.0.0.1:8118; export https_proxy=$http_proxy//只对当前shell有效</code></pre><p>接下来，git、curl、wget 等命令会自动从环境变量中读取 http 代理信息，然后通过 http 代理连接目的服务器。但有些软件是不认这个的。<br>那问题来了，ss-local 提供的是 socks5 代理，不能直接使用怎么办？也简单，Linux 中有很多将 socks5 包装为 http 代理的工具，比如 privoxy。只需要在 /etc/privoxy/config 里面添加一行 forward-socks5 / 127.0.0.1:1080 .，启动 privoxy，默认监听 127.0.0.1:8118 端口，注意别搞混了，8118 是 privoxy 提供的 http 代理地址，而 1080 是 ss-local 提供的 socks5 代理地址，发往 8118 端口的数据会被 privoxy 处理并转发给 ss-local。所以我们现在可以执行 export http_proxy=<a href="http://127.0.0.1:8118">http://127.0.0.1:8118</a>; export https_proxy=$http_proxy 来配置当前终端的 http 代理，这样 git、curl、wget 这些就会自动走 ss-local 出去了。</p><blockquote><p>Often, services on the computer communicate with each other by sending network packets to each other. They do this by utilizing a pseudo network interface called the loopback device, which directs traffic back to itself rather than to other computers.<br>同一台机器的不同进程之间有时候是通过一个虚拟的网络(loopback device)进行通信的，所以，必须要让iptables允许这些通信<br>$ sudo iptables -I INPUT 1 -i lo -j ACCEPT // -I的意思是插入，就是插入到INPUT这个规则里面。 1是说插到第一位，因为iptables排在前面的优先级高。 -i是interface的意思，lo就是loopback的简称。（也就是说，所有使用本地loopback这个interface发过来的包，放行）</p></blockquote><p><strong>注意还需要将上述规则添加到开机启动中，想要持久化的话好像有一个iptables-persistent</strong>，还有使用iptables屏蔽来自<a href="https://www.vpser.net/security/iptables-block-countries-ip.html">某个国家的IP</a>的教程</p><h3 id="透明代理的实现"><a href="#透明代理的实现" class="headerlink" title="透明代理的实现"></a>透明代理的实现</h3><p><a href="https://github.com/shadowsocks/luci-app-shadowsocks">ss-liibev的openwrt移植就是这么干的</a><br>在ss-rules(其实就是一个shell脚本)中</p><pre><code class="bash">ipset -! restore create ss_spec_src_fw hash:ip hashsize 64iptables-restore -n &lt;&lt;-EOFnat-A SS_SPEC_LAN_AC -m set --match-set ss_spec_src_fw src -j SS_SPEC_WAN_FW-A SS_SPEC_WAN_AC -m set --match-set ss_spec_dst_fw dst -j SS_SPEC_WAN_FWEOF## 这个EOF主要为了方便换行，match src是gfwlist的转到SS_SPEC_WAN_FW这个chain上(外面的流量进来)，dst是gfwlist的也转到这个chain上。## 而这个chain 只干了一件事 REDIRECT   tcp  --  anywhere             anywhere             redir ports 1080(比方说local ss-redir监听在这个端口的话)iptables -t nat -A SS_SPEC_WAN_FW -p tcp \        -j REDIRECT --to-ports $local_port //tcp流量导向ss-redir本地监听端口iptables -t mangle -A SS_SPEC_WAN_FW -p udp \        -j TPROXY --on-port $LOCAL_PORT --tproxy-mark 0x01/0x01   //udp转发    </code></pre><p><a href="https://vvl.me/2018/06/09/from-ss-redir-to-linux-nat/">UDP 透明代理是通过 TPROXY 方式实现的</a> TPROXY是LINUX内核为支持透明代理而提供的一项新技术。<br>所以在部署了ss-libev-luci的路由器上iptables -t nat -L 都能看到这些东西。事实上在iptables没有看到udp的影子，使用的是TPROXY。<br>ss-redir的原理很简单：使用iptables对PREROUTING与OUTPUT的TCP/UDP流量进行REDIRECT（REDIRECT是DNAT的特例），ss—redir在捕获网络流量后，通过一些技术手段获取REDIRECT之前的目的地址（dst）与端口（port），连同网络流量一起转发至远程服务器。<br>为了在redirect UDP后还能够获取原本的dst和port，ss-redir采用了TPROXY。Linux系统有关TPROXY的设置是以下三条命令：</p><pre><code>ip rule add fwmark 0x2333/0x2333 pref 100 table 100ip route add local default dev lo table 100iptables -t mangle -A PREROUTING -p udp -j TPROXY --tproxy-mark 0x2333/0x2333 --on-ip 127.0.0.1 --on-port 1080</code></pre><p>大意就是在mangle表的PREROUTING中为每个UDP数据包打上0x2333/0x2333标志，之后在路由选择中将具有0x2333/0x2333标志的数据包投递到本地环回设备上的1080端口；对监听0.0.0.0地址的1080端口的socket启用IP_TRANSPARENT标志，使IPv4路由能够将非本机的数据报投递到传输层，传递给监听1080端口的ss-redir。</p><h3 id="ipset的语法"><a href="#ipset的语法" class="headerlink" title="ipset的语法"></a>ipset的语法</h3><p>就是一大堆ip的一个集合，但是存的是hash。 iptables的参数可以传 -m –match-set</p><p>netfilter是kernel的实现</p><blockquote><p>Iptables is a standard firewall included in most Linux distributions by default (a modern variant called nftables will begin to replace it). It is actually a front end to the kernel-level netfilter hooks that can manipulate the Linux network stack.</p></blockquote><p>iptables的工作流程</p><blockquote><p>direct the packet to the appropriate chain, check it against each rule until one matches, issue the default policy of the chain if no match is found</p></blockquote><p><a href="https://www.digitalocean.com/community/tutorials/a-deep-dive-into-iptables-and-netfilter-architecture">a-deep-dive-into-iptables-and-netfilter-architecture</a></p><p><a href="https://unix.stackexchange.com/questions/413545/what-does-iptables-j-redirect-actually-do-to-packet-headers">iptable在透明代理中的原理就是修改了packet的destination address，同时还记住了原来的address</a></p><blockquote><p>iptables overwrites the original destination address but it remembers the old one. The application code can then fetch it by asking for a special socket option, SO_ORIGINAL_DST<br><a href="https://github.com/darkk/redsocks">著名tcp代理redsocks就是用SO_ORIGINAL_DST的</a></p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cyberciti.biz/tips/linux-iptables-examples.html">linux-iptables-examples</a><br><a href="https://blog.dreamtobe.cn/r7800-openwrt-v2ray/">网件R7800 OpenWrt使用V2Ray+mKcp+透明代理完美翻墙</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/lidongjieya_ZH-CN9263684179_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;iptables是控制linux 内核netfilter的command line frontend tool，只存在于linux平台，是system admin常用的防火墙。(虽然已经被nftables取代了，学习点网络知识还是很有必要)&lt;br&gt;
    
    </summary>
    
    
      <category term="tools" scheme="https://haldir65.github.io/tags/tools/"/>
    
      <category term="linux" scheme="https://haldir65.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>原始套接字学习指南</title>
    <link href="https://haldir65.github.io/2019/01/19/2019-01-19-learning-from-raw-socket/"/>
    <id>https://haldir65.github.io/2019/01/19/2019-01-19-learning-from-raw-socket/</id>
    <published>2019-01-19T22:20:35.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://www.haldir66.ga/static/imgs/SunFlowersStorm_EN-AU8863925685_1920x1080.jpg" alt=""><br>从原始套接字 SOCK_RAW学习到的知识<br><a id="more"></a></p><p>以下图片盗自<a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">chinaunix一篇讲解raw socket的文章</a>，感谢原作者的辛勤工作。复习一下ip包的结构。</p><ul><li><h3 id="这是IP-packet"><a href="#这是IP-packet" class="headerlink" title="这是IP packet"></a>这是IP packet</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-1.jpg" alt=""></p></li><li><h3 id="这是TCP-header"><a href="#这是TCP-header" class="headerlink" title="这是TCP header"></a>这是TCP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-2.jpg" alt=""></p></li><li><h3 id="这是IP-header"><a href="#这是IP-header" class="headerlink" title="这是IP header"></a>这是IP header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-3.jpg" alt=""></p></li><li><h3 id="这是mac-header"><a href="#这是mac-header" class="headerlink" title="这是mac header"></a>这是mac header</h3><p><img src="https://www.haldir66.ga/static/imgs/2019-01-19-4.jpg" alt=""></p></li></ul><p>从内核代码来看，这些分别对应ethhdr、iphdr、tcphdr、udphdr等结构体。</p><p>一般来讲，应用层程序的数据都是在tcp或者udp的data中的，实际发送过程中，内核会帮忙添加上tcp header，ip header以及mac header等数据，开发者无需关心也无从干涉。raw socket为我们提供了直接读写这块数据的方法。</p><p>C语言中raw socket的创建方式为:</p><blockquote><p>socket(AF_INET, SOCK_RAW, protocol); //需要root权限</p></blockquote><p>raw socket一般用于网络监测程序中比较多，比如ping , nmap这种。这类协议是没有端口的。</p><p>另一种场景是伪造tcp header应对运营商udp屏蔽和流量qos，这种类似的实现在2017年出来的比较多。(就是用一个raw socket把一个udp包伪装成一个tcp包)。</p><p>接下来这个例子是使用raw socket监听server端收到的ip packet包内容<br>server.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;linux/if_ether.h&gt;#include &lt;stdlib.h&gt;#include &lt;arpa/inet.h&gt;int main(){     printf(&quot;main is running\n&quot;);int iSock, nRead, iProtocol;        char buffer[4096] = {0};char  *ethhead, *iphead, *tcphead, *udphead, *icmphead, *p;if((iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP))) &lt; 0){    printf(&quot;create iSocket error, check root\n&quot;);  // 需要root权限， 最后运行的时候， 可以用sudo ./server    return 1;}while(1) {    nRead = recvfrom(iSock, buffer, 2048, 0, NULL, NULL);      /*        以太网帧头 14        ip头       20        udp头      8        总共42字节(最少)    */    if(nRead &lt; 42)     {        printf(&quot;packet error\n&quot;);        continue;    }    int n = 0XFF;    char szVisBuf[1024] = {0};    for(unsigned int i = 0; i &lt; nRead; ++i)    {        char szTmp[3] = {0};        sprintf(szTmp, &quot;%02x&quot;, buffer[i]&amp;n);        strcat(szVisBuf, szTmp);    }    ethhead = buffer;    p = ethhead;    iphead = ethhead + 14;      p = iphead + 12;    char szIps[128] = {0};    snprintf(szIps, sizeof(szIps), &quot;IP: %d.%d.%d.%d =&gt; %d.%d.%d.%d&quot;,        p[0]&amp;n, p[1]&amp;n, p[2]&amp;n, p[3]&amp;n,        p[4]&amp;n, p[5]&amp;n, p[6]&amp;n, p[7]&amp;n);    iProtocol = (iphead + 9)[0];    p = iphead + 20;    unsigned int iDstPort = (p[2]&lt;&lt;8)&amp;0xff00 | p[3]&amp;n;    switch(iProtocol)    {        case IPPROTO_UDP :             if(iDstPort == 8888)            {                printf(&quot;source port: %u,&quot;,(p[0]&lt;&lt;8)&amp;0xff00 |  p[1]&amp;n);                printf(&quot;dest port: %u\n&quot;, iDstPort);                printf(&quot;%s\n&quot;, szIps);                    printf(&quot;%s\n&quot;, szVisBuf);                printf(&quot;nRead is %d\n&quot;, nRead);                }            break;        case IPPROTO_RAW :             printf(&quot;raw\n&quot;);            break;        default:            break;    }}}</code></pre><p>client.c</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;unistd.h&gt;int main(){    struct sockaddr_in srvAddr;    bzero(&amp;srvAddr, sizeof(srvAddr));    srvAddr.sin_family = AF_INET;    srvAddr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;);    srvAddr.sin_port = htons(8888);    int iSock = socket(AF_INET, SOCK_DGRAM, 0); // udp    int i = 0;    while(1)    {        printf(&quot;press enter to send data\n&quot;);        while (( i = getchar()) != &#39;\n&#39;){            char szBuf[32] = {0};            snprintf(szBuf, sizeof(szBuf), &quot;hello %d&quot;, ++i);            sendto(iSock, szBuf, strlen(szBuf) + 1, 0, (struct sockaddr *)&amp;srvAddr, sizeof(srvAddr));        }    }    close(iSock);    return 0;}</code></pre><p>从raw socket 接受过来的buffer 的地址是数据链路层的地址，具体我们获取的东西就是通过偏移量来，这个偏移量我们需要查看网络书或者抓个包分析下链路层的数据格式等等。<br>client很简单，就是一个udp发包到localhost，关键在于server这边：</p><blockquote><p>iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP)</p></blockquote><p>这个socket能够监听本机接收到的所有ip packet，接收到的数据帧的头6个字节是目的地的MAC地址，紧接着6个字节是源MAC地址 , 如果是udp或者tcp的话，还能读取到port。也就是一些常用抓包工具的实现原理。</p><p>所以可以写一个简单的抓包工具，将那些发给本机的IPV4报文全部打印出来。</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;netinet/if_ether.h&gt;int main(int argc, char **argv){int sock, n;char buffer[2048];struct ethhdr *eth;struct iphdr *iph;if (0 &gt; (sock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP)))) {    perror(&quot;socket&quot;);    exit(1);}while (1) {    printf(&quot;=====================================\n&quot;);    //注意：在这之前我没有调用bind函数，raw socket这一层已经不存在port的概念了    n = recvfrom(sock, buffer, 2048, 0, NULL, NULL);    printf(&quot;%d bytes read\n&quot;, n);    //接收到的数据帧头6字节是目的MAC地址，紧接着6字节是源MAC地址。    eth = (struct ethhdr*)buffer;    printf(&quot;Dest MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\n&quot;,eth-&gt;h_dest[0],eth-&gt;h_dest[1],eth-&gt;h_dest[2],eth-&gt;h_dest[3],eth-&gt;h_dest[4],eth-&gt;h_dest[5]);    printf(&quot;Source MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\n&quot;,eth-&gt;h_source[0],eth-&gt;h_source[1],eth-&gt;h_source[2],eth-&gt;h_source[3],eth-&gt;h_source[4],eth-&gt;h_source[5]);    iph = (struct iphdr*)(buffer + sizeof(struct ethhdr));    //我们只对IPV4且没有选项字段的IPv4报文感兴趣    if(iph-&gt;version == 4 &amp;&amp; iph-&gt;ihl == 5){    unsigned char *sd, *dd;    sd = (unsigned char*)&amp;iph-&gt;saddr;    dd = (unsigned char*)&amp;iph-&gt;daddr;    printf(&quot;Source Host: %d.%d.%d.%d Dest host: %d.%d.%d.%d\n&quot;, sd[0], sd[1], sd[2], sd[3], dd[0], dd[1], dd[2], dd[3]);    //    printf(&quot;Source host:%s\n&quot;, inet_ntoa(iph-&gt;saddr));    //    printf(&quot;Dest host:%s\n&quot;, inet_ntoa(iph-&gt;daddr));    }}return 0;}</code></pre><p>顺便提一下，一般我们在Linux机器上是可以查看到当前系统对应的内核的头文件的</p><blockquote><p> root][~]# grep -n ‘ethhdr’ /usr/include/linux/if_ether.h<br>107:struct ethhdr {<br>[root][~]#<br>[root][~]# grep -n ‘iphdr’ /usr/include/linux/*<br>/usr/include/linux/if_tunnel.h:32:      struct iphdr            iph;<br>/usr/include/linux/ip.h:85:struct iphdr {</p></blockquote><p><a href="http://abcdxyzk.github.io/blog/2015/04/14/kernel-net-sock-raw/">从raw socket介绍中学到的东西</a></p><blockquote><p>接下来我们简单介绍一下网卡是怎么收报的，如果你对这部分已经很了解可以跳过这部分内容。网卡从线路上收到信号流，网卡的驱动程序会去检查数据帧开始的前6个字节，即目的主机的MAC地址，如果和自己的网卡地址一致它才会接收这个帧，不符合的一般都是直接无视。然后该数据帧会被网络驱动程序分解，IP报文将通过网络协议栈，最后传送到应用程序那里。往上层传递的过程就是一个校验和“剥头”的过程，由协议栈各层去实现。</p></blockquote><p>setsockopt (packet_send_sd, IPPROTO_IP, IP_HDRINCL, val, sizeof (one)) // IP_HDRINCL to tell the kernel that headers are included in the packet<br>这样设置告诉内核，ip packet的header将由我们自己添加，所以最终发送出去的内容需要完全由自己决定。</p><p>为了将一个udp包伪装成tcp包，需要一个SOCK_RAW的socket</p><blockquote><p>socket(AF_INET , SOCK_RAW , IPPROTO_TCP)</p></blockquote><p>接下来就是自己组装tcp包结构，tbd(这个不同的网卡的值是不一样的，最简单的就是抓包就可以了)</p><h2 id="python也提供了对应rawsocket的api"><a href="#python也提供了对应rawsocket的api" class="headerlink" title="python也提供了对应rawsocket的api"></a>python也提供了对应rawsocket的api</h2><blockquote><p> socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_TCP)</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.chionlab.moe/2017/04/06/kcptun-with-fake-tcp/">kcptun-raw：应对UDP QoS，重新实现kcptun的一次尝试</a><br><a href="https://github.com/linhua55/some_kcptun_tools">some_kcptun_tools</a><br><a href="https://github.com/Chion82/kcptun-raw">kcptun-raw</a><br><a href="https://coolshell.cn/articles/11609.html">tcp那些事</a> tcp协议为了对外实现可靠交付，内部实现有很多非常复杂的算法。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/SunFlowersStorm_EN-AU8863925685_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;从原始套接字 SOCK_RAW学习到的知识&lt;br&gt;
    
    </summary>
    
    
      <category term="c" scheme="https://haldir65.github.io/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>操作系统原理</title>
    <link href="https://haldir65.github.io/2019/01/10/2019-01-10-operating-system-related-topics/"/>
    <id>https://haldir65.github.io/2019/01/10/2019-01-10-operating-system-related-topics/</id>
    <published>2019-01-10T22:32:11.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>操作系统原理的一些记录<br><img src="https://www.haldir66.ga/static/imgs/SouthMoravian_ZH-CN13384331455_1920x1080.jpg" alt=""><br><a id="more"></a></p><h2 id="操作系统是如何做好断电保护的？"><a href="#操作系统是如何做好断电保护的？" class="headerlink" title="操作系统是如何做好断电保护的？"></a>操作系统是如何做好断电保护的？</h2><p>日志文件系统（journaling file system）是一个具有故障恢复能力的文件系统，在这个文件系统中，因为对目录以及位图的更新信息总是在原始的磁盘日志被更新之前写到磁盘上的一个连续的日志上，所以它保证了数据的完整性。当发生系统错误时，一个全日志文件系统将会保证磁盘上的数据恢复到发生系统崩溃前的状态。同时，它还将覆盖未保存的数据，并将其存在如果计算机没有崩溃的话这些数据可能已经遗失的位置，这是对关键业务应用来说的一个很重要的特性。</p><h2 id="内存中段和分页的语义是什么"><a href="#内存中段和分页的语义是什么" class="headerlink" title="内存中段和分页的语义是什么"></a>内存中段和分页的语义是什么</h2><p><a href="https://www.cnblogs.com/gtarcoder/articles/5278074.html">为什么用户态和内核态的切换耗费时间</a><br><a href="https://www.cnblogs.com/bakari/p/5520860.html">用户态与内核态</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.cnblogs.com/huxiao-tee/p/4657851.html">从内核文件系统看文件读写过程</a><br><a href="https://blog.csdn.net/ITer_ZC/column/info/computer-os-network">计算机底层知识拾遗</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;操作系统原理的一些记录&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/SouthMoravian_ZH-CN13384331455_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
  <entry>
    <title>java nio使用指南</title>
    <link href="https://haldir65.github.io/2019/01/10/2019-01-10-java-nio-intro/"/>
    <id>https://haldir65.github.io/2019/01/10/2019-01-10-java-nio-intro/</id>
    <published>2019-01-10T22:25:50.000Z</published>
    <updated>2019-08-12T11:39:32.326Z</updated>
    
    <content type="html"><![CDATA[<p>关于java nio的一些点<br><img src="https://www.haldir66.ga/static/imgs/UmbriaCastelluccio_EN-AU8834990889_1920x1080.jpg" alt=""><br><a id="more"></a></p><p><a href="https://zhuanlan.zhihu.com/p/27625923">本文大多数内容来自知乎专栏</a>的复制粘贴，因为别人写的比我好</p><h3 id="nio及DirectByteBuffer相关操作"><a href="#nio及DirectByteBuffer相关操作" class="headerlink" title="nio及DirectByteBuffer相关操作"></a>nio及DirectByteBuffer相关操作</h3><p>nio包含了很多东西，核心的应该是selector<br>DirectBuffer这个东西很容易讲，一句话就能说清楚：这是一块在Java堆外分配的，可以在Java程序中访问的内存。<br>先来解释一下几个堆是什么。以32位系统为例（64位系统也是一样的，只是地址空间更大而已，写起来没有32位系统看上去那么简洁），操作系统会为一个进程提供4G的地址空间，换句话说，一个进程可用的内存是4G。在Linux上，又为内核空间留了1G，剩下的3G是可以供用户使用的(粗略来看是这样的)。这1G就叫做内核空间，3G被称为用户空间。<br>一个java进程下不过对于操作系统而言，肯定是一个用户进程。所以jva也就有了这3G的使用权。jvm想要使用这些内存的时候，会使用malloc方法去找操作系统去要（其实中间还隔了一个C runtime，我们不去管这个细节，只把malloc往下都看成是操作系统的功能，并不会带来太大的问题）<br>而JVM要来的这些的内存，有一块是专门供Java程序创建对象使用的，这块内存在JVM中被称为堆(heap)。堆这个词快被用烂了，操作系统有堆的概念，C runtime也有，JVM里也有，然后还有一种数据结构也叫堆.<br>我们使用普通的ByteBuffer，那么这个ByteBuffer就会在Java堆内，被JVM所管理：</p><pre><code class="java">ByteBuffer buf = ByteBuffer.allocate(1024);</code></pre><p>在执行GC的时候，JVM实际上会做一些整理内存的工作，也就说buf这个对象在内存中的实际地址是会发生变化的。有些时候，ByteBuffer里都是大量的字节，这些字节在JVM GC整理内存时就显得很笨重，把它们在内存中拷来拷去显然不是一个好主意。<br>那这时候，我们就会想能不能给我一块内存，可以脱离JVM的管理呢？在这样的背景下，就有了DirectBuffer。先看一下用法：</p><pre><code class="java">ByteBuffer buf = ByteBuffer.allocateDirect(1024);</code></pre><p>这两个函数的实现是有区别的:</p><pre><code class="java">public static ByteBuffer allocateDirect(int capacity) {        return new DirectByteBuffer(capacity);    }    public static ByteBuffer allocate(int capacity) {        if (capacity &lt; 0)            throw new IllegalArgumentException();        return new HeapByteBuffer(capacity, capacity);    }</code></pre><p>DirectByteBuffer的核心就是调用了 unsafe.allocateMemory(size)方法。<br>Java对象在Java堆里申请内存的时候，实际上是比malloc要快的，所以DirectBuffer的创建效率往往是比Heap Buffer差的。<br>但是，如果进行网络读写或者文件读写的时候，DirectBuffer就会比较快了。 <strong>说起来好笑，这个快是因为JDK故意把非DirectBuffer的读写搞慢的，我们看一下JDK的源代码</strong>。<br>share/classes/sun/nio/ch/IOUtil.java</p><pre><code class="java">static int write(FileDescriptor fd, ByteBuffer src, long position,                     NativeDispatcher nd)         throws IOException    {           if (src instanceof DirectBuffer)            return writeFromNativeBuffer(fd, src, position, nd);        // Substitute a native buffer        int pos = src.position();        int lim = src.limit();        assert (pos &lt;= lim);        int rem = (pos &lt;= lim ? lim - pos : 0);         ByteBuffer bb = Util.getTemporaryDirectBuffer(rem);        try {            bb.put(src);            bb.flip();        // ................略</code></pre><p>如果src是DirectBuffer，就直接调用writeFromNativeBuffer，如果不是，则要先创建一个临时的DirectBuffer，把src拷进去，然后再调用真正的写操作。为什么要这么干呢？还是要从DirectBuffer不会被GC移动说起。writeFromNativeBuffer的实现，最终会把Buffer的address传给操作系统，让操作系统把address开始的那一段内存发送到网络上。这就要求在操作系统进行发送的时候，这块内存是不能动的(jni调用传递的是地址，地址不能乱动)。而我们知道，GC是会乱搬Java堆里的东西的，所以无奈，我们必须得弄一块地址不会变化的内存，然后把这个地址发给操作系统。</p><p>常用的ByteBuffer本质上是一个byte[]，包括这么几个变量<br>容量（Capacity） 缓冲区能够容纳的数据元素的最大数量。容量在缓冲区创建时被设定，并且永远不能被改变。<br>上界（Limit） 缓冲区里的数据的总数，代表了当前缓冲区中一共有多少数据。<br>位置（Position） 下一个要被读或写的元素的位置。Position会自动由相应的 get( )和 put( )函数更新。<br>标记（Mark） 一个备忘位置。用于记录上一次读写的位置。一会儿，我会通过reset方法来说明这个属性的含义。<br>ByteBuffer是一个抽象类，不能new出来</p><pre><code class="java">ByteBuffer byteBuffer = ByteBuffer.allocate(256);</code></pre><p>以上的语句可以创建一个大小为256字节的ByteBuffer，此时，mark = -1, pos = 0, limit = 256, capacity = 256。capacity在初始化的时候确定了，运行时就不会再变化了，而另外三个变量是随着程序的执行而不断变化的。</p><p>由于本质上就是一个byte[]，读数据的时候position放到0, limit放到当前已经存放的数据的位置，读完为止。写数据的时候也差不多，position放到当前已经存放的数据的curIndex+1，limit放到capicity的位置，填满为止。</p><p>从读变成写可以这么干</p><pre><code class="java">byteBuffer.limit(byteBuffer.position())byteBuffer.position(0);//由于这个方法实在太频繁,jdk就帮忙封装了一个叫做flip的方法public final Buffer flip() {        limit = position;        position = 0;        mark = -1;        return this;    }</code></pre><p>显然连续调用flip会导致limit变成0，不能读也不能写了。<br>mark方法类似于打一个标记，待会儿通过reset回到这个position。</p><h3 id="java的byte数组在内存层面不一定是连续的，C语言里面是连续的"><a href="#java的byte数组在内存层面不一定是连续的，C语言里面是连续的" class="headerlink" title="java的byte数组在内存层面不一定是连续的，C语言里面是连续的"></a>java的byte数组在内存层面不一定是连续的，C语言里面是连续的</h3><p>原因是GC会挪动内存，所以DirectByteBuffer存在的主要意义是为了给c语言层调用提供连续的内存。</p><h2 id="nio的channel"><a href="#nio的channel" class="headerlink" title="nio的channel"></a>nio的channel</h2><p>在Java IO中，基本上可以分为文件类和Stream类两大类。Channel 也相应地分为了FileChannel 和 Socket Channel，其中 socket channel 又分为三大类，一个是用于监听端口的ServerSocketChannel，第二类是用于TCP通信的SocketChannel，第三类是用于UDP通信的DatagramChannel。channel 最主要的作用还是用于非阻塞式读写。可以使用Channel结合ByteBuffer进行读写。<br>一个简单的client server echo程序可以这样写</p><pre><code class="java">// serverpublic class WebServer {    public static void main(String args[]) {        try {            ServerSocketChannel ssc = ServerSocketChannel.open();            ssc.socket().bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000));            SocketChannel socketChannel = ssc.accept();            ByteBuffer readBuffer = ByteBuffer.allocate(128);            socketChannel.read(readBuffer);            readBuffer.flip();            while (readBuffer.hasRemaining()) {                System.out.println((char)readBuffer.get());            }            socketChannel.close();            ssc.close();        }        catch (IOException e) {            e.printStackTrace();        }    }}// clientpublic class WebClient {    public static void main(String[] args) {        SocketChannel socketChannel = null;        try {            socketChannel = SocketChannel.open();            socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000));            ByteBuffer writeBuffer = ByteBuffer.allocate(128);            writeBuffer.put(&quot;hello world&quot;.getBytes());            writeBuffer.flip();            socketChannel.write(writeBuffer);            socketChannel.close();        } catch (IOException e) {        }    }}</code></pre><h3 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h3><p>java.nio.channels.Selector是一个抽象类，因为在不同的操作系统上的实现不一样。但基本原理是一样的，所有的Channel都由selector管理，用户层向selector注册感兴趣的IO动作，并通过selctor.select方法轮询IO事件。<br>java nio中主要的Channel的实现包括:</p><ul><li>FileChannel (处理文件io)</li><li>DatagramChannel (处理udp通信)</li><li>SocketChannel （通过tcp读取网络数据）</li><li>ServerSocketChannel(服务端接收传入的tcp数据)</li></ul><p>改进一下上面的WebClient和WebServer。</p><pre><code class="java">public class EpollServer {    public static void main(String[] args) {        try {            ServerSocketChannel ssc = ServerSocketChannel.open();            ssc.socket().bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 8001));            ssc.configureBlocking(false);            Selector selector = Selector.open();            // 注册 channel，并且指定感兴趣的事件是 Accept            ssc.register(selector, SelectionKey.OP_ACCEPT);            ByteBuffer readBuff = ByteBuffer.allocate(1024);            ByteBuffer writeBuff = ByteBuffer.allocate(128);            writeBuff.put(&quot;received&quot;.getBytes());            writeBuff.flip();            while (true) {                int nReady = selector.select();                Set&lt;SelectionKey&gt; keys = selector.selectedKeys();                Iterator&lt;SelectionKey&gt; it = keys.iterator();                while (it.hasNext()) {                    SelectionKey key = it.next();                    it.remove();                    if (key.isAcceptable()) {                        // 创建新的连接，并且把连接注册到selector上，而且，                        // 声明这个channel只对读操作感兴趣。                        SocketChannel socketChannel = ssc.accept();                        socketChannel.configureBlocking(false);                        socketChannel.register(selector, SelectionKey.OP_READ);                    }                    else if (key.isReadable()) {                        SocketChannel socketChannel = (SocketChannel) key.channel();                        readBuff.clear();                        socketChannel.read(readBuff);                        readBuff.flip();                        System.out.println(&quot;received : &quot; + new String(readBuff.array())+&quot; at &quot;+ System.currentTimeMillis());                        key.interestOps(SelectionKey.OP_WRITE);                    }                    else if (key.isWritable()) {                        writeBuff.rewind();                        SocketChannel socketChannel = (SocketChannel) key.channel();                        socketChannel.write(writeBuff);                        System.out.println(&quot;dispatched msg to client  : &quot; + new String(writeBuff.array())+&quot; at &quot;+ System.currentTimeMillis());                        key.interestOps(SelectionKey.OP_READ);                    }                }            }        } catch (IOException e) {            e.printStackTrace();        }    }}public class EpollClient {    public static void main(String[] args) {        try {            SocketChannel socketChannel = SocketChannel.open();            socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8001));            ByteBuffer writeBuffer = ByteBuffer.allocate(32);            ByteBuffer readBuffer = ByteBuffer.allocate(32);            writeBuffer.put(&quot;hello&quot;.getBytes());            writeBuffer.flip();            while (true) {                writeBuffer.rewind();                socketChannel.write(writeBuffer);                readBuffer.clear();                socketChannel.read(readBuffer);                System.out.println(&quot;received  from server :&quot; + new String(readBuffer.array()));            }        } catch (IOException e) {            e.printStackTrace();        }    }}    </code></pre><p>这套处理io事件的程序模型在python中也有对应的selector模块，使用方式也是相近的。因为无论是java还是python，都是对操作系统上的c语言api的select,poll,epoll系统调用进行了封装。SelectionKey类似于epoll中的一个事件，包括OP_READ，OP_WRITE，OP_ACCEPT和OP_CONNECT。事实上从openjdk源码来看，确实是对poll的封装</p><p>selctor在openjdk的实现是:<br>selctor.select -&gt; PollSelectorImpl.doSelect -&gt;  pollWrapper.poll -&gt; poll0</p><p>sun.nio.ch.PollArrayWrapper </p><pre><code class="java">private native int poll0(long pollAddress, int numfds, long timeout);</code></pre><p>对应的c语言实现在:<br>jdk8u-jdk/src/solaris/native/sun/nio/ch/PollArrayWrapper.c</p><pre><code class="c">#include &quot;jni.h&quot;#include &quot;jni_util.h&quot;#include &quot;jvm.h&quot;#include &quot;jlong.h&quot;#include &quot;sun_nio_ch_PollArrayWrapper.h&quot;#include &lt;poll.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/time.h&gt;JNIEXPORT jint JNICALLJava_sun_nio_ch_PollArrayWrapper_poll0(JNIEnv *env, jobject this,                                       jlong address, jint numfds,                                       jlong timeout){    struct pollfd *a;    int err = 0;    a = (struct pollfd *) jlong_to_ptr(address);    if (timeout &lt;= 0) {           /* Indefinite or no wait */        RESTARTABLE (poll(a, numfds, timeout), err); ## 就是调用了poll    } else {                     /* Bounded wait; bounded restarts */        err = ipoll(a, numfds, timeout);    }    if (err &lt; 0) {        JNU_ThrowIOExceptionWithLastError(env, &quot;Poll failed&quot;);    }    return (jint)err;}</code></pre><p>windows平台的实现是sun.nio.ch.WindowsSelectorImpl.java</p><h3 id="MMAP-memory-mapped-file"><a href="#MMAP-memory-mapped-file" class="headerlink" title="MMAP(memory mapped file)"></a>MMAP(memory mapped file)</h3><p>将文件映射到内存空间的操作，懒得看原理的话，背下这段话就够了</p><blockquote><p><strong>常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高</strong></p></blockquote><p>实际上,mmap系统调用并不是完全为了用于共享内存而设计的.它本身提供了不同于一般对普通文件的访问方式,是进程可以像读写内存一样对普通文件操作.而Posix或System V的共享内存则是纯粹用于共享内存的,当然mmap实现共享内存也是主要应用之一.<br>mmap函数是unix/linux下的系统调用，mmap系统调用并不是完全为了用于共享内存而设计的,mmap实现共享内存也是其主要作用之一，事实上可以实现两个java进程之间的通信。</p><p>A进程</p><pre><code class="java">public class Main {    public static void main(String args[]){        RandomAccessFile f = null;        try {            f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;);            FileChannel fc = f.getChannel();            MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, 20);            buf.put(&quot;how are you?&quot;.getBytes());            Thread.sleep(10000);            fc.close();            f.close();        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p>B进程</p><pre><code class="java">public class MapMemoryBuffer {    public static void main(String[] args) throws Exception {        RandomAccessFile f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;);        FileChannel fc = f.getChannel();        MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size());        while (buf.hasRemaining()) {            System.out.print((char)buf.get());        }        System.out.println();    }}</code></pre><p>很多java方法本质上就是jni进行了系统调用。<br>在sun.nio.ch.FileChannelImpl里有map的具体实现：</p><pre><code class="java">try {            // If no exception was thrown from map0, the address is valid            addr = map0(imode, mapPosition, mapSize);        } catch (OutOfMemoryError x) {private native long map0(int prot, long position, long length)</code></pre><p>比如Java的这个map0函数，具体的实现在<br>solaris/native/sun/nio/ch/FileChannelImpl.c这个文件里</p><pre><code class="c">JNIEXPORT jlong JNICALLJava_sun_nio_ch_FileChannelImpl_map0(JNIEnv *env, jobject this,                                     jint prot, jlong off, jlong len){    void *mapAddress = 0;    jobject fdo = (*env)-&gt;GetObjectField(env, this, chan_fd);    jint fd = fdval(env, fdo);    int protections = 0;    int flags = 0;    if (prot == sun_nio_ch_FileChannelImpl_MAP_RO) {        protections = PROT_READ;        flags = MAP_SHARED;    } else if (prot == sun_nio_ch_FileChannelImpl_MAP_RW) {        protections = PROT_WRITE | PROT_READ;        flags = MAP_SHARED;    } else if (prot == sun_nio_ch_FileChannelImpl_MAP_PV) {        protections =  PROT_WRITE | PROT_READ;        flags = MAP_PRIVATE;    }    mapAddress = mmap64(        0,                    /* Let OS decide location */        len,                  /* Number of bytes to map */        protections,          /* File permissions */        flags,                /* Changes are shared */        fd,                   /* File descriptor of mapped file */        off);                 /* Offset into file */    if (mapAddress == MAP_FAILED) {        if (errno == ENOMEM) {            JNU_ThrowOutOfMemoryError(env, &quot;Map failed&quot;);            return IOS_THROWN;        }        return handle(env, -1, &quot;Map failed&quot;);    }    return ((jlong) (unsigned long) mapAddress);}</code></pre><p>其实就是通过jni调用了c语言api.</p><p>jni可以做一些很有意思的事情<br>标准输入，标准输出，标准错误输出是所有操作系统都支持的，对于一个进程来说，文件描述符0,1,2固定是标准输入，标准输出，标准错误输出。</p><p>java语法中有一条是final的成员变量要么在声明的时候就初始化，要么在构造函数中就得初始化。在System这个class中，我们看到了使用jni强行修改final变量的做法（类似的情况在sun.nio.ch.IOUtil中也有，在static代码块中初始化一个final的int值）<br><a href="http://www.importnew.com/28981.html">JDK 源码阅读 : FileDescriptor</a>文中提到:</p><blockquote><p>System作为一个特殊的类，类构造时无法实例化in/out/err，构造发生在initializeSystemClass被调用时，但是in/out/err是被声明为final的，如果声明时和类构造时没有赋值，是会报错的，所以System在实现时，先设置为null，然后通过native方法来在运行时修改（学到了不少奇技淫巧。。），通过setIn0/setOut0/setErr0的注释也可以说明这一点：</p></blockquote><pre><code class="java">public final class System {    public final static InputStream in = null;    public final static PrintStream out = null;    public final static PrintStream err = null;    /**    * Initialize the system class.  Called after thread initialization.    */    private static void initializeSystemClass() {        FileInputStream fdIn = new FileInputStream(FileDescriptor.in);        FileOutputStream fdOut = new FileOutputStream(FileDescriptor.out);        FileOutputStream fdErr = new FileOutputStream(FileDescriptor.err);        setIn0(new BufferedInputStream(fdIn));        setOut0(newPrintStream(fdOut, props.getProperty(&quot;sun.stdout.encoding&quot;)));        setErr0(newPrintStream(fdErr, props.getProperty(&quot;sun.stderr.encoding&quot;)));    }    private static native void setIn0(InputStream in);    private static native void setOut0(PrintStream out);    private static native void setErr0(PrintStream err);}</code></pre><pre><code class="c">/* * The following three functions implement setter methods for * java.lang.System.{in, out, err}. They are natively implemented * because they violate the semantics of the language (i.e. set final * variable). */JNIEXPORT void JNICALLJava_java_lang_System_setIn0(JNIEnv *env, jclass cla, jobject stream){    jfieldID fid =        (*env)-&gt;GetStaticFieldID(env,cla,&quot;in&quot;,&quot;Ljava/io/InputStream;&quot;);    if (fid == 0)        return;    (*env)-&gt;SetStaticObjectField(env,cla,fid,stream);}JNIEXPORT void JNICALLJava_java_lang_System_setOut0(JNIEnv *env, jclass cla, jobject stream){    jfieldID fid =        (*env)-&gt;GetStaticFieldID(env,cla,&quot;out&quot;,&quot;Ljava/io/PrintStream;&quot;);    if (fid == 0)        return;    (*env)-&gt;SetStaticObjectField(env,cla,fid,stream);}JNIEXPORT void JNICALLJava_java_lang_System_setErr0(JNIEnv *env, jclass cla, jobject stream){    jfieldID fid =        (*env)-&gt;GetStaticFieldID(env,cla,&quot;err&quot;,&quot;Ljava/io/PrintStream;&quot;);    if (fid == 0)        return;    (*env)-&gt;SetStaticObjectField(env,cla,fid,stream);}</code></pre><p>这篇文章还指出了:</p><blockquote><p>尝试关闭0，1，2文件描述符，需要特殊的操作。首先这三个是不能关闭的，<br>如果关闭了，后续打开的文件就会占用这三个描述符，</p></blockquote><pre><code class="c">// /jdk/src/solaris/native/java/io/FileInputStream_md.cJNIEXPORT void JNICALLJava_java_io_FileInputStream_close0(JNIEnv *env, jobject this) {    fileClose(env, this, fis_fd);}// /jdk/src/solaris/native/java/io/io_util_md.cvoid fileClose(JNIEnv *env, jobject this, jfieldID fid){    FD fd = GET_FD(this, fid);    if (fd == -1) {        return;    }    /* Set the fd to -1 before closing it so that the timing window     * of other threads using the wrong fd (closed but recycled fd,     * that gets re-opened with some other filename) is reduced.     * Practically the chance of its occurance is low, however, we are     * taking extra precaution over here.     */    SET_FD(this, -1, fid);    // 尝试关闭0，1，2文件描述符，需要特殊的操作。首先这三个是不能关闭的，    // 如果关闭的，后续打开的文件就会占用这三个描述符，    // 所以合理的做法是把要关闭的描述符指向/dev/null，实现关闭的效果    // 不过Java代码中，正常是没办法关闭0，1，2文件描述符的    if (fd &gt;= STDIN_FILENO &amp;&amp; fd &lt;= STDERR_FILENO) {        int devnull = open(&quot;/dev/null&quot;, O_WRONLY);        if (devnull &lt; 0) {            SET_FD(this, fd, fid); // restore fd            JNU_ThrowIOExceptionWithLastError(env, &quot;open /dev/null failed&quot;);        } else {            dup2(devnull, fd);            close(devnull);        }    } else if (close(fd) == -1) { // 关闭非0，1，2的文件描述符只是调用close系统调用        JNU_ThrowIOExceptionWithLastError(env, &quot;close failed&quot;);    }}</code></pre><p><a href="https://www.zhihu.com/question/60892134/answer/191781461">知乎上关于DirectByteBuffer的讨论</a></p><blockquote><p>整个JVM都是运行在用户空间上的，不存在内核空间的分配。Java NIO 的IO读写如果不是directbuffer就把数据copy的临时的directbuffer中再做IO读写。所以直接使用directbuffer会节省内存copy次数，这是JavaNIO框架具体实现方式的限制，不好称之为“优势”。JavaNIO使用directbuffer进行IO读写的原因主要是在GC优化上。jvm并不是不能直接用java heapbuffer或java byte[]直接做IO读写，但会mark此段内存不能移动，从而影响GC效率。但是JavaNIO框架里的IO操作都是非阻塞模式的快速操作，究竟能影响多少GC效率还不能轻易下结论。JavaNIO的高效主要体现在相对java bio在管理大量连接时少使用了很多线程而节省的线程资源和线程切换，但其编程模型比BIO要复杂得多，只能说NIO高效，不好说它“高级”。对于客户端使用少量连接时，BIO比NIO更有优势，不但编程模型简单，IO效率也不比NIO差。directbuffer本身也是一个内存隐患，使用directbuffer并不能像heapbuffer或byte[]一样任意使用可以被GC及时的回收。所以使用directbuffer最好是分配好缓存起来重复使用，否则很容易出现OOM错误。</p></blockquote><p>DirectByteBuffer这个对象占用的内存是放在java heap上的，这部分没多少，但是其分配的native内存(也就是放在C语言的heap上的)是占主要大小的。这部分的释放使用了PhantomReference追踪DirectByteBuffer被加入到ReferenceQueue的时候就会开始运行一个runnbale，这里面去调用jni方法释放内存。</p><h3 id="FileChannel的几个重要方法"><a href="#FileChannel的几个重要方法" class="headerlink" title="FileChannel的几个重要方法"></a>FileChannel的几个重要方法</h3><p>直接上一个用FileChannel读取文件的代码</p><pre><code class="java">RandomAccessFile aFile = new RandomAccessFile(&quot;/tmp/sample.txt&quot;, &quot;rw&quot;);FileChannel inChannel = aFile.getChannel();ByteBuffer buf = ByteBuffer.allocate(48);int bytesRead = inChannel.read(buf);while (bytesRead != -1) {  System.out.println(&quot;Read &quot; + bytesRead);  buf.flip();  while(buf.hasRemaining()){    System.out.print((char) buf.get());  }  buf.clear();  bytesRead = inChannel.read(buf);}aFile.close();</code></pre><h2 id="3-从opnjdk的C语言实现来看jvm对system-call的选择"><a href="#3-从opnjdk的C语言实现来看jvm对system-call的选择" class="headerlink" title="3. 从opnjdk的C语言实现来看jvm对system call的选择"></a>3. 从opnjdk的C语言实现来看jvm对system call的选择</h2><p><a href="https://www.youtube.com/watch?v=MSYbEQLm8ww">Java File I/O大混战</a> 这篇youtube上的演讲从jdk对system call调用的选择来看分析了各自的效率<br>FileChannel.transferTo方法会根据host machine的操作系统选择文件操作的system call方案:<br>速度和效率也是依次降低</p><ol><li>sendFile（linux kernel 2.4+支持，data copy使用磁盘DMA engine，不消耗cpu，即所谓zero copy）</li><li>mmap</li><li>read(最慢)</li></ol><p><a href="https://github.com/AdoptOpenJDK/openjdk-jdk8u/blob/master/jdk/src/share/classes/sun/nio/ch/FileChannelImpl.java">上面这段话的代码实例在FileChannelImpl.java这个文件中</a></p><pre><code class="java">public long transferTo(long position, long count,                           WritableByteChannel target)        throws IOException{            // Attempt a direct transfer, if the kernel supports it    if ((n = transferToDirectly(position, icount, target)) &gt;= 0)        return n;    // Attempt a mapped transfer, but only to trusted channel types    if ((n = transferToTrustedChannel(position, icount, target)) &gt;= 0)        return n;    // Slow path for untrusted targets    return transferToArbitraryChannel(position, icount, target);}</code></pre><p><a href="https://xunnanxu.github.io/2016/09/10/It-s-all-about-buffers-zero-copy-mmap-and-Java-NIO/">zero copy技术</a></p><h2 id="4-java-nio介绍"><a href="#4-java-nio介绍" class="headerlink" title="4. java nio介绍"></a>4. java nio介绍</h2><p><a href="https://www.zfl9.com/java-nio.html#more">java nio介绍</a> 文章写的非常好<br>java io的发展经历了三个阶段</p><ol><li>io/bio 即java.io.*，面向流，阻塞io，逐个字节的读写，没有相应的缓冲（除了bufferd），效率较低</li><li>nio ，java.nio.<em> 面向缓冲区，阻塞/非阻塞，包含Buffer,Channel,Selector<br>3 .aio/nio.2,  java.nio.channels.Asynchronous</em>,异步IO、阻塞IO、由ThreadPool线程池实现，每个异步IO Channel都属于某个AsynchronousChannelGroup，而每个AsynchronousChannelGroup都与一个ThreadPool相关联。</li></ol><p>BIO、NIO、AIO 适用场景分析：<br>1) BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4 以前的唯一选择，但程序直观简单易理解。<br>2) NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4 开始支持。<br>3) AIO方式适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用 OS 参与并发操作，编程比较复杂，JDK1.7 开始支持。</p><p>linux下提供五种io model（这个主要是针对socket来讲的，本地File读取都是阻塞的，不要想太多）</p><ol><li>同步IO(synchronous IO)</li><li>阻塞IO(bloking IO)</li><li>非阻塞IO(non-blocking IO)</li><li>多路复用IO(multiplexing IO)</li><li>信号驱动式IO(signal-driven IO) 这种用的不多<br>异步IO(asynchronous IO)<br>具体的介绍看这篇文章:<a href="http://cmsblogs.com/?p=4812">五种io模式的介绍</a></li></ol><p>这里要声明，io操作可以简单的分为三类：</p><ol><li>内存io，直接对byte[]数组进行操作，效率非常高，也不存在什么阻塞的问题</li><li>文件io，FileInputStream,RamdomAccessFile这些东西，<strong>这个跟上面5种model没有太大关系</strong>，并且只能运行在阻塞模式。java的FileChannel只能是阻塞式的。</li><li>socket io ,比如说ServerSocket，DatagramSocket这种，这也是Java NIO 的主要研究对象，有阻塞模式、非阻塞模式，默认为阻塞模式。</li></ol><p>对于Socket的读(recv)和写(send)操作来说,主要有两个阶段，以recv()为例：<br>(1) 等待数据准备，通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区(tcp buffer之类的)<br>(2) 将数据从内核空间来拷贝到进程空间，将接收到的数据从内核缓冲区复制到应用进程的缓冲区（调用者提供的字节数组）<br>分别对上面四种（信号驱动式IO用的不多，不介绍了）</p><ul><li>对于<strong>同步阻塞IO</strong>来说，这两个阶段都是阻塞的</li><li>对于<strong>同步非阻塞IO</strong>来说，当socket接收缓冲区没有数据时，recv会立刻返回一个特定的状态值，表示现在没有数据，待会再来吧。当socket接收缓冲区有数据的时候，recv将数据拷贝到进程空间的这个过程，也是阻塞的。通常采用轮训polling的方式，循环往复的主动询问内核有没有数据可以读取。实际上，这样的轮询其实还不阻塞IO的性能好。只有第一步是非阻塞的，第二步还是阻塞的</li><li>对于<strong>多路复用IO</strong>来说，它的优势是可以调用select、poll、epoll这些操作系统级别的系统调用，同时轮训多个socket连接。当调用select、poll、epoll的时候，如果所监控的socket中有部分socket可读，可写或者连接上的时候，就会返回，将其返回给用户进程来处理，这个过程是阻塞的。只不过是因为select、poll、epoll系统调用而阻塞的；<br>当系统调用返回后，用户进程再调用recv，将数据从内核拷贝到进程空间中，这个过程也是阻塞的。事实上这个方式比第二种还差些，因为这里包含了两个系统调用(select/poll/epoll、recv)，而第二种只有一个系统调用recv。但是这种方式的优势是可以处理更多的连接。连接数大的时候，缺点就被优点给掩盖了。<br>IO多路复用相比多进程/多线程+ 阻塞IO的系统开销小，因为系统不需要创建新的进程或者线程，也不需要维护多个进程，线程的执行。对于多路复用IO来说，第一个阶段是因为select、poll、epoll而阻塞的，第二个阶段(recv)依旧是阻塞的。</li><li>对于<strong>异步IO</strong>来说，两个阶段都没有被阻塞，因为只需要发起rec、send请求，系统会帮忙完成数据的copy，完事之后通知用户进程一声。</li></ul><p>异步操作(asynchronous IO)的本质<br>所有的程序最终都会由计算机硬件来执行，所以为了更好的理解异步操作的本质，我们有必要了解一下它的硬件基础。<br>熟悉电脑硬件的朋友肯定对 DMA 这个词不陌生，硬盘、光驱的技术规格中都有明确 DMA 的模式指标，其实网卡、声卡、显卡也是有 DMA 功能的。<br>DMA 就是直接内存访问的意思，也就是说，拥有 DMA 功能的硬件在和内存进行数据交换的时候可以不消耗 CPU 资源。只要 CPU 在发起数据传输时发送一个指令，硬件就开始自己和内存交换数据，在传输完成之后硬件会触发一个中断来通知操作完成。<br>这些无须消耗 CPU 时间的 I/O 操作正是异步操作的硬件基础。所以即使在 DOS 这样的单进程（而且无线程概念）系统中也同样可以发起异步的 DMA 操作。</p><p>线程的本质<br>线程不是一个计算机硬件的功能，而是操作系统提供的一种逻辑功能，线程本质上是进程中一段并发运行的代码，所以线程需要操作系统投入 CPU 资源来运行和调度。<br>linux下有一条命令可以查看当前进程下有多少个线程：<br>ps –o nlwp pid ## nlwp含义是number of light-weight process。<br>ps -eLo pid ,stat | grep pid | grep running | wc -l</p><p>nio中的几个主要概念<br><strong>channel</strong> 和jdk1.4之前的bio的”将io抽象为流”的概念是差不多的，只不过流是单向的，channel是双向的<br><strong>Buffer</strong> 就是对数组的封装<br><strong>Selector</strong> 对select、poll、epoll系统调用的包装，用于Socket channel，因为它要求channel必须是非阻塞的</p><p>bio是没有缓冲区的（BufferedInputStream,BufferedReader这种除外），包括RandomAccessFile也没有缓冲区<br>Nio都是有缓冲区的，必须和Buffer对象一起使用，Buffer对象就是缓冲区。</p><p>ByteBuffer是唯一直接与channel交互的缓冲，因为所有的数据都是以二进制形式存在的<br>在 BIO 中，与文件 IO 相关联的三个类是：<br>1) java.io.FileInputStream，从文件流中读取字节数据，只读；<br>2) java.io.FileOutputStream，向文件流中写入字节数据，只写；<br>3) java.io.RandomAccessFile，独立的IO流类，支持r只读、rw读写、rws读写 + metadata/data自动同步、rwd读写 + data自动同步四种模式；</p><p>为了迎合 NIO，这几个类都进行修改，加入了getChannel()方法，获取对应的FileChannel对象，提供高效率的 I/O 操作；<br>但是 NIO 并未给 FileChannel 提供非阻塞支持，FileChannel 只能运行在阻塞模式下，但是效率依旧比 BIO 高，因为有 Buffer 啊；</p><p>而java.net包中的三个 Socket 类：<br>1) java.net.ServerSocket：TCP Socket，Server端；<br>2) java.net.Socket：TCP Socket；<br>3) java.net.DatagramSocket：UDP Socket；</p><p>这几个类其实也定义了一个getChannel()方法，但是默认只能返回null，需要显式的 open() 对应的 SocketChannel 通道。</p><p>Channel通道,java.nio.channels包，主要有：FileChannel、ServerSocketChannel、SocketChannel、DatagramChannel</p><h3 id="FileChannel"><a href="#FileChannel" class="headerlink" title="FileChannel"></a>FileChannel</h3><pre><code class="java">import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.RandomAccessFile;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;public class FileChannelDemo {    public static void main(String[] args) throws IOException {        FileChannel fc = null;        fc = new FileOutputStream(&quot;data.txt&quot;).getChannel();        fc.write(ByteBuffer.wrap(&quot;www.baidu.com\n&quot;.getBytes()));        fc.close();        fc = new RandomAccessFile(&quot;data.txt&quot;, &quot;rw&quot;).getChannel();        fc.position(fc.size());        fc.write(ByteBuffer.wrap(&quot;www.google.com\n&quot;.getBytes()));        fc.close();        fc = new FileInputStream(&quot;data.txt&quot;).getChannel();        ByteBuffer buf = ByteBuffer.allocate(1024 * 4);        fc.read(buf);        buf.flip();        while (buf.hasRemaining()) {            System.out.print((char)buf.get());        }        // or        System.out.println();        buf.rewind();        System.out.print(new String(buf.array(), 0, buf.remaining()));        fc.close();    }}</code></pre><p>或者</p><pre><code class="java">import java.nio.channels.FileChannel;import java.nio.ByteBuffer;import java.nio.file.Path;import java.nio.file.Paths;import java.nio.file.StandardOpenOption;import java.io.IOException;public class FileChannelOpen {    private static Path path = Paths.get(&quot;test.txt&quot;);    private static final int BUF_SIZE = 1024 * 4;    public static void main(String[] args)        throws IOException    {        FileChannel fc = FileChannel.open(path, // 文件路径                                          StandardOpenOption.READ, // r                                          StandardOpenOption.WRITE, // w                                          StandardOpenOption.CREATE, // 不存在时新建                                          StandardOpenOption.TRUNCATE_EXISTING); // 清空原有内容        ByteBuffer buf = ByteBuffer.allocate(BUF_SIZE);        buf.put(args.length == 0 ?                &quot;default-file-content\n&quot;.getBytes() :                args[0].getBytes());        fc.write((ByteBuffer)buf.flip());        fc.position(0).read((ByteBuffer)buf.clear());        System.out.print(new String(buf.array(), 0, buf.flip().remaining()));        fc.close();    }}</code></pre><p>transferTo，最快速的文件复制的方法</p><pre><code>import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.nio.channels.FileChannel;public class FileCopy2 {    public static void main(String[] args) throws IOException {        if (args.length &lt; 2) {            System.err.println(&quot;Usage: FileCopy2 &lt;src_file&gt; &lt;dst_file&gt;&quot;);            System.exit(1);        }        FileChannel            in = new FileInputStream(args[0]).getChannel(),            out = new FileOutputStream(args[1]).getChannel();        in.transferTo(0, in.size(), out);        // or:        // out.transferFrom(in, 0, in.size());        in.close();        out.close();    }}</code></pre><p>接下来介绍，SelectableChannel，主要包括ServerSocketChannel，SocketChannel以及DatagramChannel</p><h3 id="SocketChannel和-ServerSocketChannel"><a href="#SocketChannel和-ServerSocketChannel" class="headerlink" title="SocketChannel和 ServerSocketChannel"></a>SocketChannel和 ServerSocketChannel</h3><pre><code class="java">import java.nio.ByteBuffer;import java.nio.charset.Charset;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.net.StandardSocketOptions;import java.net.InetSocketAddress;import java.io.IOException;public class Server {    private static ServerSocketChannel servChannel;    private static final InetSocketAddress BIND_ADDR = new InetSocketAddress(&quot;0.0.0.0&quot;, 8080);    private static final int BACKLOG = 128;    private static final int BUF_SIZE = 1024;    public static void main(String[] args) throws IOException {        // 注册 shutdown hook 钩子, 关闭 servChannel        Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() {            @Override            public void run() {                try {                    servChannel.close();                } catch (IOException e) {}            }        }));        servChannel = ServerSocketChannel.open();        servChannel.setOption(StandardSocketOptions.SO_REUSEADDR, true);        servChannel.bind(BIND_ADDR, BACKLOG);        System.out.printf(&quot;----- listen: %s:%d -----\n&quot;,                          BIND_ADDR.getAddress().getHostAddress(),                          BIND_ADDR.getPort());        SocketChannel connChannel = null;        while (true) {            connChannel = servChannel.accept();            service(connChannel);        }    }    private static void service(SocketChannel connChannel) throws IOException {        InetSocketAddress remoteAddr = (InetSocketAddress) connChannel.getRemoteAddress();        System.out.printf(&quot;new Connect: %s:%d\n&quot;,                          remoteAddr.getAddress().getHostAddress(),                          remoteAddr.getPort());        ByteBuffer buf = ByteBuffer.allocate(BUF_SIZE);        while (connChannel.read((ByteBuffer)buf.clear()) != -1) {            System.out.printf(&quot;msg: %s\n&quot;, Charset.forName(&quot;UTF-8&quot;).decode((ByteBuffer)buf.flip()));            connChannel.write((ByteBuffer)buf.rewind());        }        System.out.printf(&quot;close Connect: %s:%d\n&quot;,                          remoteAddr.getAddress().getHostAddress(),                          remoteAddr.getPort());        connChannel.close();    }}public class Client2 {    private static final InetSocketAddress SERV_ADDR = new InetSocketAddress(&quot;127.0.0.1&quot;, 8081);    private static final int BUF_SIZE = 1024;    public static void main(String[] args) throws IOException {        SocketChannel sockChannel = SocketChannel.open();        sockChannel.setOption(StandardSocketOptions.SO_REUSEADDR, true);        sockChannel.connect(SERV_ADDR);        ByteBuffer buf = ByteBuffer.allocate(BUF_SIZE);        if (args.length == 0) {            buf.put(&quot;default-message&quot;.getBytes(&quot;UTF-8&quot;));            sockChannel.write((ByteBuffer)buf.flip());            sockChannel.read((ByteBuffer)buf.clear());            System.out.printf(&quot;msg: %s\n&quot;, Charset.forName(&quot;UTF-8&quot;).decode((ByteBuffer)buf.flip()));        }        for (String s : args) {            ((ByteBuffer)buf.clear()).put(s.getBytes(&quot;UTF-8&quot;));            sockChannel.write((ByteBuffer)buf.flip());            sockChannel.read((ByteBuffer)buf.clear());            System.out.printf(&quot;msg: %s\n&quot;, Charset.forName(&quot;UTF-8&quot;).decode((ByteBuffer)buf.flip()));        }        sockChannel.close();    }}</code></pre><h3 id="DatagramChannel"><a href="#DatagramChannel" class="headerlink" title="DatagramChannel"></a>DatagramChannel</h3><p>这个主要是udp了</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>不要迷信nio：</p><ol><li>DirectByteBuffer的本意并不是为了减少内存拷贝(而是为了固定内存地址)，DirectByteBuffer的回收机制比较重要，因为万一发生堆外内存泄露是比较严重的。</li><li>不要动不动就mmap，mmap在读写大文件的时候才体现出明显的优势</li><li>使用transferTo和transferFrom（会按照sendfile,mmap,bio的顺序查看当前系统支持哪个）</li><li>nio是直接和byte打交道，java的内码是utf-16BE（为毛c语言只要1个byte，java一个char却要2个byte,因为方便啊，虽然浪费点内存，但是所有的字符，不管是英文，拉丁文，中文，阿拉伯文，2个字节，2^16,unicode也没有这么多吧。相应的,1个字符的c语言的char就不能那么方便的存储中文了。）</li><li>java的很多api是直接对c语言的api的包装，java.io.RandomAccessFile，独立的IO流类，支持r只读、rw读写、rws读写 + metadata/data自动同步、rwd读写 + data自动同步四种模式。猜测和fsync和fsyncdata有关。</li><li>ByteOrder，字节序。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/23488863">美团团队出的关于nio的解说</a><br><a href="https://www.zfl9.com/java-nio.html#more">java nio</a> 作者的文章条理很清晰。<br>这里面有一句原话摘抄下来：</p><blockquote><p>线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。像Java的线程栈，一般至少分配512K～1M的空间，</p></blockquote><p>这个值(jvm创建一条线程时为其分配的call stack size)其实是可配置的，-XX:ThreadStackSize(默认是1M，也就是创建一条线程至少要占用1M的内存)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于java nio的一些点&lt;br&gt;&lt;img src=&quot;https://www.haldir66.ga/static/imgs/UmbriaCastelluccio_EN-AU8834990889_1920x1080.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="tbd" scheme="https://haldir65.github.io/tags/tbd/"/>
    
  </entry>
  
</feed>
